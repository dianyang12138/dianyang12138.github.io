{"meta":{"title":"dian的博客","subtitle":"","description":"后端Java工程师","author":"dian","url":"http://example.com","root":"/"},"pages":[],"posts":[{"title":"Redis","slug":"Redis","date":"2021-07-06T08:18:27.000Z","updated":"2021-07-08T09:03:34.654Z","comments":true,"path":"2021/07/06/Redis/","link":"","permalink":"http://example.com/2021/07/06/Redis/","excerpt":"","text":"基本操作clear：清屏 help 命令名称：帮助信息 help @组名：帮助信息 退出：quit、exit、&lt; ESC&gt; 数据存储 redis自身是一个Map,其中所有的数据都是采用key:value的形式存储 数据类型指的是存储的数据的类型，也就是value部分的类型，key部分永远都是字符串 String通常使用字符串，如果字符串以整数的形式展示，可以作为数字操作使用 基本操作 添加/修改数据：set key value 获取数据：get key 删除数据：del key 添加/修改多个数据：mset key1 valueq key2 value2 … 获取多个数据：mget key1 key2 … 获取数据字符个数（字符串长度）：strlen key 追加信息到原始信息后部（如果原始信息存在就追加，否则新建）：append key value 做数值增加 incr key：对该key的值+1 incrby key increment：该key的值+指定整数 incrbyfloat key increment：该key的值+浮点数 数值减 decr key：减一 decrby key increment减指定数值 redis用于控制数据库表主键id，为数据库表主键提供生成策略，保障数据库表的主键 此方案适用于所有数据库，且支持数据库集群 时效性设置1234&#x2F;&#x2F;设置数据的生命周期，单位 秒setex key seconds value&#x2F;&#x2F;设置数据的生命周期，单位 毫秒psetex key milliseconds value Hash类似hashMap field为属性 基本操作1234567891011121314151617181920212223242526&#x2F;&#x2F;插入（如果已存在同名的field，会被覆盖）hset key field valuehmset key field1 value1 field2 value2...&#x2F;&#x2F;插入（如果已存在同名的field，不会被覆盖）hsetnx key field value&#x2F;&#x2F;取出hget key fieldhgetall key&#x2F;&#x2F;删除hdel key field1 field2...&#x2F;&#x2F;获取field数量hlen key&#x2F;&#x2F;查看是否存在hexists key field&#x2F;&#x2F;获取哈希表中所有的字段名或字段值 hkeys keyhvals key&#x2F;&#x2F;设置指定字段的数值数据增加指定范围的值 hincrby key field increment hdecrby key field increment hash类型下的value只能存储字符串，不允许存储其他数据类型，不存在嵌套现象。如果数据未获取到， 对应的值为（nil） 每个 hash 可以存储 2^32 - 1 个键值 hash类型十分贴近对象的数据存储形式，并且可以灵活添加删除对象属性。但hash设计初衷不是为了存储大量对象而设计的，切记不可滥用，更不可以将hash作为对象列表使用 hgetall 操作可以获取全部属性，如果内部field过多，遍历整体数据效率就很会低，有可能成为数据访问瓶颈 Listlist类型：保存多个数据，底层使用双向链表存储结构实现 元素有序，且可重 基本操作123456789101112131415&#x2F;&#x2F;添加修改数据,lpush为从左边添加，rpush为从右边添加lpush key value1 value2 value3...rpush key value1 value2 value3...&#x2F;&#x2F;查看数据, 从左边开始向右查看. 如果不知道list有多少个元素，end的值可以为-1,代表倒数第一个元素&#x2F;&#x2F;lpush先进的元素放在最后,rpush先进的元素放在最前面lrange key start end&#x2F;&#x2F;得到长度llen key&#x2F;&#x2F;取出对应索引的元素lindex key index&#x2F;&#x2F;获取并移除元素（从list左边或者右边移除）lpop keyrpop key 扩展操作123456&#x2F;&#x2F;规定时间内获取并移除数据,b&#x3D;block,给定一个时间，如果在指定时间内放入了元素，就移除blpop key1 key2... timeoutbrpop key1 key2... timeout&#x2F;&#x2F;移除指定元素 count:移除的个数 value:移除的值。 移除多个相同元素时，从左边开始移除lrem key count value list中保存的数据都是string类型的，数据总容量是有限的，最多2^32 - 1 个元素 (4294967295)。 list具有索引的概念，但是操作数据时通常以队列的形式进行入队出队(rpush, rpop)操作，或以栈的形式进行入栈出栈(lpush, lpop)操作 获取全部数据操作结束索引设置为-1 (倒数第一个元素) list可以对数据进行分页操作，通常第一页的信息来自于list，第2页及更多的信息通过数据库的形式加载 Set不重复无序数据 基本操作1234567891011121314&#x2F;&#x2F;添加元素sadd key member1 member2...&#x2F;&#x2F;查看元素smembers key&#x2F;&#x2F;移除元素srem key member&#x2F;&#x2F;查看元素个数scard key&#x2F;&#x2F;查看某个元素是否存在sismember key member 扩展操作123456789101112131415161718&#x2F;&#x2F;从set中任意选出count个元素srandmember key count&#x2F;&#x2F;从set中任意选出count个元素并移除spop key count&#x2F;&#x2F;求两个集合的交集、并集、差集sinter key1 key2...sunion key1 key2...sdiff key1 key2...&#x2F;&#x2F;求两个set的交集、并集、差集，并放入另一个set中sinterstore destination key1 key2...sunionstore destination key1 key2...sdiffstore destination key1 key2...&#x2F;&#x2F;求指定元素从原集合放入目标集合中smove source destination key sorted_set 不重但有序（score） 新的存储需求：数据排序有利于数据的有效展示，需要提供一种可以根据自身特征进行排序的方式 需要的存储结构：新的存储模型，可以保存可排序的数据 sorted_set类型：在set的存储结构基础上添加可排序字段 基本操作1234567891011121314151617181920212223242526272829303132&#x2F;&#x2F;插入元素, 需要指定score(用于排序)zadd key score1 member1 score2 member2&#x2F;&#x2F;查看元素(score升序), 当末尾添加withscore时，会将元素的score一起打印出来zrange key start end (withscore)&#x2F;&#x2F;查看元素(score降序), 当末尾添加withscore时，会将元素的score一起打印出来zrevrange key start end (withscore)&#x2F;&#x2F;移除元素zrem key member1 member2...&#x2F;&#x2F;按条件获取数据, 其中offset为索引开始位置，count为获取的数目zrangebyscore key min max [withscore] [limit offset count]zrevrangebyscore key max min [withscore] [limit offset count]&#x2F;&#x2F;按条件移除元素zremrangebyrank key start endzremrangebysocre key min max&#x2F;&#x2F;按照从大到小的顺序移除count个值zpopmax key [count]&#x2F;&#x2F;按照从小到大的顺序移除count个值zpopmin key [count]&#x2F;&#x2F;获得元素个数zcard key&#x2F;&#x2F;获得元素在范围内的个数zcount min max&#x2F;&#x2F;求交集、并集并放入destination中, 其中numkey1为要去交集或并集集合的数目zinterstore destination numkeys key1 key2...zunionstore destination numkeys key1 key2... min与max用于限定搜索查询的条件 start与stop用于限定查询范围，作用于索引，表示开始和结束索引 offset与count用于限定查询范围，作用于查询结果，表示开始位置和数据总量 扩展操作12345678&#x2F;&#x2F;查看某个元素的索引(排名)zrank key memberzrevrank key member&#x2F;&#x2F;查看某个元素索引的值zscore key member&#x2F;&#x2F;增加某个元素索引的值zincrby key increment member score保存的数据存储空间是64位，如果是整数范围是-9007199254740992~9007199254740992 score保存的数据也可以是一个双精度的double值，基于双精度浮点数的特征，可能会丢失精度，使用时候要慎重 sorted_set 底层存储还是基于set结构的，因此数据不能重复，如果重复添加相同的数据，score值将被反复覆盖，保留最后一次修改的结果 通用指令Key的操作基本操作12345678&#x2F;&#x2F;查看key是否存在exists key&#x2F;&#x2F;删除keydel key&#x2F;&#x2F;查看key的类型type key 拓展操作（时效性操作）12345678910&#x2F;&#x2F;设置生命周期expire key secondspexpire key milliseconds&#x2F;&#x2F;查看有效时间, 如果有有效时间则返回剩余有效时间, 如果为永久有效，则返回-1, 如果Key不存在则返回-2ttl keypttl key&#x2F;&#x2F;将有时限的数据设置为永久有效persist key 拓展操作（查询操作）12&#x2F;&#x2F;根据key查询符合条件的数据keys pattern 查询规则 *：匹配任意数量字符 ?：匹配单个字符 []：匹配一个指定字符 拓展操作（其他操作）123456&#x2F;&#x2F;重命名key，为了避免覆盖已有数据，尽量少去修改已有key的名字，如果要使用最好使用renamenxrename key newKeyrenamenx key newKey&#x2F;&#x2F;查看所有关于key的操作, 可以使用Tab快速切换help @generic 数据库通用操作 Redis为每个服务提供有16个数据库，编号从0到15 每个数据库之间的数据相互独立 基本操作1234567&#x2F;&#x2F;切换数据库 0~15select index&#x2F;&#x2F;其他操作quitpingecho massage 拓展操作12345&#x2F;&#x2F;移动数据, 必须保证目的数据库中没有该数据mov key db&#x2F;&#x2F;查看该库中数据总量dbsize https://nyimac.gitee.io/2020/06/07/Redis%E5%AD%A6%E4%B9%A0%E6%96%87%E6%A1%A3/#string-%E7%B1%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E6%89%A9%E5%B1%95%E6%93%8D%E4%BD%9C","categories":[],"tags":[{"name":"后端","slug":"后端","permalink":"http://example.com/tags/%E5%90%8E%E7%AB%AF/"},{"name":"redis","slug":"redis","permalink":"http://example.com/tags/redis/"}]},{"title":"Git笔记","slug":"Java并发编程","date":"2021-05-24T06:21:23.000Z","updated":"2021-07-08T08:55:52.838Z","comments":true,"path":"2021/05/24/Java并发编程/","link":"","permalink":"http://example.com/2021/05/24/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/","excerpt":"","text":"线程与进程线程与进程对比 进程基本上相互独立的，而线程存在于进程内，是进程的一个子集 进程拥有共享的资源，如内存空间等，供其内部的线程共享 进程间通信较为复杂 同一台计算机的进程通信称为 IPC（Inter-process communication） 不同计算机之间的进程通信，需要通过网络，并遵守共同的协议，例如 HTTP 线程通信相对简单，因为它们共享进程内的内存，一个例子是多个线程可以访问同一个共享变量 线程更轻量，线程上下文切换成本一般上要比进程上下文切换低 异步与同步 从方法调用来说： 需要等待结果返回，才能继续运行是同步 不需要是异步 注解应用 12345//这些是jmh测试基准工具@Fork(1)@BenchmarkMode(Mode.AverageTime) //测试模式，统计平均时间@Warmup(iterations=3) //预热次数@Measurement(iterations=5) //进行5论测试 创建线程 继承Thread，重写run方法 new Thread传一个Runnable对象（更推荐） FutureTask实质是Runnable的扩展。能够用来返回执行结果(Callable) 1234567891011public void test1() throws ExecutionException, InterruptedException &#123; FutureTask futureTask = new FutureTask&lt;Integer&gt;(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; Thread.sleep(3000); return 100; &#125; &#125;); new Thread(futureTask).start(); System.out.println(futureTask.get());&#125; 常用方法 sleep yield：从运行态进入就绪态。接下来是否运行看cpu调度 join：当前线程等待调用join的线程指向结束。如果添加参数(最多等待n毫秒)表示在n毫秒内如果没有执行完就不等了，如果执行完就提前结束等待 interrupt：打断 打断阻塞(sleep、wait、join)：会抛出一个打断异常，打断标记为真，但会清除标记，标记就为false 打断正常：打断标记为真，线程正常运行 扩展 LockSupport.park();：该方法阻塞后，可用interrupt打断来唤醒。但标记为真时，park会失效 Thread.interrupted()：会返回打断标记，并设置标记为false 过时方法：会破坏同步代码块，造成锁不释放，形成死锁 stop：强行停止线程运行 suspend：线程暂停运行 resume：恢复暂停的线程 setDaemon(true)：为ture就是设置为守护线程，如果非守护线程全部结束，守护线程自动结束 常用在垃圾回收器线程，垃圾回收器就是守护线程 Tomcat中Acceptor和Poller线程都是守护线程，Tomcat接受shutdown命令后，就不会等待它们处理请求 线程状态操作系统层面：初始状态、可运行状态、运行状态、终止状态、阻塞状态 JAVA API层面： NEW：刚创建没执行start方法 RUNNABLE：调用start之后，包括运行和可运行，覆盖了操作系统层面的阻塞。 如：读取文件时，操作系统层面是阻塞，但JAVA层面依旧是RUNNABLE BLOCKED：阻塞 WAITING：join后的状态 TIMED_WAITING：sleep后的状态 TERMINATED 共享模型管程i++和i–在字节码层面并不是一条指令而是多条 1234getstatic i // 获取静态变量i的值iconst_ 1 // 准备常量1iadd //自增putstatic i // 将修改后的值存入静态变量i 1234getstatic i // 获取静态变量i的值iconst_ 1 //准备常量1isub // 自减putstatic i //将修改后的值存入静态变量i 局部i++是只有一条指令 竞态条件：多线程在临界区内执行，由于代码的执行顺序不同而导致结果无法预测 synchronized在使用到对象的地方，都要加上锁。 只加一个地方是没用的 synchronized加在方法上，相当于锁this对象。 加在静态方法上，相当于锁类对象(Object.class) 锁类时，所有的对象也是会锁的 final和private，可以在一定程度上保证变量线程安全 底层 原理参考地址 对象头：以32位虚拟机为例 普通对象头：Mark Word、Klass Word各32位(8字节)共64位 数组对象头：Mark Word、Klass Word、array length各32位(8字节)共96位 Mark Word：hashcode 25位、age(分代年龄) 4位、biased_lock是否位偏向锁 1位、最后两位 加锁状态 12345678910111213|-------------------------------------------------------|--------------------|| Mark Word (32 bits) | State ||-------------------------------------------------------|--------------------|| hashcode:25 | age:4 | biased_lock:0 | 01 | Normal ||-------------------------------------------------------|--------------------|| thread:23 | epoch:2 | age:4 | biased_lock:1 | 01 | Biased ||-------------------------------------------------------|--------------------|| ptr_to_lock_record:30 | 00 | Lightweight Locked ||-------------------------------------------------------|--------------------|| ptr_to_heavyweight_monitor:30 | 10 | Heavyweight Locked ||-------------------------------------------------------|--------------------|| | 11 | Marked for GC ||-------------------------------------------------------|-------------------- 12345678910111213|--------------------------------------------------------------------|--------------------|| Mark Word (64 bits) | State ||--------------------------------------------------------------------|--------------------|| unused:25 | hashcode:31 | unused:1 | age:4 | biased_lock:0 | 01 | Normal ||--------------------------------------------------------------------|--------------------|| thread:54 | epoch:2 | unused:1 | age:4 | biased_lock:1 | 01 | Biased ||--------------------------------------------------------------------|--------------------|| ptr_to_lock_record:62 | 00 | Lightweight Locked ||--------------------------------------------------------------------|--------------------|| ptr_to_heavyweight_monitor:62 | 10 | Heavyweight Locked ||--------------------------------------------------------------------|--------------------|| | 11 | Marked for GC ||--------------------------------------------------------------------|--------------------| synchronized原理Monitor译为监视器或管程 每个 Java 对象都可以关联一个 Monitor 对象，如果使用 synchronized 给对象上锁（重量级）之后，该对象头的 Mark Word 中就被设置指向 Monitor 对象的指针。 一旦有synchronized对象头会变成Heavyweight Locked状态。 流程 一开始Monitor的owner是null，当 Thread-2 执行 synchronized(obj) 就会将 Monitor 的所有者 Owner 置为 Thread-2 在 Thread-2 上锁的过程中，如果 Thread-3，Thread-4，Thread-5 也来执行 synchronized(obj)，就会进入 EntryList BLOCKED Thread-2 执行完同步代码块的内容，然后唤醒 EntryList 中等待的线程来竞争锁，竞争的时是非公平的 WaitSet 中的 Thread-0，Thread-1 是之前获得过锁，但条件不满足进入 WAITING 状态的线程 WaitSet后面会将 字节码层面解读 1234567static final Object lock = new Object();static int counter = 0;public static void main(String[] args) &#123; synchronized (lock) &#123; counter++; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=3, args_size=1 0: getstatic #2 // &lt;- lock引用 （synchronized开始） 3: dup 4: astore_1 // lock引用 -&gt; slot 1 5: monitorenter // 将 lock对象 MarkWord 置为 Monitor 指针 6: getstatic #3 // &lt;- i 9: iconst_1 // 准备常数 1 10: iadd // +1 11: putstatic #3 // -&gt; i 14: aload_1 // &lt;- lock引用 15: monitorexit // 将 lock对象 MarkWord 重置, 唤醒 EntryList 16: goto 24 //19到23行，对应的是如果代码块内发生异常的处理方式 19: astore_2 // e -&gt; slot 2 20: aload_1 // &lt;- lock引用 21: monitorexit // 将 lock对象 MarkWord 重置, 唤醒 EntryList 22: aload_2 // &lt;- slot 2 (e) 23: athrow // throw e 24: return Exception table: from to target type 6 16 19 any 19 22 19 any LineNumberTable: line 8: 0 line 9: 6 line 10: 14 line 11: 24 LocalVariableTable: Start Length Slot Name Signature 0 25 0 args [Ljava/lang/String; StackMapTable: number_of_entries = 2 frame_type = 255 /* full_frame */ offset_delta = 19 locals = [ class \"[Ljava/lang/String;\", class java/lang/Object ] stack = [ class java/lang/Throwable ] frame_type = 250 /* chop */ offset_delta = 4 synchronized优化轻量级锁一个对象虽然有多线程访问，但多线程访问时间错开，可用轻量级锁优化。 虚拟机自动使用轻量级，轻量级失败再用重量级。 流程 创建锁记录（Lock Record）对象，每个线程都的栈帧都会包含一个锁记录的结构，内部可以存储锁定对象的 Mark Word 让锁记录中 Object reference 指向锁对象，并尝试用 cas 替换 Object 的 Mark Word，将 Mark Word 的值存 入锁记录 如果 cas 替换成功，对象头中存储了 锁记录地址和状态 00 ，表示由该线程给对象加锁 如果 cas 失败，有两种情况 如果是其它线程已经持有了该 Object 的轻量级锁，这时表明有竞争，进入锁膨胀过程 如果是自己执行了 synchronized 锁重入，那么再添加一条 Lock Record 作为重入的计数 重入锁，添加所记录。lock record不再存储mark word而是null 当退出 synchronized 代码块（解锁时）如果有取值为 null 的锁记录，表示有重入，这时重置锁记录，表示重 入计数减一 当退出 synchronized 代码块（解锁时）锁记录的值不为 null，这时使用 cas 将 Mark Word 的值恢复给对象 头 成功，则解锁成功 失败，说明轻量级锁进行了锁膨胀或已经升级为重量级锁，进入重量级锁解锁流程 锁膨胀如果在尝试加轻量级锁的过程中，CAS 操作无法成功，这时一种情况就是有其它线程为此对象加上了轻量级锁（有 竞争），这时需要进行锁膨胀，将轻量级锁变为重量级锁。 流程 当 Thread-1 进行轻量级加锁时，Thread-0 已经对该对象加了轻量级锁 这时 Thread-1 加轻量级锁失败，进入锁膨胀流程 即为 Object 对象申请 Monitor 锁，让 Object 指向重量级锁地址 然后自己进入 Monitor 的 EntryList BLOCKED 当 Thread-0 退出同步块解锁时，使用 cas 将 Mark Word 的值恢复给对象头，失败。这时会进入重量级解锁 流程，即按照 Monitor 地址找到 Monitor 对象，设置 Owner 为 null，唤醒 EntryList 中 BLOCKED 线程 自旋优化重量级锁竞争的时候，还可以使用自旋来进行优化，如果当前线程自旋成功（即这时候持锁线程释放了锁），这时当前线程就可以避免阻塞。 阻塞意味着要发生上下文切换 较耗费性能 注意点： 自旋会占用 CPU 时间，单核 CPU 自旋就是浪费，多核 CPU 自旋才能发挥优势。 在 Java 6 之后自旋锁是自适应的，比如对象刚刚的一次自旋操作成功过，那么认为这次自旋成功的可能性会 高，就多自旋几次；反之，就少自旋甚至不自旋，总之，比较智能。 Java 7 之后不能控制是否开启自旋功能？ 偏向锁Java 6 中引入了偏向锁来做进一步优化：只有第一次使用 CAS 将线程 ID 设置到对象的 Mark Word 头，之后发现 这个线程 ID 是自己的就表示没有竞争，不用重新 CAS。以后只要不发生竞争，这个对象就归该线程所有(锁释放不会修改对象的线程id)。 如果开启了偏向锁（默认开启），那么对象创建后，markword 值为 0x05 即最后 3 位为 101，这时它的 thread、epoch、age 都为 0 偏向锁是默认是延迟的，不会在程序启动时立即生效，如果想避免延迟，可以加 VM 参数 -XX:BiasedLockingStartupDelay=0来禁用延迟 如果没有开启偏向锁，那么对象创建后，markword 值为 0x01 即最后 3 位为 001，这时它的 hashcode、 age 都为 0，第一次用到 hashcode 时才会赋值 撤销偏向锁 调用hashcode()时，会禁用偏向锁。hash码默认为0，第一次调用才会产生，并且填充到wark word。 轻量级锁和重量级锁会将hashcode存入线程栈帧记录中。 其它线程使用偏向锁对象时，会升级为轻量级锁 只有一个线程使用时偏向锁。两个线程交错开使用时轻量级锁。两个及以上线程交叉使用时重量级锁 调用wait/notify时，锁会升级为重量级锁 批量重偏向 撤销偏向锁超过20次后，JVM会给这些对象枷锁时重写偏向锁 批量撤销 当撤销偏向锁阈值超过40后，那么整个类的所有对象都会变为不可偏向。新建的也是 锁粗化锁消除锁消除(默认打开)：JIT即时编译时，不需要锁时会把锁消除 常见线程安全类String、Integer、StringBuffer、Random、Vector、Hashtable、 juc包。 可以理解为它们每个方法都是原子的 多个线程，调用同一个实例的某个方法都是线程安全的 Integer、String是不可变类 使用Spring过程中，尽量将变量为局部变量。不然容易引起线程安全问题。 重写或实现父方法，导致该方法内容不确定。可能会引起线程不安全的发生，称为外星方法 wait-notifyBLOCKED是等待锁 WAITING是已经获得锁，又放弃锁进行等待 wait：让进入object监视器的线程到waitSet等待 带参：有限等待n毫秒 带两参：第一个为毫秒，第二个为纳秒。实际纳秒会进位1毫秒 notify：在waitSet挑一个唤醒 notifyAll：全部唤醒 只有在synchronized(obj)内才能对该对象wait sleep与wait的区别： sleep是Thread方法，wait是Object方法 sleep不需要配合synchronized配合使用。wait必须配合使用 sleep睡眠不会释放对象锁，wait等待时会释放锁 共同点是状态都为TIMED_WAITING 设计模式同步模型保护性暂停 Guarded Suspension(保护性暂停)：一个线程等待另一个线程的执行结果 有一个结果需要从一个线程传递到另一个线程，让他们关联同一个 GuardedObject 如果有结果不断从一个线程到另一个线程那么可以使用消息队列（见生产者/消费者） JDK 中，join 的实现、Future 的实现，采用的就是此模式 因为要等待另一方的结果，因此归类到同步模式 join原理：就是运用了保护性暂停，等待另一个线程结束 12345678910111213141516171819202122232425262728public final synchronized void join(long millis) throws InterruptedException &#123; //一开始先做参数有效性检查 long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException(\"timeout value is negative\"); &#125; if (millis == 0) &#123; //线程是否一直存活 while (isAlive()) &#123; //一直等待 wait(0); &#125; &#125; else &#123; while (isAlive()) &#123; //记录时间来等待 long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125;&#125; 异步模型生产者消费者模式学过了，就不记录了 park&amp;unparkLockSupport中的方法 LockSupport.park();：暂停当前线程。wait状态 LockSupport.unpark(暂停线程对象);：恢复某个线程运行。即可在park前调用也可在之后调用，都可恢复运行 原理每个线程都有自己的一个 Parker 对象，由三部分组成 _counter ， _cond 和 _mutex 打个比喻 _counter ：用来记录数，当为0的时候使用park则阻塞。当为1时使用park则变为0不阻塞 _mutex：互斥锁 _cond：用来控制线程的阻塞还是运行 状态转化 NEW –&gt; RUNNABLE 当调用 t.start() 方法时，由 NEW –&gt; RUNNABLE RUNNABLE &lt;–&gt; WAITING t 线程用 synchronized(obj) 获取了对象锁后 调用 obj.wait() 方法时，t 线程从 RUNNABLE –&gt; WAITING 调用 obj.notify() ， obj.notifyAll() ， t.interrupt() 时 竞争锁成功，t 线程从 WAITING –&gt; RUNNABLE 竞争锁失败，t 线程从 WAITING –&gt; BLOCKED RUNNABLE &lt;–&gt; WAITING 当前线程调用 t.join() 方法时，当前线程从 RUNNABLE –&gt; WAITING 注意是当前线程在t 线程对象的监视器上等待 t 线程运行结束，或调用了当前线程的 interrupt() 时，当前线程从 WAITING –&gt; RUNNABLE RUNNABLE &lt;–&gt; WAITING 当前线程调用 LockSupport.park() 方法会让当前线程从 RUNNABLE –&gt; WAITING 调用 LockSupport.unpark(目标线程) 或调用了线程 的 interrupt() ，会让目标线程从 WAITING –&gt; RUNNABLE RUNNABLE &lt;–&gt; TIMED_WAITING t 线程用 synchronized(obj) 获取了对象锁后 调用 obj.wait(long n) 方法时，t 线程从 RUNNABLE –&gt; TIMED_WAITING t 线程等待时间超过了 n 毫秒，或调用 obj.notify() ， obj.notifyAll() ， t.interrupt() 时 竞争锁成功，t 线程从 TIMED_WAITING –&gt; RUNNABLE 竞争锁失败，t 线程从 TIMED_WAITING –&gt; BLOCKED RUNNABLE &lt;–&gt; TIMED_WAITING 当前线程调用 t.join(long n) 方法时，当前线程从 RUNNABLE –&gt; TIMED_WAITING 注意是当前线程在t 线程对象的监视器上等待 当前线程等待时间超过了 n 毫秒，或t 线程运行结束，或调用了当前线程的 interrupt() 时，当前线程从 TIMED_WAITING –&gt; RUNNABLE RUNNABLE &lt;–&gt; TIMED_WAITING 当前线程调用 Thread.sleep(long n) ，当前线程从 RUNNABLE –&gt; TIMED_WAITING 当前线程等待时间超过了 n 毫秒，当前线程从 TIMED_WAITING –&gt; RUNNABLE RUNNABLE &lt;–&gt; TIMED_WAITING 当前线程调用 LockSupport.parkNanos(long nanos) 或 LockSupport.parkUntil(long millis) 时，当前线 程从 RUNNABLE –&gt; TIMED_WAITING 调用 LockSupport.unpark(目标线程) 或调用了线程 的 interrupt() ，或是等待超时，会让目标线程从 TIMED_WAITING–&gt; RUNNABLE RUNNABLE &lt;–&gt; BLOCKED t 线程用 synchronized(obj) 获取了对象锁时如果竞争失败，从 RUNNABLE –&gt; BLOCKED 持 obj 锁线程的同步代码块执行完毕，会唤醒该对象上所有 BLOCKED 的线程重新竞争，如果其中 t 线程竞争 成功，从 BLOCKED –&gt; RUNNABLE ，其它失败的线程仍然 BLOCKED RUNNABLE &lt;–&gt; TERMINATED RUNNABLE &lt;–&gt; TERMINATED 多把锁通过一个增加锁的数量提高细粒度。但是有可能会造成死锁现象 活跃性死锁一个线程需要同时获取多把锁 定位死锁：使用jconsole或jps定位id再用jstack 进程id定位 有时：能用加锁的顺序来解决一定的问题。 活锁两个线程互相改变对方的结束条件，导致一直在运行，但谁也无法结束 饥饿由于线程优先级太低，始终得不到CPU调度 也指：没有死锁，但锁一直被其他线程抢占。导致无法运行 ReentrantLock相较于synchronized的特点：可中断、可设置超时时间、可设置公平锁、支持多个条件变量 可重入：同一个lock对象可以锁多次。 可打断：lock.lockInterruptibly();能获得可打断的锁。而lock()获得的锁是不可打断的 打断用线程.interrupt() 锁超时：lock.tryLock();会尝试获得锁，获取到返回true否则返回false。 带参的tryLock(long timeout, TimeUnit unit)，第一个参数表示等待时长数值，第二个为时间单位。表示尝试在该时间段内尝试获取锁。 公平锁ReentrantLock默认和synchroinzed都是不公平锁。阻塞线程队列抢锁是任意的。 公平锁是按序获得。 公平锁一般用来解决饥饿问题。但实际往往没有必要会降低并发度。 new ReentrantLock(true);：传true表示公平锁 条件变量通过lock.newCondition();获得条件变量 通过条件变量的condition.await()方法阻塞condition.signal()唤醒其中一个线程，signalAll为唤醒全部 共享模型内存Java内存模型(JMM)：它定义了主存、工作内存抽象概念，底层对应着 CPU 寄存器、缓存、硬件内存、 CPU 指令优化等。 让Java程序员可以不用直接面对复杂的底层 volatilevolatile：用来修饰成员变量和静态变量。局部变量线程私有不能修饰。使得必须到主存中获取 它的值，线程操作 volatile 变量都是直接操作主存。 但它只能解决可见性、有序性问题，并不是解决原子性问题。 如i++，i–。 12345678getstatic i &#x2F;&#x2F; 线程1-获取静态变量i的值 线程内i&#x3D;0 iconst_1 &#x2F;&#x2F; 线程1-准备常量1 iadd &#x2F;&#x2F; 线程1-自增 线程内i&#x3D;1 putstatic i &#x2F;&#x2F; 线程1-将修改后的值存入静态变量i 静态变量i&#x3D;1 iconst_1 &#x2F;&#x2F; 线程2-准备常量1 isub &#x2F;&#x2F; 线程2-自减 线程内i&#x3D;-1 putstatic i &#x2F;&#x2F; 线程2-将修改后的值存入静态变量i 静态变量i&#x3D;-1 有序性现代CPU支持多级指令流水线，如支持同时执行：取指令-指令译码-执行指令-内存访问-数据写回的处理器称为五级指令流水线。变相提高指令吞吐率。 volatile：可以防止该变量不会重排序到前面 有序性难易演示就借助Java并发压测工具jcstress 创建maven项目 123mvn archetype:generate -DinteractiveMode=false -DarchetypeGroupId=org.openjdk.jcstress -DarchetypeArtifactId=jcstress-java-test-archetype -DarchetypeVersion=0.5 -DgroupId=cn.itcast -DartifactId=ordering -Dversion=1.0 测试类 123456789101112131415161718192021222324@JCStressTest//1，4是正常结果@Outcome(id = &#123;\"1\", \"4\"&#125;, expect = Expect.ACCEPTABLE, desc = \"ok\")//0是感兴趣的结果@Outcome(id = \"0\", expect = Expect.ACCEPTABLE_INTERESTING, desc = \"!!!!\")@Statepublic class ConcurrencyTest &#123; int num = 0; boolean ready = false; @Actor public void actor1(I_Result r) &#123; if(ready) &#123; r.r1 = num + num; &#125; else &#123; r.r1 = 1; &#125; &#125; @Actor public void actor2(I_Result r) &#123; //指令重排可能导致ready先赋值，然后另一个线程执行到了actor1方法，结果num为0 本来不可能出现的情况 num = 2; ready = true; &#125;&#125; 执行 12mvn clean install java -jar target/jcstress.jar 原理可见性 volatile 的底层实现原理是内存屏障，Memory Barrier（Memory Fence） 对 volatile 变量的写指令后会加入写屏障 对 volatile 变量的读指令前会加入读屏障 写屏障和读屏障保证的不仅仅是volatile修饰的变量。不过写屏障之前的变量和读屏障之后的其它变量。 有序性 写膨胀和读屏障会保证指令重排序时，不会将写屏障之前的代码排在写屏障之后，也不会将读屏障之后的代码排在读屏障之前 有序性是本线程内的 synchronzied也能保证有序性，但内部是有可能发生重排序。只能保证synchronized内使用过程中没问题。但是外部可能引起问题 double-checked locking 问题volatile：解决了内部INSTANCE = new Singleton();的指令重排问题。否则可能INSTANCE已经赋值，但还未调构造方法，别的线程进来取了一个未构造的对象 两个if判断：第一个使得以后的代码可以不进入锁，提升效率。第二个保证如果一开始就进入锁，依然不会多次创建。 synchronized 12345678910111213141516public final class Singleton &#123; private Singleton() &#123; &#125; private static volatile Singleton INSTANCE = null; public static Singleton getInstance() &#123; // 实例没创建，才会进入内部的 synchronized代码块 if (INSTANCE == null) &#123; synchronized (Singleton.class) &#123; // t2 // 也许有其它线程已经创建实例，所以再判断一次 if (INSTANCE == null) &#123; // t1 INSTANCE = new Singleton(); &#125; &#125; &#125; return INSTANCE; &#125;&#125; 单例模式实现1 为什么加 final：防止子类破坏单例模式 如果实现了序列化接口, 还要做什么来防止反序列化破坏单例：加上readResolve方法，可以使得反序列化后还是同一个对象 如果没有该方法，反序列化时，会new一个新的对象。破坏单例 为什么设置为私有? 是否能防止反射创建新的实例?：否则外部可以多次初始化。不能防止反射功能强大。可以暴力反射。 这样初始化是否能保证单例对象创建时的线程安全?：类加载阶段完成，由JVM来保证，线程安全。 为什么提供静态方法而不是直接将 INSTANCE 设置为 public, 说出你知道的理由：可以通过修改方法，改变为懒加载，也可能在方法内有更多的操作 12345678910public final class Singleton implements Serializable &#123; private Singleton() &#123;&#125; private static final Singleton INSTANCE = new Singleton(); public static Singleton getInstance() &#123; return INSTANCE; &#125; public Object readResolve() &#123; return INSTANCE; &#125;&#125; 实现2 枚举单例是如何限制实例个数的：枚举对象定义时有几个就是几个，相当于静态成员变量。 枚举单例在创建时是否有并发问题：没有，静态成员变量。在类加载阶段，由JVM保证安全 枚举单例能否被反射破坏单例：不能 枚举单例能否被反序列化破坏单例：不能，枚举类默认实现序列化接口。枚举类在反序列化时已经考虑到反序列化破坏单例的问题 枚举单例属于懒汉式还是饿汉式：饿汉式 枚举单例如果希望加入一些单例创建时的初始化逻辑该如何做：枚举类也可以写构造方法，普通方法 123enum Singleton &#123; INSTANCE; &#125; 实现3(懒汉式) synchronized锁的是类对象，保证线程安全。类对象和静态成员变量是一一对应的，也相当于对INSTANCE进行保护。 不能直接锁INSTANCE，INSTANCE会重新赋值，不是final。不能与synchronized配合使用。并且有可能为null，null上面不能加锁 缺点：每次获取都要加锁，性能低 123456789101112public final class Singleton &#123; private Singleton() &#123; &#125; private static Singleton INSTANCE = null; public static synchronized Singleton getInstance() &#123; if( INSTANCE != null )&#123; return INSTANCE; &#125; INSTANCE = new Singleton(); return INSTANCE; &#125;&#125; 实现4(DCL) 解释为什么要加 volatile ? 对比实现3, 说出这样做的意义 为什么还要在这里加为空判断, 之前不是判断过了吗 12345678910111213141516public final class Singleton &#123; private Singleton() &#123; &#125; private static volatile Singleton INSTANCE = null; public static Singleton getInstance() &#123; if (INSTANCE != null) &#123; return INSTANCE; &#125; synchronized (Singleton.class) &#123; if (INSTANCE != null) &#123; // t2 return INSTANCE; &#125; INSTANCE = new Singleton(); return INSTANCE; &#125; &#125;&#125; 实现5(静态内部类) 属于懒汉式还是饿汉式：懒汉式 类加载是懒汉式的，只有用到时才加载 在创建时是否有并发问题：JVM保证线程安全 123456789public final class Singleton &#123; private Singleton() &#123; &#125; private static class LazyHolder &#123; static final Singleton INSTANCE = new Singleton(); &#125; public static Singleton getInstance() &#123; return LazyHolder.INSTANCE; &#125;&#125; 共享模型无锁CAS和volatileCAS必须借助volatile才能读取到共享变量的最新值来实现【比较并交换】的效果 为什么无锁效率高： 无锁情况下，即使重试失败，线程始终在高速运行，没有停歇，而 synchronized 会让线程在没有获得锁的时 候，发生上下文切换，进入阻塞。 但无锁情况下，因为线程要保持运行，需要额外 CPU 的支持，CPU 在这里就好比高速跑道，没有额外的跑 道，线程想高速运行也无从谈起，虽然不会进入阻塞，但由于没有分到时间片，仍然会进入可运行状态，还 是会导致上下文切换。 CAS乐观锁的思想：不怕别的线程来修改共享变量，就算改了就重试呗。 synchronized悲观锁的思想：最悲观的估计，得防着其它线程来修改共享变量。 CAS工具类J.U.C 并发包提供了：AtomicBoolean、AtomicInteger、AtomicLong 以AtomicInteger为例 123456789101112131415161718192021222324252627AtomicInteger i = new AtomicInteger(0);// 获取并自增（i = 0, 结果 i = 1, 返回 0），类似于 i++System.out.println(i.getAndIncrement());// 自增并获取（i = 1, 结果 i = 2, 返回 2），类似于 ++iSystem.out.println(i.incrementAndGet());// 自减并获取（i = 2, 结果 i = 1, 返回 1），类似于 --iSystem.out.println(i.decrementAndGet());// 获取并自减（i = 1, 结果 i = 0, 返回 1），类似于 i--System.out.println(i.getAndDecrement());// 获取并加值（i = 0, 结果 i = 5, 返回 0）System.out.println(i.getAndAdd(5));// 加值并获取（i = 5, 结果 i = 0, 返回 0）System.out.println(i.addAndGet(-5));// 获取并更新（i = 0, p 为 i 的当前值, 结果 i = -2, 返回 0）// 其中函数中的操作能保证原子，但函数需要无副作用System.out.println(i.getAndUpdate(p -&gt; p - 2));// 更新并获取（i = -2, p 为 i 的当前值, 结果 i = 0, 返回 0）// 其中函数中的操作能保证原子，但函数需要无副作用System.out.println(i.updateAndGet(p -&gt; p + 2));// 获取并计算（i = 0, p 为 i 的当前值, x 为参数1, 结果 i = 10, 返回 0）// 其中函数中的操作能保证原子，但函数需要无副作用// getAndUpdate 如果在 lambda 中引用了外部的局部变量，要保证该局部变量是 final 的// getAndAccumulate 可以通过 参数1 来引用外部的局部变量，但因为其不在 lambda 中因此不必是 finalSystem.out.println(i.getAndAccumulate(10, (p, x) -&gt; p + x));// 计算并获取（i = 10, p 为 i 的当前值, x 为参数1, 结果 i = 0, 返回 0）// 其中函数中的操作能保证原子，但函数需要无副作用System.out.println(i.accumulateAndGet(-10, (p, x) -&gt; p + x)); 原子引用：AtomicReference、AtomicMarkableReference、AtomicStampedReference AtomicStampedReference：可以比较版本。来解决ABA问题 AtomicMarkableReference：只关心中间是否改变了 123456789101112131415161718192021222324252627static AtomicStampedReference&lt;String&gt; ref = new AtomicStampedReference&lt;&gt;(\"A\", 0);public static void main(String[] args) throws InterruptedException &#123; log.debug(\"main start...\"); // 获取值 A String prev = ref.getReference(); // 获取版本号 int stamp = ref.getStamp(); log.debug(\"版本 &#123;&#125;\", stamp); // 如果中间有其它线程干扰，发生了 ABA 现象 other(); sleep(1); // 尝试改为 C log.debug(\"change A-&gt;C &#123;&#125;\", ref.compareAndSet(prev, \"C\", stamp, stamp + 1));&#125;private static void other() &#123; new Thread(() -&gt; &#123; log.debug(\"change A-&gt;B &#123;&#125;\", ref.compareAndSet(ref.getReference(), \"B\", ref.getStamp(), ref.getStamp() + 1)); log.debug(\"更新版本为 &#123;&#125;\", ref.getStamp()); &#125;, \"t1\").start(); sleep(0.5); new Thread(() -&gt; &#123; log.debug(\"change B-&gt;A &#123;&#125;\", ref.compareAndSet(ref.getReference(), \"A\", ref.getStamp(), ref.getStamp() + 1)); log.debug(\"更新版本为 &#123;&#125;\", ref.getStamp()); &#125;, \"t2\").start();&#125; AtomicMarkableReference 123456789101112131415161718192021222324252627282930313233343536@Slf4jpublic class TestABAAtomicMarkableReference &#123; public static void main(String[] args) throws InterruptedException &#123; GarbageBag bag = new GarbageBag(\"装满了垃圾\"); // 参数2 mark 可以看作一个标记，表示垃圾袋满了 AtomicMarkableReference&lt;GarbageBag&gt; ref = new AtomicMarkableReference&lt;&gt;(bag, true); log.debug(\"主线程 start...\"); GarbageBag prev = ref.getReference(); log.debug(prev.toString()); new Thread(() -&gt; &#123; log.debug(\"打扫卫生的线程 start...\"); bag.setDesc(\"空垃圾袋\"); while (!ref.compareAndSet(bag, bag, true, false)) &#123;&#125; log.debug(bag.toString()); &#125;).start(); Thread.sleep(1000); log.debug(\"主线程想换一只新垃圾袋？\"); boolean success = ref.compareAndSet(prev, new GarbageBag(\"空垃圾袋\"), true, false); log.debug(\"换了么？\" + success); log.debug(ref.getReference().toString()); &#125;&#125;class GarbageBag &#123; String desc; public GarbageBag(String desc) &#123; this.desc = desc; &#125; public void setDesc(String desc) &#123; this.desc = desc; &#125; @Override public String toString() &#123; return super.toString() + \" \" + desc; &#125;&#125; 原子数组：AtomicIntegerArray、AtomicLongArray 、AtomicReferenceArray 字段更新器：AtomicReferenceFieldUpdater、AtomicIntegerFieldUpdater、AtomicLongFieldUpdater 该属性必须加volatile 1234567891011121314151617public class Test5 &#123; private volatile int field; public static void main(String[] args) &#123; AtomicIntegerFieldUpdater fieldUpdater = AtomicIntegerFieldUpdater.newUpdater(Test5.class, \"field\");//类的class，属性名 Test5 test5 = new Test5(); fieldUpdater.compareAndSet(test5, 0, 10);//参数1 哪个对象 参数2原始值 参数3期待值 // 修改成功 field = 10 System.out.println(test5.field); // 修改成功 field = 20 fieldUpdater.compareAndSet(test5, 10, 20); System.out.println(test5.field); // 修改失败 field = 20 fieldUpdater.compareAndSet(test5, 10, 30); System.out.println(test5.field); &#125;&#125; 原子累加器：LongAdder 专门用于做累加，相较于atomicInteger，累加效率更高 性能原理：在竞争时，设多个累加单元线程0设置cell[0]线程1设置cell[1]最后汇总结果。 CAS锁是用一个标记：不要用于实践 123456789101112131415//cas锁标记public class LockCas &#123; private AtomicInteger state = new AtomicInteger(0); public void lock() &#123; while (true) &#123; if (state.compareAndSet(0, 1)) &#123; break; &#125; &#125; &#125; public void unlock() &#123; log.debug(\"unlock...\"); state.set(0); &#125;&#125; 伪共享： 1234567891011//会给使用次直接的对象或字段前后加上128字节的padding，是对象预读时占用不同的缓存行。这样不会使得缓存行失效@sun.misc.Contended static final class Cell &#123; volatile long value; Cell(long x) &#123; value = x; &#125; // 最重要的方法, 用来 cas 方式进行累加, prev 表示旧值, next 表示新值 final boolean cas(long prev, long next) &#123; return UNSAFE.compareAndSwapLong(this, valueOffset, prev, next); &#125; // 省略不重要代码 &#125; Unsafe只能通过反射获取。 123456789101112131415public class UnsafeAccessor &#123; static Unsafe unsafe; static &#123; try &#123; Field theUnsafe = Unsafe.class.getDeclaredField(\"theUnsafe\"); theUnsafe.setAccessible(true);//设置private访问权限 unsafe = (Unsafe) theUnsafe.get(null);//传入获取属性的对象。因为是静态变量穿nukk即可 &#125; catch (NoSuchFieldException | IllegalAccessException e) &#123; throw new Error(e); &#125; &#125; static Unsafe getUnsafe() &#123; return unsafe; &#125;&#125; 不可变享元模式对相同值共享 包装类提供了valueOf方法，在一定范围内才会重用对象。 final原理赋值的时候，会加入写屏障。别的线程只可能读到初始赋值的数值，而不会读到默认值。 在使用时，final会复制一份使用，使用的指令效率也更高。更安全。 并发工具线程池线程池中的线程都是非守护线程，不会随着主线程的结束而结束 线程池状态线程池状态：ThreadPoolExecutor 使用 int 的高 3 位来表示线程池状态，低 29 位表示线程数量 状态名 高 3 位 接收新任务 处理阻塞队列任务 说明 RUNNING 111 Y Y SHUTDOWN 000 N Y 不会接收新任务，但会处理阻塞队列剩余 任务 STOP 001 N N 会中断正在执行的任务，并抛弃阻塞队列 任务 TIDYING 010 任务全执行完毕，活动线程为 0 即将进入 终结 TERMINATED 011 终结状态 从数字上比较，TERMINATED &gt; TIDYING &gt; STOP &gt; SHUTDOWN &gt; RUNNING 这些信息存储在一个原子变量 ctl 中，目的是将线程池状态与线程个数合二为一，这样就可以用一次 cas 原子操作进行赋值 1234// c 为旧值， ctlOf 返回结果为新值ctl.compareAndSet(c, ctlOf(targetState, workerCountOf(c))));// rs 为高 3 位代表线程池状态， wc 为低 29 位代表线程个数，ctl 是合并它们private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 构造方法 corePoolSize 核心线程数目 (最多保留的线程数) maximumPoolSize 最大线程数目 核心线程数+最大线程数 keepAliveTime 生存时间 - 针对救急线程 unit 时间单位 - 针对救急线程 workQueue 阻塞队列 常见队列： 直接交换：SynchronousQueueron容量为0只用交换 无界队列：LinkedBlockingQueue无容量限制 有界队列：ArrayBlockingQueue threadFactory 线程工厂 - 可以为线程创建时起个好名字 、指定优先级，是否为守护线程等 handler 拒绝策略 1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 线程是懒创建，线程分为核心线程和救急线程。只有有界列队才有救急线程 在核心线程和阻塞队列用完后才会将新任务交给救急线程。 救急线程有生存时间完成任务后就会销毁。核心线程不会，即时任务消失也一直存在。 jdk提供了四种拒绝策略： AbortPolicy 让调用者抛出 RejectedExecutionException 异常，这是默认策略 CallerRunsPolicy 让调用者运行任务 DiscardPolicy 放弃本次任务 DiscardOldestPolicy 放弃队列中最早的任务，本任务取而代之 很多第三方框架都新实现了拒绝策略 Dubbo 的实现，在抛出 RejectedExecutionException 异常之前会记录日志，并dump(记录)线程栈信息，方 便定位问题 Netty 的实现，是创建一个新线程来执行任务 ActiveMQ 的实现，带超时等待（60s）尝试放入队列，类似我们之前自定义的拒绝策略 PinPoint 的实现，它使用了一个拒绝策略链，会逐一尝试策略链中每种拒绝策略 工厂提供的构造方法JDK为了方便开发者，在Executors中提供了众多工厂方法来创建线程池 newFixedThreadPool 特点 核心线程数 == 最大线程数（没有救急线程被创建），因此也无需超时时间 阻塞队列没有指定大小是无界的，可以放任意数量的任务 123456//参数：核心线程数public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 适用于任务量已知，相对耗时的任务 使用范例 123456789//这里的线程工厂，我们可以用指定线程名Executors.newFixedThreadPool(3, new ThreadFactory() &#123; private AtomicInteger t = new AtomicInteger(1); @Override public Thread newThread(Runnable r) &#123; return new Thread(r, \"自己取得线程名\" + t.getAndIncrement()); &#125;&#125;); newCachedThreadPool 特点 核心线程数是 0， 最大线程数是 Integer.MAX_VALUE，救急线程的空闲生存时间是 60s，意味着 全部都是救急线程（60s 后可以回收） 救急线程可以无限创建 队列采用了 SynchronousQueue 实现特点是，它没有容量，没有线程来取是放不进去的，会阻塞（一手交钱、一手交 货） 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 整个线程池表现为线程数会根据任务量不断增长，没有上限，当任务执行完毕，空闲 1分钟后释放线 程。 适合任务数比较密集，但每个任务执行时间较短的情况 newSingleThreadExecutor 特点： 只有一个单线程串行执行任务，如果任务执行失败而终止那么没有任何补救措施，而线程池还会新建一 个线程，保证池的正常工作 使用FinalizableDelegatedExecutorService装饰者模式，只对外暴露了 ExecutorService 接口，因 此不能调用 ThreadPoolExecutor 中特有的方法 Executors.newFixedThreadPool(1) 初始时为1，以后还可以修改，可以强转后调用 setCorePoolSize 等方法进行修改。而Executors.newSingleThreadExecutor() 线程个数始终为1，不能修改 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 希望多个任务排队执行。线程数固定为 1，任务数多于 1 时，会放入无界队列排队。任务执行完毕，这唯一的线程 也不会被释放。 ScheduledExecutorService 定时任务线程池：就是后面提到的任务调度线程池 提交任务1234567891011121314151617181920// 执行任务void execute(Runnable command);// 提交任务 task，用返回值 Future 获得任务执行结果&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);// 提交 tasks 中所有任务&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException;// 提交 tasks 中所有任务，带超时时间&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException;// 提交 tasks 中所有任务，哪个任务先成功执行完毕，返回此任务执行结果，其它任务取消&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException;// 提交 tasks 中所有任务，哪个任务先成功执行完毕，返回此任务执行结果，其它任务取消，带超时时间&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; 关闭线程池shutdown()：线程池状态变为 SHUTDOWN 不会接收新任务 但已提交任务会执行完 此方法不会阻塞调用线程的执行 12345678910111213141516public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); // 修改线程池状态 advanceRunState(SHUTDOWN); // 仅会打断空闲线程 interruptIdleWorkers(); onShutdown(); // 扩展点 ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; // 尝试终结(没有运行的线程可以立刻终结，如果还有运行的线程也不会等) tryTerminate();&#125; shutdownNow：线程池状态变为 STOP 不会接收新任务 会将队列中的任务返回 并用 interrupt 的方式中断正在执行的任务 12345678910111213141516171819public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); // 修改线程池状态 advanceRunState(STOP); // 打断所有线程 interruptWorkers(); // 获取队列中剩余任务 tasks = drainQueue(); &#125; finally &#123; mainLock.unlock(); &#125; // 尝试终结 tryTerminate(); return tasks;&#125; 其它方法 123456// 不在 RUNNING 状态的线程池，此方法就返回 trueboolean isShutdown();// 线程池状态是否是 TERMINATEDboolean isTerminated();// 调用 shutdown 后，由于调用线程并不会等待所有任务运行结束，因此如果它想在线程池 TERMINATED 后做些事情，可以利用此方法等待boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; 异步模式之工作线程让有限的工作线程（Worker Thread）来轮流异步处理无限多的任务。也可以将其归类为分工模式，它的典型实现 就是线程池，也体现了经典设计模式中的享元模式。 （对比另一种多线程设计模式：Thread-Per-Message）每个消息一个线程 不同任务类型应该使用不同的线程池，这样能够避免饥饿，并能提升效率 饥饿固定大小的线程池会有饥饿现象。 线程数不足导致的死锁(类似死锁)，如：所有线程都去消费，没有线程去生产 不同类型的任务可以用不同线程池，来解决这个问题 线程池大小过小会导致不能充分利用系统资源、任意导致饥饿。过大会导致线程上下文切换，占用内存。 CPU密集型通常采用 cpu 核数 + 1 能够实现最优的 CPU 利用率，+1 是保证当线程由于页缺失故障（操作系统）或其它原因 导致暂停时，额外的这个线程就能顶上去，保证 CPU 时钟周期不被浪费 I/O密集型CPU 不总是处于繁忙状态 经验公式：线程数 = 核数 * 期望 CPU 利用率 * 总时间(CPU计算时间+等待时间) / CPU 计算时间 如 4 核 CPU 计算时间是 50% ，其它等待时间是 50%，期望 cpu 被 100% 利用：4 * 100% * 100% / 50% = 8 如 4 核 CPU 计算时间是 10% ，其它等待时间是 90%，期望 cpu 被 100% 利用，套用公式 4 * 100% * 100% / 10% = 40 任务调度线程池在『任务调度线程池』功能加入之前，可以使用 java.util.Timer 来实现定时功能，Timer 的优点在于简单易用，但 由于所有任务都是由同一个线程来调度，因此所有任务都是串行执行的，同一时间只能有一个任务在执行，前一个 任务的延迟或异常都将会影响到之后的任务。 Timer已经过时了，现在基本使用任务调度线程池 任务调度线程池 123456789101112131415161718ScheduledExecutorService pool = Executors.newScheduledThreadPool(1);//一秒后执行pool.schedule(() -&gt; &#123; try &#123; log.debug(\"task1\"); int i = 1 / 0; &#125; catch (Exception e) &#123; log.error(\"error:\", e); &#125;&#125;, 1, TimeUnit.SECONDS);//延迟一秒后第一个任务开始，从此每隔一秒执行下一个任务pool.scheduleAtFixedRate(() -&gt; &#123; log.debug(\"running...\");&#125;, 1, 1, TimeUnit.SECONDS);//延迟一秒后第一个任务开始，每个任务**完成**后再隔一秒执行下一个任务pool.scheduleWithFixedDelay(() -&gt; &#123; log.debug(\"running...\");&#125;, 1, 1, TimeUnit.SECONDS); 异常处理线程池中线程出现异常不会显示。 可以自己用try catch来抓取异常 也可以用submit返回Future类，如果异常get方法获取的是异常信息 日期扩展获取本周四 1234567LocalDateTime now = LocalDateTime.now();// 获取周四时间LocalDateTime time = now.withHour(18).withMinute(0).withSecond(0).withNano(0).with(DayOfWeek.THURSDAY);// 如果 当前时间 &gt; 本周周四，必须找到下周周四if(now.compareTo(time) &gt; 0) &#123; time = time.plusWeeks(1);&#125; Tomcat线程池 LimitLatch 用来限流，可以控制最大连接个数，类似 J.U.C 中的 Semaphore Acceptor 只负责【接收新的 socket 连接】 Poller 只负责监听 socket channel 是否有【可读的 I/O 事件】 一旦可读，封装一个任务对象（socketProcessor），提交给 Executor 线程池处理 Executor 线程池中的工作线程最终负责【处理请求】 Tomcat 线程池扩展了 ThreadPoolExecutor，行为稍有不同 如果总线程数达到 maximumPoolSize 这时不会立刻抛 RejectedExecutionException 异常 而是再次尝试将任务放入队列，如果还失败，才抛出 RejectedExecutionException 异常 源码 tomcat-7.0.42 12345678910111213141516171819202122232425public void execute(Runnable command, long timeout, TimeUnit unit) &#123; submittedCount.incrementAndGet(); try &#123; //交由JDK的线程池来执行 super.execute(command); &#125; catch (RejectedExecutionException rx) &#123; //JDK的线程池抛出异常后再次尝试 if (super.getQueue() instanceof TaskQueue) &#123; final TaskQueue queue = (TaskQueue)super.getQueue(); try &#123; if (!queue.force(command, timeout, unit)) &#123; submittedCount.decrementAndGet(); throw new RejectedExecutionException(\"Queue capacity is full.\"); &#125; &#125; catch (InterruptedException x) &#123; submittedCount.decrementAndGet(); Thread.interrupted(); throw new RejectedExecutionException(x); &#125; &#125; else &#123; submittedCount.decrementAndGet(); throw rx; &#125; &#125;&#125; 配置Connector 配置 配置项 默认值 说明 acceptorThreadCount 1 acceptor 线程数量，一般不用改，一个线程来建立连接就足够了。建立连接大部分时候是阻塞状态。 pollerThreadCount 1 poller 线程数量，一般也是1，该线程采用多路复用的思想，一个线程就能监控多个channel minSpareThreads 10 核心线程数，即 corePoolSize maxThreads 200 最大线程数，即 maximumPoolSize executor - Executor 名称，用来引用下面的 Executor。如果配置了这个，那么上面两个配置会失效 Executor 线程配置 配置项 默认值 说明 threadPriority 5 线程优先级 daemon true 是否守护线程 minSpareThreads 25 核心线程数，即 corePoolSize maxThreads 200 最大线程数，即 maximumPoolSize maxIdleTime 60000 线程生存时间，单位是毫秒，默认值即 1 分钟 maxQueueSize Integer.MAX_VALUE 队列长度，相当于无界。有可能造成任务堆积。 prestartminSpareThreads false 核心线程是否在服务器启动时启动。默认懒加载 tomcat会先交给救急线程，救急线程满了再给阻塞队列 Fork/JoinFork/Join 是 JDK 1.7 加入的新的线程池实现，Fork/Join 是 JDK 1.7 加入的新的线程池实现 123456789101112131415161718192021222324252627282930313233343536class AddTask3 extends RecursiveTask&lt;Integer&gt; &#123; int begin; int end; public AddTask3(int begin, int end) &#123; this.begin = begin; this.end = end; &#125; @Override public String toString() &#123; return \"&#123;\" + begin + \",\" + end + '&#125;'; &#125; @Override protected Integer compute() &#123; // 终止条件 if (begin == end) &#123; log.debug(\"join() &#123;&#125;\", begin); return begin; &#125; if (end - begin == 1) &#123; log.debug(\"join() &#123;&#125; + &#123;&#125; = &#123;&#125;\", begin, end, end + begin); return end + begin; &#125; //任务拆分 int mid = (end + begin) / 2; // 3 AddTask3 t1 = new AddTask3(begin, mid); // 1,3 t1.fork();//将拆分的t1交给一个线程执行 AddTask3 t2 = new AddTask3(mid + 1, end); // 4,5 t2.fork(); log.debug(\"fork() &#123;&#125; + &#123;&#125; = ?\", t1, t2); //等待t1和t2的运行结果 int result = t1.join() + t2.join(); log.debug(\"join() &#123;&#125; + &#123;&#125; = &#123;&#125;\", t1, t2, result); return result; &#125;&#125; 1.8后JDK拆分工作由框架内部来做，如stram JUCAQS原理全称是 AbstractQueuedSynchronizer，是阻塞式锁和相关的同步器工具的框架 特点： 用 state 属性来表示资源的状态（分独占模式和共享模式），子类需要定义(如具体哪个值表示独占)如何维护这个状态，控制如何获取 锁和释放锁 getState - 获取 state 状态 setState - 设置 state 状态 compareAndSetState - cas机制设置 state 状态 独占模式是只有一个线程能够访问资源，而共享模式可以允许多个线程访问资源 提供了基于 FIFO 的等待队列，类似于 Monitor 的 EntryList 条件变量来实现等待、唤醒机制，支持多个条件变量，类似于 Monitor 的 WaitSet 子类主要实现这样一些方法（默认抛出 UnsupportedOperationException） tryAcquire tryRelease tryAcquireShared tryReleaseShared isHeldExclusively 1234567891011/*获取锁*/// 如果获取锁失败if (!tryAcquire(arg)) &#123; // 入队, 可以选择阻塞当前线程 // 用park unpark来阻塞&#125;/*释放锁*/// 如果释放锁成功if (tryRelease(arg)) &#123; // 让阻塞线程恢复运行&#125; 自定义锁1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// 自定义锁（不可重入锁）class MyLock implements Lock &#123; // 独占锁 同步器类 class MySync extends AbstractQueuedSynchronizer &#123; @Override protected boolean tryAcquire(int arg) &#123; if(compareAndSetState(0, 1)) &#123; // 加上了锁，并设置 owner 为当前线程 setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; @Override protected boolean tryRelease(int arg) &#123; setExclusiveOwnerThread(null); setState(0);//state是volatile放后面写屏障可以保证前面代码的可见性 return true; &#125; @Override // 是否持有独占锁 protected boolean isHeldExclusively() &#123; return getState() == 1; &#125; public Condition newCondition() &#123; return new ConditionObject(); &#125; &#125; private MySync sync = new MySync(); @Override // 加锁（不成功会进入等待队列） public void lock() &#123; sync.acquire(1);//如果是tryAcquire只会尝试一次，不会放入等待队列 &#125; @Override // 加锁，可打断 public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; @Override // 尝试加锁（一次） public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; @Override // 尝试加锁，带超时 public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(time)); &#125; @Override // 解锁 public void unlock() &#123; sync.release(1);//会讲状态置为0，exclusiveOwnerThread设为null，唤醒阻塞线程 //tryRelease只会讲状态置为0，exclusiveOwnerThread设为null不会唤醒其它线程 &#125; @Override // 创建条件变量 public Condition newCondition() &#123; return sync.newCondition(); &#125;&#125; ReentrantLock原理ReentrantLock实现了Lock接口 内部维护Sync同步器(继承自AQS)，Sync是抽象类，有两个实现非公平锁(默认)和公平锁 非公平锁构造器默认为非公平 123public ReentrantLock() &#123; sync = new NonfairSync();&#125; 加锁 123456final void lock() &#123; if (compareAndSetState(0, 1))//尝试将state改为1 setExclusiveOwnerThread(Thread.currentThread());//将exclusiveOwnerThread置为当前线程 else //修改state失败 acquire(1);//&#125; 123456public final void acquire(int arg) &#123; //tryAcquire非公平会返回nonfairTryAcquire方法 if (!tryAcquire(arg) &amp;&amp;//尝试加锁，如果锁释放则重试成功，若失败取反为真 acquireQueued(addWaiter(Node.EXCLUSIVE), arg))//尝试创建Node节点对象加入队列 addWaiter构造等待队列 selfInterrupt();&#125; 一开始等待队列的head和tail是null，等有节点加入才有指向。该队列是双向链表 Node蓝创建，第一个Node称为 Dummy（哑元）或哨兵，用来占位，并不关联线程 黄色三角表示该 Node 的 waitStatus 状态，其中 0 为默认正常状态 12345678910111213141516171819202122final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123;//死循环，尝试获得锁 final Node p = node.predecessor();//获得前驱节点 if (p == head &amp;&amp; tryAcquire(arg)) &#123;//查看前驱节点是否为头节点，如果是，则再次tryAcquire，若成功则进入 setHead(node); p.next = null; failed = false; return interrupted; &#125; //tryAcquire失败 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;//在尝试获取锁失败后进行Park，返回真则park，返回假则再次循环 parkAndCheckInterrupt())//阻塞当前线程 interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; shouldParkAfterFailedAcquire 逻辑，将前驱 node的 waitStatus 改为 -1，返回 false。置为-1表示前驱节点有责任唤醒它之后的一个节点 再次进入 shouldParkAfterFailedAcquire 时，这时因为其前驱 node 的 waitStatus 已经是 -1，这次返回 true 1234567891011121314151617181920212223final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); // 如果无锁 if (c == 0) &#123; // 直接尝试抢占锁，使用 cas 获得, 这里体现了非公平性: 不去检查 AQS 队列 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 如果已经获得了锁, 线程还是当前线程, 表示发生了锁重入 else if (current == getExclusiveOwnerThread()) &#123; // state++ int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; // 获取失败, 回到调用处 return false;&#125; 释放锁 123public void unlock() &#123; sync.release(1);&#125; 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123;//将state设为0，exclusiveOwnerThread设为null。以及一些可重入的实现 Node h = head; if (h != null &amp;&amp; h.waitStatus != 0)//检查head是否不为空，head的waitStatus是否不等于0.若为-1则表示要唤醒侯继界限 unparkSuccessor(h);//若不等于0则唤醒后继节点，unparjSuccessor方法则找到离head最近的没有取消的节点唤醒 return true; &#125; return false;&#125; 无竞争：唤醒后，会在acquireQueued方法的阻塞位置向下执行。再次循环，再次tryAcquire，尝试加锁，成功后将当前节点设为头节点，原来头节点断开，关联的线程设为null。 有竞争(非公平)：若有新的线程添加进来，也尝试获得锁并且成功。则wait队列的线程会再次进入acquireQueue流程，获取失败进入阻塞 可重入加锁和释放锁加入了判断exclusiveOwnerThread是否为当前线程 1234567891011121314151617181920212223242526272829303132333435363738394041static final class NonfairSync extends Sync &#123; // ... // Sync 继承过来的方法, 方便阅读, 放在此处 final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 如果已经获得了锁, 线程还是当前线程, 表示发生了锁重入 else if (current == getExclusiveOwnerThread()) &#123; // state++ int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; &#125; // Sync 继承过来的方法, 方便阅读, 放在此处 protected final boolean tryRelease(int releases) &#123; // state-- int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 支持锁重入, 只有 state 减为 0, 才释放成功 if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125;&#125; 打断不可打断模式 在此模式下，即使它被打断，仍会驻留在 AQS 队列中，一直要等到获得锁后方能得知自己被打断了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// Sync 继承自 AQSstatic final class NonfairSync extends Sync &#123; // ... private final boolean parkAndCheckInterrupt() &#123; // 如果打断标记已经是 true, 则 park 会失效 LockSupport.park(this); // interrupted 返回true 会清除打断标记设置标记为false return Thread.interrupted(); &#125; final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; failed = false; // 还是需要获得锁后, 才能返回打断状态 return interrupted; &#125; if ( shouldParkAfterFailedAcquire(p, node) &amp;&amp; //可以被interrupt打断唤醒 parkAndCheckInterrupt() ) &#123; // 如果是因为 interrupt 被唤醒, 返回打断状态为 true //但不打断 interrupted = true; &#125; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; public final void acquire(int arg) &#123; if ( !tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg) ) &#123; // 如果打断状态为 true selfInterrupt(); &#125; &#125; static void selfInterrupt() &#123; // 重新产生一次中断 Thread.currentThread().interrupt(); &#125;&#125; 可打断模式 c采用了抛出异常的方式 1234567891011121314151617181920212223242526272829303132333435static final class NonfairSync extends Sync &#123; public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 如果没有获得到锁, 进入 ㈠ if (!tryAcquire(arg)) doAcquireInterruptibly(arg); &#125; // ㈠ 可打断的获取锁流程 private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) &#123; // 在 park 过程中如果被 interrupt 会进入此 // 这时候抛出异常, 而不会再次进入 for (;;) throw new InterruptedException(); &#125; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125;&#125; 公平锁12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; acquire(1); &#125; // AQS 继承过来的方法, 方便阅读, 放在此处 public final void acquire(int arg) &#123; if ( !tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg) ) &#123; selfInterrupt(); &#125; &#125; // 与非公平锁主要区别在于 tryAcquire 方法的实现 protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 先检查 AQS 队列中是否有前驱节点, 没有才去竞争 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; &#125; // ㈠ AQS 继承过来的方法, 方便阅读, 放在此处 public final boolean hasQueuedPredecessors() &#123; Node t = tail; Node h = head; Node s; // h != t 时表示队列中有 Node return h != t &amp;&amp; ( // (s = h.next) == null 表示队列中还有没有老二 (s = h.next) == null || // 或者队列中老二线程不是此线程 s.thread != Thread.currentThread() ); &#125;&#125; 条件变量await流程 每个条件变量(ConditionObject)维护一个双向链表作为需要wait的线程类似waitset。 线程1持有锁，调用await进入ConditionObject 的 addConditionWaiter 流程。会被踢出Sync的等待队列，加入条件变量的waitset 12345678910111213141516171819//条件变量调用awaitpublic final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter();//将线程添加入条件变量的双向链表，但没有占位空节点 int savedState = fullyRelease(node);//将节点上所有锁(考虑到锁重入)都释放。 int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this);//阻塞当前线程 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125; 12345678910111213141516private Node addConditionWaiter() &#123; Node t = lastWaiter; // Node.CONDITION就是-2条件变量等待，相当于上图的黄色三角 if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; Node node = new Node(Thread.currentThread(), Node.CONDITION); //若为空则作为第一个节点 if (t == null) firstWaiter = node; else //不为空则加入尾部 t.nextWaiter = node; lastWaiter = node; return node;&#125; 12345678910111213141516171819202122232425final int fullyRelease(Node node) &#123; boolean failed = true; try &#123;//拿到重入后的计数值 int savedState = getState(); if (release(savedState)) &#123;//清零，还会唤醒后继节点 failed = false; return savedState; &#125; else &#123; throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; if (failed) node.waitStatus = Node.CANCELLED; &#125;&#125;public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h);//唤醒后继节点 return true; &#125; return false;&#125; signal流程 12345678910111213141516171819202122232425262728public final void signal() &#123; if (!isHeldExclusively())//检查调用线程是否是锁的持有者，只有onwer线程才能唤醒 throw new IllegalMonitorStateException(); Node first = firstWaiter;//找条件队列队首元素 if (first != null)//如果first不为空 doSignal(first);&#125; private void doSignal(Node first) &#123; do &#123; if ( (firstWaiter = first.nextWaiter) == null)//如果下个节点为null，九江下个节点置为null，如果有就将下一个变为首节点 lastWaiter = null; first.nextWaiter = null; &#125; while (!transferForSignal(first) &amp;&amp;//将节点转移到竞争锁的链表(等待队列) 转移成功就跳出循环。如果转移失败就尝试唤醒下一个元素。转移失败可能是因为超时或者被打断 取消 (first = firstWaiter) != null);&#125;final boolean transferForSignal(Node node) &#123; //将状态-2改为0，在这可能被取消等，导致失败返回false if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; Node p = enq(node);//enq就是将当前节点加入等待队列，成功后返回前驱节点 int ws = p.waitStatus; //检查前驱节点状态，并且修改为-1 if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true;&#125; 下面是老师的代码(补充) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); // 如果还没有获得锁 if (c == 0) &#123; // 尝试用 cas 获得, 这里体现了非公平性: 不去检查 AQS 队列 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 如果已经获得了锁, 线程还是当前线程, 表示发生了锁重入 else if (current == getExclusiveOwnerThread()) &#123; // state++ int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; // 获取失败, 回到调用处 return false;&#125;if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter;&#125;// 创建一个关联当前线程的新 Node, 添加至队列尾部Node node = new Node(Thread.currentThread(), Node.CONDITION);if (t == null) firstWaiter = node;else t.nextWaiter = node;lastWaiter = node;return node;&#125;// 唤醒 - 将没取消的第一个节点转移至 AQS 队列private void doSignal(Node first) &#123; do &#123; // 已经是尾节点了 if ( (firstWaiter = first.nextWaiter) == null) &#123; lastWaiter = null; &#125; first.nextWaiter = null; &#125; while ( // 将等待队列中的 Node 转移至 AQS 队列, 不成功且还有节点则继续循环 ㈢ !transferForSignal(first) &amp;&amp; // 队列还有节点 (first = firstWaiter) != null );&#125;// 外部类方法, 方便阅读, 放在此处// ㈢ 如果节点状态是取消, 返回 false 表示转移失败, 否则转移成功final boolean transferForSignal(Node node) &#123; // 如果状态已经不是 Node.CONDITION, 说明被取消了 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; // 加入 AQS 队列尾部 Node p = enq(node); int ws = p.waitStatus; if ( // 上一个节点被取消 ws &gt; 0 || // 上一个节点不能设置状态为 Node.SIGNAL !compareAndSetWaitStatus(p, ws, Node.SIGNAL) ) &#123; // unpark 取消阻塞, 让线程重新同步状态 LockSupport.unpark(node.thread); &#125; return true;&#125;// 全部唤醒 - 等待队列的所有节点转移至 AQS 队列private void doSignalAll(Node first) &#123; lastWaiter = firstWaiter = null; do &#123; Node next = first.nextWaiter; first.nextWaiter = null; transferForSignal(first); first = next; &#125; while (first != null);&#125;// ㈡private void unlinkCancelledWaiters() &#123; // ...&#125;// 唤醒 - 必须持有锁才能唤醒, 因此 doSignal 内无需考虑加锁public final void signal() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first);&#125;// 全部唤醒 - 必须持有锁才能唤醒, 因此 doSignalAll 内无需考虑加锁public final void signalAll() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignalAll(first);&#125;// 不可打断等待 - 直到被唤醒public final void awaitUninterruptibly() &#123; // 添加一个 Node 至等待队列, 见 ㈠ Node node = addConditionWaiter(); // 释放节点持有的锁, 见 ㈣ int savedState = fullyRelease(node); boolean interrupted = false; // 如果该节点还没有转移至 AQS 队列, 阻塞 while (!isOnSyncQueue(node)) &#123; // park 阻塞 LockSupport.park(this); // 如果被打断, 仅设置打断状态 if (Thread.interrupted()) interrupted = true; &#125; // 唤醒后, 尝试竞争锁, 如果失败进入 AQS 队列 if (acquireQueued(node, savedState) || interrupted) selfInterrupt();&#125;// 外部类方法, 方便阅读, 放在此处// ㈣ 因为某线程可能重入，需要将 state 全部释放final int fullyRelease(Node node) &#123; boolean failed = true; try &#123; int savedState = getState(); if (release(savedState)) &#123; failed = false; return savedState; &#125; else &#123; throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; if (failed) node.waitStatus = Node.CANCELLED; &#125;&#125;// 打断模式 - 在退出等待时重新设置打断状态private static final int REINTERRUPT = 1;// 打断模式 - 在退出等待时抛出异常private static final int THROW_IE = -1;// 判断打断模式private int checkInterruptWhileWaiting(Node node) &#123; return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0;&#125;// ㈤ 应用打断模式private void reportInterruptAfterWait(int interruptMode) throws InterruptedException &#123; if (interruptMode == THROW_IE) throw new InterruptedException(); else if (interruptMode == REINTERRUPT) selfInterrupt();&#125;// 等待 - 直到被唤醒或打断public final void await() throws InterruptedException &#123; if (Thread.interrupted()) &#123; throw new InterruptedException(); &#125; // 添加一个 Node 至等待队列, 见 ㈠ Node node = addConditionWaiter(); // 释放节点持有的锁 int savedState = fullyRelease(node); int interruptMode = 0; // 如果该节点还没有转移至 AQS 队列, 阻塞 while (!isOnSyncQueue(node)) &#123; // park 阻塞 LockSupport.park(this); // 如果被打断, 退出等待队列 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; // 退出等待队列后, 还需要获得 AQS 队列的锁 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; // 所有已取消的 Node 从队列链表删除, 见 ㈡ if (node.nextWaiter != null) unlinkCancelledWaiters(); // 应用打断模式, 见 ㈤ if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125;// 等待 - 直到被唤醒或打断或超时public final long awaitNanos(long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) &#123; throw new InterruptedException(); &#125; // 添加一个 Node 至等待队列, 见 ㈠ Node node = addConditionWaiter(); // 释放节点持有的锁 int savedState = fullyRelease(node); // 获得最后期限 final long deadline = System.nanoTime() + nanosTimeout; int interruptMode = 0; // 如果该节点还没有转移至 AQS 队列, 阻塞 while (!isOnSyncQueue(node)) &#123; // 已超时, 退出等待队列 if (nanosTimeout &lt;= 0L) &#123; transferAfterCancelledWait(node); break; &#125; // park 阻塞一定时间, spinForTimeoutThreshold 为 1000 ns if (nanosTimeout &gt;= spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); // 如果被打断, 退出等待队列 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; nanosTimeout = deadline - System.nanoTime(); &#125; // 退出等待队列后, 还需要获得 AQS 队列的锁 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; // 所有已取消的 Node 从队列链表删除, 见 ㈡ if (node.nextWaiter != null) unlinkCancelledWaiters(); // 应用打断模式, 见 ㈤ if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return deadline - System.nanoTime();&#125;// 等待 - 直到被唤醒或打断或超时, 逻辑类似于 awaitNanospublic final boolean awaitUntil(Date deadline) throws InterruptedException &#123; // ...&#125;// 等待 - 直到被唤醒或打断或超时, 逻辑类似于 awaitNanospublic final boolean await(long time, TimeUnit unit) throws InterruptedException &#123; // ...&#125;// 工具方法 省略 ...&#125; 读写锁ReentrantRedWriteLock读写操作分离，提高性能 例如 1234567891011121314151617181920212223242526272829class DataContainer &#123; private Object data; private ReentrantReadWriteLock rw = new ReentrantReadWriteLock(); private ReentrantReadWriteLock.ReadLock r = rw.readLock(); private ReentrantReadWriteLock.WriteLock w = rw.writeLock(); public Object read() &#123; log.debug(\"获取读锁...\"); r.lock(); try &#123; log.debug(\"读取\"); sleep(1); return data; &#125; finally &#123; log.debug(\"释放读锁...\"); r.unlock(); &#125; &#125; public void write() &#123; log.debug(\"获取写锁...\"); w.lock(); try &#123; log.debug(\"写入\"); sleep(1); &#125; finally &#123; log.debug(\"释放写锁...\"); w.unlock(); &#125; &#125;&#125; 注意事项： 读锁不支持条件变量 重入时升级不支持：即持有读锁的情况下去获取写锁，会导致获取写锁永久等待 不能有读锁再获取写锁 重入时降级支持：即持有写锁的情况下去获取读锁 应用缓存Map的key必须是不可变而且要重写equals和hashCode方法 保证可变可以将属性私有化，不提供set方法。只在构造时使用 这只是样例，还要很多问题 适合读多写少，如果写操作比较频繁，以上实现性能低 没有考虑缓存容量 没有考虑缓存过期 只适合单机 并发性还是低，目前只会用一把锁 更新方法太过简单粗暴，清空了所有 key（考虑按类型分区或重新设计 key） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374class GenericCachedDao&lt;T&gt; &#123; // HashMap 作为缓存非线程安全, 需要保护 HashMap&lt;SqlPair, T&gt; map = new HashMap&lt;&gt;(); ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); GenericDao genericDao = new GenericDao(); public int update(String sql, Object... params) &#123; SqlPair key = new SqlPair(sql, params); // 加写锁, 防止其它线程对缓存读取和更改 lock.writeLock().lock(); try &#123; int rows = genericDao.update(sql, params); map.clear(); return rows; &#125; finally &#123; lock.writeLock().unlock(); &#125; &#125; public T queryOne(Class&lt;T&gt; beanClass, String sql, Object... params) &#123; SqlPair key = new SqlPair(sql, params); // 加读锁, 防止其它线程对缓存更改 lock.readLock().lock(); try &#123; T value = map.get(key); if (value != null) &#123; return value; &#125; &#125; finally &#123; lock.readLock().unlock(); &#125; // 加写锁, 防止其它线程对缓存读取和更改 lock.writeLock().lock(); try &#123; // get 方法上面部分是可能多个线程进来的, 可能已经向缓存填充了数据 // 为防止重复查询数据库, 再次验证 T value = map.get(key); if (value == null) &#123; // 如果没有, 查询数据库 value = genericDao.queryOne(beanClass, sql, params); map.put(key, value); &#125; return value; &#125; finally &#123; lock.writeLock().unlock(); &#125; &#125; // 作为 key 保证其是不可变的 class SqlPair &#123; private String sql; private Object[] params; public SqlPair(String sql, Object[] params) &#123; this.sql = sql; this.params = params; &#125; @Override public boolean equals(Object o) &#123; if (this == o) &#123; return true; &#125; if (o == null || getClass() != o.getClass()) &#123; return false; &#125; SqlPair sqlPair = (SqlPair) o; return sql.equals(sqlPair.sql) &amp;&amp; Arrays.equals(params, sqlPair.params); &#125; @Override public int hashCode() &#123; int result = Objects.hash(sql); result = 31 * result + Arrays.hashCode(params); return result; &#125; &#125;&#125; 原理加锁 读写锁用的是同一个 Sycn 同步器，因此等待队列、state 等也是同一个 流程与 ReentrantLock 加锁相比没有特殊之处，不同是写锁状态占了 state 的低 16 位，而读锁 使用的是 state 的高 16 位 123456789101112131415161718192021222324252627282930313233//写锁public void lock() &#123; sync.acquire(1);&#125;public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); int c = getState(); int w = exclusiveCount(c); //不等于表示可能加了读锁或写锁 if (c != 0) &#123; //w表示写锁，它等于0表示加的是读锁 if (w == 0 || current != getExclusiveOwnerThread())//看加锁是否是自己加的 可重入 return false;//读写互斥返回false if (w + exclusiveCount(acquires) &gt; MAX_COUNT)//如果加上1后超过16位写锁最大范围，返回 throw new Error(\"Maximum lock count exceeded\"); setState(c + acquires);//在原有写锁基础上加1 return true; &#125; //没加锁才会往这走 if (writerShouldBlock() ||//写锁是否应该阻塞，如果是非公平总返回false，公平锁会检查队列看队列的第二个是否存在，如果存在则返回true，表示队列优先 !compareAndSetState(c, c + acquires))//尝试去加锁，如果成功取反就是false。如果失败取反为true返回false return false; //设置owner线程 setExclusiveOwnerThread(current); return true;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071//读锁public void lock() &#123; sync.acquireShared(1);&#125;public final void acquireShared(int arg) &#123; //读写锁只会返回-1或正数，不会用到0 if (tryAcquireShared(arg) &lt; 0)//尝试去获取读锁 返回值：-1 表示失败 0 表示成功，但后继节点不会继续唤醒 正数表示成功，而且数值是还有几个后继节点需要唤醒，读写锁返回 1 doAcquireShared(arg);&#125;protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); int c = getState(); //写锁部分是否不为0 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current)//看加写锁的线程是否为当前线程 return -1;//失败返回-1 int r = sharedCount(c);//查看高16位读锁 if (!readerShouldBlock() &amp;&amp;//读锁应该阻塞 r &lt; MAX_COUNT &amp;&amp;//读锁是否没超过最大计数 //将c高位+1 compareAndSetState(c, c + SHARED_UNIT)) &#123; //下面是给读锁计数 if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1;//成功返回1 &#125; return fullTryAcquireShared(current);&#125;//加锁失败进入private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED);//加SHARED节点 而不是EXCLUSIVE 加节点也会有null节点 boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123;//如果前驱节点是head，则进入 int r = tryAcquireShared(arg);//尝试获取锁，加锁成功返回1 if (r &gt;= 0) &#123; setHeadAndPropagate(node, r);//将头节点替换成它的下一个节点 p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; //将前驱节点设为-1返回false 第二次循环 //第二次后进入park阻塞住 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt())//释放锁后会唤醒 interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 加读锁是加的是share锁，加写锁时加的是EXCLUSIVE锁。 123456789101112131415161718192021222324252627282930313233//释放锁唤醒后加读锁的一部分流程//该方法就是将头节点的下一个节点设置为头节点private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node); if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; //如果节点是可共享的则进入，这里可以共享读锁，防止写锁 if (s == null || s.isShared()) doReleaseShared();// &#125;&#125;private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; //尝试将头节点从-1改成0，防止其它线程干扰，如果其它线程进来了发现还是-1又要做一次唤醒就重复操作了。失败则重新尝试 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; unparkSuccessor(h);//唤醒头结点的后继节点 &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; &#125; if (h == head) break; &#125;&#125; 解锁 12345678910111213141516171819202122232425//写锁public void unlock() &#123; sync.release(1);&#125;public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123;//尝试解锁 Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); //唤醒后的操作看加锁部分的park return true; &#125; return false;&#125;protected final boolean tryRelease(int releases) &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); int nextc = getState() - releases;//原来基础上减一 boolean free = exclusiveCount(nextc) == 0;//写锁是否减到0 if (free)//释放锁 setExclusiveOwnerThread(null); setState(nextc); return free;//减为0 就返回真 否则返回false&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101//读锁public void unlock() &#123; sync.releaseShared(1);//这里没有用到返回值&#125;public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123;//读锁释放完才会执行下面 doReleaseShared(); return true; &#125; return false;&#125;protected final boolean tryReleaseShared(int unused) &#123; Thread current = Thread.currentThread(); if (firstReader == current) &#123; if (firstReaderHoldCount == 1) firstReader = null; else firstReaderHoldCount--; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); int count = rh.count; if (count &lt;= 1) &#123; readHolds.remove(); if (count &lt;= 0) throw unmatchedUnlockException(); &#125; --rh.count; &#125; for (;;) &#123; int c = getState(); int nextc = c - SHARED_UNIT;//在state上减高位1 if (compareAndSetState(c, nextc))//设置值 return nextc == 0;//还有读锁就返回false，如果读锁释放完，返回true &#125;&#125;private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; //尝试将头节点从-1改成0，防止其它线程干扰，如果其它线程进来了发现还是-1又要做一次唤醒就重复操作了。失败则重新尝试 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; unparkSuccessor(h);//唤醒头结点的后继节点 &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; &#125; if (h == head) break; &#125;&#125;final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor();//查看是否为第二节点 if (p == head &amp;&amp; tryAcquire(arg)) &#123;//获取写锁 setHead(node); p.next = null; failed = false; return interrupted;//获取成功，返回 &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt())//从这里恢复运行 interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); int c = getState(); int w = exclusiveCount(c); if (c != 0) &#123; if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); setState(c + acquires); return true; &#125; if (writerShouldBlock() || !compareAndSetState(c, c + acquires))//设置状态 return false; setExclusiveOwnerThread(current); return true;&#125; 读写戳锁StampedLock读读时候还是要修改状态，使用AQS方法，不够快。性能比不上不加锁。 在使用读锁、写锁时都必须配合【戳】使用 缺点：不支持锁重入和条件变量 加解锁 123456//读锁long stamp = lock.readLock();lock.unlockRead(stamp);//写锁long stamp = lock.writeLock();lock.unlockWrite(stamp); 乐观读：读取完毕后需要做一次 戳校验 如果校验通 过，表示这期间确实没有写操作，数据可以安全使用，如果校验没通过，需要重新获取读锁，保证数据安全。 12345long stamp = lock.tryOptimisticRead();// 验戳if(!lock.validate(stamp))&#123; // 锁升级 可以使用lock.readLock();&#125; Semaphore信号量。用来限制能同时访问共享资源的线程上限。 12345678910111213141516171819202122//范例public static void main(String[] args) &#123; // 1. 创建 semaphore 对象 Semaphore semaphore = new Semaphore(3); // 2. 10个线程同时运行 for (int i = 0; i &lt; 10; i++) &#123; new Thread(() -&gt; &#123; // 3. 获取许可 try &#123; semaphore.acquire(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; try &#123; //具体操作 &#125; finally &#123; // 4. 释放许可 semaphore.release(); &#125; &#125;).start(); &#125;&#125; 应用： 可以使用Semaphore限流，但只适用于单机情况下，而且仅仅限制的是线程数而不是资源数 用 Semaphore 实现简单连接池，对比『享元模式』下的实现（用wait notify），性能和可读性显然更好 原理许可存在AQS的state中 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//获取线程资源public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125;public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0)//tryAcquireShared由子类来实现，如果返回负数表示失败，大于等于0表示成功 doAcquireSharedInterruptibly(arg); //走完表示加锁成功&#125;public boolean tryAcquire() &#123; return sync.nonfairTryAcquireShared(1) &gt;= 0;&#125;final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; int available = getState();//获取状态置 int remaining = available - acquires;//获取一个后的剩余许可数 if (remaining &lt; 0 ||//如果remaining小于0 就不会执行compareAndSetState compareAndSetState(available, remaining)) return remaining; &#125;&#125;//竞争失败时要调用doAcquireSharedInterruptibly(arg);private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172//释放public void release() &#123; sync.releaseShared(1);&#125;public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123;//执行成功进入 doReleaseShared(); return true; &#125; return false;&#125;protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; int current = getState(); int next = current + releases;//释放是state+1 if (next &lt; current) // overflow throw new Error(\"Maximum permit count exceeded\"); if (compareAndSetState(current, next)) return true; &#125;&#125;private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; //看头节点状态是否为-1，如果-1就唤醒后继 if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; unparkSuccessor(h);//唤醒后继节点 &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; &#125; if (h == head) break; &#125;&#125;//唤醒后在这里private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); //看是不是队列第二 if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; //设置头节点， setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt())//在这里唤醒 throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; CountdownLatch倒计时锁：用来进行线程同步协作，让一个线程等待所有线程完成倒计时才恢复运行。 构造参数用来初始化等待计数值，await() 用来等待计数归零，归零后才能继续运行，countDown() 用来让计数减一 该锁是不能重用的 123456789101112131415161718192021222324public static void main(String[] args) throws InterruptedException &#123; CountDownLatch latch = new CountDownLatch(3); new Thread(() -&gt; &#123; log.debug(\"begin...\"); sleep(1); latch.countDown(); log.debug(\"end...&#123;&#125;\", latch.getCount()); &#125;).start(); new Thread(() -&gt; &#123; log.debug(\"begin...\"); sleep(2); latch.countDown(); log.debug(\"end...&#123;&#125;\", latch.getCount()); &#125;).start(); new Thread(() -&gt; &#123; log.debug(\"begin...\"); sleep(1.5); latch.countDown(); log.debug(\"end...&#123;&#125;\", latch.getCount()); &#125;).start(); log.debug(\"waiting...\"); latch.await(); log.debug(\"wait end...\");&#125; 线程池的线程，往往一直存活。所以join有局限性 CyclicBarrier可以重复使用，当计数变为0时，再次调用计数值又恢复 1234567891011121314151617181920212223242526272829public static void main(String[] args) &#123; ExecutorService service = Executors.newFixedThreadPool(3); //第一个值是计数，第二个值是计数为0时需要的操作 CyclicBarrier barrier = new CyclicBarrier(2, ()-&gt; &#123; log.debug(\"task1, task2 finish...\"); &#125;); for (int i = 0; i &lt; 3; i++) &#123; // task1 task2 task1 service.submit(() -&gt; &#123; log.debug(\"task1 begin...\"); sleep(1); try &#123; barrier.await(); // 2-1=1 &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;); service.submit(() -&gt; &#123; log.debug(\"task2 begin...\"); sleep(2); try &#123; barrier.await(); // 1-1=0 &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;); &#125; service.shutdown();&#125; 线程安全集合类 主要有三类 遗留的线程安全集合如 Hashtable ， Vecto 使用 Collections 装饰的线程安全集合，如： Collections.synchronizedCollection Collections.synchronizedList Collections.synchronizedMap Collections.synchronizedSet Collections.synchronizedNavigableMap Collections.synchronizedNavigableSet Collections.synchronizedSortedMap Collections.synchronizedSortedSet JUC中的类 JUC下又有三类：Blocking、CopyOnWrite、Concurrent Blocking 大部分实现基于锁，并提供用来阻塞的方法 CopyOnWrite 之类容器修改开销相对较重 (修改时拷贝)适用于读多写少 Concurrent 类型的容器 (性能高) 内部很多操作使用 cas 优化，多把锁，一般可以提供较高吞吐量 弱一致性 遍历时弱一致性，例如，当利用迭代器遍历时，如果容器发生修改，迭代器仍然可以继续进行遍 历，这时内容是旧的 求大小弱一致性，size 操作未必是 100% 准确 读取弱一致性 遍历时如果发生了修改，对于非安全容器来讲，使用 fail-fast 机制也就是让遍历立刻失败，抛出 ConcurrentModificationException，不再继续遍历 ConcurrentHashMapmap.computeIfAbsent：接受两个参数，一个key和参数为key生成value的方法。如果没有这个key就创建并且赋value。 参数key可以不使用，灵活点。 JDK7 hashmap会产生并发死链问题 JDK8 修改为尾插法，虽然不会出现并发死链问题，但依然不能在多线程的情况下安全扩容，还可能出现其他问题，如丢数据 JDK 8 ConcurrentHashMap 重要属性和内部类 1234567891011121314151617181920// 默认为 0// 当初始化时, 为 -1// 当扩容时, 为 -(1 + 扩容线程数)// 当初始化或扩容完成后，为 下一次的扩容的阈值大小也就是容量*3/4private transient volatile int sizeCtl;// 整个 ConcurrentHashMap 就是一个 Node[]static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123;&#125;// hash 表transient volatile Node&lt;K,V&gt;[] table;// 扩容时的 新 hash 表private transient volatile Node&lt;K,V&gt;[] nextTable;//下面都为Node的子类// 扩容时如果某个 bin 迁移完毕, 用 ForwardingNode 作为旧 table bin 的头结点 表示已经处理过 用get时遇到该节点表示要去新的对应节点找static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123;&#125;// 用在 compute 以及 computeIfAbsent 时, 用来占位, 计算完成后替换为普通 Nodestatic final class ReservationNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123;&#125;// 作为 treebin 的头节点, 存储 root 和 first 可以一定程度避免BOS攻击static final class TreeBin&lt;K,V&gt; extends Node&lt;K,V&gt; &#123;&#125;// 作为 treebin 的节点, 存储 parent, left, rightstatic final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123;&#125; 链表长度小于6时，红黑树会重新转为链表 重要方法 12345678// 获取 Node[] 中第 i 个 Nodestatic final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) // cas 修改 Node[] 中第 i 个 Node 的值, c 为旧值, v 为新值static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) // 直接修改 Node[] 中第 i 个 Node 的值, v 为新值static final &lt;K,V&gt; void setTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) CopyOnWriteArrayList适用于：读操作尽可能快，写满一些不要紧 读写锁的升级：读取完全不加锁，只有写写互斥 缺点：占内存、不能保证实时一致性 写的时候，复制一份再写。读的时候读的是老的 并发队列 BlockingQueue(阻塞队列)ArrayBlockingQueue有界、指定容量、指定是否公平。 公平会有性能损耗 LinkedBlockingQueue无界，take和put是两把锁。粒度更小，吞吐量更高 PriorityBlockingQueue支持优先级、不是先进先出排序、无界队列。 传入必须可比较，不然会抛异常 SynchronousQueue容量为0。本身不做存储，只做传递。 DelayQueue延迟队列，根据延迟时间排序 元素需要实现Delayed接口， 非阻塞并发队列ConcurrentLinkedQueue","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"并发编程","slug":"并发编程","permalink":"http://example.com/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"JVM","slug":"JVM","date":"2021-05-07T08:37:12.000Z","updated":"2021-07-08T08:57:38.619Z","comments":true,"path":"2021/05/07/JVM/","link":"","permalink":"http://example.com/2021/05/07/JVM/","excerpt":"","text":"内存与垃圾回收1、JVM与JAVA体系结构JVM规范下载，这里使用Java8 推荐书目： Java虚拟机规范：官方规范的翻译版不推荐阅读，需要时查阅 深入理解Java虚拟机-JVM高级特性与最佳实践：紫色 实战Java虚拟机-JVM故障诊断与性能优化 自己动手写Java虚拟机：用go语言实现，1w多行 Java虚拟机精讲 码出高效-Java开发手册 JVM：跨语言的平台。 字节码文件可以通过不同的变成语言来编译如：Kotlin、Clojure、Groovy、Scala、Jython、JRuby、JavaScript等。 随着Java7发布，Java虚拟机设计者通过JSR-292规范实现Java虚拟机上运行非Java语言程序 以后每个版本都会发布OpenJDK、OracleJDK。区别基于协议不同OpenJDK基于JPL、OracleJDK基于OTN 虚拟机 系统虚拟机：Visual Box，VMware。完全是对物理计算机的仿真，提供了可运行完整操作系统的软件平台 程序虚拟机：Java虚拟机。专门为执行单个计算机程序而设计，Java虚拟机中执行的指令成为Java字节码指令 JVM整体结构 类装载器子系统：装载Class files生成Class对象 运行时数据区：方法区和堆为多线程共享，其余为每个线程独有一份 执行引擎：含有解释器、JIT Compliter和垃圾回收器。 JIT将字节码编译后会在方法区缓存 JVM的架构模型 指令集的架构模型分两种：基于栈的指令集架构、基于寄存器的指令集架构 HotSpot虚拟机除了PC寄存器之外，再无其它寄存器。它的所有操作都需要出栈和入栈的操作。 俩种架构区别 基于栈式架构的特点 设计和实现更简单，适用于资源受限的系统。 避开了寄存器的分配难题：使用零地址指令方式分配 指令流中的指令大部分是零地址指令，其执行过程依赖于操作栈。指令集更小，编译器容易实现 不需要硬件支持，可移植性更好，更好实现跨平台 基于寄存器架构的特点 典型的应用是x86的二进制指令集：如传统的PC以及Android的Davlik虚拟机 指令集架构则完全依赖硬件，可移植性差 性能优秀和执行更高效 花费更少的指令去完成一项操作 在大部分情况下，基于寄存器架构的指令集往往都以一地址指令、二地址指令和三地址指令为主，而基于栈式架构的指令集却是以零地址指令为主 栈(总结)：跨平台性、指令多、性能较低 JVM的生命周期 启动：通过引导类加载器创建一个初始类来完成的，这个类是由虚拟机的具体实现指定 执行： 一个运行中的Java虚拟机有一个清晰的任务：执行Java程序 程序开始执行时他才运行，程序结束时就停止 执行一个所谓的Java程序时候，真正执行的是一个叫Java虚拟机的进程 可用jps命令查看Java程序进程 退出： 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致Java虚拟机进程终止 某线程调用Runtime类或System类的exit方法，或Runtime类的halt方法，并且Java安全管理器也允许这次exit或halt操作 除此之外，JNI规范描述了用JNI Invocation API来加载或卸载Java虚拟机时，Java虚拟机的退出情况 JVM发展历程 Sun Classic VM：第一款商用虚拟机，只提供了解释器。hotspot内置了此虚拟机 Exact VM：可以知道内存中某个位置的数据具体类型。编译器与解释器混合工作，热点探测(知道热点类) HotSpot VM：市场占有率最高 JRockit：BEA公司，专注于服务器应用。不关注启动速度，全部代码都靠即时编译器编译后执行，最快的JVM。有全面的Java运行时解决方案。面对低延迟应用解决方案JRockit Real Time。MissionControl服务套件，以极低开销监控程序的工具。 J9：IBM公司。专注于IBM公司的产 Azul VM：特定硬件平台虚拟机 Microsoft JVM：只能在win下运行 Taobao JVM：基于OpenJDK定制AlibabaJDK，简称AJDK。基于OpenJDK HotSpot VM的虚拟机。严重依赖于intel的cpu Dalvik VM：应用于Android系统，不遵循Java虚拟机规范，执行dex文件。寄存器的架构模型 Graal VM：最有可能取代HotSpot 2、类加载子系统类的加载过程 加载 通过一个类的全限定名获取定义此类的二进制字节流 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口 补充：加载.class文件方式 从本地系统直接加载 从网络获取，如Web Applet 从zip压缩包读取，如jar、war格式 运行时计算生成，如动态代理 从其他文件生成，如JSP 从专有数据库中提取.class文件 从加密文件中获取，防class文件反编译 链接 验证 保证Class文件符合要求，不危害虚拟机安全 主要有四种验证：文件格式验证、元数据验证、字节码验证、符号引用验证 准备 为类变量赋默认初始值即零值。 零值不为程序中指定的初始值，而是0或null或fals final修饰的static，在编译的时候就分配了，不在该阶段 也不会为实例变量分配初始化，类变量分配在方法区，而实例变量在Java堆中 解析 将常量池的符号引用转化为直接引用 实际上，解析往往会伴随JVM在执行完初始化后再执行 初始化 初始化阶段就是执行类构造器方法&lt;clinit&gt;()的过程。 &lt;clinit&gt;()方法不需定义，由javac编译器自动收集类中的所有类变量的赋值动作和静态代码块的语句合并而来， 类中后面声明的静态属性，是可以在前面的静态代码块中赋值，但不能调用 &lt;clinit&gt;()不同于类的构造器，构造器是虚拟机视角下的&lt;init&gt;() 若有父类，会先执行父类的&lt;clinit&gt;() &lt;clinit&gt;()方法在多线程下被同步加锁 可以在IDEA插件中搜索jclasslib Bytecode viewer直接查看字节码文件，然后在view-&gt;Show Bytecode with jclasslib可以显示。 类加载器分类 引导类加载器：目前只有Bootstrap Class Loader 自定义加载器：所有派生于抽象类ClassLoader的类加载器都划分为自定义类加载器 虚拟机自带的类加载器： 启动类加载器(引导类加载器，Bootstrap ClassLoader)：用C++实现，嵌套在JVM内部，用来加载Java核心库(JAVA_HOME/jre/lib/rt.jar、resources.jar或sun.boot.class.path路径下内容)，没有父加载器。用户创建的jar放在对应目录，它会自动由扩展类加载器加载 12345//查看能加载api的路径URL[] urls = sun.misc.Launcher.getBootstrapClassPath().getURLs();for (URL element : urls) &#123; System.out.println(element.toExternalForm());&#125; 应用程序类加载器(系统类加载器、AppClassLoader)：父类加载器为扩展类加载器，程序默认的类加载器。 用户自定义类加载器： 为什么要自定义加载器：隔离加载类(避免包冲突)、修改类加载的方式、扩展加载源、防止源码泄露 实现步骤：JDK1.2之前需要继承ClassLoader类重写loadClass()方法，JDK1.2之后建议加载逻辑写在findClass()中。若没有过于复杂的需求，可以继承URLClassLoader类，避免编写findClass()和获取字节码流方式 ClassLoader ClassLoader类，是抽象类，所有类加载器都继承它。(除了启动类加载器) getPrent()：返回它的超类加载器 loadClass(String name)：加载name类，返回java.lang.Class实例 findClass(String name)：查找name类，返回java..Class实例 finLoadedClass(string name)：查找已被加载过的name类，返回java.lang.Class实例 defineClass(String name,byte[] b,int off,int len)：将字节数组b转化类Java类，返回java.lang.Class实例 resolveClass(Class&lt;?&gt; c)：连接指定的一个Java类 获取ClassLoader方式 clazz.getClassLoader()：获取当前类的ClassLoader Thread.currentThread().getContextClassLoader()：获取当前线程上下文的ClassLoader ClassLoader.getSystemClassLoader()：后去系统的ClassLoader DriverManager.getCallerClassLoader()：获取调用者的CLassLoader 双亲委派机制 Java虚拟机对class文件采用按需加载方式，需要使用才会加载生成class对象。加载class时，采用双亲委派模式，把请求交给父类处理，一种任务委派模式。 工作原理：类加载器收到类加载请求，会先将该请求委托给父类加载器执行。父类也会如此，直到顶层启动类加载器。如果父类加载器可以完成加载，就成功返回。如果父类加载器无法加载，子加载器才会尝试自己加载。 优势：避免类的重复加载、保护程序安全，防止核心API被随意篡改 避免重复加载：因为双亲委派机制使得类加载也有此次关系 沙箱安全机制：自定义String时，加载器会加载rt.jar下的String，以保证堆源代码保护。 JVM中表示两个Class对象是否为同一个类的俩必要条件：包名+类名完全一致、类加载器一致 类的主动使用和被动使用 主动使用： 创建类的实例 访问某个类或接口的静态变量，或堆它赋值 调用类的静态方法 反射 初始化一个类的子类 Java虚拟机启动时被标明为启动类的类 JDK7开始提供的动态语言支持：java.lang.invoke.MethodHandle实例的解析结果，REF_getStatic、REF_putStatic、REF_invokeStatic句柄对应的类没有初始化，则初始化 被动使用：除了以上七种情况，其他使用都被看做被动使用，不会导致初始化类 3、运行时数据区及线程JVM内存布局规定了Java在运行过程中内存申请、分配、管理的策略。保证JVM的运行。不同JVM堆内存的划分方式和管理机制存在一些差异。 元空间：1.8以后叫永久代 线程独有：程序计数器、栈、本地站 线程间共享：堆、堆外内存(永久代或元空间、代码缓存) 每个JVM只有一个Runtime实例，即为运行时环境，相当于内存结构中的框框：运行时环境 在HotSpot JVM中，每个线程都与操作系统的本地线程直接映射。 如果程序中只有剩下守护线程，虚拟机就退出了。如果当前线程是最后一个普通线程，终止后，虚拟机就停了。 HotShot JVM的后台线程主要有： 虚拟机线程：JVM达到安全点才出现。主要执行垃圾收集、线程栈收集、线程挂起以及偏向锁撤销 周期任务线程：用于时间周期时间的体现，一般用于周期性调度执行 GC线程：垃圾收集 编译线程：将字节码编译为本地代码 信号调度线程：接受信号发给JVM，在内部调度进行处理。 4、PC寄存器PC寄存器(程序计数寄存器)：用来存储下一条指令的地址。 JVM中的PC寄存器是对物理PC寄存器的一种抽象模拟。 特点：内存空间小、速度最快，每个线程都有私有，与线程生命周期一致。程序计数器会存储当前线程正在执行的Java方法的JVM指令地址，或未指定值(undefned)。程序控制流程都依赖它完成。字节码解释器工作时，通过改变计数器的值来选取吓一跳执行的字节码指令。唯一一个在Java虚拟机中没规定如何oom情况的区域 未指定值是在执行native方法时 为了能记录各个线程正在执行的字节码地址，就给每个线程分配一个pc寄存器 并发：是可以交替执行。 并发：同时执行。 5、虚拟机栈栈是运行时的单位，堆是存储的单位 栈解决程序运行问题，堆解决数据的存储问题 Java虚拟机栈：每个线程创建时都会创建一个虚拟机栈，内部保存一个个的栈帧，对应一次次的Java方法调用。线程私有的。 生命周期：与线程生命周期一致。 做哦那个：主管Java程序运行，保存方法的局部变量、部分结果，并参与方法的调用和返回。 特点： 快速有效的分配存储方式，速度仅次于程序计数器 JVM对栈的操作只有两个：方法执行时入栈操作、结束后出栈 栈不存在垃圾回收问题 栈常见异常 Java虚拟机规范允许栈的大小是动态或固定不变的 如果是固定大小，如果线程请求分配的栈容量超过虚拟机栈允许的最大容量，虚拟机会抛出StackOverflowError异常 如果是动态扩展，在尝试扩展时无法申请到足够内存，或在创建新线程时没有足够内存去创建对应虚拟机栈，虚拟机会抛出OutOfMemoryError 设置栈空间大小在官网查看信息说明 通过-Xss size设置栈空间大小(以字节为单位) 123-Xss1m-Xss1024k-Xss1048576 IDEA可以在Run-&gt;Edit Configuration…设置VM options 栈的存储内容：栈中数据都是以栈帧的格式存在，这个线程上正在执行的每个方法都对应一个栈帧，栈帧是一个内存区块，是一个数据集，维系着方法执行过程中的各种数据信息 运行原理： 遵循：先进后出原则 在一条活动线程中，一个时间点上只能有一个活动的栈帧(栈顶栈帧)，成为当前栈帧，与之对应的方法就是当前方法，定义该方法得类就是当前类 执行引擎运用的所有字节码指令只针对当前栈帧进行操作 如果调用了其它方法，会创建新的栈帧并放在栈顶 不同线程中所包含的栈帧是不允许存在相互引用的 两种返回函数的方式都会导致栈帧被弹出：一是正常的函数返回，使用return指令、二是抛出异常(没有处理) 栈帧内部结构 局部变量表(Local Variables或本地变量表)： 操作数栈(Operand Stack或表达式栈) 动态链接(Dynamic Linking或指向运行时常量池的方法引用) 方法返回地址(Return Address或方法正常退出或异常退出的定义) 一些附加信息 方法返回地址、动态链接、一些附加信息，统称帧数据区 局部变量表： 定义为一个数字数组，主用与存储方法参数和定义在方法体内的局部变量。数据类型包括基本数据类型、对象应用和returnAddress类型。 局部变量表，最基本存储单元是Slot(变量槽) 在局部变量表里32位以内的类型只占一个slot(包括returnAddress类型)，64位的类型(long和double)占两个slot byte、short、char在存储前被转化为int，boolean也被转化为int，0表示false，非0表示true。 long和double，则占俩slot 每个Slot都会分配一个访问索引，通过索引访问指定局部变量值。 当实例方法被调用，它的方法参数和方法体内部定义的局部变量会被顺序复制到局部变量表的每个slot上。 如果访问64bit的局部变量值时，只需要使用前一个索引即可 如果当前帧是构造方法或实例方法创建，那么对象应用this会存放在index为0的slot上，其余参数按序排列。 没有声明的变量在局部变量表里是没有的。 slot槽位是可以重用的，如果一个局部变量过了其作用域，之后声明的新局部变量可以重复使用槽位，如 12345678public void test() &#123; int a = 0; &#123; int b = 0; b = a + 1; &#125; int c = a + 1;&#125; 局部变量表是建立在线程栈上，线程私有的，不存在数据安全问题 局部变量所需的容量大小在编译器就确定下来，并保存在方法的属性maximum local variables数据项中。方法运行期间不改变它的大小 在反编译后就是locals=?指的就是大小 在方法调用结束后，随着方法栈桢的销毁，局部变量表也会随之销毁 在class文件里，LineNumberTable记录的是指令行号和Java代码行号对应关系 在class文件里，LocalVariableTable就是局部变量表 里面startPC就是字节码指令行号，length和startPC结合是描述当前变量作用域的范围 在class文件里Descriptor就是描述参数和返回值，Access flags指权限(如public static) 变量分类： 按数据类型：基本数据类型、引用数据类型 按类中声明位置： 成员变量：在使用前，都经历默认初始化赋值 类变量：linking的prepare阶段：给类变量赋默认值–&gt;initial阶段：给类变量赋值即静态代码块赋值 实例变量：随着对象的创建在堆空间中分配变量空间，并进行默认赋值 局部变量：在使用期，必须显式赋值。 补充 在栈帧中，与性能调优关系最密切的就是局部变量表 局部变量表的引用会涉及垃圾回收，并且局部变量表的大小比较严重的影响了栈帧的大小。 局部变量表中变量也是重要的垃圾回收根节点，只要被局部变量直接或间接引用的对象都不会被回收 操作数栈：在方法执行过程中，根据字节码指令，往栈中写入数据或提取数据，即入栈/出栈 某些字节码指令将值压入操作数栈，其余的字节码指令将操作数取出栈，使用它们后再把结果压入栈。如执行复制、交换、求和等 主要用于保存计算过程的中间结果，同时作为计算过程中变量临时存储空间 操作数栈就是JVM执行引擎的一个工作区，当一个方法刚开始执行，新的栈帧也会被创建，这个方法的操作数栈是kk哦那个的 每个操作数栈都有一个明确的栈深度用于存储数值，所需的最大深度，在编译器就定义好，保存在方法的Code属性中，为max_stack的值 32bit占一个栈单位深度、63bit占两个栈单位深度 操作数栈并非采用索引的方式来访问，而是入栈和出栈操作来完成一次数据访问。 如果调用的方法带有返回值，返回值也会被压如操作数栈中，并更新PC寄存器的指令 操作数栈中元素的数据类型和字节码指令的序列严格匹配。由编译器在编译期间验证，在类加载过程中的类检验阶段的数据流分析阶段再验证 Java虚拟机的解释引擎是基于栈的执行引擎，栈就是指操作数栈 栈式架构虚拟机的入栈和出栈指令次数多。由于操作数存储在内存中，大量的出栈入栈会频繁的执行内存读写操作，影响执行深度，HotSpot引入了栈顶缓存技术，将栈顶元素全部缓存在物理CPU的寄存器中，来降低对内存的读写次数，提升执行效率 动态链接 大部分字节码执行的时候需要进行常量池访问，每个栈帧内部都包含一个执行运行时常量池中该栈帧所属方法的引用。为了能使得当前方法的代码能够实现动态链接。动态链接的作用就是将这些符号引用转换为调用方法的直接引用。 这里的#2就是动态链接 方法的调用： 在JVM中，将符号引用转化为调用方法的直接引用与方法的绑定机制有关 静态链接：被调用的目标方法在编译期可知，且在运行期保持不变，这时将调用方法的符号引用转为直接引用，过程称为静态链接 动态链接：被调用的方法在编译期无法确定下来，只能在程序运行期将调用方法的符号引用转化为直接引用，被称为动态引用 方法的绑定机制：绑定是一个字段、方法或类在符号引用被替换为直接引用的过程，这仅仅发生一次 早期绑定：被调用的目标方法如果在编译器可知，且运行期保持不变，即可将该方法和所属类型绑定。 晚期绑定：若被调用的方法在编译期无法确定，只能在运行期根据实际的类型绑定相关方法。则称晚期绑定。 Java中任何一个普通方法都具备虚函数的特征，相当于C++中虚函数，如果不希望某个方法拥有虚函数的特征时，可以用final来修饰该方法 虚方法：除非虚方法都为虚方法 非虚方法：在编译期间就确定了具体的调用版本，在运行期不变的，这样的方法被称为非虚方法(如：静态方法、私有方法、final方法、实例构造器、父类方法) 虚拟机提供了几条方法调用指令： 普通调用指令 invokestatic：调用静态方法，解析阶段确定为一方法版本 invokespecial：调用&lt;init&gt;方法、私有以及父类方法，解析阶段确定唯一方法版本 invokevirtual：调用所有虚方法 invokeinterface：调用接口方法 动态调用指令 invokedynamic：动态解析出需要调用的方法，再执行 在子类调用父类的final方法，不加super.指令可能是invokevirtual，但我们不认为它是虚方法 区分动态类型语言和静态类型语言：区别在于对类型的检查是在编译期还是运行期，前者静态类型语言，后者动态类型语言。 Java中重写本质 找到操作数栈顶的第一个元素所执行的对象的实际类型，记c 若类型c中找到与常量中描述符合简单名称都相符的方法，则进行访问权限校验，如果通过，就返回方法引用，如果不通过返回java.lang.IllegalAccessError异常 否则就按照继承关系网上找 如果始终没找到，抛出java.lang.AbstractMethodError java.lang.IllegalAccessError：当程序试图访问或修改一个属性或调用一个方法，这个属性或方法，没有权限访问时，会引起编译器异常，若错误发生在运行时，会报错。maven项目中jar包冲突经常会发生。 虚方法表：如果每次都动态分派，寻找相应目标，会影响效率，为了提高性能，JVM在类的方法区建立一个虚方法表。 每个类都有一个虚方法表，表中存放各个方法实际入口。 虚方法表在类加载的链接阶段被创建并开始初始化，类的变量初始化准备完之后，JVM会把该类的方法表也初始化完毕 方法返回地址 方法返回地址：存放调用该方法的pc寄存器的值 方法结束后，会返回到该方法被调用的位置，方法正常退出时，调用者的pc计数器的值作为返回地址，就是调用该方法指令的下一条指令的地址。若异常退出，返回地址要通过异常表来确定，栈帧中一般不保存这部分信息。 异常完成出口退出的不会给他的上层调用者产生任何返回值 返回指令：ireturn(boolean、byte、char、short、int)、lreturn、freturn、dreturn、areturn(引用)、return(void) 附加信息：可选。 面试题 举例栈溢出情况：StackOverflow 调整栈大小，能保证不出现溢出吗？不能 分配的栈内存越大越好吗?可能会挤占别的空间 垃圾回收是否会涉及到虚拟机栈?不会！ 程序计数器：无error无GC 虚拟机栈：存在error无GC。只有进栈出栈，出栈就相当于垃圾回收 本地方法栈：和虚拟机栈类似 堆：存在error有GC 方法区：存在溢出有error有GC 方法中定义的局部变量是否线程安全?具体问题具体分析。如果是方法内部创建销毁，不由参数传入或返回则是安全的。不然是不安全的 如果只有一个线程才可以操作此数据，必然是线程安全的。如果多个线程操作可能不安全 StringBuilder线程不安全、StringBuffer线程安全。 6、本地方法接口一个Native Method就是一个Java调用非Java代码的接口 为何要用Native Method 与Java环境外交互：如与底层系统交换信息等。为我们提供一个简洁的接口，无需区了解Java外的细节 与操作系统交互：通过本地方法，可以用Java实现jre与底层系统的交互 Sun’s Java：sun的解释器是c实现的，使得它能像c一样与外部交互 7、本地方法栈本地方法栈用于管理本地方法的调用。 线程私有 可以设置为固定或动态扩展的大小 如果超过分配大小报StackOverflowError异常 如果动态扩展，没有足够内存去创建本地方法栈。会抛出OutOfMemoryError异常 当线程调用本地方法时，就进入不再受虚拟机限制的世界，它和虚拟机拥有同样的权限 本地方法可以通过本地方法接口访问虚拟机内部运行时数据区 甚至可以使用本地处理器的寄存器 直接从本地内存的堆里分配任意数量的内存 不是所有JVM都都支持本地方法。Java虚拟机规范没有明确要求本地方法栈的使用语言、具体实现方式、数据结构等。也可以不实现本地方法栈。 在HotShot JVM中，直接将本地方法栈和虚拟机栈合二为一 8、堆方法区和堆对于一个进程(一个JVM实例)是唯一的。一个进程有多个线程。 堆是Java内存管理的核心区域。在JVM启动的时候就创建了，大小也就确定了，是JVM管理的最大的内存空间。 堆可以处于物理上不连续的内存空间，但逻辑上应该被视为连续的。 所有的线程共享Java堆，这里还能划分线程私有缓冲区(TLAB ) JVM规范描述：所有对象实例以及数组都应当在运行时分配在堆上。(实际上是”几乎”都在堆分配内存) 堆中对象，仅在垃圾收集时才会移除。 堆，是GC执行垃圾回收的重点区域。 堆内存大小可以调节 因为都共享的话并发能力较弱 在jdk/bin目录下的jvisualvm.exe工具可以查看进程的详细信息。并且可以在工具装插件 堆内存 现代垃圾收集器大部分基于粉黛收集理论设计，将堆空间细分 Java7以前：新生区、养老区、永久区 Java8及以后：新生区、养老区、元空间 新生区又分：伊甸园区、幸存者0区、幸存者1区(0区和1区不会同时使用，会选择一个使用) 新生区=新生代=年轻代、养老区=老年区=老年代、永久区=永久代 幸存者0、1区，又称from区和to区。 to区是指空的幸存者区 堆内存大小的设置： “-Xms”：用于表示堆区的起始内存等价于”-XX:InitialHeapSize” “-Xmx”：用于表示堆区的最大内存等价于“-XX:MaxHeapSize” 通常会将-Xms和-Xmx两个参数配置相同的值，为了能够在垃圾回收机制清理完堆区后不需要重新分隔计算堆区大小，从而提高性能 默认：初始内存大小为物理电脑内存大小/64、最大内存大小为物理电脑内存大小/4 123-Xms1m-Xms1024k-Xms1048576 12345678public static void main(String[] args) &#123; long initialMemory = Runtime.getRuntime().totalMemory() / 1024 / 1024; long maxMemory = Runtime.getRuntime().maxMemory() / 1024 / 1024; System.out.println(\"-Xms : \" + initialMemory + \"M\"); System.out.println(\"-Xmx : \" + maxMemory + \"M\"); System.out.println(\"系统内存大小为：\" + initialMemory * 64.0 / 1024 + \"G\"); System.out.println(\"系统内存大小为：\" + maxMemory * 4.0 / 1024 + \"G\");&#125; jstat gc 线程号查看进程的内存使用情况 查看堆空间参数： 1.jps 2.jstat -gc 进程id -XX:+PrintGCDetails S：幸存者区 E：伊甸园区 O：老年代 C：可用 U：用完 年轻代与老年代 JVM中的Java对象可以分为两类： 生命周期较短的瞬时对象 生命周期长，甚至与JVM生命周期一致 配置新生代与老年代在堆结构占比(一般不会改)： 默认 -XX:NewRatio=2，表示新生代1，老年代2 可以修改-XX:NewRation=4，表示新生代1，老年代4 -Xmn可以设置新生代空间大小(一般用不到)。可能会使得比例失效 jinfo -flag NRation 进程id可以查看进程的新生代与老年代占比 在HotSpot中，Eden空间和另外两个Survivor空间比例是8:1:1。可以通过-XX:SurvivorRatio=数字调整占比，默认为8。 几乎所有对象都是在Eden区new出来，绝大部分对象在新生代销毁 但实际情况，比例可能不是8。因为有一个适合设置，可以通过配置-XX:-UseAdaptiveSizePolicy关闭自适应，自适应也会影响，两个幸存者区，可能使得两个大小不一样。 分配对象过程：新创建的对象分配在伊甸园区，直到伊甸园区，放满。进行垃圾回收(YGC/Minor GC)。判断为垃圾的对象销毁，剩余对象放入幸存者区并且为每个对象分配一个年龄计数器(age)为1。再往伊甸园区创建对象，直到放满。触发GC。将伊甸园区未被销毁的对象和幸存者区未被销毁的对象age+1，放入另一个线程者区。然后循环往复。当幸存者区的对象age为15，晋升入老年代age为16。在老年代就不再考虑age值。 YGC/Minor GC触发的时候会将幸存者区和伊甸园区一起回收 幸存者满了不会触发垃圾回收，如果满了但没有达到15，会放入老年代。 可以设置XX:MaxTenuringThreshold=&lt;N&gt;设置区养老区的次数，默认15 总结： 幸存者S0、S1区：复制之后有交换，谁空谁是to。(复制指的是用到的复制算法) 垃圾回收：频繁在新生区，很少在养老区，几乎不在永久区/元空间 GC对比 GC的时候会导致用户线程的暂停 jVM进行GC时，并非每次都对三个内存(新生代、老年代、方法区)区域一起回收。大部分回收是在新生代。 HotSpot VM的实现，GC按照回收区域分俩类： 部分收集(Partial GC)：又分 新生代收集(Minor GC / Young GC)：当Eden代满，触发Minor GC。Survivor满不会触发。Minor GC非常频繁，回收深度快。会引发STW，暂停其它用户的线程，等结束再恢复。 老年代收集（Major GC / Old GC)：对象从老年代消失时，Major GC就发生了，往往还会伴随至少一次的Minor GC。老年代空间不足会先尝试触发Minor GC，空间还不足则触发major GC。Major比Minor慢10倍以上，STW时间更长。如果内存还不足报OOM 目前只有CMS GC会单独收集老年代 很多时候Major GC和Full GC混淆使用。需要具体分辨。 混合收集(Mixed GC)：收集整个新生代和部分老年代 目前只有G1 GC会有这种行为 整堆收集(Full GC) ：收集整个堆和方法区的垃圾收集 触发机制 System.gc()，但不是必然执行 老年代空间不足 方法区空间不足 通过Minor GC后进入老年代的平均大小大于老年代可用内存 由Eden、From区向To区复制时，对象大小大于To区可用内存，则把该对象转存到老年代且老年代的可用内存小于该对象大小。 分代思想 为何分代：不同的对象生命周期不同，70%—99%的对象都是临时对象 不分代也是完全可以的，分代的原因是为了优化GC性能。 大对象往往直接分配到老年代。因为幸存者区往往比伊甸园区小，伊甸园区都放不下一般直接到老年代。尽量避免大对象。 动态对象年龄判断：若Survivor区中相同年龄的对象大小总和大于Survivor空间的一半，那么年龄大于等于该年龄的对象直接进入老年代。无需达到阈值 空间分配担保：当GC后仍有大量对象存活。因为幸存者区较小，需要老年代担保，幸存者区无法容纳的对象放入老年代。 -XX:HandlePromotionFailure：在Minor GC之前，虚拟机会检查老年代最大可用的连续空间是否大于新生代所有的总空间。 若大于，则Minor GC安全 若小于，会查看-XX:HandlePromotionFailure是否为true 若为true，会检查老年代的连续空间是否大于历次晋升到老年代对象的平均大小 若大于，则尝试Minor GC，但仍有风险 若小于，则进行Full GC 若为false，则进行一次Full GC 现在的规则变为：只要老年代的连续空间大于新生代对象总大小或历次晋升的平均大小就会进行Minor GC，否则Full GC。 在JDK7以及之后，HandlePromotionFailure不会影响空间分配担保策略，但源码中仍然定义，只是不起作用。 TLAB TLAB解决的问题：堆区是线程共享区域，任何线程都能访问，由于对象实例化在JVM中非常频繁，因此在并发环境下堆区中划分内存空间是不安全的，为避免并发操作同一地址，需要加锁等机制进而影响分配速度。 TLAB：是从内存模型而不是垃圾收集的角度，对Eden区域进行划分。JVM在Eden区为每个线程分配了一个私有缓存区域。TLAB可以避免一系列非线程安全问题，同时还能提升内存分配的吞吐量，所以称为快速分配策略。 由Open JDK衍生的JVM都提供了TLAB的支持。 不是所有对象都在TLAB中成功分配，但TLAB确是JVM内存分配的首选。可以通过-XX:UseTLAB设置是否开启TLAB。默认情况下TLAB仅占Eden的1%。可以通过-XX:TLABWasteTargetPercent设置占比大小。一旦TLAB失败，JVM会通过加锁机制确保操作原子性。 堆空间参数设置 官网参数说明 测试堆空间常用的jvm参数： -XX:+PrintFlagsInitial : 查看所有的参数的默认初始值 -XX:+PrintFlagsFinal ：查看所有的参数的最终值（可能会存在修改，不再是初始值 具体查看某个参数的指令：jps：查看当前运行中的进程，jinfo -flag SurvivorRatio 进程id -Xms：初始堆空间内存 （默认为物理内存的1/64） -Xmx：最大堆空间内存（默认为物理内存的1/4） -Xmn：设置新生代的大小。(初始值及最大值) -XX:NewRatio：配置新生代与老年代在堆结构的占比 -XX:SurvivorRatio：设置新生代中Eden和S0/S1空间的比例 -XX:MaxTenuringThreshold：设置新生代垃圾的最大年龄 -XX:+PrintGCDetails：输出详细的GC处理日志 打印gc简要信息（用的少）：① -XX:+PrintGC ② -verbose:gc -XX:HandlePromotionFailure：是否设置空间分配担保 堆分配对象不是唯一的选择 如果经过逃逸分析，一个对象没有逃逸出方法的话，那么就可能被优化成栈上分配。这样就无需垃圾回收 此外，TaoBao VM中创新的GCIH技术实现off-heap，将生命周期较长的Java对象移到heap外，且GC不能管理GCIH内部Java对象。以此达到降低GC频率和提高效率的目的。 《深入理解Java虚拟机》：随着JIT编译器的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了 只要在该方法外部引用就是逃逸了。jdk开始就开启逃逸分析。 -XX:+DoEscapeAnalysis：老版本可以通过该参数开启逃逸分析 -XX:+PrintEscapeAnalysis：查看逃逸分析的筛选结果 使用逃逸分析后，可以做以下优化： 栈上分配：将堆分配转化为栈分配。 同步省略：如果一个对象被发现只能从一个线程被访问，对这个对象的操作可以不考虑同步 线程同步的代价是相当高的，代价是降低并发性和性能。 在动态编译同步块的时候，JIT编译器可以借助逃逸分析来判断同步块所使用的锁对象是否能够被一个线程访问而没有被发布到其他线程。如果没有，JIT编译器在编译时会取消对这部分代码的同步，也叫锁消除。 分离对象或标量替换：有的对象可能不需要作为一个连续的内存结构存在也能被访问，那么对象的部分或全部可以不存储在内存，而是CPU寄存器中(Java是放入栈中) 标量：指无法再分解为更小的数据的数据。如Java中的基本数据类型 聚合量：可以分解的数据 标量替换：经过逃逸分析，如果一个对象不被外界访问，可以把它分解成若干个成员变量还代替。 标量替换后，就存入栈中，减少GC和内存占用 -XX:-EliminateAllocations：关闭标量替换 -server -Xmx100m -Xms100m -XX:+DoEscapeAnalysis -XX:PrintGC -XX:+EliminateAllocations server：启动Server模式，在Server模式下才可以打开逃逸模式。默认打开 -XX:+DoEscapeAnalysis：启用逃逸分析 -Xmx100m：指定堆空间最大10MB -XX:PrintGC：打印GC日志 -XX:+EliminateAllocations：开启标量替换(默认打开) 逃逸分析并不成熟，因为无法保证逃逸分析的性能小号一定高于它的性能消耗。 HotSpot并未使用栈上分配，使用了标量替换。所以所有的对象实例都是创建在堆cc上。 9、方法区元空间、永久代都是方法区的实现。 栈、堆、方法区交互关系 线程共享的角度看： 计数器是没有GC和异常，虚拟机栈和本地方法栈没有GC。堆和元空间都有 Person person = new Persion()：中Person类是放在方法区，new对象是放入Java堆，person引用变量放入Java栈。 方法区逻辑上是堆空间一部分，但方法区可以即不GC也不压缩。规范没有要求方法区为堆的一部分，或不是。也没要求具体存储哪些数据。既可以动态扩展，也可以固定大小。 但对于HotSpot而言，方法区别名Non-Heap(非堆)，就是为了区分堆。所以方法区看作一块独立于Java堆的内存空间 方法区： 与堆一样，各个线程共享的内存区域 方法区在jvm启动时创建，实际的物理内存空间和堆一样可以不连续 方法区大小，可固定，可扩展 方法区的大小决定了可以保存多少类。太多类可能会导致方法区溢出，抛OOM 如加载大量第三方jar包；Tomcat部署工程过多；大量动态生成反射类 关闭JVM就会释放该区域内存 到JDK8，完全废弃永久代概念，与JRoctit、J9一样在本地内存中实现的元空间来代替。 元空间与永久代最大的区别：元空间不再虚拟机设置的内存中，而是本地内存 设置方法区内存大小(jdk7) -XX:PermSize：设置永久代初始分配空间，默认20.75m。jdk8替换为-XX:MetaspaceSize=size --XX:MaxPermSize：设置永久代最大可分配空间，32位默认64m，4位默认82m。jdk8替换为-XX:MaxMetaspaceSize jinfo -flag MetaspaceSize 进程id查看元空间大小 设置方法区内存大小(jdk8) -XX:MetaspaceSize=size：windows下默认21M。当超过该值，会触发Full GC。为避免频繁触发GC，可以设置较高的值 -XX:MaxMetaspaceSize：：值为-1，没有限制。 1234567891011121314151617181920212223//-XX:MetaspaceSize=10m -XX:MaxMetaspaceSize=10m 设置元空间大小//循环使得方法区溢出代码public class OOMTest extends ClassLoader &#123; public static void main(String[] args) &#123; int j = 0; try &#123; OOMTest test = new OOMTest(); for (int i = 0; i &lt; 10000; i++) &#123; //创建ClassWriter对象，用于生成类的二进制字节码 ClassWriter classWriter = new ClassWriter(0); //指明版本号，修饰符，类名，包名，父类，接口 classWriter.visit(Opcodes.V1_6, Opcodes.ACC_PUBLIC, \"Class\" + i, null, \"java/lang/Object\", null); //返回byte[] byte[] code = classWriter.toByteArray(); //类的加载 test.defineClass(\"Class\" + i, code, 0, code.length);//Class对象 j++; &#125; &#125; finally &#123; System.out.println(j); &#125; &#125;&#125; 如何解决OOM 要解决OOM异常或heap space异常，一般先通过内存映像分析工具，堆dump出来的堆存储快照分析，重点确认内存中对象是否必要的，分清楚是内存泄漏还是内存溢出 若是内存泄漏，通过工具查看泄露对象到GC Roots的引用链。找到泄漏对象是怎样的路径导致无法回收。然后定位泄漏代码的位置 内存泄漏，指内存中对象后续不会用到，但仍然被引用，使得无法被GC 若不存在内存泄漏，就要检查虚拟机堆参数。与机器物理内存对比，是否可以调大。从代码上检查是否存在生命周期过长的对象 方法区的内部结构 方法区主要存储：类型信息、常量、静态变量、即时编译器编译后的代码缓存等。 类型信息：clss、interface、enum、annotation。JVM必在方法区存储以下类型信息。 这个类型的完整院校名称(全名=包名.类名) 这个类型直接父类的完整有效名(对于interface或是java.lang.Object，都没有父类) 类型的修饰符(public,abstract,final) 这个类型直接接口的一个有序列表 域信息(Field)信息 所有域的相关信息以及域的声明顺序 域的相关信息包括：域名称、域类型、域修饰符(public，private，protected，static，final，volatile，transient) 方法信息 声明顺序 方法名称 返回类型 参数的数量和类型 方法的修饰符 方法的字节码、操作数栈、局部变量表及大小 异常表 每个异常处理的开始位置、结束位置、代码处理在程序计数器中的偏移地址、被捕获的异常类的常量池索引 全局常量：static final。被声明为final的类变量在编译的时候就被分配了 运行时常量池/常量池 方法区内部含运行时常量池。字节码文件内部含常量池。 字节码文件中常量池，加载到内存后，就是运行时常量池。 常量池表：包含各种字面量和对类型、域和方法的符号引用。 运行时常量池，在加载每个类和接口到虚拟机后，都会维护一个常量池。常量池内的数据像数组，通过索引访问。运行时常量池不仅包括编译器已经确定的数值字面量，也包括到运行期解析后才能获得的方法或字段引用。此时不再是常量池的符号地址，而是真实地址。运行时常量池具备动态性。能够扩展一些字节码文件内无的数据。 HotSpot中方法区变化 jdk1.6及以前 有永久代，静态变量放永久代 jdk1.7 有永久代，但已逐步”去永久代”，字符串常量池、静态变量移除，保存在堆 jdk1.7及以后 无永久代，类型信息、字段、方法、常量保存在本地内存的元空间，的那字符串常量池，静态变量仍在堆 为何替换永久代 永久代空间大小的设置是很难确定的：在某些场景下，动态加载类过多，很容易产生OOM 永久代进行调优是很困难的：主要回收常量池中废弃的常量和不再使用的类型 总结：本地内存可以很大，减少GC StringTable为何让如堆：因为永久代的回收率很低，只有在full gc才会触发，而full gc是老年代空间不足、永久代不足时才会触发。这导致StringTable回收效率低，而开发中有大量字符串会创建。 只要是对象实例，不管是不是静态都在Java堆中分配。 JDK7以后的HotSpot把静态变量与类型在Java语言一端的映射class对象存放在译器，存储于Java堆中。 JDK8以前静态变量的引用名是放在方法区。 方法区的垃圾回收 Java虚拟机规范，规范可以不在方法区实现垃圾收集。 这个区域的回收效果也不那么令人满意，尤其是类型的卸载，条件相当苛刻。但这部分的回收有时是必要的。曾经因为低版本HotSpot虚拟机未完全回收而导致内存泄漏。 方法区的垃圾回收，主要回收常量池中废弃的常量和不再使用的类型 常量(字面量和符号引用)主要有三类：这类回收比较简单，只要没有被任何地方引用，就可以被回收 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 类的回收比较苛刻，需要同时满足三个条件 该类的所有实例都被回收了。就是堆中不存在该类及其任何派生子类的实例 加载该类的类加载器以及被回收，这个条件除非是经过精心设计的可替换类加载器的场景，如OSGI、JSP的重加载等，否则通常很难达成 字节码文件是没有记录类加载器的。在被类加载器加载后，放入方法区。方法区里关于当前类记录了由谁进行加载，同时加载器也记录了加载过谁。 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 严格来说，major GC指的是老年代的GC，Full GC指的是整个堆区和方法区的GC 10、对象的实例化内存布局与访问定位对象的实例化 创建对象的方式 new 最常见的方式 单例模式下，构造器不对外暴露，调用它的静态方法。 工厂模式，创建。 Claa的newInstance()：反射方式，只能调用空参构造器，权限必须为public Constructor的newInstance(Xxx)：反射方式，可以调用空参、带参的构造器，权限没要求 使用clone()：不调用任何构造器，需要类实现Cloneable接口，实现clone() 使用反序列化：从文件中、网络中获取对象的二进制流 第三方库Ojbenesis 创建对象的步骤 判断对象对应的类是否加载、链接、初始化。如果已经加载直接下一步，如果没有就在双亲委派模式下使用类加载器进行查找对应class文件，如果有就加载，如果没有就抛出ClassNotFoundException异常。 为对象分配内存 如果内存规整：使用指针碰撞法 指针碰撞法：在剩余空间和已使用空间之间会有指针指向。如果剩余空间足够，指针相应移动到分界点。 如果内存不规整：虚拟机需要维护一个列表、空闲列表分配。 空闲列表：记录哪些内存块可用，再分配时从列表中找到一块足够的空间划分，任何更新列表。 说明：Java堆是否规整取决于所采纳的垃圾收集器是否带有压缩整理功能来决定 处理并发安全问题：因为Java堆是共享空间，多线程操作可能有并发安全问题。 采用CAS配上失败重试保证更新的原子性 每个线程预先分配一块TLAB：通过-XX:+/-UseTLAB参数设定jdk8 默认打开 初始化分配到空间：所有属性设置默认值，保证对象实例字段不在赋值时可以直接使用 设置对象的对象头：将对象所属类、对象的HashCode和对象的GC信息、锁信息等数据存储在对象的对象头中。这个过程具体取决于JVM实现。 执行init方法进行初始化：显式初始化、代码块中初始化、构造器中初始化 字节码角度创建对象： new：判断运行时常量池中是否有Object类，没的话用类加载器加载到方法区。再在堆空间确定空间大小和临时初始化。 dup：复制，将栈空间操作数栈中引用复制，共有俩个引用指向堆空间。一个是在栈底用于赋值操作。上面的用于调用相关方法 invokespecial：调用&lt;init&gt;方法，如果构造器有形参，也需要放入操作数栈。可能会属性进行初始化 astore_1：最后将变量从操作数栈取出，放入局部变量表。 对象的内存布局 对象头 运行时元数据 哈希值 GC分代年龄：age 锁状态标志：同步时锁 线程持有的锁 偏向线程ID 偏向时间戳 类型指针：指向类元素InstanceKlass，确 定该对象所属的类型(getclass) 若是数组，还要记录数组长度 实例数据：实体内真正存储的有效信息。包括父类继承下来的和本身拥有的 规则： 相同宽度的字段总是被分配在译器 父类中定义的变量会出现在子类之前 如果CompactFields参数为true(默认为true)：子类的窄变量可能插入到父类变量的空隙 对齐填充：不是必须，单纯的占位符 对象访问： JVM通过栈帧上referencec定位访问对象实例 对象访问的两种方式： 句柄访问 句柄池：堆空间的一片区域，放了大量句柄。一个对象对应一个句柄。存放俩个信息，一是存放实例数据的指针，二是到对象类型数据的指针 特点：速度慢，对象地址修改只需要修改句柄 直接指针：栈空间的引用直接指向对象实体，对象实体中有类型指针指向，对象类型数据 特点：速度快，但对象地址修改也要跟随变动 11、直接内存直接内存：位于Java堆外，直接向系统申请的内存区间。通常直接内存的访问速度优于Java堆。 NIO库允许使用直接内存 使用IO读写文件时，需与磁盘交互，需要由用户态切换到内核态。就需要俩份内存存储重复数据，效率低使用NIO读写文件，操作系统划出直接缓冲区直接被Java代码访问，只有一份，提高效率。 直接内存也可能导致OOM异常。它的大小受系统能给出的最大内存限制。 缺点：分配回收成本较高、不受JVM内存回收管理。 直接内存大小可以通过MaxDirectMemorySize设置。如果不指定默认和堆最大值一致。 12、执行引擎前端编译：Java程序到字节码文件 后端编译：执行引擎将字节码编译为机器指令 执行引擎在执行过程中执行什么字节码指令完全依赖于PC寄存器。每执行完一项指令操作后，PC寄存器就会更新下一条将被执行的指令地址。在执行过程中，执行引擎可能会通过存储在局部变量表中的对象引用定位到存储在堆中的对象实例信息，以及通过对象头中的元数据指针定位到目标对象的类型信息。 Java程序编译解释运行： 绿色为解释过程，蓝色为编译过程 解释器：虚拟机启动时会对字节码采用逐行解释的方式执行。 JIT编译器：虚拟机将源代码直接编译成和本地机器平台相关的机器语言 Java是半解释半编译型语言，可以编译执行也可解释执行。 机器在热机状态可以承受的负载大于冷机状态。如果以热机状态时流量切流，可能使冷机服务器过载假死。 因为热机状态有一部分字节码以及编译缓存为机器指令效率更高 编译器： 前端编译器：将.java文件变成.class文件的过程 后端运行期编译器：将字节码变成机器码的过程 静态提前编译器：直接将.java文件编译为本地机器代码 热点代码及探测方式 是否启动JIT编译器将字节码编译为本地机器指令，需根据执行的频率。执行频率高的代码，称之为”热点代码”，JIT编译器会在运行时针对这些代码做出深度优化。 栈上替换：一个被调用多次的方法，或是方法内部循环多次的循环体都能被称为”热点代码”，都可以通过JIT编译器编译为本地机器指令，由于这种编译方式发生在方法执行过程中，因此也被称为栈上替换，简称OSR。 目前HotSpot采用的热点探测方式是基于计数器的热点探测。HotSpot为每个方法都建立了2个不同类型的计数器，分别为方法调用计数器和回边计数器 方法调用计数器用于统计方法的调用次数 该计数器的默认阈值在Client模式下1500次，在Server模式下10000次。超过该阈值，就会触发JIT -XX:CompileThreshold：可以设定阈值 回边计数器用于统计循环体执行的循环次数 热度衰减： 如果不做设置，方法调用计数器统计的并不是方法被调用的绝对次数，而是相对频率，即一段时间内方法被调用的次数。当超过一定时间限度，如果仍然达不到阈值，就计数器就会变少一半。该过程称为衰减。这段时间称为半衰周期 -XX:UseCounterDecay可以关闭热度衰减 -XX:CounterHalfLifeTime设置半衰周期的时间，单位秒 HotSpot可以通过命令显式的指定虚拟机式完全采用解释器执行，还是完全采用即使编译器执行，或是混合： -Xint：完全采用解释器模式执行程序 -Xcomp：完全采用即时编译器模式执行程序，如果即时出问题，解释器会介入 -Xmixed：采用解释器+即时编译器的混合模式 如在命令行内java -Xmixed version：改模式 JIT分类 HotSpot内嵌俩个JIT编译器，Client Compiler和Server Compiler，简称C1和C2 -client：使用C1编译器。编译器对字节码简单和可靠的优化，耗时短。 优化策略： 方法内联：将引用的函数代码编译到引用点出，减少栈帧生成，减少参数传递以及跳转 去虚拟化：对唯一的实现类进行内联 冗余消除：在运行期间把一些不会执行的代码折叠掉 -server：使用C2编译器，进行耗时长的，激进的优化，执行效率高。用C++编写的 优化策略： 标量替换 栈上分配 同步消除：清除同步操作，通常指synchronized 分层编译策略：程序解释执行不开启性能监控可以触发C1编译，将字节码编译成机器码，也可以加上监控，C2会根据性能监控信息激进优化，优化失败就退回C1。-server模式下默认开启分层编译策略。互相协作完成编译任务 64位默认用server。使用client会被忽略。 JDK10起，HotSpot加入全新即时编译器Graal编译器，编译效果追平C2编译器，目前带“实验状态”标签，要使用开关参数-XX:+UnlockExperimentalVMOptions -XX:+UseJVMCICompiler激活才能用。 JDK9引入AOT编译器(静态提前编译器，和JIT一个性质)，AOT编译指的是在程序运行之前将代码转化为机器码的过程 即时编译指的是，在程序运行过程中，将字节码转化为机器指令并部署到托管环境中的过程 AOT的特点 优点：以即编译为二进制，不必等编译器预热，减少Java程序第一次运行慢的体验 缺点：破坏了一次编译，到处运行，必须为不同硬件、os编译对应发行包。降低了Java链接过程的动态性，加载的代码在编译器就必须全部已知。还需继续优化最初支持linux x64 13、StringTable JDK9及以后底层又char改为byte，String是主要的空间存储对象，大部分String是拉丁字符。拉丁字符一个byte就能存。其它String结构底层同样做了修改 String基本特性： 字符串常量池中不会存储相同内容的字符串 String的String Pool是固定大小的Hashtable，默认值1009(JDK7中默认长度60013，JDK8开始1009是可设最小值)若String Pool中String非常多，会造成hash冲突，从而导致链表很长，影响调用String.intern时的性能 -XX:StringTableSize可设置StringTable长度 String.inter()如果字符串常量池中没有对应的字符的话，则在常量池中生成，并返回常量池中地址。有就直接返回。 常量池：为了使8种基本数据类型和String运行过程中速度更快、更节省内存，都提供了一种常量池的概念。类似Java系统级别提供的缓存，由系统协调。 String的常量池比较特殊使用方法有两种 String info = &quot;xxx&quot;：双引号直接声明的String对象存储在常量池中 如果不是双引号声明的String对象，可以用intern()方法 Java6及以前，字符串常量池放在永久代，7 中Oracle工程师对字符串池的逻辑做了很大改变，将字符串常量池的位置调整到Java堆内 所有的字符串都保存在堆内，和其它普通对象一样，调优时仅需调整堆大小即可 字符串常量池概念原本使用的较多，该改动使我们有足够理由重新考虑Java7中使用String.intern() 为何调整StringTable：1.因为永久代默认比较小，容易溢出2.永久代回收效率低 Java语言规范要求完全系统的字符串字面量，应该包含同意的Unicode序列，并且必须指向同一个String实例 字符串拼接操作 常量与常量(或常量引用)的拼接结果在常量池，原理是编译器优化。非StringBuilder 常量池中不存在相同内容的常量 只要其中有一个是变量，结果就在堆中。变量拼接原理是StringBuilder 12345//s1+s2的实质 5.0之前是StringBufferStringBuilder stringBuilder = new StringBuilder();stringBuilder.append(s1);stringBuilder.append(s2);stringBuilder.toString();//约等于new String(\"s1和s2的内容\") 如果拼接结果调用intern()，则主动将常量池中还没的字符串对象放入池中，并返回此对象地址。 总结：如果拼接符号前后出现了变量，则相当于在堆空间中new String()，具体的内容位拼接的结果 在开发中，如果基本确定前后添加字符串的长度不高于一个值，可以在创建StringBuilder的时候就指定它的容量 题目： new String(&quot;ab&quot;)会创建几个对象 从字节码看是两个，一个是new关键字在堆空间创建的，一个是常量池中的”ab”，用指令ldc取出入栈 new String(&quot;a&quot;) + new String(&quot;b&quot;)：有几个对象？ 对象1：new StringBuilder 对象2：new String(“a”) 对象3：常量池“a“ 对象4：new String(“b”) 对象5：常量池中的”b” 对象5：StringBuuilder的toString()会new String(“ab”)，但常量池中是没有ab的 1234567891011121314//jdk7后intern方法的变化public static void main(String[] args) &#123; String s = new String(\"1\"); s.intern();//调用此方法之前，字符串常量池中已经存在了\"1\" String s2 = \"1\"; System.out.println(s == s2);//jdk6：false jdk7/8：false String s3 = new String(\"1\") + new String(\"1\");//s3变量记录的地址为：new String(\"11\") //执行完上一行代码以后，字符串常量池中，是否存在\"11\"呢？答案：不存在！！ s3.intern();//在字符串常量池中生成\"11\"。如何理解： // jdk6:在常量池创建了一个新的对象\"11\",也就有新的地址。 // jdk7:此时常量中并没有创建\"11\",而是创建一个指向堆空间中new String(\"11\")的地址 String s4 = \"11\";//s4变量记录的地址：使用的是上一行代码代码执行时，在常量池中生成的\"11\"的地址 System.out.println(s3 == s4);//jdk6：false jdk7/8：true&#125; 12345678910//intern扩展public static void main(String[] args) &#123; //StringIntern.java中练习的拓展： String s3 = new String(\"1\") + new String(\"1\");//new String(\"11\") //执行完上一行代码以后，字符串常量池中，是否存在\"11\"呢？答案：不存在！！ String s4 = \"11\";//在字符串常量池中生成对象\"11\" String s5 = s3.intern(); System.out.println(s3 == s4);//false System.out.println(s5 == s4);//true&#125; intern总结： jdk1.6中，将字符串尝试放入串池 若有，则不放入，返回串池中的地址 若无，则复制对象放入串池，并返回串池中地址 jdk1.7起，将字符串尝试放入串池 若有，则不放入，返回串池中地址 若无，则将对象的引用地址复制放入，并返回串池中引用地址 -XX:+PrintStringTableStatistics：打印字符串常量池的统计信息 G1的String去重 堆许多Java应用中，堆存活数据集合里String占25%、重复的String有13.5%、String的平均长度位45. 垃圾收集器工作时，会访问堆上存活的对象，对每个访问的对象都检查是否是候选的要去重的String对象。 若是，将该对象的一个引用插入到对象中等待处理。一个去重线程在后台运行处理该队列。处理一个元素意味着从队列删除这个元素，然后尝试去重它引用的String对象 使用hashtable来记录所有被String对象使用的不重复的cahr数组，去重时，查询该hashtable，看堆上是否有一样的cahr数组 若存在，String对象会调整引用那个数组，释放堆原来的数组的引用，然后被回收 若无，char数组会插入hashtable。 命令行选项： UseStringDepublication：开启String去重，默认不开启 PrintStringDeduplicationStatistics：打印详细的去重统计信息 StringDeduplicationAgeThreshold：达到该年龄的String对象被认为是去重的候选对象 14、垃圾回收概述垃圾：指在运行程序中没有任何指针指向的对象，就是需要被回收的垃圾 内存泄漏：垃圾对象无法被清除。 垃圾回收是对于堆和方法区，堆是工作重点。频繁收集Young区，较少收集Old区，基本不动Perm区 15、垃圾回收相关算法 垃圾标记阶段：对象存活判断 一个对象不再被任何存活对象继续引用时，就宣判死亡 判断对象存活方式： 引用计数算法：对每个对象保存一个整型的引用计数器属性，用于记录对象被引用的情况。有一个对象引用了它，计数器+1，引用失效计数器-1。当计数器值位0，就可以回收 优点：实现简单、易于辨识、效率高、没有延迟 缺点：需要单独字段存储，增加空间开销、每次赋值都要更新计数器，增加了时间开销、计数器无法处理循环引用的情况，导致Java的垃圾回收器没有使用这类算法 python引用了这个算法，如何解决循环引用 手动解除：在合适时机解除引用关系 使用弱引用weakref，weakref是python提供的标准库，旨在解决循环引用 因为Java中没选择该算法，所以Java中不会出现引用计数算法的内存泄漏 可达性分析算法(或根搜索算法、追踪性垃圾收集)：以根对象集合为起始点，按从上至下方式搜索被根对象集合所连接的目标对象是否可达，不可达意味着该对象死亡，可标记为垃圾对象 “GC Roots”根集合：一组必须活跃的引用 GC Roots包括以下几类元素 虚拟栈中引用的对象：如各线程被调用的方法中使用的参数、局部变量 本地方法栈内JNI引用的对象 方法区中类静态属性引用的对象：如Java类的引用类型静态变量 方法区中常量引用的对象：字符串常量池里的引用 所有被同步锁synchronized持有的对象 虚拟机内部的引用：基本数据类型对于的Class对象，一些常驻的异常对象、系统类加载器 反映Java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等 除了固定的GC Roots集合外，根据用户所选的垃圾收集器以及当前回收的内存区域不同，还会有其它对象“临时性”加入，共同构成根集合如：分代收集和局部收集 如果使用可达性分析算法来判断内存是否可回收，分析工作必须在一个能保障一致性的快照中进行。这点不满足的话准确性就无法保证。这也是导致GC时必须”Stop The World”的一个重要原因 即使号称几乎不会发生停顿的CMS手机其中，枚举根节点时也是必须要停顿的 引用链：搜索所走过的路径称为引用链 可用MAT来查看GC Roots MAT：Memory Analyzer简称，强大的Java堆内存分析器，用于查找内存泄漏以及查看内存消耗情况。基于eclipse开发的免费性能分析工具。官网下载地址 finalization机制 Java语言提供了对象终止机制允许开发人员提供对象被销毁之前的自定义处理逻辑。垃圾回收对象之前，会调用该对象的finalize()方法，该方法允许在子类中被重写，通常用于一些资源释放和清理工作 不要主动调用finalize()方法，应该交由垃圾回收机制调用。理由三点： 在finalize()时可能会导致对象复活 finalize()的指向时间是没保障的，完全由GC线程决定，可能永远不会执行 一个糟糕的finalize()会严重影响GC性能 由于finalize()方法的存在，虚拟机中对象一般处于三种可能状态： 可触及的：从根节点可以达到 可复活的：对象的所有引用被释放，但可能在finalize()中复活 不可触及的：finalize()调用后，没有复活。 对象只有在不可触及时才可以被回收 判断对象是否可回收，至少要经历两次标记； 如果该对象到GC Roots没有引用链，进行第一次标记 进行筛选，判断是否有必要执行finalize()方法 如果没有重写finalize()或意境调用过，则视为“没有必要执行”，判定为不可触及 如果重写了finalize()还未执行过，该对象会被插入F-Queue队列中，由一个虚拟机自动创建的、低优先级的Finalizer线程触发finalize()方法执行 finalize()是对象逃脱死亡的最后机会，如果对象在finalize()方法与引用链上任一对象建立联系，该对象会被移出”即将回收”集合。若该对象再次出现没有引用，这个情况下finalize()不会被再次调用，对象直接判定为不可触及状态。 获取dump文件 命令行使用jmap JVisualVM导出 在左侧“Application”子窗口中右击相应的应用程序，选择heap dump 在Monitor子标签页中点击Heap Dump按钮。 如果关闭JVisualVM快照就消失了，可以另存为。 开发中因为GC Roots比较多，我们通常只看一个引用变量的一支上，对应的对象。 -XX:+HeapDumpOnOutOfMemoryError：当堆空间出现OOM，生成dump 清除阶段 标记清除(Mark-Sweep)算法：当堆中有效内存空间被耗尽时，停止整个程序，然后进行两项工作，标记和清除 标记：Collector从引用根节点开始遍历，标记所有被引用对象，一般是可达对象(非清除对象) 清除：Collector堆堆内存所有对象线性遍历，如果发现对象不是可达对象，就清除。 缺点：效率不算高，需要STW，体验差。清除出的内存不连续，产生内存碎片，需维护一个空闲表 优点：易于理解 清除：并不是真置空，而是将需清除的对象地址保存在空闲地址列表 复制算法： 核心思想：将活着的内存空间分为两块，每次只使用其中一块，回收时将存活对象复制到未被使用的内存块中，之后清除正在使用的内存块中所有对象，交换两内存的角色。 优点：没有标记和清除过程，效率高、保证空间连续性，不会出现”碎片“问题 缺点：需要两倍内存空间、对于G1这种分拆大量region的GC，复制而不是移动，意味着GC要维护region之间对象引用关系，内存和时间开销变大。 若存活对象很多，复制算法就不会很理想 在新生代，对象通常朝生夕死，复制算法性价比很高 标记-压缩(或标记-整理、Mark-Compact)算法 第一阶段：和标记-清除算法一样 第二阶段：将所有存活对象压缩到内存的一段，按顺序排放 第三阶段：清理边界外所有空间 优点：消除了内存区域分散的缺点、消除了复制算法中内存消耗的缺点 缺点：效率低于复制算法、移动时如果对象被其它对象引用，还要调整引用地址、移动时需要STW 对比三种算法 Mark-Sweep Mark-Compact Copying 速度 中等 最慢 最快 空间开销 少(会堆积碎片) 少(不会堆积碎片) 通常需要活对象的2倍大小 移动对象 否 是 是 分代收集算法：不同生命周期的对象可以采用不同的收集方式，来提高效率。 目前所有GC都采用分代收集 增量收集算法：每次垃圾收集线程只收集一小片区域的内存空间，接着切换到应用程序线程，依次反复，直到垃圾收集完成。 总的来说，增量收集算法的基础仍然是标记-清除和复制算法 缺点：因为线程切换和上下文转换的消耗，使得垃圾回收总成本上升，造成系统吞吐量下降 为解决一次性所有垃圾处理时间过长。 分区算法：将大的内存区域分割称多个小块，每次合理收集若干个小区间，将整个堆划分成连续的不同的小区间region。每个小区见都独立使用、独立回收。可以控制一次回收多少小区间。 16、垃圾回收相关概念System.gc() System.gc();和Runtime.getRuntime().gc();的调用，会显示触发Full GC。 然而System.gc();调用附带一个免责声明，无法保证堆垃圾收集器的调用 一般情况下无需手动触发，应该自动进行。特殊情况下，如编写性能基准，可以在运行之间调用 System.runFinalization();会强制调用失去引用的对象的finalize()方法 123456789101112131415161718192021222324252627282930313233343536//System.gc()回收情况//不会回收public void localvarGC1() &#123; byte[] buffer = new byte[10 * 1024 * 1024];//10MB System.gc();&#125;//会回收public void localvarGC2() &#123; byte[] buffer = new byte[10 * 1024 * 1024]; buffer = null; System.gc();&#125;//不会回收，因为在局部变量表里，buffer还占据第二个位置public void localvarGC3() &#123; &#123; byte[] buffer = new byte[10 * 1024 * 1024]; &#125; System.gc();&#125;//会回收，value会替换掉buffer占的位置。public void localvarGC4() &#123; &#123; byte[] buffer = new byte[10 * 1024 * 1024]; &#125; int value = 10; System.gc();&#125;//会回收public void localvarGC5() &#123; localvarGC1(); System.gc();&#125; 内存溢出(OOM) javadoc对OutOfMemoryError的解释：没有空闲内存，并且垃圾收集器也无法提供更多内存。 由于GC一直在发展，一般情况下，很难出现OOM的情况 Java虚拟机堆内存不够主要原因有二 Java虚拟机的堆内存设置不够 代码中创建了大量大对象，并且长时间不能被垃圾收集器收集 通常情况下抛出OOM之前，通常垃圾收集器会被触发，但在分配超大对象超出堆最大值时，可能直接抛出OOM 老版本jdk由于永久代大小有限，永久代出现oom非常多见，随着元数据的映入，方法区内存不再那么窘迫，相应的OOM有所改观 内存泄漏 也称”存储渗漏”：严格来说，只有对象不会再被程序用到了，但GC又不能回收他们的情况，才叫内存泄漏。 实际情况中很多时候，一些不太好的处理会导致对象生命周期变得很长，甚至导致OOM，也可叫做宽泛意义上的“内存泄漏” 如类的静态变量 Java中举例： 单例模式：单例的生命周期和应用程序一样长，如果单例程序中，持有外部对象的引用，那么外部对象是不能被回收，导致内存泄漏 一些提供close的资源未关闭 STW事件 STW：指的是在GC过程中，会产生应用程序的停顿。停顿产生时整个程序线程都会暂停，没有任何响应，有点像卡死。 并发：不是真正意义上的“同时进行”，只是CPU快速切换，让用户感觉多个应用程序同时进行 并行：当CPU有多核时，一个核执行一个进程，另一个执行另一个。互不抢占CPU资源，可以同时进行 垃圾回收的并发与并行 并行：多条垃圾收集线程并行工作，但此时用户线程仍处于等待状态。 串行：相较于并行，单线程执行，内存不够，程序暂停，启动JVM垃圾回收器进行回收，回收玩，在启动程序的线程 并发：用户线程和垃圾收集线程同时执行，垃圾回收线程在执行时不停顿用户程序的运行。如CMS、G1 安全点：程序不是在任意地方都能停顿下来开始GC，只有在特定位置才能停顿开始GC，这种位置称为“安全点” Safe Point，太少可能导致GC等待时间太长，如果太多可能影响性能。 大部分指令执行时间非常短，通常会根据“是否具有让程序长时间执行的特征”为标准，如：选择一些执行时间较长的指令作为Safe Point，如方法调用、循环跳转和异常跳转等。 如何在GC发生时，让所有线程停顿(两种方式)： 抢先式中断(没有虚拟机采用)：先这段所有线程，如果有线程不在安全点，就再恢复线程，让线程跑到安全点 主动式中断：设置中断标志，各个线程运行到Safe Point时主动轮询这个标志，如果中断标志为真，则自行中断挂起 安全区域：指的是在一段代码中，对象的引用关系不会发生变化，在该区域中任何位置开始GC都是安全的。 当线程处于“Sleep”状态或“Blocked：无法响应中断请求，走到安全点，JVM也不大可能去等待线程被唤醒。 安全区域实际执行： 当线程运行到Safe Region时，标识进入Safe Region，如果这段时间发生GC，JVM会忽已标示的线程 当离开Safe Region时，会检查JVM是否完成GC，如果完成则运行，否则等待直到收到可以安全离开Safe Region的信号为止 引用 JDK1.2以后，Java堆引用的概念进行了扩充：强、软、弱、虚。引用强度依次减弱。后三个继承自java.lang.ref.Reference 强引用：最传统的”引用“定义，代码中普遍存在的引用赋值。无论任何情况下，只要强引用关系还在，垃圾收集器就永远不会回收掉被引用对象 软引用：系统将要发生内存溢出之前，将会把这些对象列入回收范围之内进行二次回收。 通常用来实现高速缓存，内存不足时清理掉。如Mybatis就用到 垃圾回收器在某个时刻决定回收软可达对象时，会清理软引用，并可选地将引用存放到一个引用队列 当内存足够时不会回收软引用。不够时才回收 123//软引用代码示例，别忘了销毁强引用SoftReference&lt;&gt; softRef = new SoftReference&lt;类型&gt;(具体对象);类型 对象 = softRef.get() 弱引用：只要垃圾收集器工作时，物理看见是否足够，都要被回收被弱引用关联的对象 由于垃圾回收器线程优先级很低，因此弱引用可能可以存在较长的时间。 弱引用和软引用一样，在构造弱引用时，可以指定一个由于队列，当被弱引用对象被回收时，就会加入指定由于队列，可以通过该队列追踪对象的回收情况。 WeakHashMap弱引用的HashMap，只要看到就回收 123Object obj = new Object();WeakReference&lt;Object&gt; wr = new WeakReference&lt;&gt;(obj);obj = null;//销毁强引用 虚引用：虚引用不会对对象生成时间构成影响，无法通过虚引用来获得一个对象实例。为一个对象设置虚引用关联的目的就是能在该对象被收集器回收时收到一个系统通知。 虚引用的get()方法返回总是null 设置虚引用关联的唯一目的就是在于追踪垃圾回收过程。如：在该对象被回收时收到一个系统通知。 123456789101112131415//创建时必须指定引用队列Object obj = new Object();ReferenceQueue&lt;Object&gt; phantomQueue = new ReferenceQueue&lt;&gt;();PhantomReference&lt;Object&gt; pf = new PhantomReference&lt;Object&gt;(obj, phantomQueue);obj = null;//可以用来判断是否被GCtry &#123; PhantomReference&lt;Object&gt; reference = (PhantomReference&lt;Object&gt;)phantomQueue.remove(); if (reference != null) &#123; System.out.println(\"已经被GC了\"); &#125;&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; thread.setDaemon(true);可以设置为守护线程，当程序中没有非守护线程了，守护线程也就自动结束 终结器引用(Final reference)：用以实现对象的finalize()方法，无需手动编码，其内部配合引用队列使用。在GC时，终结器引用入队。由Finalizer线程通过终结器引用找到被引用对象并调用它的finalize()方法，第二次GC才能回收被引用对象 17、垃圾回收器按线程数分，可分为： 串行垃圾回收器：在单CPU或硬件平台不是很好的场合。串行回收器的性能表现可以超过并行、并发回收器。所以串行回收默认被应用在客户端的Client模式下的jvm中 并行垃圾回收器：多个CPU同时执行垃圾回收，提升应用吞吐量，不过并行回收仍然与串行回收一样，采用独占式，使用STW机制 按照工作模式，可分为 并发式垃圾回收器：并发式垃圾回收器与应用程序交替工作，尽可能减少停顿时间 独占式垃圾回收器：一旦运行，就停止应用程序中所以用户线程，直到完全结束 按碎片处理方式分，可分为 压缩式：回收完成后，对存活对象进行压缩整理，消除回收后的碎片 非压缩式：不进行整理 按工作的内存区间分：年轻代、老年代 评估GC的性能指标 吞吐量：运行用户代码的时间占总运行时间的比例 暂停时间：STW的时间 内存占用：Java堆区所占用内存大小 快速：一个对象从诞生到回收所经历时间 垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总时间的比例 收集频率：收集操作发生的频率 前三个为重点，这三个构成“不可能三角”。暂停时间的重要性日益凸显。吞吐量也比较重要 吞吐量和暂停时间，式一顿矛盾体，无法兼得。 现在标准：在最大吞吐量优先的情况下，降低停顿时间 常见的垃圾回收器 7款经典的垃圾收集器： 串行回收器：Serial、Serial Old 并行回收器：ParNew、Parallel Scavenge、Parallel Old 并发回收器：CMS、G1 垃圾分代 收集器 新生代收集器：Serial、ParNew、Parallel Scavenge 老年代收集器：Serial Old、Parallel Old 整堆收集器：G1 图中为垃圾收集器的组合关系： 连线为JDK8之前不包括8的组合方案(CMS GC和MSC组为后备方案) 红色虚线：JDK8时将红虚线的两个组合声明废弃，在JDK9彻底移除 绿色虚线：JDK14弃用该组合 青色虚线：JDK14中，删除CMS垃圾回收器 Parallel Scavenge和Parallel Old为JDK8默认的组合， Parallel Scavenge和ParNew都是串行回收器，为何CMS不能和Parallel Scavenge搭配。Parallel Scavenge底层框架和CMS不兼容。 查看默认的垃圾收集器： -XX:+PrintCommandLineFlags查看命令行相关参数(包含使用的垃圾收集器) 使用命令行指令：jinfo -flag 相关垃圾回收器参数 进程ID JDK8版本下 ) JDK9版本下 Serial回收器 串行回收 作为HotSpot中Client模式下默认新生代垃圾收集器 采用复制算法、串行回收和“STW”机制的方式执行内存回收 在老年代的Serial Old收集器，采用串行回收、STW，标记-压缩算法 在Client模式下默认老年代垃圾收集器 在Server模式下的用途 与新生代的Parallel Scavenge配合使用 作为老年代CMS收集器的后备垃圾收集方案 优势：简单高效(与其他收集器的单线程比) -XX:+UseSerialGC可以指定年轻代和老年代都使用串行收集器 总结：现在很少使用串行垃圾收集器，只在限定单核才用。 ParNew回收器 并行回收 ParNew和Serial除了并行和串行外，几乎没有区别。在新生代同意采用复制算法、STW。 ParNew是许多JVM在Server模式下新生代默认垃圾收集器 在单CPU场景下，Serial效率更高。 除了Serial，目前只要ParNew能与CMS配合使用。 -XX:+UseParNewGC手动指定ParNew -XX:ParallelGCThreads指定线程数量， 默认和CPU核数一样。 Parallel Scavenge回收器 效率算法，机制方面和ParNew类似。不同的是它的目标是达到一个可控制的吞吐量。也被称为吞吐量优先垃圾收集器。自适应策略是俩回收器之间重要区别。 自适应调节策略：在JVM运行中，根据实际情况，动态调整内存分配情况。以达到最优策略。 高吞吐量可以高效利用CPU时间，尽快完成程序的运算，适合在后台运算，而不需要太多交互的任务。 Parallel收集器在JDK1.6提供了Parallel Old收集器来代替Serial Old收集器。 Parallel Old采用标记-压缩算法，同样基于并行和STW机制。 在程序吞吐量优先场景中，Parallel收集器和Parallel Old的组合，在Server模式下回收性能很不错。 JDK8中，默认此收集器 -XX:+UseParallelGC：指定年轻代使用Parallel -XX:+UseParallelOldGC：指定老年代使用并行回收收集器 上面俩参数，相互激活，开启一个另一个也会打开。JDK8中默认开启 -XX:ParallelGCThreads：设置收集器线程数。一般设置与核数一直 当CPU核数小于8时，该值等于CPU核数 当大于8时，等于3+[5*CPU_count]/8 -XX:MaxGCPauseMillis设置STW最大停顿时间，单位ms -XX:GCTimeRatio垃圾收集时间占总时间比例，默认为99，即垃圾回收时间不超过百分之1。与前面参数有一定矛盾性。 -XX:+UseAdaptiveSizePolicy设置Parallel Scavenge收集器具有自适应策略。默认打开 在该模式下，年轻代、eden、survivor的比例、晋升老年代的对象年龄等参数会自动调整。 在手动调优困难的场合，可以使用自适应方式。仅指定虚拟机的最大堆、目标的吞吐量、停顿时间。让虚拟机自动调优。 CMS回收器 低延迟 HotSpot虚拟机中第一款真正意义上的并发收集器，第一次实现了让垃圾收集线程与用户线程同时工作。 有很多Java应用集中在互联网站或B/S系统的服务端，要求低延迟，CMS符合需求。 CMS采用标记-清除算法，也会STW CMS无法和Parallel Scavenge配合，所以在JDK1.5中，配合CMS，往往在ParNew或Serial中选择一个 CMS工作过程较为复杂，分为4个主要阶段： 初始标记阶段：程序中所有工作线程都STW，仅仅只是标记出GC Roots能总结关联到的对象。速度很快 并发标记阶段：从GC Roots的直接关联对象，遍历整个对象图。耗时长，但不需要停顿用户线程 重新标记阶段：在并发标记阶段，会STW，收集线程和用户线程同时执行，会导致，对象标记变更。因此在修正比并发标记期间，会修正并发标记期间导致的变更的记录。时间比初始标记长，远比并发标记时间短 并发清除阶段：清理删除标记阶段判断的已死亡对象。释放内存空间。由于不移动存活对象，该阶段也能与用户线程并发。 因为，在CMS回收时，用户线程仍在运行，需要足够的内存。因此CMS应该是在堆内存使用率达到阈值时，开始回收。 若CMS过程中，预留内存无法满足程序需要，会出现”Concurrent Mode Failure”，这时，虚拟机会启用后备预案，临时启用Serial Old收集器。 优势：低延迟、并发收集 劣势：会产生内存碎片、对CPU资源非常敏感(总吞吐量降低)、无法处理浮动垃圾。 浮动垃圾：出现”Concurrent Mode Failure”时，并发标记产生的新垃圾，没被标记，导致新垃圾要到下一次GC才能释放 -XX:+UseConMarkSweepGC手动指定使用CMS，开启后会自动打开-XX:+UseParNewGC即：ParNew+CMS+Serial Old -XX:CMSlnitiatingOccupanyFraction设置要回收的阈值。若内存增长缓慢，可以设置较大值，若增长快，可以设置较小。 jdk5以前默认值为68%，6以上为92% -XX:+UseCMSCompactAtFullCollection：用于指定执行完Full GC后是否对内存空间进行压缩整理。 -XX:CMSFullGCsBeforeCompaction：设置多少次Full GC后压缩整理 -XX:ParallelCMSThreads设置CMS线程数。默认是(ParallelGCThreads+3)/4。 ParallelGCThreads是年轻代并行收集器的线程数。 在JKD9中CMS被标记为Deprecate。JDK14删除了CMS。在JDK14-XX:+UseConMarkSweepGC，不会报错，只会报warning，然后以默认GC方式启动JVM G1回收器(垃圾优先) 区域分代化 G1是一个并行回收器，将堆内存分割为很多不相关的区域。使用不同的Region表示Eden、幸存者区、老年代等。 有计划的避免了在整个Java堆中进行全区域垃圾收集。G1跟踪每个Region里，垃圾堆积的价值大小，在后台维护一个优先列表。每次根据允许收集时间，优先回收价值最大的Region。 G1面向服务器端，主要针对多核CPU和大容量内存的机器。 JDK7正式启用，JDK9以后的默认垃圾回收器。取代了CMS以及Parallel + Parallel Old组合。称为”全功能的垃圾收集器。” G1使用了全新的分区算法，特点： 并行与并发 并行性：G1回收期间，可以有多个GC线程同时工作，有效利用多核计算能力，此时用户线程STW 并发性：G1拥有与应用程序交替执行的能力，部分工作可和应用程序同时执行，因此，一般来说，不会在整个回收阶段发生完全阻塞应用程序的情况 分代收集 G1仍然属于分代型垃圾回收器，会区分年轻代老年代，依然有Eden区和Survivor区，但它不要求整个Eden区、年轻代或老年代是连续的，也不再固定大小和数量 将堆空间分为若干个区域(Region)，包含了逻辑上的年轻代和老年代 它同时兼顾年轻代和老年代。 空间整合 G1将region之间用复制算法，整体上可看作标记-压缩算法。可以避免内存碎片，有利于长时间运行，在大内存优势更加明显。 可预测的停顿时间模型(软实时(小误差))：能让使用者明确指定在长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。 由于分区的原因，G1可以只选取部分区域。 G1跟踪各个Region内垃圾堆积的价值大小(回收所得的空间大小以及回收所需时间的经验值)。后台维护一个优先列表，每次根据允许的时间，优先回收价值最大的Region。保证了在有限时间尽可能高的收集效率 缺点：相较于CMS，在程序运行过程中，G1无论是内存占用还是程序运行时的额外执行负载都比CMS高。 G1在大内存上优势比较大，6~8G式，俩差不多 G1参数设置 -XX:+UseG1GC：手动指定使用G1 -XX:G1HeapRegionSize：设置Region的大小。2的幂。范围为1到32MB。通常分为2048个区域，默认式堆内存的1/2000。 -XX:MaxGCPauseMillis：设置预期的最大GC停顿时间，默认200ms。JVM会尽量实现 -XX:ParallelGCThread：设置STW工作线程数，最多为8 -XX:ConcGCThreads：设置并发标记的线程数，将n设置为并行垃圾回收线程数(上个参数)的1/4左右。 -XX:InitiatingHeapOccupancyPercent：设置触发并发GC周期的Java堆占用率阈值。超过此值就触发GC，默认45。 常见操作步骤 开启G1 设置堆最大内存 设置最大停顿时间 剩下的都能交给JVM调优 G1使用场景 用来替换掉JDK1.5中的CMS，下面情况中，G1表现可能比CMS好 超过50%的Java堆被活动数据占用 对象分配频率或年代提升频率变化大 GC停顿时间过长(长于0.5至1秒) Region 一个region，只有一个角色。但是角色是可变的。有Eden、Survivor或OldTenured区域。 G1还增加了，新的内存区域，Humongous区域用于存储大对象，如果超过1.5region，就放到这 为了解决短期存在大对象，放入老年代影响性能的问题，划分了Humongous区来存放大对象，大多情况下，会把他当老年代的一部分来看待。 G1回收过程主要包括三个环节 年轻代GC 老年代并发标记过程 混合回收 (若需要，单线程、独占式、高强度的Full GC。是一种失败保护机制) 过程概述：当年轻代Eden区用尽时开始年轻代回收，G1的年轻代收集阶段是一个并行的独占式收集器。回收期间，暂停所有应用程序线程，启动多线程执行年轻代回收，然后将年轻代区间移动存活对象到Survivor区间或老年区间。当堆内存使用达到阈值后，开始老年代并发标记。标记完成开始混合回收，将老年区间移动存活对象到空闲区间。老年代回收器不需要整个老年代被回收，一次只需要扫描/回收一部分老年代的Region。老年代Region和年轻代一起被回收的。 记忆集与写屏障 问题：一个对象被不同区域应用，回收新生代也不得不扫描老年代。这样会降低GC效率。 解决：每个记忆集对应一个region，记录引用该区域的region的引用。当垃圾收集时，在GC根节点的枚举范围内加入记忆集，这样避免全局扫描和遗漏。 写屏障：每次对引用类型写操作时都会产生写屏障。会中断操作，检查是否引用在其它region。如果不同，就卡表，将相关引用信息记录到记忆集 回收过程详细(三大必过程+一个可选过程) 年轻代GC：在JVM启动时，G1会准备好eden，当Eden区空间耗尽，G1启动年轻代垃圾回收过程。只回收Eden区和Survivor区 TGC会STW，创建回收集。回收集指的是需要被回收的内存分段的集合。YGC的回收集包含Eden和Survivor 具体回收过程 扫描根：GC Roots，记忆集 更新RSet：处理dirty card queue中的card，更新RSet。此阶段完成后RSet可以准确的反映老年代对所在的内存分段中对象的引用。 dirty card queue：在引用赋值语句之前和之后执行特殊操作，在该队列入队一个对象引用信息card。以更新Rset。 这样性能更好 处理RSet：识别存活对象 复制对象：Eden区内存活对象复制到Survivor区，Survivor年龄+1，若达到阈值，或空间不够，晋升入老年代 处理引用：处理Soft，weak，phantom，Final，JNI Weak等引用，最终Eden为空，GC终止活动。 Survivor区满，是不会触发回收的 并发标记过程 初始标记阶段：STW，只是标示从根节点直接可达的对象 根区域扫描：扫描Survivor区直接可达的老年代区域对象，标记被引用的。这一过程必须在YGC之前完成。 并发标记：应用程序和标记并发执行。此过程可能被YGC中断。若发现区域对象中所有对象都是垃圾，那此区域立即回收。并发标记过程中，会计算每个region的对象活性(存活比例) 再次标记：修正上次的标记结果，STW。G1采用了比CMS更快的初始快照算法：snapshot-at-the-beginning(SATB) 独占清理：计算各个区域的存活对象和GC回收比例。进行排序。为下阶段做铺垫。STW 并发清理阶段：识别，并清空完全空闲区域 混合回收：当越来越多对象晋升到老年代，为会触发混合的垃圾收集器，Mixed GC。会回收整个Young Region和一部分Old Region。复制算法 并发标记结束后，老年代中全为垃圾的内存分段被回收了，部分为垃圾的内存被计算出来。默认情况下，老年代的内存分段会分8次(可以通过-XX:G1MixedGCCountTarget设置) 混合回收的回收集包括1/8的老年代内存分段，Eden区内存分段，Survivor区内存分段。混合回收的算法和年轻代回收完全一样，只是回收集多了老年代的内存分段。 老年代中，G1会优先回收垃圾多的分段。有一个阈值会决定内存分段是否回收-XX:G1MixedGCLiveThresholdPercent默认为65%。 混合回收并不一定要进行8此，阈值-XX:G1HeapWastePercent默认10%，意为允许堆内存有10%的空间被浪费。表面如果发现可以回收的垃圾占堆内存比例低于10%，就不再混合回收。 可选过程：Full GC G1会尽量避免Full GC。但如果上述不能正常工作，G1会停止应用程序的执行，使用单线程的内存回收算法，进行垃圾回收。 导致Full GC的原因：Evacuation(回收阶段)时候没有足够的to-space来存放晋升对象、并发处理过程完成之前空间耗尽。 G1优化 年轻代大小设置 避免使用-Xmn或-XX:NewRatio等选项显示设置年轻代大小。该选项是独占式，可能会覆盖暂停时间目标，使得无法达到。让JVM动态调整 暂停时间目标不要过于严苛 太严苛的暂停时间会使得，影响吞吐量。 垃圾回收器总结 垃圾收集器 分类 作用位置 使用算法 特点 使用场景 Serial 串行运行 新生代 复制算法 响应速度优先 单CPU的client模式 ParNew 并行运行 新生代 复制算法 响应速度优先 多CPU的Server模式与CMS配合使用 Parallel 并行运行 新生代 复制算法 吞吐量优先 后台运算，少交互的环境 Serial Old 串行运行 老年代 标记-压缩算法 响应速度优先 单CPU的client模式 Parallel Old 并行运行 老年代 标记-压缩算法 吞吐量优先 后台运算，少交互的环境 CMS 并发运行 老年代 标记-清除算法 响应速度优先 互联网或B/S业务 G1 并发、并行 老年代、新生代 标记-压缩、复制算法 响应速度优先 面向服务器端应用 -XX:+PrintCommandLineFlags：查看程序使用的默认JVM参数 -XX:+UseSerialGC:表明新生代使用Serial GC ，同时老年代使用Serial Old GC -XX:+UseParNewGC：标明新生代使用ParNew GC -XX:+UseParallelGC:表明新生代使用Parallel GC -XX:+UseParallelOldGC: 表明老年代使用 Parallel Old GC 说明：二者可以相互激活 -XX:+UseConcMarkSweepGC：表明老年代使用CMS GC。同时，年轻代会触发对ParNew 的使用 常用GC日志参数 -XX:+PrintGC：输出GC日志 -XX:+PrintGCDetails：输出GC详细日志 -XX:+PrintGCTimeStamps：输出GC的时间戳 -XX:+PrintGCDateStamps：输出GC时间戳，以日期的形式 -XX:+PrintHeapAtGC：在进行GC的前后打印出堆信息 -Xloggc:../logs/gc/log：日志输出路径 [GC和[Full GC说明此次停顿类型，若有Full则说明发生了STW Serial在新生代名字是Default New Generation，显示为DefNew ParNew在新生代为[ParNew Parallel Scavenge在新生代为[PSYoungGen G1显示为garbage-first heap Allocation Failure：失败原因，在年轻代没有足够空间 [PSYoungGen: 5986k-&gt;696K(8704K) 5986K-&gt;704K(9216K)：中括号内表示回收前年轻代大小、回收后大小。外表示回收前年轻代和老年代大小，回收后大小 user代表用户态回收好事、sys内核态回收耗时、rea实际耗时。由于多核时间总和可能会超过real jdk7中，空间不足，会先将eden区的晋升到老年代，然后再放入eden jdk8中，空间不足，直接放入老年代 垃圾回收器的新发展 串行的Full GC、Card Table扫描的低效等都被大幅改进 JDK10以后Full GC是并行运行的，很多场景下表现略优于Parallel GC 随着云计算兴起，在Serverless等新应用场景下，有了新舞台。 CMS在jdk9标记为废弃，14中移除 A No-Op Garbage Collector(无操作回收器)官网：只做内存分配，不做回收。JDK11新特性 Shenandoah GC：低停顿时间JDK12，OpenJDK9开始是默认回收器。RedHat出品。在OracleJDK不支持。宣称停顿时间与堆大小无关。 从结果看，吞吐量有明显下降 ZGC 革命性的ZGC：ZGC是一款基于Region内存布局的，(暂时)不设分代，使用读屏障、染色指针和内存多重映射等技术来实现可并发的标记-压缩算法，以低延迟为首要目标的垃圾收集器。 工作过程4个阶段：并发标记、并发预备重分配、并发重分配、并发重映射等 除了初始标记是STW，这部分时间非常少，其余都并发。 JDK14前，ZGC仅Linux支持，现在mac或windows也能使用ZGC-XX:+UnlockExperimentalVMOptions -XX:+UseZGC 吞吐量差不多，延迟极低。 ALiGC：基于G1，面向大堆 18、Class文件结构 编译器 前端编译器：将代码编译为字节码文件。javac是默认前端编译器。前端编译器不直接设计编译优化等方面的技术。 Eclipse使用ECJ编译器，一种增量式编译器。把为编译部分进行编译，效率较高 Tomcat也用的是ECJ Idea默认使用javac。也可设置位AspectJ编译器ajc 后端编译器： jit即使编译器，在运行过程中，将热点代码翻译为机器指令 AOT在运行之前，翻译为机器指令。但这样会打破动态性 Integer xx= 1这里调用的是Integer.valueOf(1)，如果在-128到12之间，返回的是提前生成好的对象 字节码 字节码：二进制的类文件，内容是JVM指令。 字节码指令：JVM的指令由一个字节长度的、代表某种特定操作的操作码以及后跟随的零或多个所需参数的操作数构成。 可以通过javap或idea的插件查看class文件 class的本质和内部结构 class文件的本质是以8位字节为基础单位的二进制流 class文件格式类似C语言结构体。结构中只有两种数据类型，无符号数和表。 无符号数属于基本数据类型，u1、u2、u4、u8来代表1、2、4、8哥字节的无符号数。可用来描述数字、索引引用、数量值或按utf-8编码 表是多个无符号数或其他表作为数据项。所有表习惯性以_info结尾。因为表没有固定长度，所以通常会在其前加个数说明 class总体内部结构： 魔数：标识该文件为class文件 每个class文件开头4字节无符号数字 只要是合法的都以ca fe ba be开头 class文件版本：紧接着魔数的4字节为版本号。5、6字节为副版本号minor_version，7、8字节为主版本号major_version。 主版本从45开始，JDK1.1开始每个JDK大版本发布，主版本+1。副版本除了主版本为45以外为3其它都为0。 向下兼容 常量池：class文件内容最丰富的区域 紧跟版本号的是常量池的数量，以及若干个常量池表项。 常量池容量计数器：计数从1开始。第0项空出来，为了满足后面某些指向常量池的索引值的数据在特定情况下需要表达“不引用任何一个常量池项目”的含义(相当于占用不表示什么)，这种情况用索引值0表示 如：0x0016就是22，实际为21个常量。索引1~21。 常量池表项中，存放编译期生成的各种字面量和符号引用。类加载后放入运行时常量池中。 常量池：存放字面量和符号引用。 字面量：文本字符串、声明为final的常量值 符号引用：类和接口的全限定名、字段的名称和描述符、方法的名称和描述符 全限定名：将全限定类名的分隔.改成/。最后加个; 描述符描述字段的数据类型、方法的参数列表和返回值 包含了class文件结构及其子结构中引用的所有字符串常量、类或接口名、字段名和其它常量。常量池中的每一项都具备相同的特征。第1个字节作为类型标记，确定该项的格式，称为tag byte。 类型 标志(或标识) 描述 CONSTANT_utf8_info 1 UTF-8编码的字符串 CONSTANT_Integer_info 3 整型字面量 CONSTANT_Float_info 4 浮点型字面量 CONSTANT_Long_info 5 长整型字面量 CONSTANT_Double_info 6 双精度浮点型字面量 CONSTANT_Class_info 7 类或接口的符号引用 CONSTANT_String_info 8 字符串类型字面量 CONSTANT_Fieldref_info 9 字段的符号引用 CONSTANT_Methodref_info 10 类中方法的符号引用 CONSTANT_InterfaceMethodref_info 11 接口中方法的符号引用 CONSTANT_NameAndType_info 12 字段或方法的符号引用 访问标志：用来区别接口类和访问权限级别 类索引、父类索引、接口索引集合 字段表集合 方法表集合 属性表集合 类型 名称 说明 长度 数量 u4 magic 魔数，识别class文件格式 4字节 1 u2 minor_version 副版本号(小版本) 2字节 1 u2 major_version 主版本号(大版本) 2字节 1 u2 constant_pool_count 常量池计数器 2字节 1 cp_info constant_pool 常量池表 n字节 constant_pool_count-1 u2 access_flags 访问标识 2字节 1 u2 this_class 类索引 2字节 1 u2 super_class 父类索引 2字节 1 u2 interfaces_count 接口计数器 2字节 1 u2 interfaces 接口索引集合 2字节 interfaces_count u2 fields_count 字段计数器 2字节 1 field_info fields 字段表 n字节 fields_count u2 methods_count 方法计数器 2字节 1 method_info methods 方法表 n字节 methods_count u2 attributes_count 属性计数器 2字节 1 attribute_info attribute 属性表 n字节 attributes_count","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://example.com/tags/JVM/"}]},{"title":"爬虫","slug":"爬虫","date":"2021-04-27T07:12:32.000Z","updated":"2021-07-08T08:59:08.872Z","comments":true,"path":"2021/04/27/爬虫/","link":"","permalink":"http://example.com/2021/04/27/%E7%88%AC%E8%99%AB/","excerpt":"","text":"爬虫web请求分析 服务器渲染：服务器将数据写好，一块返回 客户端渲染：先请求页面框架，再请求数据 http协议 请求： 请求行：请求方式 url 协议 请求头：服务器要用的附加信息 请求体：请求参数 响应： 状态行：协议 状态码 响应头：放一些客户端使用的附加信息 响应体：html，json等 requests模块安装 pip install requests：原生python conda install requests：anaconda下安装 如果太慢可以用清华源 pip install -i https://pypi.tuna.tsinghua.edu.cn/simple 下载的包 请求可以用F12中network的XHR筛选出第二次请求的数据 123456789101112131415161718192021222324252627282930313233343536373839import requests'''# get请求url = \"https://www.sogou.com/web?query=周杰伦\"headers = &#123; \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36\"&#125;resp = requests.get(url,headers=headers)print(resp)print(resp.text) # 拿到页面文本''''''# post请求url = \"https://fanyi.baidu.com/sug\"data = &#123; \"kw\":\"dog\"&#125;resp = requests.post(url,data=data)print(resp.json())'''url = \"https://movie.douban.com/j/chart/top_list?type=24&amp;interval_id=100%3A90&amp;action=&amp;start=0&amp;limit=20\"param = &#123; \"type\": \"24\", \"interval_id\": \"100:90\", \"action\": \"\", \"start\": \"0\", #从第0条开始 20条 \"limit\": \"20\"&#125;headers = &#123; \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36\"&#125;resp = requests.get(url=url, params=param, headers=headers)print(resp.request.url)print(resp.json())resp.close() #访问次数过多可能会报错，因为会保留访问连接 解析re解析正则试验正则的网站 元字符 匹配内容 \\w 匹配一位字母（包含中文）或数字或下划线 \\W 匹配一位非字母（包含中文）或数字或下划线 \\s 匹配任意的空白符（\\t，空格等） \\S 匹配任意非空白符 \\d 匹配一位数字 \\D p匹配非数字 \\A 从字符串开头匹配 \\z 匹配字符串的结束，如果是换行，只匹配到换行前的结果 \\n 匹配一个换行符 \\t 匹配一个制表符 ^ 匹配字符串的开始 $ 匹配字符串的结尾 . 匹配任意字符，除了换行符，当re.DOTALL标记被指定时，则可以匹配包括换行符的任意字符。 […] 匹配字符组中的字符 [^…] 匹配除了字符组中的字符的所有字符 * 匹配0个或者多个左边的字符。 + 匹配一个或者多个左边的字符。 ？ 匹配0个或者1个左边的字符，{}后非贪婪方式。 {n} 精准匹配n个前面的表达式。 {n,m} 匹配n到m次由前面的正则表达式定义的片段，贪婪方式 a|b 匹配a或者b。 () 匹配括号内的表达式，也表示一个组 \\b 单词结尾 \\ 转义 [xxx]：一个[]表示只匹配一个，内部写要匹配的字符。根据ascii进行范围比对。如果要匹配abc中的任意一个，就是[abc]或者 [0-9]表示匹配0到9任一字符 [a-zA-Z]：所有大小写 ^ab&amp;：表示匹配ab其他都不匹配 ing\\b：以ing结尾的单词 W{}：用来约束左边的符号。 \\d{2,}：匹配数字至少2个 贪婪匹配：在量词允许的情况下，按最多的匹配内容 \\d{3,}4：如果一个字符串出现多个4，一直会匹配到最后一个4 \\d{3,}?4：在量词后加?表示非贪婪模式。匹配到第一个4 \\：转义如\\\\表示\\ 在[]里，.、()等没有特殊意义，就表示该符号，但是-需要转义要用\\- ?问号常用到非贪婪匹配 re模块 用(?P&lt;名字&gt;具体正则)给组起名，在group方法时，可以传名字来拿 findall：按照完整的正则进行匹配，但只显示括号里匹配到的内容。没有括号显示所有 如果多个括号列表返回，元素为匹配到的括号元组 finditer：匹配字符串所有内容，返回迭代器 search：按照完整的正则进行匹配。反对一个match对象 group()：返回第一个匹配到完整显示 group(1)：返回匹配到的第一个括号，2、3…按照顺序 match：默认在正则前加了^ 预加载正则：complie 方法可以传入re.S表示.可以匹配换行符 ?:是可以不显示 ?P&lt;name&gt;：取名 (?P=name)：引用取名的，如果不相同就匹配不上 \\1：表示引用第一组的内容，但是\\1有特殊含义，所有往往在字符串前加r。用的少 123456789101112131415161718192021222324252627# (?P&lt;名字&gt;正则表达式)# ret.group('名字')# 分组命名的引用import reexp= '&lt;abc&gt;akd7008&amp;(&amp;*)hgdwuih&lt;/abb&gt;008&amp;(&amp;*)hgdwuih&lt;/abd&gt;'ret= re.search('&lt;(?P&lt;tag&gt;\\w+)&gt;.*?&lt;/(?P=tag)&gt;',exp)print(ret)import reexp= '&lt;abc&gt;akd7008&amp;(&amp;*)hgdwuih&lt;/abc&gt;008&amp;(&amp;*)hgdwuih&lt;/abd&gt;'ret= re.search(r'&lt;(\\w+)&gt;.*?&lt;/\\1&gt;',exp)ret= re.search('&lt;(\\w+)&gt;.*?&lt;/\\\\1&gt;',exp)print(ret)import reret=re.findall(r\"\\d+\\.\\d+|(\\d+)\",\"1-2*(60+(-40.35/5)-(-4*3))\")print(ret)ret = ['1', '2', '60', '', '5', '4', '3','','']ret.remove('')print(ret)ret = filter(lambda n:n,ret)print(list(ret))# 分组命名(?P&lt;组名&gt;正则) (?P=组名)# 有的时候我们要匹配的内容是包含在不想要的内容之中的,# 只能先把不想要的内容匹配出来,然后再想办法从结果中去掉 re不常用方法 12345import rere.split('[|]','sa|dsadd')#根据正则表达式切割保留，带括号会保留re.sub('\\d+','数字','sads45dfs566dd3556sadsa',2)#根据正则替换2次。sads数字dfs数字dd3556sadsare.subn('\\d+','数字','sads45dfs566dd3556sadsa')#返回替换后的和次数元组('sads数字dfs数字dd数字sadsa', 3)re.match('\\d+','123sdasa')#相当于在正则之前加了^。&lt;re.Match object; span=(0, 3), match='123'&gt; re编译和迭代 123456789import reret = re.compile('\\d+') # 编译正则表达式ret.search(\"传入字符串\\'sadsa56165\\'\")# 节省时间ret = re.finditer('\\d+', \"sad516das11d56as4dsa561das531fa6w465s3a21d321as5f1ds531gs56ad1ads65f4a684fa9d\")for i in ret: print(i.group())# 两个可以结合使用 实操豆瓣案例 123456789101112131415161718192021222324import reimport requestsimport csvurl = \"https://movie.douban.com/top250\"header = &#123; \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36\"&#125;resp = requests.get(url, headers=header)page_context = resp.textobj = re.compile(r'&lt;li&gt;.*?&lt;div class=\"item\"&gt;.*?&lt;span class=\"title\"&gt;(?P&lt;name&gt;.*?)' r'&lt;/span&gt;.*?&lt;p class=\"\"&gt;.*?&lt;br&gt;(?P&lt;year&gt;.*?)&amp;nbsp.*?&lt;span ' r'class=\"rating_num\" property=\"v:average\"&gt;(?P&lt;score&gt;.*?)&lt;/span&gt;.*?' r'&lt;span&gt;(?P&lt;num&gt;.*?)人评价&lt;/span&gt;', re.S)result = obj.finditer(page_context)f = open(\"data.csv\", mode=\"w\",encoding=\"UTF-8\")cvswriter = csv.writer(f)for it in result: dic = it.groupdict() dic['year'] = dic['year'].strip() cvswriter.writerow(dic.values())f.close() 电影天堂 bs4解析pip install -i https://pypi.tuna.tsinghua.edu.cn/simple bs4 1234567891011121314151617181920212223import requestsfrom bs4 import BeautifulSoupurl = \"http://xinfadi.com.cn/marketanalysis/0/list/1.shtml\"res = requests.get(url)page = BeautifulSoup(res.text, \"html.parser\") # 指定html解析器# find(标签,属性=值) class为关键字加_，返回一个 find_all返回所有# table = page.find(\"table\", class_=\"hq_table\")# 都可table = page.find(\"table\", attrs=&#123; \"class\": \"hq_table\"&#125;)trs = table.find_all(\"tr\")[1:]for tr in trs: tds = tr.find_all(\"td\") name = tds[0].text low = tds[1].text avg = tds[2].text high = tds[3].text gui = tds[4].text kind = tds[5].text date = tds[6].text print(name, low, avg, high, gui, kind, date) 123456789101112131415161718192021222324from bs4 import BeautifulSoupimport requestsimport timeurl = \"https://www.umei.cc/bizhitupian/weimeibizhi/\"resp = requests.get(url)resp.encoding = 'utf-8'main_page = BeautifulSoup(resp.text, 'html.parser')alist = main_page.find(\"div\", class_=\"TypeList\").find_all(\"a\")for a in alist: href = a.get('href') child_page_resp = requests.get(href) child_page_resp.encoding = 'utf-8' child_page_text = child_page_resp.text child_page = BeautifulSoup(child_page_text, \"html.parser\") p = child_page.find(\"p\", align=\"center\") img = p.find(\"img\") src = img.get(\"src\") img_resp = requests.get(src) img_name = src.split(\"/\")[-1] with open(\"img/\" + img_name, mode=\"wb\") as f: f.write(img_resp.content) time.sleep(1)print(\"over_all\") xpath解析安装lxml pip install -i https://pypi.tuna.tsinghua.edu.cn/simple lxml //：表后代 *：通配符 任意 1234567891011121314from lxml import etreeparser = etree.HTMLParser(encoding=\"utf-8\")tree = etree.parse(\"a.html\", parser=parser)# result = tree.xpath(\"/html/body/ol/li/a[@href='dapao']/text()\")#获取href属性是dapao的# print(result)ol_li_list=tree.xpath(\"/html/body/ol/li\")for li in ol_li_list: print(li.xpath(\"./a/text()\")) print(li.xpath(\"./a/@href\"))print(tree.xpath(\"/html/body/ul/li/a/@href\"))print(tree.xpath(\"/html/body/div[1]\"))# 浏览器F12 直接复制Xpath 进阶 模拟登录：处理cookie 防盗链处理：抓梨视频 Referer 代理：放封IP 模拟登录 可以通过使用session进行请求，session过程中cookie不会丢失 12345678910import requestsdata = &#123; \"loginName\":\"18614075987\", \"password\":\"q6035945\"&#125;url = \"https://passport.17k.com/ck/user/login\"session=requests.session()resp=session.post(url,data=data)resp=session.get(\"https://user.17k.com/ck/author/shelf?page=1&amp;appKey=2406394919\")print(resp.json())#也可以在headers里传入cookie 防盗链处理 1234567891011121314151617181920#梨视频案例import requestsurl = \"https://www.pearvideo.com/video_1723346\"contId = url.split(\"_\")[1]videoStatusUrl = f\"https://www.pearvideo.com/videoStatus.jsp?contId=&#123;contId&#125;&amp;mrd=0.9678561427651502\"#https://www.pearvideo.com/videoStatus.jsp?contId=1723346&amp;mrd=0.9678561427651502headers = &#123; \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36\", \"Referer\": f\"http://www.pearvideo.com/video_&#123;contId&#125;\" # 来源地址&#125;print(videoStatusUrl)resp = requests.get(videoStatusUrl, headers=headers)dic = resp.json()srcUrl = dic['videoInfo']['videos']['srcUrl']systemTime = dic['systemTime']srcUrl = srcUrl.replace(systemTime, f\"cont-&#123;contId&#125;\")with open(\"a.mp4\", mode=\"wb\") as f: f.write(requests.get(srcUrl).content) 代理 通过第三方的机器发送请求 百度找免费代理 123456import requestsproxies = &#123; \"https\":\"https://ip地址\"#有些直接ip地址就行，看版本，是http还是https看要爬取的网站&#125;resp = requests.get(\"http://www.baidu.com\",proxies=proxies)resp.encoding='utf-8' 网易云项目查看调用栈，从下往上依次调用。 点进去后，左下角的按钮，能使代码更美观 在最后停的地方打断点，逐个查看请求。 找到请求后，可以在call Stack查看调用栈。一直找到加密的位置。","categories":[],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://example.com/tags/%E7%88%AC%E8%99%AB/"},{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}]},{"title":"机器学习","slug":"机器学习","date":"2020-09-26T13:00:56.000Z","updated":"2021-07-08T08:59:17.722Z","comments":true,"path":"2020/09/26/机器学习/","link":"","permalink":"http://example.com/2020/09/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"一、初识机器学习定义： E：经验 T：任务 P：性能 监督学习：教计算机做某事 给算法一个数据集，其中包含正确答案 回归问题：预测连续正确输出 无监督学习：计算机自己学习，不给出答案 如自动分类朋友圈 二、单变量线性回归梯度下降法 在更新θ0和θ1需要同时更新。 α为学习速率，用来控制以多大的幅度来更新参数。 α后面的为偏导数项","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"计算机组成原理","slug":"计算机组成原理","date":"2020-09-25T05:19:40.000Z","updated":"2021-07-08T07:59:06.402Z","comments":true,"path":"2020/09/25/计算机组成原理/","link":"","permalink":"http://example.com/2020/09/25/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/","excerpt":"","text":"计算机组成原理—硬件 前置知识：数电 该课程是计算机课程中唯一一门讲授计算机硬件实现的课程。 什么是组成？组成是指计算机硬件系统的逻辑实现。 非物理实现 什么是逻辑实现：使用数电的知识来实现计算机的硬件系统 讲授内容 基本部件的结构和组织方式 基本运算的操作原理 基本部件和单元的设计思想 特色 计算机组成的一般原理，不以具体机型为依托 采用自顶向下的方式、层层细化 教材：唐朔飞 计算机组成原理(第2版) 因为不以具体机型为依托，学完后会觉得有点空，推荐两本教材可以实现课程的落地：《计算机组成与设计：硬件·软件接口》、《数字设计和计算机体系结构》 可以通过以上教材简单实现一个处理器(2) 一、计算机系统概论1.1计算机系统简介现代计算机的多态性 将感应器嵌入、装备到各种物体中，形成“物联网”，实现人类社会与物理系统的整合 计算机系统 硬件：计算机的实体 软件：由具有各类特殊功能的信息（程序）组成 系统软件：用来管理整个计算机系统 语言处理程序 操作系统 服务性程序 数据库管理系统 网络软件 应用软件：按任务需要编制成的各种程序 计算机系统的层次结构 系统复杂性管理的方法-1：抽象 软件角度划分 高级语言 — 虚拟机器M3 — 用编译程序翻译成汇编语言程序 汇编语言 — 虚拟机器M2 — 用汇编程序翻译成机器语言程序 操作系统 — 虚拟机器 — 用机器语言解释操作系统 以上是软件实现，以下是软件实现 机器语言 — 实际机器M1 — 用微指令解释机器指令 微指令系统 — 微程序机器M0 — 由硬件直接执行微指令 计算机组成与计算机体系结构从研究内容上来说有什么区别呢？ 计算机系统结构定义计算机系统的软硬件交界面，定义了哪些功能由软件来实现，哪些功能由硬件来实现，提供了上层软件进行编写的时候和硬件进行交互的接口 计算机体系结构：程序员所见到的计算机系统的属性概念性的结构与功能特性（指令系统、数据类型、寻址己数、I/O机理） 这里的程序员指的是机器语言程序员 计算机组成：实现计算机体系结构所体现的属性（具体指令的实现） 如：计算机体系结构规定有无乘法指令。计算机组成如何实现乘法指令。 1.2计算机的基本组成冯·诺依曼计算机的特点： 计算机由五大组成部分 运算器 控制器 存储器 输入设备 输出设备 指令和数据以同等地位存于存储器，可按地址寻访 指令和数据用二进制表示 指令由操作码（什么操作）和地址码（操作数）组成 存储程序 以运算器为中心 问题：以运算器为核心，会比较繁忙，也容易成为性能瓶颈 改进：以存储器为中心的计算器 现代计算机硬件结构 主机 CPU ALU—运算器 CU—控制器 主存、辅存—存储器 I/O设备 输入设备 输出设备 系统复杂性管理的方法-2： 层次化：将被设计的系统划分为多个模块或子模块 模块化：有明确定义的功能和接口 规则性：模块更容易被重用 是不是所有问题都可以用计算的方法来解决。可计算理论 计算机的工作准备 上机前的装备 建立数学模型 确定计算方法 编制解题程序 程序—运算的全部步骤 指令—每一个步骤 编程举例：同一算式，两种算法 指令格式：操作码+地址码 存储器 核心结构：存储体。要能保存指令和数据，并且能访问 存储体由若干个存储单元构成，存储单元由多个存储元件构成 存储单元存放了一串二进制代码（指令和数据都是存放在存储单元中） 存储字：存储单元中二进制代码的组合 存储字长：存储单元中二进制代码的位数 每个存储单元都可以赋予一个地址，每个存储单元存放一个存储字 MAR：存储器地址寄存器 反映存储单元的个数 保存地址 MDR：存储器数据寄存器 反映存储字长 如：MAR=4位、MDR=8位。存储单元个数16个，存储字长8 运算器运算器的基本组成及操作过程 ALU通常是组合电路 组合电路特点：如果输入撤销，输出结果也会相应撤销 为了使ALU能够完成运算功能，能够对结果进行保存，必须在ALU的输入端加上寄存器，寄存器保存参与运算的数据，需要两个寄存器作为输入数据的保存设备，一个是ACC一个是X（数据寄存器）acc也用于保存结果，当运算结果长度过长，我们将增加出来的长度保存至MQ ACC MQ(又叫乘商寄存器) X 加法 被加数、和 加数 减法 被减数、差 减数 乘法 乘积高位 乘数、乘积地位 被乘数 除法 被除数、余数 商 除数 乘法：利用加法和移位的方法。 除法：利用减法和移位的方法。 类似十进制的乘除法 加法操作： 初态 ACC 被加数 指令： 加 M [M]-&gt;X 从内存中读取到X [ACC]+[X]-&gt;ACC 减法类似加法 乘法操作： 初态 ACC 被乘数 指令： 乘 M [M]-&gt;X [ACC]-&gt;x 0-&gt;ACC [X]*[MQ]-&gt;ACC//MQ 除法操作： 初态 ACC 被除数 指令 除 M [M] -&gt;X [ACC] ÷ [X] -&gt;MQ 余数在ACC中 这些操作的先后顺序是由控制器来决定的 控制器功能： 解释指令：不是执行 从取址到分析，到取操作数，到执行指令，到保存结果都是由控制器来完成 保证指令的按序执行 控制器的基本组成 完成一条指令 取指令 程序计数器（PC）：存放当前欲执行指令的地址，具有计数功能（PC）+1—&gt;PC 分析指令 指令寄存器（IR）：存放当前欲执行的指令 执行指令 CU 从PC中取址指令 放入IR 然后PC自动指向下一条指令 完成一条取数指令的具体过程 取指令 PC将指令的地址送到MAR MAR送到存储体 在控制器的控制下，存储体把指定存储单元中保存的那条取数指令取出，送到MDR中 取出的指令，送至IR 分析指令 IR将指令的操作码部分送至CU 执行指令 IR将地址取出，送到MAR，MAR送到存储体 IR中不仅存放了指令地址，也存放了操作数的地址 在控制器的控制下，将取数指令要取得数取出 存入MDR 然后送入ACC 存数指令 取指令：与取数指令的取指令过程一致 分析指令 将IR中保存的指令操作码部分送给CU，由CU进行分析 执行指令 将IR中地址码部分送到MAR，由MAR送到存储体。告知有一个数据将要存入哪 将ACC的数据送到MDR 程序运行过程 将程序通过输入设备送至计算机 程序首地址—PC 启动程序运行 取指令 PC—&gt;MAR—&gt;MDR—&gt;IR，(PC)+1—&gt;PC 分析指令 OP(IR)—&gt;CU 执行指令 Ad(IR)—&gt;MAR—&gt;M—&gt;MDR—&gt;ACC 疑问：存储体，MDR MAR和M的区别 1.3计算机硬件的主要技术指标主要指标 机器字长：CPU一次能处理数据的位数，与CPU中的寄存器位数有关。 如：我的CPU可以一次对两个8位数字作运算得到一个8位数字。得机器字长8位，而不是24位。 运算速度 主频 核数、每个核支持的线程数 吉普森法 指令的静态使用频率：在程序清单上直接计算某一条指令出现频率 指令的动态使用频率计算在程序的执行过程中每一条指令出现的频率 CPI：执行一条指令所需要的时钟周期数。C：时钟周期、P：每一个、I：指令。 CPI越少越好。 IPC：一个时钟周期能完成多少指令 MIPS：每秒执行百万条指令 FLOPS：每秒浮点运算次数 在F前加M表示百万 是从机器做多少操作角度衡量（更合理） 存储容量：存放二进制信息的总位数 主存容量： 存储单元个数×存储字长 如MAR：10位 MDR：8位 1K × 8位 （2^10^约等于1k ） 字节数 如2^13^b=1KB、1B=2^3^b、2^21^=256KB 辅存容量：字节数 如80GB 二、计算机的发展和应用非主要学习内容 2.1计算机的发展史现代计算机产生的驱动力：需求 技术发展 电子技术的发展 计算机体系结构的发展 代 时间 硬件技术 速度次/秒 一 1946—1957 电子管 40 000 二 1958—1964 晶体管 200 000 三 1965—1971 中小规模集成电路 1 000 000 四 1972—1977 大规模集成电路 10 000 000 五 1978—现在 超大规模集成电路 100 000 000 IBM 360计算机 Moore定律：在价格不变的情况下，微芯片上集成的晶体管数目每三年翻两番 2.2计算机的应用科学计算和数据处理 工业控制和实时控制 网络技术 电子商务 网络教育 敏捷制造 虚拟现实 办公自动化和管理信息系统 CAD/CAM/CIMS 多媒体技术 人工智能 2.3计算机的展望芯片集成度的提高受限制 芯片集成度受物理极限的制约 按几何级数递增的制作成本 芯片的功耗、散热、线延迟 替代传统的硅芯片 光计算机 利用光子取代电子进行运算和存储，数据存储已经实现 DNA生物计算机 通过控制DNA分子间的生化反应 量子计算机 利用原子锁具有的量子特性 三、系统总线3.1总线的基本概念总线是链接各个部件的信息传输线，是各个部件共享的传输介质 总线上信息的传送： 串行：将要传输的信息一位一位的放置在总线。 并行：要传输的数据多位同时放在总线。需要多条数据线。 线和线之间会产生干扰，当线过长，接收方很难接收到正确的信息 单总线结构框图 在任何时刻只能有一个部件使用，会发生总线的征用，严重影响性能 如果设备过多总线过长，会导致延迟较高 面向CPU的双总线结构框图 主存无法跟直接外部设备信息传输，如果传输会打断cpu的计算任务 以存储器为中心的双总线结构框图 目前这两条总线还是无法做到同时传输，我们一般是使用分时技术来做 3.2总线的分类根据总线的位置分类 片内总线：芯片内部的总线 系统总线：计算机各个部分之间的信息传输线 数据总线：双向 与机器字长、存储字长有关。 通常情况，总线的宽度是小于等于机器字长或存储字长 地址总线：单向 与存储地址、I/O地址有关 控制总线：有出 有入 输出如存储器读、存储器写、总线允许、中断确认 输入如中断请求、总线请求 通信总线：用于计算机系统之间或计算机系统与其他系统（如控制仪表、移动通信等）之间的通信 根据传输方式分类 串行通信总线 并行通信总线 3.3总线特性及性能指标总线物理实现：其他部件 模块，可以通过接口连接到主板上 总线特性 机械特性：尺寸、形状、管脚数 及 排列顺序 电气特性：传输方向 和有效的 电平 范围 电平：什么样的高压范围，什么样的低压范围。 功能特性：每根传输线的 功能（传输什么类型的信号）（地址、数据、控制） 时间特性：信号的 时序 关系 总线的性能指标 总线宽度：数据线的根数 标准传输率：每秒传输的最大字节数（MBps） 时钟同步/异步：同步、不同步（不同步和异步不一样，有其他多种情况） 总线复用：地址线、数据线复（共）用 8086就是地址线 数据线复用 信号线数：地址线、数据线和控制线的总和 总线控制方式：突发、自动、仲裁、逻辑、计数 其他指标：负载能力 总线标准 模块划分 3.4总线结构单总线结构 多总线结构 双总线结构 通道： 是一种特殊类型 结构简单的处理器 专门用于输入输出操作 实现主存、CPU与I/O总线的连接 通道的程序通常情况下是由操作系统来编写，不是人工编写 三总线结构 DMA：直接存储器访问（外部设备直接访问存储） 三总线结构的又一形式 内存发展慢于cpu所以在cpu和内存见加了缓存 四总线结构 将高速设备和低速设备分离 总线结构举例 传统微型机总线结构 VL-BUS局部总线结构 VL-BUS高速总线连接图形设备等 PCI 总线结构 多层 PCI 总线结构 3.5总线控制(重难点)总线判优控制 基本概念 主设备(模块) 对总线有控制权：可以控制总线的占用申请，并且可以控制与另一台设备之间的通信 从设备(模块) 响应从主设备发来的总线命令 总线判优控制 集中式(方法)：总线的判优逻辑集中到一个部件，比如cpu 链式查询 计数器定时查询 独立请求方式 分布式(方法)：判优逻辑分布到各个设备 链式查询方式： 数据线：信息交换过程中数据的传输 地址线：主设备占用总线之后要和从设备进行数据传输要通过地址线找到要通讯的从设备 BR—总线请求：所有设备都通过这条线发出总线占用的请求 BS—总线忙：如果某一个设备占用的总线控制权，就通过该线告诉总线控制部件或其他部件 BG—总线授权线：链式的特点。一个接着一个连下。BG会一个一个向下传输，直到找到发起总线控制请求的部件 过程：部件通过BR向总线请求，总线控制通过BG一个一个向下传输，直到找到发起总线请求的部件，然后该部件通过BS发出总线忙信号 优先级就是BG传递的顺序，由排列方式决定。如果一个部件排靠后有可能一直无法获取总线控制权。一般用在微机，简单的嵌入式 优点：结构简单，增删设备简单，进行可靠性设计的时候比较容易实现。 缺点：对电路故障特别敏感，特别是BG 计数器定时查询方式 设备地址：这上面传输的地址是由计数器给出的，通过这个地址来查找某一个设备是否发出了总线占用请求。 过程：总线控制部件中有一个计数器，初值可以是0或其他，如果某一个主设备和从设备需要占用总线进行数据传输。通过BR向总线控制部件提出占用请求，总线控制器在接收到信号后，在能够响应的情况下可以让出总线使用权的情况下会启用计数器，这个计数器的值会通过设备地址这条线向外输出，设备地址给出信号后，如计数0 会向I/O接口0查询是否提出总线占用请求，如果没有计数+1.然后向I/O接口1查询，直到找到发出请求的接口。 如果初值为固定值，那么它的优先级最高。如果为最后一次的计数则是循环优先级。也可以通过软件的方式对总线控制部件进行设置。使得优先级的顺序更加灵活 设备地址线的宽度和设备数有关 独立请求方式 内部有一个排队器。非常灵活，可以通过配置排队器，设置优先级，也可以在内部使用计数器等等。用的多，速度快 所有请求的部件将信号发至总线控制部件，总线控制部件通过排队器对某个设备进行应答，那么该设备就占用总线的使用权。 总线通信控制目的：解决通信双方协调配合问题 总线传输周期：总设备和从设备之间完成一次完整的并且可靠的通信需要的时间 申请分配阶段：主模块申请，总线仲裁决定 寻址阶段：主模块向从模块 给出地址和命令** 传数阶段：主模块和从模块 交换数据 结束阶段：主模块 撤消有关信息 总线通信的四种方式 同步通信：由统一时标(定宽定距)控制数据传送 异步通信：采用应答方式，没用公共时钟标准 半同步通信：同步、异步结合 分离式通信：充分挖掘系统总线每个瞬间的潜力 同步式数据输入 这里的总线传输周期由四个时钟周期构成，四个时钟周期就是一个完整的数据通信 过程：T1时钟的上升点 必须要给出地址信号(主设备给出)，T2时钟上升点必须给出读命令信号，T3上升点必须要给出数据信号，T4上升点数据信号控制信号撤销，T4结束时地址信号撤销 同步式数据输出 过程：在T1时钟周期的上升点要给出地址信号，在T1时钟周期的下降点要给出数据信号，在T2时钟的上升点要给出写命令，T3做写入操作，T4的上升点主设备撤销写命令，T4结束的时候撤销地址信号。完成写命令 对多个速度不同的模块，必须选择速度最慢的模块，作统一的时标。 一般应用在总线长度比较短，并且各个模块存取时间比较一致的情况。 异步通信 主设备发起总线通信，从设备受主设备控制。与同步相比没有定宽定距的时钟，但是要加两条线：请求线（主设备发出请求信号）、应答线（从设备对主设备发出的请求进行应答） 不互锁过程：主设备发出通信请求，从设备接受到后发出应答，主设备撤销请求信号，从设备撤销应答信号。在这过程中，主设备不管是否接收到应答信号，经过一段后都会撤销请求信号。从设备也是。 消息可靠性无法保证 半互锁过程：主设备发出请求，从设备接收到后发出应答，主设备接收到请求信号后，会撤销，如果没有接收到，请求会保持。 有可能会造成请求信号一直保持 全互锁过程：主设备发出请求，从设备接收到后发出应答，主设备接收到请求信号后，会撤销，只有主设备撤销请求信号后，从设备才会撤销应答信号。 半同步通信(同步、异步结合) 同步：发送方 用系统 时钟前沿 发信号。接收方 用系统 时钟后沿 判断、识别 （有定宽定距的时钟管理整个通信过程） 异步：允许不同速度的模块和谐工作，增加一条”等待“响应信号（wait信号，由从设备给出） 以输入数据为例的半同步通信时序 T1主模块发地址 T2主模块发命令 当wait信号低电平时，等待一个T …… T3从模块提供数据 T4从模块撤销数据，主模块撤销命令 如果在T3到来之前，从模块无法提供数据。从模块就发出wait信号，主模块如果监测到wait信号，就插入Tw等待数据到来。在下一个时钟周期到来之前，主模块还会检测，直到低电平变成高电平 由等宽定距的时钟控制整个通信过程 过程： T1CPU要给出地址信号，T2CPU要给出读信号，T3从设备如果不能准备好数据，通过wait信号给出一个低电平让cpu等待，插入Tw周期，wait变为高电平，可以接受数据信号。T3开始接收数据。T4开始时读命令和数据信号开始撤销。T4地址信号撤销。 三种通信的共同点 一个总线传输周期（以输入数据为例） 主模块发地址、命令：占用总线 从模块准备数据：不占用总线（总线空闲） 从模块向主模块发数据：占用总线 在准备数据过程中，总线是被浪费的 分离式通信 充分挖掘系统总线每个瞬间的潜力 子周期1：主模块申请占用总线，使用完后。即放弃总线的使用权 子周期2：从模块申请占用总线，将各种信息送至总线上 特点 各模块有权申请占用总线 采用同步方式通信，不等对方回答 各模块准备数据时，不占用总线 总线被占用时，无空闲 四、存储器4.1概述存储器可分哪些类型 现代存储器的层次结构，为什么要分层 存储器分类 按存储介质分类 半导体存储器：易失 TTL：晶体管。集成度低，功耗高速度快。 MOS(现在计算机主要)：晶体氧化物半导体。功耗低，集成度高。 磁表面存储器：非易失 磁头 载磁体 磁芯存储器：磁芯里有导线，导线有电流，通过电流，将磁芯磁化。磁芯本身是铁氧体。在电流的作用下被磁化，磁化为N极和S极。根据磁场的方向就可以保存信息。磁芯只要流过电流就会被磁化，改变磁场方向。我们可以通过材料工艺获得改变磁场方向最小电流的阈值。然后每个磁芯里放两个相互垂直的导线，另一条导线斜着穿过。两条相互垂直的导线作为数据的写入和读出的驱动线。另外一条线用作数据读出。（了解）非易失 硬磁材料、环状元件 光盘存储器：非易失 激光、磁光材料 按存取方式分类 存取时间与物理地址无关（随机访问）：不管存在哪里访问时间一样 随机存储器（RAM）：在程序的执行过程中可读可写（这么说其实是有问题的随机存储器被分为只读存储器、随机存储器） 只读存储器：在程序的执行过程中只读 存取时间与物理地址有关（串行访问） 顺序存取存储器（磁带）：必须转动磁带到指定位置下才能读写 直接存取存储器（磁盘）：首先要找到给定的磁道，通过磁头在表面jinxiang移动，然后停留在磁道上，直到指定的扇区转到磁头下，才能开始读出和写入 按在计算机中的作用分类 主存储器 RAM（可读写）： 静态RAM 动态RAM ROM（只读） MROM（掩模ROM） PROM（可编程ROM） EPROM（电可编程ROM） EEPROM（电可擦写可编程ROM） Flash Memory：在主存储器和辅助存储器之间，常用U盘就是这个做的。半导体存储器，速度比磁盘块，比主存储器慢。也可以做计算机硬盘。SSD的核心存储材料。 高速缓冲存储器（Cache）：在主存储器和CPU之间。通常用静态ROM来做。比主存和FM快。 辅助存储器：磁盘、磁带、光盘 存储器的层次结构存储器的三个主要特征的关系（速度、容量、价格） 寄存器不光在CPU中，I/O设备中也有，有些寄存器我们在指令中可以使用，从体系结构角度来说这些寄存器是不透明的是提供给机器语言程序员的，叫体系结构寄存器，CPU中还有一些寄存器不需要机器语言程序员了解，对机器语言程序员来说是透明的，被称为非体系结构寄存器，指令不能直接对这些寄存器操作。 缓存的一部分CPU中有。早期CPU是没有的 为什么要分这么多层：用户的要求，单一的任何一种都无法满足用户的要求，用户需要高速度，大容量，低价格。采用层次结构形成存储体系。 存储体系：把两种或两种以上的存储介质构成的存储器，用软件、硬件或软硬件结合的方式连接成一个整体。使得从某一级程序员的角度看具有高速度、大容量、低价格。 程序员在使用过程中不需要考虑层次结构，信息在层次结构间的调入调出都是由软件硬件，软硬件相结合的机构自动完成。 计算机中有两个非常重要的层次：缓存—主存层次、主存—辅存层次 主存的容量是有限的，程序如果足够大或文件太大，主存放不下就需要用到辅存。但程序的运行是在主存，如果程序要运行，就要将程序调入到主存，主存和辅存也需要数据交换 就构成了一个存储层次。在这个存储层次上我们用软硬件相结合的方法把主存和辅存构成一个整体。从应用程序员的角度看这个存储有主存的速度，辅存的容量，辅存的价格。在程序执行过程中超过主存容量应用程序员也不用自己去考虑如何将程序分割。这些都由软硬件结合的来调配。 CPU和主存速度发展的差距称为剪刀差。为了弥补这个差距就在CPU与主存间加上了一层缓存（cache容量小功耗大速度快）。 将常用程序放入缓存。这里用到了程序的局部性原理，包括时间局部性、空间局部性。 缓存和主存采用硬件的方法连接为一个整体。主要为了解决速度问题，所以采用硬件方法。 主存和辅存是软硬件相结合的方法连接为一个整体。主要为了解决容量问题，所以采用软硬件方法。 主存和辅存构成的整体一般称为虚拟存储器。地址既不是主存地址也不是辅存地址，这里用的是虚拟地址（逻辑地址）。 缓存和主存之间的地址，我们使用的是主存的地址（实地址，物理地址），没有定义一个空间也没有使用缓存的地址。缓存是按照内容来查找，即使给出一个地址也是主存中的地址，然后转化为缓存块的编号。 4.2主存储器(重点)概述主存的基本组成 MDR（主存数据寄存器）：保存了要读出或写入的数据。具体是读出还是写入要通过读写电路和控制电路来控制。 MAR：保存了我们要访问的存储单元的地址。必须结果译码器译码以后才能选定指定的存储单元。 主存与CPU之间的联系 数据总线直接连到MDR上是双向的，可能读出也可能写入 地址总线连接在MAR寄存器和主存的地址总线之间，给出了要访问内存单元的地址，单向，从CPU—&gt;主存。 控制信号两个，读和写都是单向 CPU与主存的连接，实际上是三种类型的信号 主存中存储单元地址的分配 假设主存的结构存储字长32位，也就是说对这个存储器某个单元读或写一次最多读出或者写入32位的01。 主存的编址单位是字节，每一个字节都有一个地址。 每个字节8位，所以编址单位是8位，编址单位可以理解为切割存储空间的粒度 存储字节32位，用8位的字节分割，一个存储单元被分为4个地址 字地址=存储字地址=存储单元地址 存储字长32位=4字节，所以包含4个字节地址 12345678H(16进制数)在主存储器如何存储 高位字节地址(这里1是最高位) X86采用小尾方式。两种方式没有高下之分。两种类型的机器通信会产生问题，需要重新调整顺序。 所有的地址线组成的地址值对应一个字节，24根地址线就有2^24^种状态。就是2^24^字节 一个字节是8位，字长如果位16位就是2个字节，字长如果是32位就是4个字节 这里的MW，W指的是word，第一个w是16位，第二个w是32位。 这里的16MB、8MW和4MW大小其实是一样的，只是表示方式不同 主存的技术指标 存储容量 主存存放二进制数的总位数 存储速度 存储时间：从存储器给出地址一直到得到稳定的数据输出或者输入 存储器的访问时间读出时间、写入时间 存储周期：连续两次独立的存储器操作（读或写）所需的最小间隔时间 第一次开始到第二次进行存取操作，称为存储时间 存储周期和存取时间不一样的。一般来说存取周期要比存取时间长。存取周期=存取时间+回复时间。 存储周期分为：读周期、写周期 存储带宽 （位/秒） 半导体存储芯片简介半导体存储芯片的基本结构 地址线是单向的输入的，CPU、外部设备给出地址。结果译码驱动选择指定存储单元完成读写操作。 数据线是双向的 片选线：芯片选择信号，指出了这次操作给出的地址是不是针对这个存储芯片的地址，被选择存储单元、字节是否在这个芯片中。 CS、CE上面一横表示低电平有效，不同芯片采用不同标识来表示 CS（chip selection）：如果是低电平的话，这次数据访问他的地址就是在这个存储序列中。 CE（chip enable）：芯片使能信号。也可以用这个来标识。 内存条上有很多芯片，片选线来确定在哪个或哪几个芯片中 读写控制信号可能一条可能两条，如果是一根线给出WE表示，当信号是低电平对这个芯片写操作。也可以用两根线表示，第一根是OE，O是输出，如果这根线低电平表示输出，从存储矩阵中把指定单元的数据写入数据线。WE也是低电平写操作。 片选线作用：用 16K × 1位 的存储芯片组成 64K × 8位 的存储器。用8个这种类型的芯片，同时进行读写，每个芯片给出或者写入一位二进制信息。8个芯片就构成一个8位，那么8个芯片就为一组，这一组就是16k×8位的芯片组。这样的芯片布置四组就满足了。然后每组用片选线连接。将CPU的地址中0—(16-1)k分配给第一组芯片，从16k—(32-1)k分到第二组以此类推。当地址为65535时，最后一组片选信号有效，其他的无效也就是高电平。 片选线可以让某一个或者某些芯片同时进行工作 半导体存储芯片的译码驱动方式：给出了存储单元的地址后，如何去找到指定的存储单元 线选法 地址：A0—A3一共四位地址，说明有16(2^4^)个存储单元。数据线是D0—D7一共8位。说明存储器是16×8。 地址译码器实质就是一个译码器。给定一个输入，只有一根线会控制响应的存储单元中所有存储元件，进行数据输入或输出操作。 读写控制电路：如果是读就向外，如果是写就向内 如果输入0000，那么只要0这根线有效，如果是读信号，只有给定单元才能输出 问题：地址线只有4条，容量为16乘8。没有这么小的存储器，假设有1M×8的存储器，1M有20个地址线。1M条线做在芯片中会非常密集，就很难将内存芯片集成度做高。 比如输入01，那么输出的第一根线有效，其他三根无效。译码器就是从编码向数据翻译的过程 重合法： 我们将地址分为两部分，X和Y。称为行地址和列地址。行列地址分别进行译码，都只有一条线有效 过程：假如X、Y都是00000，那么只有X0和Y0有效。(0,0)的数据就可以输出，(0,31)的数据也会输出由于Y31是无效的，尽管会但不会送到数据线上。中间的1到30都是一样的情况。 线选法如果是20条输入线，输出线就是1M条。重合法分为两部分假如每一部分都是10位，行列各1K条，总计2K条。比线选法要少很多，就可以提高芯片集成度 随机存取存储器（RAM）静态RAM(SRAM) 保存0和1的原理是什么 核心利用了一个触发器(数电中) 这里的触发器利用了T1—T4四根管子。这个触发器是一个双稳态的触发器，在两端用来存储信息，一端是触发器的原端，另外一端是触发器的非端。如果一端是1另一端就是0，如果一端是0另一端是1。 T5和T6用于解决读写。T5和T6都是由行地址选择控制 静态RAM的基本单元电路就包括两部分，一部分是存放01的，另一部分就是控制对这个部分读写的两个晶体管，一共6个晶体管。 这个存储元件(虚线中)如果做在芯片中往往会构成一列，而不是一个。T7和T8是一列所有存储元件共有的开关。 如果某一个单元被选中，它所对应的T5和T6被打开，行地址选择继续向下延续，这一行上所有的存储单元都是由行地址选择线控制。存储的数据会送到相对应的位线上，但只有列地址选择线有效，行列交叉点才能进行读写。 写入的时候，由于是双稳态的触发器，我们分为两个方向，一个方向写入直接要写入的数据，另一个方向写入要写入数据的非。所以我们在电路里用到了三态门取反 类比前面的重合法 静态RAM的基本读操作 过程：给出行选信号，打开T5、T6。再给出列选信号，打开T7、T8。如果读有效，读放的管子会打通。存放在A中的数据就会通过T6晶体管送到位线，同时T8也是打通的，信号会继续向前送。一直送到数据总线上。非端也会发出信号，也会送出，但是在写放大器部分时被劫持。 静态RAM的基本写操作 左侧的写放大器是取非以后输出的，保证A端和A‘端写入相反信号。 过程：如果基本电路被选中，行译码以后产生的行地址选择信号会打开T5和T6，同样列地址信号会打开T7和T8。 静态RAM芯片举例 WE：读写控制信号，低电平表示写操作，高电平表示读操作。 CS：片选信号，只有CS是低电平的时候该芯片才会被选中。 A0—A9：地址线，所以得出2^10^个存储单元 I/O1—I/O4：数据线，每个存储单元被选中可以读出或写入4位信号。 所以存储容量是1K×4位。 这里可以64×64来布置存储单元，用译码驱动的方式来选择存储单元。 Intel 2114 RAM(64×64 ) 64列分为4组，每组16列 行地址，一共6位，译码后可以产生2^6^，列地址一共4位，2^4^. 要想每次从阵列中读取4位数据或写入4位数据，每一个列选信号要控制4列。所以64列分为4组每一组16列。每一个列选信号，控制了每一组中的一列。比如第0列选信号，分别控制1组2组3组4组的第0列。 读过程：经过行地址译码器，第0行被选中。经过列地址译码每一组中的第0列都会被选中，WE、CS信号有效。第0行每一组中的第0列都经过列控制管还有读写电路输出到响应的数据线上。 列地址(0000) 行地址(000000)，行列地址译码后，第0行的行选择信号有效，第0列对应每一组的第0列有效。we低电平，cs低电平。数据通过I/O1—I/O4输入读写电路写到每一个基本单元电路的A端和A’端。 动态RAM(DRAM) 利用电容保存0和1。如果电容中保存了电荷，信息为1，如果没电保存信息为0 动态RAM基本单元电路 3管动态RAM 信息保存在电容Cg。 T1、T2、T3是控制管，通过这三根控制管控制读出和写入 上面的线为读选择线，读选择线有效会打通T2，下面的线为写选择线，写选择线有效会打通T3。外部的数据可以通过T3这个管子对Cg读或写。 读过程：先通过T4预充电信号，使T4晶体管打通，VDD通过T4晶体管给读数据线充电，读数据线高电平表示1。左侧：读选择信号有效，T2被打通。如果Cg保存的是0，T1删极是低电平，T1不会导通，读数据线就会保持高电平。也就是说如果保持的信息是0在读书极限上读出的数据就是1。如果保存的信息是1，T1这个电容会充电T1的删极有电，T1就导通，因为预充电保存的是1，那么高电平就会通过T2和T1的管子放电，变成低电平。 写过程：写选择线有效，T3导通，写数据线会通过T3管子向Cg进行充电或放电，如果写入的是低电平，Cg会通过T3放电，Cg就是0. 读出与原存信息相反，如果想读出正确信号。就需要在读数据的输出端加一个非电容。 写入与输入信息相同 单管动态RAM：存储信息的原理和3管动态RAM一样。CS保存信息 读过程：字线是控制线。如果响应的行被选中，字线控制的T被打开，电容可以通过管子T1，进行充电或者放电。如果CS保存是0数据线上就不会有电流，如果数据线上保存的是1，那么数据线上就会有电流。通过有无电流就可以确定保存的信息。读出时有点为“1”，无电“0” 写入如果是“1”就是充电，写入如果是“0”就是放电。 动态RAM芯片举例 三管动态RAM芯片(Intel 1103) A0到A9十位地址线，说明容量为1K。每次读出或写入只有一位数据。芯片容量：1K×1. 行地址经过译码以后产生的信号，每一个都对应两个控制信号一个读选择线一个写选择线，读写用不同的信号进行控制。也就是说在行地址译码器参加译码的不仅仅是地址同时还有读写控制信号。 三角形：刷新放大器，因为我们采用电容存储电荷来保存信息。电容会漏电，经过一段时间电容上信号会消失，所以用刷新放大器对电容中保存信息进行重现。每经过一段时间都要刷新 读过程：行地址译码器给出第0行读操作，列地址译码器给出第0行。通过读数据线把数据送到读写控制电路上，同时可以向外输出。 写过程：给出响应地址信号，假如行地址11111，就是31行，列地址00001，就是第一列。第31行第1列被选中，数据通过D端进行输出，经过读写控制电路写入第31行第1列 单管动态RAM 4116(16K×1位)外特性 16K需要14根地址线，但4116只有7根地址线。实际需要14位地址，这14位地址是分两次传送的，第一次接受到的7位是行地址，被放到行地址缓存器中。再接受7位列地址，译码后选中给定的存储单元进行输入和输出。 I/O缓存器，完成数据的输入输出缓冲，两端连接了数据输入寄存器和数据输出驱动，来完成数据的输入和输出。 4116 读写 16k的基本单元电路被放在128行，128列上。(这张图竖的是行横着是列) 在63行64行之间每一列都有一个放大器，这个放大器是跷跷板电路（如果在一端强制为1，另一端则为0） 读原理：行地址：0111111，那么63行被选中，63行对应的行选线有效，对应的所有晶体管被打开，电容中的信息被送出到读放大器左侧。读放大器取反送出。也就是说读放大器左侧，电容有电表示0电容无电表示1。右侧相反。第0列打开，其他管子截止。 写操作：行地址：0111111，63行所有晶体管打开。数据通过I/O缓冲送到读写线。第0列打开，其他管子截止。数据只能送到第0列读放大器右端(取反)，通过读放大器左端。把它写入指定的单元。 读出和写入都反向了，所以读出和写入信息一致。 动态RAM刷新 动态RAM是利用电容存储电荷的方式来保存信息。电容做的非常小很容易漏电，在一段时间如果不对电容中的信息再生的话，电容信息就会丢失。 对动态RAM刷新，之和行地址有关，和列地址无关。每一次刷新操作刷新的是动态RAM中一行所有的基本单元电路。 刷新过程：(参考三管动态RAM1103)给出行地址后，该行上所有的基本单元电路信息都会被送到读数据线上，如果在读数据线和写数据线之间，加上一个刷新放大器的话，就可以完成对某一行的全部信息的刷新 刷新方式： 集中刷新（存取周期为0.5 s ):把刷新的时间集中在一个时间段来操作. 假设存取周期是0.5微秒,动态RAM中的电容刷新周期假设为2毫秒也就是说动态RAM中所有的电容在2毫秒内都完成信息的刷新。2毫秒一共是4k个存储周期(2毫秒/0.5微秒)。这4000个存储周期中前面的3872个周期可以供CPU、I/O对动态RAM读出或写入操作,后面128个周期专用于芯片的刷新操作。 在死区时,CPU和IO想进行读写,只能进行等待。 在这128个周期中,无论是CPU还是IO都无法对动态RAM进行信息交换。又叫死区 分散刷新(存取周期为1 s) tC：tC=tM+tR整个存储周期。 tM(0.5微秒)：原来的读写周期，也就是CPU、IO和内存进行信息交换的读写或者存储周期。 tR(0.5微秒)：专门用于某一行的动态RAM刷新 这样实际将动态RAM芯片读写周期变为原来的两倍 无死区 每1微秒就刷新一行，128微秒就全部刷新完了，2毫秒就是每一行刷新15.6次。这实际上是过度刷新。动态RAM不需要这么频繁。 分散刷新与集中刷新相结合（异步刷新） 2毫秒需要刷新128行，每经过15.6微秒刷新一行即可。就将2毫秒分为128份，每份15.6微秒。在每一份时间里对某一行进行刷新，可以放到该份的最后，也可以放在中间或者前面。相对于每一份来说是集中刷新，相对于整个来说是分散刷新。 动态RAM和静态RAM的比较 DRAM(主存、内存条) SRAM(缓存、cache) 存储原理 电容 触发器 集成度 高 低 芯片引脚 少 多 功耗 小 大 价格 低 高 速度 慢 快 刷新 有 无 动态RAM每一个单元电路都非常简单包含一个晶体管一个电容，静态RAM比较复杂包含6个晶体管 动态RAM行地址和列地址可以分别进行传送，地址线条数可以减少到原来的一半，芯片的引脚就可以减少，芯片的封装体积也就小了。 静态RAM价格贵速度快，一般使用时不会分别传送行列地址，在内部再译码。主要是需要静态RAM的速度优势。 动态RAM刷新耗电，由T1到T4构成的双稳态触发器，工作后有三个管子一直保持导通状态，一直漏电。 触发器要比电容充放电快 只读存储器（ROM）一般用于保存系统程序或系统的配置信息。 发展历程：厂家写好内容—&gt;用户可以自己写(一次性)—&gt;多次写(对信息擦除)—&gt;电可擦写(特定设备)—&gt;电可擦写(计算机) 掩模ROM(MROM) 用户不能修改，只能读不能擦除。 (教材P88 图4.27)是1k×1的掩模ROM内部结构，上面一排晶体管是预充电管，经过预充电管充电后。所有的位线都是高电平。在行和列的交叉点上有的有晶体管有的无晶体管。假设交叉点被选中并且有晶体管，晶体管被选中就是导通的，预充电位线上的高电平变为低电平。输出端有一个读出放大器并且对输出的数据进行反向。 行列交叉处有MOS管为”1“ 行列交叉处无MOS管为”0“ PROM(一次性编程) 熔丝断为”0“ 熔丝未断为”1“ EPROM(多次性编程) N型沟道浮动栅MOS电路 G端栅极：栅极如果有电，源和漏就是通的。 如果在漏端加正点压，就会在源和漏之间形成浮动栅。使S和D不导通。保存信息认为是“0” 如果要修改，用紫外线照射驱散浮动栅 EEPROM(多次性编程) 电可擦写 局部擦写 全部擦写 Flash Memory(闪速型存储器) EPROM 价格便宜、集成度高 EEPROM 电可擦写 FM比EEPROM快，且具备RAM功能 存储器与CPU的连接(重难点)CPU执行的指令、需要的数据、运行结果都要保存在主存储器中。 存储器容量的扩展 位扩展(增加存储字长) 用2片1K×4位存储芯片组成1K×8位的存储器。1K容量需要10根地址线，地址线输入到每个芯片上。每个芯片数据线分别和CPU数据线上的四条形成连接。片选和读写一定要连接在一起，使同时工作。 问：2114的地址线是否需要按序的和系统地址线连接？2114的数据线是否需要按序的和系统数据线连接？ 字扩展(增加存储字的数量) 用2片1K×8位存储芯片组成2K×8位的存储器。A0到A10将A10做片选线，A10为0选择第一个芯片，A10为1选择第二个芯片。 字、位扩展 用8片1K×4位存储芯片组成4K×8位的存储器 A0到A9做地址线，剩余两根做片选信号。两个芯片一组，分别和系统数据线8位相连。 存储器与CPU的连接 基本方法 地址线的连接：一般来说地址连接，都将地址的地位作为地址送到存储器的地址线中，高位作为芯片选择信号 数据线的连接： CPU的数据线条数可能比存储器数据线条数多。这种情况下就要使用位扩展，使存储器输出、输入的能满足CPU的要求。 读/写命令线的连接：CPU给出读写命令，把读写线连接到每一个芯片上，连接到读写控制端上。(ROM除外，只读存储器，只能读不能写) 片选线的连接：这次访问的地址空间，在哪个或哪几个芯片上。进行片选线连接时，要确认①CPU的访问操作，访问的是存储器而不是IO，存储器的访问信号一定要在片选线中体现②每一个内存芯片都有自己的地址范围，这个地址范围必须满足CPU的要求，每根地址线，都要用到。有一些地址作为存储芯片的内部地址输入到每一个存储芯片中，有一些地址要用作片选信号来保证对某一个芯片的访问一定是在给定的地址范围之内。 合理选择存储芯片： ROM和RAM的选择。一般来说，保存系统程序的和保存配置信息的地方，存储空间选择ROM。用户程序区，系统程序运行区，采用RAM。 同样的ROM或RAM，技术参数或性能参数是不一样的。芯片数量尽可能少，片选逻辑尽可能简单。 其他： 时序：CPU时序和存储器时序相互配合 负载：CPU能带多少个存储芯片 举例 CPU 16根地址线 8根数据线。MREQ(低电平有效)作为访存控制信号。也就是低电平访问存储器，高电平访问IO RAM：1K×4位、4K×8位、8K×8位。ROM：2K×8位、4K×8位 、8K×8位。 利用以上，要构成一个存储器，要求从6000H到67FFFH是系统程序区。从6800H到6BFFH是用户程序区。 写出对应的二进制地址码(把16进制数转化为2进制)CPU有16位地址线，那么写的地址也要有16位A0到A15。 起始地址(A15到A0)6000H：0 110 000 000 000 000 结束地址(A15到A0)67FFH：0 110 011 111 111 111 一共2K×8位，存放系统程序 起始地址(A15到A0)6800H：0 110 100 000 000 000 结束地址(A15到A0)6BFFH：0 110 101 111 111 111 1K×8位 确定芯片的数量及类型 系统程序区，应该选择ROM。选择1片 2K×8位的ROM 用户程序区，需要可读写，用RAM。选择2片1K×4位的RAM。通过片选信号，连接到一起。 分配地址线 A10A0接到2K×8位ROM的地址线(2K需要11根地址线)，剩余的作芯片选择信号。 A9A0分别接到两个1K×4位RAM的地址线(1K需要10根地址线)，剩余的作芯片选择信号。 教材要求使用138译码器。138译码器有三个输入C、B、A。八个输出端有一个低电平，其他都是高电平。138译码器要工作，三个控制端G1、G2A、G2B要有响应的信号输入才能工作。确定片选信号，CBA用哪些信号连接。 这里用A13连接C，A12连接B，A11连接A。这样如果138译码器进行工作，他的Y4如果是低电平的话选择就是第一个ROM，如果Y5有效选择的就是2片RAM(这里还要求A10有效才能，所以也加入片选) 138译码器是将二进制编码译成十进制输出，如CBA=111，那么输出端(Y7非) 这里的Y4就是100，Y5就是101 A14连接到G1(要求高电平有效)上。A15(低电平)连接到G2A上，或同时连G2A和G2B(都是低电平有效)。 这里MREQ一定要使用，所以G2A和G2B不同时连接A15 确定片选信号 CPU还有一个MREQ信号连到片选信号上。CPU给出的地址不一定是主存中的地址，也可能是IO端口中端口的地址。 G2B连接MREQ 因为ROM只读不能写，所以编程端(PD/Progr)接地 弹幕看到的(我自己搞不懂)：当输入101时，Y5高电，经Y5非门转化为低电。在Y5与非门连线上表现为低电，若A10输入低电，两个低电在与门输入前呗非门转化为高向与门输入，此时与门输出高电，被非门转化为低电，低电表示片选激活 假设同前，要求最小4K为系统程序区，相邻8K为用户程序区 写出对应的二进制地址码 最小的4K，所以从全0开始。相邻8K，所以在系统程序区结束地址+1 起始地址(A15到A0)ROM：0 000 000 000 000 000 结束地址(A15到A0)ROM：0 000 111 111 111 111 起始地址(A15到A0)RAM0：0 001 000 000 000 000 结束地址(A15到A0)RAM0：0 001 111 111 111 111 起始地址(A15到A0)RAM1：0 010 000 000 000 000 结束地址(A15到A0)RAM1：0 010 111 111 111 111 确定芯片的数量及类型 一片4K×8位ROM 两片4K×8位RAM(这两片不是一组，各自有片选信号) 分配地址线 A15到A12做片选信号，A11到A0做地址线。CBA需要3个输入，那么选择A14到A12作为CBA输入到138译码器。 如果138译码器有效，3个控制端也要有效。G1高电平可以直接连接电源(VCC)或者把A15取反以后接到G1，G2AG2B要求低电平，可以把A15接到G2A或G2B上。只有MREQ信号有效访问的才是内存，MREQ低电平有效接到G2A或G2B上， 确定片选信号(访存信号要包含其中，地址信号也要包含其中) 确定片选逻辑 片选信号中的地址信号+芯片输入的地址信号，才是全部的地址信号 多做练习，不要拘泥于教材，片选信号非常灵活，只要题目上没有要求，完全可以用学过的数字逻辑知识(我没学过数电)画出片选逻辑。 但是对任何一个芯片来说，CPU的地址线要么输入到芯片中，要么出现在片选输入端。MREQ 存储器的校验信息保存在电容(或四管触发器)中，如果内存的电磁环境复杂，或者空间环境下受带电粒子的打击。可能会造成电容的充电放电或触发器的反转。存放的信息就可能出错。因此需要校验。 合法代码集合(判断哪些代码出现就是错误) {000、001、010、011、100、101、110、111}检0位错、纠0位错。 000最后一位出错变成001，出错后的代码依然是集合的合法代码。计算机很难检查出错误 {000、011、101、110} 编码特点：1的个数是偶数个。检1位错、纠0位错。 可以检测出错误，但是无法知道哪位错 {000、111} 三倍冗余的方式存储，000表示0，111表示1。检1位错、纠1位错。 在计算机中，一位错误的情况超过百分之90所以很容易就能纠错 {0000、1111}四倍冗余的方式存储，0000表示0，1111表示1。检2位错、纠1位错。 无法判断1100，是11错还是00错。 {00000、11111}五倍冗余的方式存储，00000表示0，11111表示1。检2位错、纠2位错。 编码的检测能力和纠错能力与任意两组合法代码之间 二进制位的最少差异数有关 第一种情况差1位，第二种差2位……第五种差5位 编码的最小距离：任意两组合法代码之间二进制位数的最少差异 编码的纠错、检错能力与编码的最小距离有关。L-1=D+C(D≥C)：L编码的最小距离，D检测错误的位数，C纠正错误的位数 汉明码是具有一位纠错能力的编码 奇偶校验，计算机网络会学 汉明码 汉明码采用奇偶检验 汉明码采用分组校验 汉明码的分组是一个非划分方式 划分方式：组与组之间没有重叠 非划分：组合组之间有交叉(有些位是多个组，有些位是一个组) 例：1234567划分为3组，每组一位校验位，共包括4位数据位。{1357、2367、4567} 1为偶数个校验结果应该为3个0 若校验结果P3P2P1：000。无差错 若校验结果P3P2P1：001。1差错 若校验结果P3P2P1：101。5差错 若校验结果P3P2P1：110。6差错 若校验结果P3P2P1：111。7差错 校验位放在1，2，4前。2^i^位 分组规则 第一组：XXXX1 第二组：XXX1X 第三组：XX1XXi 第四组：X1XXX 第五组：1XXXX 如果第1个值和第3个值是1就是第五和第三组共有的 汉明码的组成 添加？位检测位。2^k^≥n+k+1i 添加多少位检测位实际就是分成多少组。对每一组检测。检测位编码要指出哪一位错，或没有错。要传输的代码信息位n位，校验位k位。还有一种情况是没有错，所以总的是n+k+1 检测位的位置。2^i^位 检测位取值。取值与该位所在检测”小组“种奇偶有关，我们一般采用偶校验 各检测位Ci承担的检测小组(汉明码分组规则) C1检测的g1小组包含第1，3，5，7，9，11位置的二进制编码位XX..X1 C2检测的g2小组包含第2，3，6，7，10，11位置的二进制编码位XX..1X C4检测的g3小组包含第4，5，6，7，12，13位置的二进制编码位X..X1XX C8检测的g4小组包含第8，9，10，11，12，13位置的二进制编码位X..X1XXX …… Ci表示校验位 规律： gi 小组独占第 2^i－1^ 位 位置的二进制编码为0…10…0 gi 和 gj 小组共同占第 2^i－1^ + 2^j－1^ 位 位置的二进制编码为0…010…010…0 gi、gj 和 gl 小组共同占第 2^i－1^ + 2^j－1^ + 2^l－1^ 位 位置的二进制编码为0…010…010…010…0 例：求0101按”偶校验“配置的汉明码 解：n=4 根据2^k^≥n+k+1 得k=3 1，2，4位置放校验位。 C1包括1，3，5，7有两个1，所以C1取0。C2包括2，3，6，7有1个1，所以C2取1。C4包括4，5，6，7有两个1所以取0. 0101的汉明码：0100101 汉明码的纠错过程 首先在接收方收到数据后，发送方和接收方要有协议。要说明由汉明码编码采用偶校验，根据接收到的数据的位数来判断，编码被编为多少组，对每一组都要进行校验。 每组都会形成新的检测位Pi，其位数与增添的检测位有关 以K=3为例。 P1为1、3、5、7，半加操作或异或操作得到P1.第一组中1的个数应该为偶数个，P1应该等于0 P2为2，3，6，7，也一样 P4为4，5，6，7，也一样 例：已知接收的汉明码为0100111(按配偶原则配置) P1为1，3，5，7=0。无错 P2为2，3，6，7=1，有错 P4为4，5，6，7=1，有错 P2、P4都含有6所以6出错，7虽然也含有但是P1有7所以无错 例：写出按偶校验配置的汉明码0101101纠错过程 P4为4，5，6，7=1 P2为2，3，6，7=0 P1为1，3，5，7=0 P4P2P1=100 第4位错，校验码错误可以不纠 练习 按奇配置0011的汉明码 答案：0101011 思路：分组方式是相同的，只不过增加了一位校验位，增加了以后使得这一组中1的个数是奇数。 思考：汉明码的最小距离是多少。至少是3。 奇偶配置纠错过程有什么区别 奇偶校验举例：00100011，在最前面加上一位校验位1，变为100100011。1的个数变为偶数个，如果1的个数为奇数个，那么代码错误。X 汉明码就是分组进行奇偶校验，更加精细。 如：将00100011分为两组，前四位前加1后四位前加0。变为10010 00011。 提高访存速度的措施存储墙：存储器太慢，CPU得不到所需要的指令、数据就只能进行空等。 采用高速器件 采用层次结构 Cache—主存 调整主存结构 调整主存结构 单体多字系统：把存储器的存储字长加长 比如CPU的字长16位，存储器的存储字长可以设成64位。CPU每一次访问都访问出4个机器字，每一个机器字都可以是指令或长度为16的数据。CPU一次取出放到数据寄存器中，再用的时候可以直接从数据寄存器中读取 缺点 因为数据寄存器有48位，数据要从单字长寄存器先写入数据寄存器再写入存储器，写入16位时修改到存储器时会造成48位被修改，导致数据错误。如果要让存储器完成16位的单字长的写入，那在存储器内部还要用硬件实现这个功能，会导致存储器复杂化。 如果要取的数据或指令不是连续存放在相邻的地址中，或不是连续存放在一个存储器中。比如第一条就是跳转指令，而且跳转幅度大。那么其他三条就无效。 多体并行系统 高位交叉(顺序编址) 前几位选定存储体，后面是存储体内的地址。四个存储体并行工作。 问题 如果程序的指令是连续的存放在一个存储体，该存储体不断被访问，其他存储体空闲。 这种方式实际就是前面讲过的存储器容量的扩展。这种方式更适合存储器容量的扩展并不适合提高带宽 低位交叉(各个体轮流编址) 横向编码。地址的后几位对同一个存储器来说是一样的。 在讲总线的时候讲过类似的，叫分离式通信 特点：不改变存取周期的前提下，增加存储器的带宽 以流水线方式存取，一个存储器启动就启动下一个依次。 设四体低位交叉存储器，存取周期为T，总线传输周期为τ，为实现流水线方式存取，应满足 T ＝ 4τ。连续读取 4 个字所需的时间为 T＋(4 －1)τ )) 高性能存储芯片 SDRAM(同步DRAM)：之前讲过的动态RAM都是异步。 在系统时钟的控制下进行读出和写入 CPU 无须等待 CPU和存储器之间在给定的时间点上必须开始或完成给定的操作，这样存储器的速度和CPU的速度就可以保持一致 RDRAM 由 Rambus 开发，主要解决 存储器带宽 问题 有兴趣了解查资料，书上不是很透彻 带 Cache 的 DRAM 在 DRAM 的芯片内 集成 了一个由 SRAM 组成的Cache ，有利于 猝发式读取 书上有个图给出了带Cache的DRAM结构，核心是存储阵列。存储阵列上标识的2048×512×4。实际是2048行×2048列，列被分为4组。行选信号11条用于寻找2048行，列选信号9条，每个列选信号会选中四列，在不同组中。所以是512个存储单元，每个单元长度为4 工作过程：CPU给出一个地址访问存储器，到了存储器后，存储器先将该地址和上一次访问的行地址进行比较，如果相等说明上一次访问也是这行，那么这行已经被写到相应的cache当中，可以用列选信号，直接在cache中选中指定的存储单元。如果不一样，那么新的行要写入cache以便于下次使用 4.3高速缓冲存储器概述Cache为了避免CPU”空等”现象。在CPU和主存间加入缓存。要想充分发挥Cache的能力必须要保障CPU访问的数据或指令大多数情况下都能在Cache中取得。 程序的局部性原理：①时间的局部性(当前正在使用的指令和数据在不久将来还会使用到) ②空间的局部性(当前正在使用的指令和数据在不久将来相邻的指令和数据就可能使用到) 把正在使用的指令和数据放入Cache，同时还需要把相邻的指令和数据放入Cache Cache的工作原理 ①主存和缓存的编址 Cache和主存之间的信息交换单位叫做块。 M&gt;&gt;C 如果主存或Cache分为若干块的话，CPU给出内存地址可以分为两部分一部分是块内偏移地址位数决定块大小(比如一个块包含16字节并且内存的编制单位是字节，那么块内地址部分就是4位)，剩余的部分就是主存的块的编号。Cache地址也分成了块内地址和缓存块号，在实际应用中Cache地址意义并不大，也不需要真正地形成Cache地址。 内存块和Cache块大小是相同的。一个块在内存和Cache之间传送是整体进行传送的，字节顺序不会发生任何变化。所以内存块内地址和Cache块内地址值是完全相同的。 Cache上有标记，是用来标记主存块和Cache块的对应关系。 若CPU给出内存地址，希望在Cache访问到该数据，首先要确定数据是否送到Cache中，拿给出地址的主存块号，和Cache中的标记比较，如果相等并且Cache快有效，就可以字节获取。 ②命中与未命中 命中：主存块调入缓存(CPU能在缓存中获取相应的数据或指令) 未命中：主存块未调入缓存(CPU不能在缓存中获取相应的数据或指令，必须要主存中去获取) 用 标记记录与某缓存块建立了对应关系的主存块号 ③Cache的命中率 概念：CPU 欲访问的信息在 Cache 中的 比率 命中率与Cache的容量与块长(一般4到8个字)有关(还有一些不是课程重点) 块长取一个存取周期内从主存调出的信息长度 块太大会导致块数少，而每块中可能有一部分数据是无用的，从而导致浪费。 块的大小与4.2节中提高访存速度的措施中多体交叉有直接关系。 例(一个存储字64位) CRAY_1 16体交叉 块长取16个存储字 IBM 370/168 4体交叉 块长取4个存储字 ④主存系统的效率 效率 e 与 命中率 有关。命中率是最关键的。 e= (访问Cache的时间)/(平均访问时间)× 100% 平均访问时间内包含访问Cache和内存的时间 设Cache 命中率 为 h，访问Cache的时间为tc，访问主存的时间为tm 则 e = (tc)/(h×tc+(1-h)×tm) × 100% 从时间上看访问Cache和访问内存是并行进行的。如果是在Cache中访问后没找到再去访问内存，那么公式就会变化。 Cache的基本结构 工作过程：CPU要访问内存，给出的地址包括了块号和块内地址。由于Cache是以块为单位进行数据传送的，所以块内地址可以直接送到Cache的地址。然后利用块号在“主存Cache地址映射变换机构”中确认是否命中，如果命中给出当前内存块保存在哪个Cache块中。如果未命中需要查询Cache是否还有空间能够装入这个主存块，如果有的话访问主存把主存块装入Cache。如果没有主存块能装入的Cache的位置都是满的就要启用”Cache替换机构“，由它根据替换算法决定Cache中哪一个块从Cache中踢出，写回到主存或者直接作废。把主存中要用的块写入Cache。 映射规则：主存中的一个块如果要放入Cache中，它可以放入Cache哪个块或哪些块中 变换：将主存的块号或地址转化成响应的Cache的块号或地址 主存和Cache之间的直接通路，用来完成信息交换。 有些电脑为了速度，发生未命中的情况，主存会通过数据总线先把CPU需要的数据送到CPU中同时这个块在Cache和主存间传送。 Cache的读写操作 读操作：访问主存取出信息送CPU和看Cache是否满 是同时执行的 写操作： 写操作会造成Cache和主存不一致(比如值写了Cache没写主存)。因此一定要解决Cache和主存的一致性问题 写直达法(写通过法 Write – through) 写操作时数据既写入Cache又写入主存 写操作时间就是访问主存的时间，Cache块退出时，不需要对主存执行写操作，更新策略比较容易实现 优点：使内存和Cache一直保持一致 缺点：可能会造成CPU对同一个内存单元反复地写(比如累加，每次加都要访问) 写回法（Write – back） 写操作时只把数据写入 Cache 而不写入主存当 Cache 数据被替换出去时才写回主存 写操作时间就是访问 Cache 的时间，Cache块退出时，被替换的块需写回主存，增加了Cache的复杂性 缺点：无法保证实时一致性，也可能造成多处理器的情况下，每个处理器都有自己的Cache，在其中都有副本，这就会导致各个副本之间一致性问题。 Cache的改进 增加Cache的级数 片载(片内)Cache 片外Cache 现代处理器都是多核的，每个核都有自己的Cache。多核也有共用的Cache 统一缓存和分立缓存 把指令和数据分开。指令Cache和数据Cache，与指令执行的控制方式有关。可以避免在在流水的过程中造成资源冲突。 Pentium 8K 指令 Cache 8K 数据 Cache PowerPC620 32K 指令 Cache 32K 数据 Cache Cache—主存的地址映射如果主存中任意一个块，可以加载到cache中哪个块 直接映射 概念：主存中任意一个给定的块，只能映射到或只能装载到某一个指定的Cache块中 具体做法：拿Cache存储体作为一个尺子，去度量主存储体，根据主存储体和Cache存储体大小，把主存储体划分成若干个以Cache存储体相等的区，每个区的大小和Cache存储体的大小是相同的，每个区中包含的字块数和Cache存储体当中包含的字块数是相等的，这样的话每个区里的字块进行编号的时候都可以从0号开始编写，一直编导2^c-1^，在进行映射的时候任何一个区的第零块只能放入Cache存储体字块0中，任何一个区的第一块只能放到Cache存储体的第一块中。 存储体字块取模运算 如：主存的任何区的第0块，只能放在cache的第0块 这种方法如果CPU给出一个地址(区号：主存字块标记、块号：Cache字块地址、块内偏移地址：字块内地址)。由于Cache中字块0可能为主存储体任意区的字块0，所以要将区号写入标记中(t位)，t位表示对应主存哪个区 优点：结构简单速度快 缺点：Cache利用率低(如果其它Cache空闲，但由于字块号必须对应就可能导致利用率低) 每个缓存块 i 可以和 若干 个 主存块 对应 每个主存块 j 只能和 一 个 缓存块 对应 全相联映射 全相联：主存中任何一个块可以被放入Cache任意一个块中。任何一个块要从主存调入Cache，只要Cache有空余部分就可以调入。 如果给出一个主存地址，主存字块中的标记需要和Cache块中所有标记进行比较，如果有相等就命中，如果没有就可能发生替换。 缺点： 这个比较是需要同时进行，电路比较复杂，速度比较慢。 需要比较的位数比较长，比较器的长度也会比较长。 组相联映射 先将Cache分成块，再将块分为组(每组可以2块、4块或8块)。主存的字块也进行分区，每个区分块数和Cache的组数相同。每个区的第0块可以放入Cache中第0组的任意一位置。也就是说主存中每个区内的编号，在区内编号直接决定了可以放入Cache的哪个组。 如果只分每组只分两块，可以有两个比较器，比较标记，可以并行进行。 优点： 和直接相连相比一个块有多个位置，即使一个被占用，另一个如果是空的依然可以使用。 和全相连相比，如果去找某个内存卡是不是被调入Cache中，只需要确定在某个区的标号，然后找到给定的组，再去比较组内块的标记。 复杂度可以接受，速度够快，Cache利用率高。是现代计算机常用方法。 如果只有一组，组相联就变为全相联。如果组相联每组只有一块，就变为直接相连。 这三种相连方式在多层次的Cache结构中，用途不一样。靠近CPU的层次要求高速可以采用直接相连或者路数(每组块数)比较少的组相连。中间层次采用组相连。里CPU远可以采用全相联的方式。 替换算法当发现cache中可以放内存块的地方都被占用，就使用替换算法 先进先出(FIFO)算法 先进的块，先被替换 近期最少使用(LRU)算法 4.4辅助存储器(非重点)主要作用：用来保存程序、数据、文档、音像资料。 特点：不直接与CPU交换信息。 程序要运行必须调到主存当中，CPU才能读写 磁表面存储器(最常见)的技术指标 记录密度 道密度Dt：硬盘在径向方向上单位长度有多少个此道 位密度Db：单位长度的磁道保存了多少位二进制信息 磁盘每个磁道都是同心圆，越往外位密度越低 存储容量：C = n × k × s 平均寻址时间：寻道时间+ 寻道时间：读写头在硬盘表面找到指定的磁道 等待时间：找到后读写头停止运动，磁盘旋转，等待给定的扇区旋转到磁头下。 辅存的速度 寻址时间 磁头读写时间 数据传输率：Dr = Db × V(旋转速度) 误码率：出错信息位数与读出信息的总位数之比 磁记录原理和记录方式 磁写原理：线圈上通上不同方向的电流，在铁线内部就会产生不同方向的磁通，磁会对载磁体表面的磁层进行磁化，磁化方向的不同区分0和1。 磁读原理：磁场经过读写头切割磁极线，在读线圈上产生电流。磁通发生变化，电势也会发生变化，根据电势变化确认磁载体中保存的0和1. 硬磁盘存储器 硬磁盘存储器的类型 按磁头是否固定划分： 固定磁头：盘片只会旋转不会平移，每个磁道都有一个磁头。速度快，不需要磁头径向移动，只要等待指定扇区移动 移动磁头：常用的磁盘 按硬盘的盘片是否可更换 可换盘：可以更换盘片 固定盘：常用，不能取出一旦取出沾上灰尘后，盘片就报废了 硬磁盘存储器结构 磁盘控制器：相当于主机与磁盘驱动器之间的接口，连接磁盘驱动器，由磁盘驱动器驱动盘片的旋转磁头的移动以及数据的读写。 磁盘驱动器结构： 磁盘组(核心)，信息保存在磁盘组盘面上，固定在主轴上，下面是传动机构。传动机构带动主轴带动各个盘片旋转。磁盘表面为磁头，一旦磁盘高速旋转，磁头就会悬浮在磁盘表面。磁头可以沿着磁盘的径向进行移动。移动是由小车(图上的长方形 上下4个⚪)来控制的，小车的移动推动磁头在磁盘表面，小车由电机控制。 工作流程：磁盘控制器会送来目标磁道的信息，到底磁头要移动到哪个磁道。根据目标此道的信息由音圈电机控制小车，小车左右移动来移动读写头。 这个控制是非常精确的，音圈电机会测量小车的移动速度会送控制端，同时对读写头也是有位置控制。 数据控制在图上没有体现，主要是为了完成数据的转化和读写控制。 磁盘控制器： 接收主机发来的命令，转换成磁盘驱动器的控制命令 实现主机和驱动器之间的数据格式转换 控制磁盘驱动器读写 实质上磁盘控制器 是 主机与磁盘驱动器之间的 接口。这个接口对主机通过总线进行连接、同时直接对硬盘进行控制 盘片：由硬质铝合金材料制成 软磁盘存储器 实际上，软盘已经退出市场 硬盘 软盘 速度 高 低 磁头 固定、活动、浮动(在磁盘表面和读头之间有高速的空气流进行隔开) 活动、直接接触盘片 盘片 固定盘、盘组大部分不可换 可换盘片(塑料的，外壳也是塑料的，需要的情况下可以打开外壳更换盘片) 价格 高 低 环境 苛刻(盘的表面落一粒灰尘都会对读写头造成损失) 软盘的磁头都是可以活动的，磁头可以通过读写口在软磁盘表面进行移动，找到指定的磁道和扇区进行读写。 软磁盘比较容易损坏。 中间是主轴孔，盘片想转起来，驱动器的主轴会压在这个空，然后驱动器旋转，盘片跟着旋转。 写保护口上有一个小的塑料块，可以上下推。如果写保护了，就只能读不能写。 读写磁头访问槽：中间直，两边圆。这个孔一般由金属片保护起来，只有读写的时候金属片打开，磁头通过读写口和盘片本身进行接触，来读写内容。 光盘存储器 采用光存储技术 利用激光读写 第一代光存储技术：采用非磁性介质 不可擦写 第二代光存储技术：cai用磁性介质 可擦写 原理： 只读型、只写一次型：热作用（物理或化学变化） 可擦写光盘：热磁效应 五、输入输出系统5.1概述输入输出系统的发展概述 早期：计算机数量少，应用少，外部设备少 采用分散连接的方式，每个设备都有专门的控制电路。这些控制电路甚至和CPU的控制电路设计在一起。 CPU和I/O 串行工作 程序查询方式：IO在数据输入输出时，CPU必须允许响应程序或者等待 增加和减少外部设备很困难 接口模式和DMA阶段 采用总线连接的方式，IO设备通过接口连接在总线上，一个总线可以连接多个设备，总线另外一端与主机相连 CPU和I/O设备 并行工作 出现了两种信息交换的传输控制方式： 中断方式 DMA方式 在信息传输过程中，或者完成之后，CPU仍要参与部分信息传输的处理工作，为了使CPU和IO的工作能并行，或者是输入输出系统的数据输入输出的管理控制，尽可能的从主机中独立出来，就出现了具有通道结构的阶段 具有通道结构的阶段 通道可以看作是一种简单的处理器或是小型的功能更强的DMA控制器，能执行通道程序，通道有自己的指令系统，通道通过执行通道程序可以控制连接在连接上的IO设备和主机之间直接进行信息传输 具有I/O处理机的阶段 I/O处理机独立性更强，I/O处理机可以是专用的处理器，在大型计算机中，可以用现代微处理器直接作为I/O处理机控制I/O设备的工作。或是在一些大型计算机中直接采用和主机当中处理器完全相同的处理器来作为I/O处理机。甚至在没有I/O设备工作的时候I/O处理机可以作为主机的处理器完成相应的计算任务。 输入输出系统的组成 I/O软件： I/O指令：CPU指令的一部分 组成：操作码+命令码+设备码 I/O指令的操作码相当于I/O指令的标志，它表示第二个指令是I/O指令 命令码：相当于CPU指令集中普通指令的操作码，指出了对I/O设备怎样的操作，比如查询，输入，输出等 设备码：I/O设备的编码，也就是I/O设备的地址或I/O设备中某一个寄存器的地址。这些寄存器我们称之为I/O的端口 程序将它编写到应用程序中，CPU执行这些I/O指令，控制外部设备，使得外部设备和CPU和主机之间能协调的进行工作 通道指令：通道自身的指令 通道是一种小型的DMA处理机，能够实现I/O设备和主机之间直接进行信息传送。通道有自己的控制器，有的通道还有自己的存储器。 工作流程：通道能执行由通道指令组成的通道程序。通常情况下，编程人员在应用程序中，为了调用外部设备，使其工作，应用程序中需要增加广义I/O指令。广义I/O指令要指出参加数据传输的IO设备，数据传输主存的首地址，传输数据的长度，传输的方向(是向I/O设备传输还是向主存传输)。操作系统根据广义I/O指令给出的参数以及要求的操作会编写由通道指令组成的通道程序，并且把通道程序放入内存或是通道自己内存的指定位置，之后启动通道进行工作。通道拿到通道程序的首地址后就可以执行通道程序，控制I/O设备进行相应的输入和输出工作。 通道指令指出数组的首地址、传送字数、操作命令 这些指令一般比较长：如 IBM/370 通道指令为 64 位 通道下可以带若干个子通道，子通道可以并行工作，每个子通道可以连接多个设备控制器。每个设备控制器可以连接多个设备 I/O硬件 设备、I/O接口 通道方式：设备、设备控制器、通道 I/O设备与主机的联系方式 I/O设备编制方式 统一编制 用取数、存数指令直接对I/O设备进行访问，不需要单独的指令 就是把I/O设备的地址看成内存地址的一部分。 比如内存地址为1M，那么1M地址中低地址或高地址64k拿出作为I/O设备的地址或端口地址，如果输入输出指令或访存指令他的地址码部分的地址，落入I/O地址部分，这次输入或输出操作实际是对I/O设备进行的。 指令集相对简单，如果内存系统的编址空间大的话就可以采用统一编址方式 不统一编址(单独编址) 有专门的I/O指令 在内存地址空间外，专门设置一个地址空间。 如：内存的地址空间20位寻址空间1M，对外部设备编址时他的地址空间是从16个0到16个1，就是64K为了区分一条指令是对内存操作还是对I/O设备操作，在单独编制的计算机当中，输入输出指令不能再采用计算机系统原有的取数或存数指令，用专用的I/O指令进行控制。 设备选址：用设备选择电路识别是否被选中 只要把CPU给出的地址和设备中保存的地址进行比较，如果两者相同，就选中。 传送方式(第三章有介绍) 串行：一位一位传输，传输速度慢，但适合远程传输 并行：同时多位在多条数据线上传输，数量通常是8的倍数 联络方式 立即响应：对一些结构简单，状态数量少，接收到数据直接进行显示。 异步工作采用应答信号(指I/O接口与I/O设备之间) 并行 CPU和接口之间一般都是异步 I/O接口与I/O设备之间要有多条的类似总线结构的数据线，来完成数据并行的输入和输出。双方之间要采用应答信号。 输入输出工作流程：I/O设备要接收数据，I/O端口把数据准备好以后通过“Ready”信号告诉I/O设备，端口中的数据准备好了，I/O设备对端口中的数据进行读取并且给出应答”Strobe”信号。如果是输入I/O设备把数据通过I/O接口输入到主机中。I/O接口中数据块缓冲器一旦空了，就会向I/O设备发送“Ready”信号告诉I/O设备可以向I/O接口中发送数据，I/O设备向I/O接口发送数据并且给出应答信号。 串行 起始位9.09ms低电平结束之后是若干位的数据位，数据位结束后给出2位高电平终止位 同步工作采用同步时标：必须有定宽定距的时标 I/O设备与主机的连接方式(在发展概述早期有介绍) 辐射式连接(分散连接)：增加一个I/O设备就需要在主机中增加一套控制电路 增加和删除设备麻烦 可移植性差 总线连接： 外部设备通过接口和主机连接，接口能够向外部设备传送主机的控制命令，可以向主机传送外部设备的状态信息，同样接口也可以完成设备传输，外部设备的输入数据可以先缓存接口中，完成数据的格式转化等操作然后输入到主存。或者主机的数据在接口换算，经过格式的变化等处理传输给外部设备。 便于增删设备 I/O设备与主机信息传送的控制方式 程序查询方式：最早的，CPU和外设采用串行的方式进行工作 工作流程：CPU在程序中执行读操作指令，向I/O设备发出读命令，CPU开始读取I/O的状态(实际是I/O接口中状态触发器或状态标志的一个值)，看数据是否准备好，如果没有跳转指令CPU会不断地反复的去读状态标志如果出错进入出错处理，如果准备就绪，这时CPU可以从接口中读出一个数据(该数据可以是一个字节也可以是一个字)，读出后放入CPU的某个寄存器，然后再把寄存器中的数据写入内存指定位置，再判断传输是否结束，如果没有结束还会通过程序发出读指令。 内存和I/O要想数据交换必须通过CPU 程序中断方式：CPU与I/O设备之间部分并行工作，也就是I/O设备，CPU还可以执行自己的程序 I/O工作两个阶段：自身准备阶段、与主机交换信息。 在自身准备阶段CPU不查询，只有当外部设备和主机间开始进行信息交换，CPU会暂停现行程序 工作流程：在执行程序过程中碰到I/O指令，执行过程中，启动I/O设备进行数据准备。然后继续执行原来的程序。外部设备接收到命令开始进行数据准备，准备好接受或者输入数据后，会向CPU提出中断请求，让CPU停止对当前程序的执行，转而和I/O设备进行数据交换。 中断流程：CPU发出读指令，I/O和CPU的工作并行进行。CPU继续原来的程序，I/O开始设备的准备工作一直到准备就绪，I/O设备向CPU发出中断请求，CPU读取I/O状态，确定哪个设备，检查状态是否出错，如果出错就出错处理，如果没有就在I/O接口中读一个字送到CPU，然后写入内存再判断输入输出工作是否完成，如果没完成CPU向I/O发出下一个字的读指令。如果完成就结束 收到中断请求信号，执行完当前指令后，将程序断点等进行保存，跳转到中断服务程序，通过终端服务程序来完成输入和输出操作。再转回到原来程序 恢复和中断都需要指令来完成，需要时间。 DMA 方式：使外部设备和内存之间可以建立直接的连接，由DMA控制器或DMA接口直接控制外部设备和内存之间进行内部交换。 主存和I/O之间有一条直接数据通道，不需要中断现行程序。采用周期挪用(周期窃取)的方式 DMA控制器控制主存和外设之间信息交换，一定会用到总线包括地址线‘、控制线、数据线。如果DMA利用的时候，CPU就要让出来，让出一个存取周期的时间。 工作流程：CPU在执行主程序中碰到了I/O指令，CPU发出启动I/O指令，CPU继续自己的操作，I/O设备在DMA控制器的控制下完成数据准备，准备好后要进行数据传输，由DMA控制器发出DMA请求，占用总线的使用权，占用一个存取周期，进行外部设备和内存之间的数据交换。结束后归还总线使用权，CPU可以对内存进行数据交换。 CPU虽然不能使用系统总线，不能使用内存，但可以执行。比如现代处理器不需要CPU每执行一条指令就从内存取指令，在指令执行之前若干条指令被预取到缓存当中了。 通道方式、I/O处理机方式可以看计算机系统结构的教材，往往有介绍。 三种工作效率的比较 还有通道方式、IO处理机方式放到后面讲 5.2外部设备(简要介绍)概述 外部设备通过接口电路和主机进行连接。 外部设备包括：设备控制器，机、电、磁、光部分。 外部设备通过I/O接口进行数据交换，主机通过I/O接口向设备控制器传输控制命令，主机还通过I/O接口读取外部状态。 外部设备分类(3大类) 人机交互设备：将人能识别的信息转化为计算机能识别的信息输入，或是二进制信息转化为人能识别的文字、图像等 键盘、鼠标、打印机等 计算机信息存储设备 磁盘、光盘、磁带 机—机通信设备 调职解调器、网卡等 输入设备 键盘：按键 —&gt; 判断哪个键按下 —&gt; 将此键翻译为ASCII码(编码键盘法) 流程：把若干个键排列成矩阵，用计数器，经过行译码、列译码以后对键盘进行扫描，确定哪个键摁下，一旦扫描到计数器的计数就停止，同时把计数器输出作为ROM输入地址，ROM保存了键盘上对应的ASCII码，通过中断方式读入，CPU读入操作经过一段时间延迟后可以输入到中断控制装置来清除中断标记，可以用于再一次启动计数器，使计数器再对键盘访问，为下一次做准备。 鼠标、触摸屏 输出设备 显示器 字符显示：字符发生器 图形显示：主观图像(人工的方式在计算机上画，或通过程序在计算机上画点线面构成的图像) 图像显示：客观图像 打印机： 打击式(点阵式)：逐字、逐行 非打击式：激光（逐页）喷墨（逐字） 也可以通过宽度分为窄行打印机和宽行打印机 其他 A/D、D/A：模拟/数字（数字/模拟）转换器(A指模拟信号，D指数字信号) 计算机内部使用的使数字信号，如果要进行外部控制或者远程传输需要使用D/A设备将数字信号转化成模拟信号 终端：由键盘和显示器组成(不仅仅使这两样，还有控制系统、缓存等。类似瘦客户机)。 完成显示控制与存储、键盘管理及通信控制 汉字处理：汉字输入、汉字存储、汉字输出 多媒体技术 概念：多种媒体技术和手段相结合进行综合应用给人以更多的视听或动作上的感受 触摸屏 5.3I/O接口概述 实现设备的选择：确认哪个设备参与输入输出操作 实现数据缓冲达到速度匹配：一些设备数据量大，一些设备数据量小 实现数据串—并格式转换 实现电平转化：I/O设备和主机电平不一致，通过接口转换 传送控制命令：CPU将控制命令传送到接口，由这些命令来控制工作 反映设备的状态（“忙”、“就绪”、“中断请求”） 接口的功能和组成这些接口决定了硬件电路的接口 总线方式的I/O接口电路 设备选择线：参与本次信息传输的设备的设备码或者是端口号(设备地址或端口地址)传输给I/O接口进行匹配，看是否是该接口连接的一个设备。 数据线：完成数据的输入输出，条数和接口的类型有关 命令线：主机的命令通过命令线输入I/O接口中，经过缓冲译码后控制设备做相应操作 状态线：单向，I/O接口送到总线再送到主机 接口的功能和组成 功能 组成 选址功能 设备选择电路(逻辑实现上说就是一个比较器) 传送命令的功能 命令寄存器、命令译码器 传送数据的功能(核心功能) 数据缓冲寄存器 DBR 反映设备状态的功能 设备状态标记 设备状态标记 完成触发器 D：D=1表示准备工作已经完成，D=0表示准备工作尚未完成 工作触发器 B：用来标识外部设备工作状态是否忙，B=1表示忙，B=0表示完成工作 中断请求触发器 INTR 屏蔽触发器 MASK：如果等于1表示尽管设备已经完成工作依然不能向主机发送中断请求。表示主机现在工作重要性比现在输入输出的重要性要大。 并串转换、电平转换应该在接口的功能当中，为了使电路简单明了，没有放到教材上，实际是有的。 CPU和接口之间 数据线：双向，并行传输 地址线：给出外部设备地址，供设备选择电路使用 命令线：给出操作命令，放在命令寄存器当中进行存储，进而进行译码。并且在持续电路的控制下给出各个操作以及各个操作的时间关系。 状态线：把I/O接口的状态，外部设备的状态传输给CPU 外部设备和I/O接口之间 数据线：传输接口和设备之间需要传输的数据 命令：命令来自于命令译码器和时序逻辑，控制外部设备做相应的工作 状态：外部设备的状态，把它进行输入，对状态标记进行置位或者复位 接口类型 按数据传送方式分类： 串行接口 Intel 8255 并行接口 Intel 8251 按功能选择的灵活性分类： 可编程接口：功能和工作方式可以通过编程的方式进行设置 Intel8255、Intel 8251 不可编程接口：不能通过软件的方式来设置接口的功能和工作方式，但可以通过硬连线方式来进行改变 Intel 8212 按通用性分类 通用接口：把多种类型接口中通用的电路做到一个芯片中，就形成一个通用接口 Intel 8255、Intel 8251 专用接口：只能用于主机和某一种类型的设备进行连接 Intel 8279、Intel 8275 按数据传送的控制方式分类 中断接口 Intel 8259 DMA接口 Intel 8257 前面介绍过3种数据传送的控制方式，程序查询方式不需要接口来控制。 5.4程序查询方式查询流程单个设备 如果在传输过程种只有一个设备参与内存和I/O之间数据传输，在执行程序的过程中，CPU会执行到一个输入输出指令又这个指令发出启用设备命令，相应的设备接收到命令以后就开始数据准备，数据准备好以后再传输给CPU，CPU在发出设备启用命令之后就开始检查状态标记，I看/O接口中数据、设备是否准备好进行输入和输出，如果准备就绪就进行数据交换，如果没有CPU就踏步状态。直到开始交换数据为止。 测试指令负责检查状态标记。准备就绪阶段使用转移(分支)指令。交换数据使用传送指令或输入输出指令或访存指令 多个设备 如果在传输过程种多个设备要通过程序查询方式和CPU、内存进行数据交换，当我们需要把参与传输的设备，根据他的优先级，根据轻重缓急对他进行排序，优先级越高的设备被查询到的时间越早。 程序流程 程序查询方式要完成内存和外部设备之间的数据输入输出，需要借助CPU中的某一个寄存器，对数据进行暂存，如果数据有用，要对寄存器中的数据进行保存，可以写入内存，压入堆栈或放入放入CPU中闲置寄存器中，保存后设置计数器的值，为了控制传输的数据量(到底多大数据)。为了完成内存和I/O之间的数据传输，需要知道内存块起始地址，所以需要设置主存缓冲区首址。然后启动外设。CPU开始查询I/O接口或设备的状态，看是否准备好，如果没有，就原地踏步的方式反复查询，一直到状态标志表明数据已经准备好，开始进行数据传输，传送一个字，传送完后，修改设置的初始值，修改内存地址，修改计数器的值，为输入或输出下一个数据做准备。然后判断是否传输完，如果没有就再次启动外设，循环过程，直到传输完，结束I/O传送。 两种计数器方式； 如果要传送n个字，计数器的值设为n，每完成一个字的传输，计数器-1，直到0为止 设置为负n，并且用补码来表示，每传输一个字，计数器+1，直到计数器发生溢出，值变为0 程序查询方式的接口电路设备选择电路：它给出的设备选择信号实际是整个I/O接口电路的选择信号，只有它有效I/O接口才会工作。 如果SEL信号有效，并且启动命令有效，I/O接口就会开始工作。 输入(外部设备—&gt;主机)流程：CPU通过地址线给出外部设备的地址，设备选择电路把设备地址或者端口号和地址线上的地址比较，如果相同SEL就有效，在启动命令和SEL信号都有效的情况下，对两个状态标记置位或复位，标记D为0表示数据未准备好，标记B为1表示开始工作忙状态，设备接收到B信号和启动命令信号之后设备开始工作，将设备准备好，并且数据通过输入的数据线保存到DBR当中，设备工作结束。设备通过状态线向接口电路送入设备工作结束信号，该信号会修改两个标记，D为1表示数据准备好，B为0表示设备已经工作完成。D信号被送出。CPU查询的就是D信号。CPU通过数据线读入数据。 5.5程序中断方式中断的概念：指CPU在执行程序的过程当中，如果发生意外事件或是特殊事件，CPU要中断当前程序的执行，转而去处理特殊事件或异常事件，通过执行中断服务程序的方式来进行处理。处理结束之后要返回到被中断的程序的程序断点，继续去执行原来的程序。 如果有中断请求还要判断能不能进行响应，如果能响应才中断现行程序的执行。 中断需要保存程序的断点，中断返回之后要知道从哪继续执行，要保存中断现场(寄存器的值)，做完之后再去执行中断服务程序。 I/O中断的产生中断源：在主机外部、内部和CPU的外部、内部能够引发CPU发生中断的因素都称为中断源。 例打印机 程序中断方式的接口电路采用中断方式不仅仅需要5.3介绍的基本接口电路，还需要有中断请求标志，有外部设备对中断请求标志进行设置，表示有中断请求了。这个中断请求标志能否变成中断请求信号向CPU发出中断请求，还要看中断请求标志是否会被屏蔽。 配置中断请求触发器INTR和中断屏蔽触发器MASK：就是配置两个标志 屏蔽触发器：正在执行的程序或中断服务程序重要性要比这个设备提出的中断请求的重要性要高，这个中断标志就会被屏蔽 INTR值为1表示有中断请求，0为无请求，并且通过中断请求线可以把中断请求送给CPU，通知CPU外部设备有一个中断请求 Q端输出为1表示中断会被屏蔽，0表示开放。要进行数据传输的时候，I/O接口中的状态标记应该是工作休息状态(D=1)。 当D输出为1，MASK Q端为0 Q非端输出为1。两端都为1的时候，中断请求触发器设置为1，表示有中断请求。指令执行周期结束之前CPU会发出中断查询信号，会使INTR的D端的输入被送到输出当中，产生中断请求信号。 排队器：排出优先级最高的设备 硬件：在CPU内或在接口电路中(链式排队器) 接口电路：把硬件的排队电路放在每个接口中，每个接口和排队电路相关的电路连接在一起，就组成了一个链，叫菊花链方式或链式排队器 INTR上面一横：表示相应的中断请求信号，他的非端进行输入。 在该链式排队器中，每一个接口，他的排队线路包含了两个门电路一个非门一个与非门。这个接口中的排队电路把他相互的连接在一起，构成了一个链式排队器。1号设备对应的中断请求信号，被输入到链式排队器中，从设备优先级来说，图左侧优先级高 如果所有中断源都没有中断请求，INTR非的值就为1，每个INTP’输出都是1，如果某一个设备有中断请求INTRi=1，INTRi非就为0 当INTR1有请求INTR1=1，INTR1非=0，那么在第一部分的输出端就为1，在2部分经过非门后，INTP‘2就变成0，在与门和与非门之间的线输出就为0，后面都是一样。也就是说如果某一个优先级的设备提出中断请求的话，排在后面的INTP’都会变成0，在它之前的都是1 方框1是非门的意思 若2有效，前面无效，则前面输出均为1，后面都为0.所以组成是若干个1和若干个0。那么中断请求就是若干个1中最后的一个1，优先级最高。 在INTPi‘外接一个与非门同时连接INTRi，再通过非门，传输出去，这样就只有最后一个1才有效。(这里比较简单稍微想想就行了) 与门：同时输入为高电平1时候才输出高电平，否则低电平 非门：输入取反 与非门：先与再非 软件：通过查询的方法，中断的优先级在表格中进行规定，排队的过程就是高优先级到低优先级的查询的过程(详见第八章)。 中断向量地址形成部件：传递中断程序的入口地址 寻址入口之地同样两种方法：由软件产生(详见第八章)、硬件向量法 硬件向量法：由硬件产生向量地址，再由向量地址找到入口地址 中断号：如8086中支持255个中断这256个中断被编号为0到255 中断向量：和中断服务程序相关的入口地址。包括断地址或偏移量，有时候也指程序状态字，也包括执行中断服务程序的时候需要的一些状态信息。 程序断开字：一些非体系寄存器或表示程序状态的寄存器，这些寄存器指令无法读取，在计算机内部就把它集成成一个字，这个字称为程序状态字 向量地址：指中断向量保存的内存单元的地址(存储中断向量的存储单元地址)如：中断服务程序入口地址，它所保存的内存单元的地址，或者是利用跳转指令，通过该指令跳转到中断服务程序，这时他的向量地址，是指跳转指令在内存中的地址。 中断服务程序的入口地址，可以由中断向量来生成。 要形成向量地址，要用一个硬部件“中断向量地址形成部件”，输入为排队器(链式排队器或其它类型的中断优先级的排队器)的输出结果(只有一位高电平其它低电平)。输出对应了向量地址。 中断向量地址形成部件 从属性上看是 设备编码器 程序中断方式接口电路的基本组成 设备选择电路：输出是接口的选择信号，只有该输出有效接口才开始工作。 命令译码蓝框是我们的命令缓存器、命令译码器、命令寄存器，通过译码确认本次操作确认本次操作对接口和响应设备做什么样的操作。 D、B：标记触发器(在程序查询方式中介绍过) INTR：表示中断请求标记，如果中断源有中断请求INTR的值可能会设为1，具体是不是设为1和中断屏蔽触发器有关。 如果中断没被屏蔽，并且设备工作完成，在中断查询信号的控制下INTR输出就为1。 设备编码器：就是硬件结构的中断地址向量形成部件。 I/O中断处理过程CPU响应中断的条件和时间 条件：允许中断触发器EINT = 1(用开中断指令设置EINT为”1”、用关中断指令或硬件自动复位将EINT置“0”) 时间：当D=1(随机)且MASK=0时。 CPU不能随时中断，一般在每条指令执行阶段的结束前，CPU查询是否有中断请求。CPU发中断查询信号(将INTR置“1”) I/O中断处理过程 输入为例：CPU在执行主程序的过程中，执行到输入指令，要求指定的外部设备将数据输入到主机中。CPU在数据线上给出设备的地址，设备地址送到接口电路中后，利用设备选择电路和设备地址进行比较，如果相同这个接口以及相对应设备被选中，SEL信号有效。由CPU送来启动命令或对接口设备的控制命令，该命令经过译码后输入到接口中，在接口中译码。当该命令和SEL信号同时有效才会使触发器B和D被设置。输入操作要求外部设备将数据输入接口再到主机。因此在启动命令启动后B应被设为1表示设备开始工作同时数据还未准备好触发器D设为0，设备工作结束以后，会把输入数据送入输入接口中的数据缓冲寄存器DBR。同时修改D、B的状态，这时设备工作结束，设备准备好，CPU随时可以把数据取走。因此D被设为1，设备处于空闲，所以B为0。如果接口提出的中断请求没有被屏蔽，意味着MASK触发器非端为1，D输出也为1，两个值经过与非门和非门将值送入INTR输入端。CPU在执行指令结束阶段后发出中断查询信号，这个信号会把接口中中断请求触发器INTR值置位1，同时启动排队器进行排队。经过排队器排队后输出信号只有一个是1其他都是0，CPU发出中断响应信号，发出后形成向量地址，向量地址经过数据线传给CPU传给PC，PC利用地址取出中断程序的入口地址或跳转指令。设备编码器的地址会通过数据线传递给CPU，CPU利用地址找到中断服务程序的入口地址，进而去执行中断服务程序，完成对应操作取走数据。 中断服务程序流程中断服务程序的流程 保护现场 程序断点的保护(中断隐指令完成)：中断返回后，去执行哪条指令的地址要保持。和程序执行状态，不能由指令直接读取的状态。由硬件完成。 中断隐指令并不是一条指令而是硬件要完成的一系列操作。 寄存器内容的保护：通用寄存器或体系结构寄存器如果被利用到，它的值也要保存。一般利用进栈指令进行保存也可以保存在内存单元的指定位置，也可以转存到寄存器。 体系结构寄存器和非体系结构寄存器相对立，体系结构寄存器是可以被程序员“看到”，一般是通用寄存器部分可以被修改和赋值。而非体系结构寄存器是“用户透明”的，不可见的，机器自身执行指令使用。 中断服务：不同I/O设备具有不同内容的设备服务 恢复现场：如果采用进栈指令保存，用出栈指令。如果保存到内存单元，就用取数指令。 中断返回：中断返回指令 单重中断和多重中断 单重中断：指CPU在执行中断服务程序过程中，如果有了新的中断请求，不管新的中断请求优先级有多高都不能中断现行的中断服务程序。 多重中断(中断的嵌套)：允许级别更高的中断源中断现行的中断服务程序 单重中断的流程：在指令执行结束之后查询是否有中断请求，如果没有接着执行下一条，如果有要响应中断请求，进入中断周期(保护断点、形成中断服务程序的入口地址、关中断)中断周期是在一条指令解释的几个阶段中一个阶段(取指令、形成操作数地址、取操作数、执行，执行之后是中断周期)。中断周期结束就进入中断服务程序的执行。保护现场、设备服务、恢复现场、开中断中断返回。在中断返回之后才把中断打开让EINT为1，在整个中断服务程序中EINT都为0。即使有优先级更高的请求CPU也不会响应。 中断周期的操作都是由硬件按照时序来完成的 多重中断的流程：前面和单重中断流程一致。在中断服务程序开始执行过程中不一样。为了让更高级的中断请求能响应。把开中断的位置提前，在设备服务的过程中允许响应更高级的中断请求。 5.6DMA方式DMA方式的特点中断方式：I/O设备和主存数据交换，必须经过CPU中的寄存器。模型中给定ACC寄存器。在内存和I/O设备数据交换的过程中尽管CPU和数据交换可以并行，但是依然要中断现行程序，来执行中断服务程序。 DMA：外部设备和内存之间的数据交换可以直接通过DMA接口而不需要CPU。 程序中断的数据通路和程序查询是相同的 DMA与主存交换数据的三种方式 停止CPU访问主存：从第一块数据交换开始，CPU就放弃了对总线的控制权和内存的访问权，都交给DMA接口 优势：控制简单 劣势：只有指令缓存器中有指令或指令已经取入Cache，CPU才可以继续工作。如果没有CPU就不工作或保持状态，无法充分发挥CPU对主存的利用率。 周期挪用(或周期窃取) 周期：访存周期 如果DMA接口准备好数据传输，就申请建立总线的使用权，占用一个或几个内存访问周期，完成数据的传输，在数据传输的间隔或数据准备阶段，DMA接口放弃对总线的占用 DMA访问主存有三种可能 CPU不访问：DMA正好可以访问 CPU正在访问：DMA等待 CPU和DMA同时请求访存：DMA优先。因为DMA上都是高速设备，如果不响应可能会造成数据丢失 存储墙问题Memory wall DMA与CPU交替访问：实用性不强 CPU工作周期分为：C1、C2 C1专供DMA访存 C2专供CPU访存 由于在固定时间点存储器和I/O总线使用权是固定的，就不需要DMA提出申请对总线的控制器和对内存的使用权，所以速度快。 DMA 接口的功能和组成DMA 接口功能 向 CPU 申请 DMA 传送：DMA要向CPU提出总线和内存占用请求 处理总线 控制权的转交：一旦允许，要转交控制权 管理 系统总线、控制 数据传送 确定 数据传送的 首地址和长度、修正传送过程中的数据地址和长度：也要知道数据传输方向、修改长度主要是为了数据块的传输是否结束 DMA传送结束时，给出操作完成信号 DMA 接口组成 假设为单总线结构 要进行数据传输CPU首先要告诉DMA接口传输的地址，所以需要一个地址寄存器AR 需要知道传输的数据量所以需要计数器WC进行传输量的计数 数据缓存器BR：外部设备的数据或存储单元输出的数据要暂存其中 设备地址寄存器DAR： 供设备选择电路使用，看下这次访问的设备是不是接口中当前连接的设备。可以把设备地址保存其中 对硬盘访问的时候，DAR还能保存柱面号，磁道号，扇区号 地址线：AR把要访问的内存地址送给主存 数据线：要给AR、WC、DAR、BR置值。 外部设备和数据缓存器直接相连。 输入输出控制是由DMA控制逻辑来进行控制，要控制接口内部进行协调工作，控制在给定的时序发出给定的信号(如：给CPU发出DMA请求、向主存发出读写控制信号) 外部设备如果进行DMA传输，要向DMA控制逻辑发出请求信号DREQ(设备请求缩写)。DMA要向CPU发出控制信号，DMA控制器要对设备给出应答信号DACK，还要对CPU发出总线使用的请求信号HRQ。CPU发出应答信号HLDA由MDA控制器接收。 中断机构：用于数据传输完后，对后续工作进行处理。计数器为0时表示传输结束，就会向中断机构发信号，给中断机构的中断请求触发器置1，当一条指令执行结束后，由中断机构向CPU发出中断请求。由CPU做数据传输后处理 DMA 的工作过程DMA传送过程 预处理：在数据传输之前要做的一些响应的设置 通过几条输入输出指令预置如下信息 通知DMA控制逻辑传输方向(入/出) 设备地址—&gt;DMA的DAR 主存地址—&gt;DMA的AR 传送字数—&gt;DMA的WC 数据传送 是否允许传送：能否占用总线和内存的使用权 主存地址由AR送入总线 由DMA控制逻辑进行一个字的传输，传输完后修改主存地址为下一次传输做准备。同时修改字计数器 通过计数器的值是否为0来判断传输是否结束。如果没结束再判断是否允许数据传输。如果结束了，就向CPU申请程序中断。 后处理：执行中断程序，做DMA结束处理 全部做完后继续执行主程序 CPU先做预处理，启动设备后，CPU继续执行输入输出指令后的一些指令，真正的数据输入输出操作由DMA接口完成。DMA接口控制完成一批数据的传送。 以输入为例，看DMA接口工作流程：这里的输入指数据从外部设备送入主存。数据从外部设备送入BR，BR保存了要输入的数据，之后通过DREQ信号通知DMA接口数据已经准备好。DMA控制逻辑通过HRQ信号通过总线向CPU提出总线和主存的占用请求。CPU在允许的情况下给出HLDA信号，然后放弃总线和主存的占用。要进行数据传输要给出主存地址，地址通过AR寄存器给出使系统总线上地址总线有效。再由DMA控制器通过DACK信号通知设备已经开始进行数据传输。数据和控制信号由DMA控制器和BR发出。DMA控制器发出对内存的控制指令，同时BR通过数据线将数据送到数据总线。每传送一个内存AR和WC+1。然后判断是否传输完，如果没有就再来一次，如果结束，WC发出溢出。溢出信号送到中断机构使中断机构中的中断请求触发器参加中断排队。CPU接收到中断请求后去执行中断服务程序做后处理。 如果是输出：首先要将BR中的数据送入设备，这时候BR空，数据传输完。由设备通过DREQ信号通知DMA控制器BR空可以用于接收下一个数据。DMA控制器通过HRQ信号向CPU发出总线和内存的控制请求。CPU在允许的情况下给出HLDA应答信号，这时内存和总线控制权都交给DMA接口。如果要进行输出还要给出要访问的内存单元的地址。AR给出该地址。同时DMA通过DACK信号对设备应答。通过这些控制信号以及给出的地址信号，主存当中的数据会被再次写入到BR中。同时要修改AR和WC。再判断传输是否结束，如果没有再循环刚才的过程。如果结束，用WC的溢出信号告诉中断机构，把中断机构中的INTR信号置1。由中断机构发出中断请求。进行后处理。 后处理的工作内容 校验送入主存的数是否正确 是否继续用 DMA 测试传送过程是否正确，错则转诊断程序 后处理是CPU在响应了DMA接口以后中断请求以后执行中断服务程序来完成 DMA接口与系统的连接方式 一台机器上可以有多个DMA接口，都要连接到总线上。 连接方式： 具有公共请求线的DMA请求：DMA接口通过地址线数据线和主存进行连接同时所有的DMA接口共享一条请求线 请求线是送至CPU。 进行DMA响应的时候各个DMA接口也是有优先级排序的。CPU通过查询线一个一个进行查询。越靠近CPU的DMA接口优先级越高。 独立的DMA请求：类似于独立请求方式。每个DMA接口要和地址线数据线进行连接。每个接口都有独立的DMA请求信号、DMA响应信号。排队的工作在CPU内。 优缺点可以参照第三章中串行和独立请求方式的优缺点。也可以模拟第三章给出的方法，给出第三中连接方法。 DMA方式与程序中断方式的比较 中断方式 DMA方式 数据传送 程序(中断服务程序) 硬件 响应时间 指令执行结束 存取周期(设备与主存直接数据交换) 处理异常情况 能 不能 中断请求(两者的目的和作用不一样) 传送数据 后处理 优先级 低 高 DMA 接口的类型 选择型：在物理上连接多个设备，在逻辑上只允许连接一个设备。 如果是选择型接口这些寄存器、时序电路就只有一套。某一个设备要使用该接口进行数据传输，CPU通过允许一条输入输出指令，要对这些寄存器设置。其他设备无法和主存进行DMA请求、数据交换。 多路型：在物理上连接多个设备，在逻辑上只允许连接多个设备。 但正在进行传输的时候也只能有一个设备与内存进行传输 数据准备阶段可以有多个设备进行数据准备 通道是一种小型的DMA处理机也是一种DMA接口。每个通道下都有若干个子通道，每个子通道都有主存地址寄存器、设备地址寄存器、字计数器。这些子通道可以控制多个设备，设备进行数据传输的时候，CPU执行到输入输出指令，要控制某个设备进行输入输出，他就对相应的子通道当中的寄存器进行设置。设置完后他就继续执行自己的程序。碰到了吓一跳输入输出指令如果两个设备用不同的子通道，还会对其他的子通道当中主存地址寄存器、字计数器、设备地址寄存器再次进行设置。外部设备在之后的时间里可以进行数据准备。这个数据准备是多个外部设备并行进行的。外部设备准备好后通过子通道向通道提出数据传输请求。这时候不同设备的数据传输是串行执行的。 多路DMA接口工作原理 假设磁盘每隔30微秒(包含了数据的传送时间和数据的准备时间)提出一次数据传输请求。 假设磁带每隔45微秒提出一个DMA请求。 假设打印机每隔150微秒提出一个DMA请求。 假设真正用于数据传送的时间只有5微秒。DMA接口的数据送入主存或主存数据送入DMA接口。 一个多路型接口连接了这三个设备，由于打印机最早提出请求，就最先响应打印机，把5微秒给打印机。然后磁盘和磁带同时发出请求(速度越高的设备优先级越高)。响应磁盘用5微秒完成数据传输。因为请求之前数据已经放入数据缓存器里，所以这5微秒就用于接口的数据和内存的数据进行传输。再响应磁带请求。 尽管一个多路型接口连接了很多设备，但依然有很多时间是空闲的。还可以连接更多的设备。 计算机组成原理—数字 计算机中 数的表示：硬件识别和处理的数据类型。 在计算机系统的指令集中包含对这些中类型操作的指令 运算器的设计：分析数据的比算方法，对其改进，借助该算法，研究在硬件如何实现。给出相应硬件组成。 六、计算机的运算方法6.1无符号数和有符号数无符号数概念：没有正负号的数据。 把它变换为二进制，用计算机当中的寄存器或存储器按规定长度，保存到计算机中。如果保存在寄存器中，那寄存器的长度就直接反映了无符号数的表示范围 有符号数概念：有正负号的数据。 有符号数包含数值部分和数值部分。 机器数与真值 机器数：符号数字化的数(保存在计算机中的数) 真值：带符号的数(不一定是十进制) 小数点的位置可以以约定的方式给出。没有任何硬件来表示。 可以通过小数点的位置分类：小数定点机(小数点约定在符号位后面)、整数定点机 原码表示法 PS：我觉得以下公式有点鬼扯。就理解为0是正1是负。原码组成就是符号位+照抄 定义(x为真值，n为整数的位数)：|X|原= 0,x 2^n^＞x≥0 2^n^-x 0≥x＞-2^n^ 如 x=+1110 [x]原=0,1110 用逗号将符号位和数值部分隔开。 ​ x=-1110 [x]原=2^4^+1110 =1,1110 0的原码计算不同，表示的机器数也不同。0有两种形式 符号位+照抄 小数的原码表示 定义：[x]原= x 1&gt;x≥0 1-x 0≥x＞-1 小数的0也有两个表示方式 如 x=+0.1101 [x]原=0.1101 ​ x=-0.1101 [x]原=1-(-0.11.1)=1.1101 小数点将符号位和数值部分隔开。 整数用逗号表示，小数用小数点表示。但在计算机中是不需要存储表示的。 特点：简单、直观 缺点：加减法运算有问题。 要求 数1 数2 实际操作 结果符号 加法 正 郑 加 正 加法 正 负 减 可正可负 加法 负 正 减 可正可负 加法 负 负 加 负 思考：能否只作加法？ 找到一个与负数等价的正数来替代这个负数，使减—&gt;加 补码表示法 PS：公式复杂，正数就是0+照抄。负数就是1+原码取反+1。补码转原码也是除符号位取反+1。 补的概念：一个负数加上”模“即得该负数得补数。 一个正数和一个负数互为补数时，它们绝对值之和即为模数。 在时钟内可以用-3当作+9，-5当作+7. 如：寄存器四位：-1011可以记作0101。三位011记作101 补码定义(x为真值 n为整数的位数)：[x]补= 0，x 2^n^&gt;x≥0 2^n+1^+x 0&gt;x≥ -2^n^(mod 2^n+1^) 如x=+1010 [x]补=0,1010 ​ x=-1011000 [x]补=1,0101000 小数的补码表示 定义(x为真值)：[x]补= x 1&gt;x≥0 2+x 0&gt;x≥-1 (mod2) 如 x=+0.1110 [x]补=0.1110 ​ x=-0.1100000 [x]补=1.0100000 补码的100…0当特例来记 反码表示法 PS：正数为0+照抄，负数为1+取反 定义(x为真值，n为整数位数)：[x]反= 0，x 2^n^&gt;x≥0 (2^n+1^-1)+x 0≥x&gt; -2^n^(mode 2^n+1^-1) 如 x=+1101 [x]反=0,1101 ​ x=-1101 [x]反=1,0010 小数的反码 定义： [x]反= x 1&gt;x≥0 (2-2^-n^)+x 0≥x&gt;-1 (mod 2-2^-n^) 如：x=+0.1101 [x]反=0.1101 ​ x= -0.1010 [x]反=1.0101 小结： 最高位为符号位，书写上用“,”(整数)或”.“(小数)将数值部分和符号位隔开 对于正数，原码=补码=反码 对于负数，符号位为1，其数值部分原码除符号位外每位取反末尾加1—&gt;补码，原码除符号位外每位取反—&gt;反码 移码表示法 PS：移码和补码只差一个符号位 补码表示很难直接判断其真值大小 定义：[x]移=2^n^+x (2^n^&gt;x≥-2^n^) 不管是正负数都加2^n^ 无小数 如： x=10100 [x]移=1,10100 ​ x=-10100 [x]移=0,01100 6.2数的定点表示和浮点表示定点表示概念：小数点按约定方式标出。小数点位置是由计算机体系结构设计人员，在设计过程中约定的。在硬件实现和软件实现都要遵守约定，软件编程人员要根据该约定在程序中调整数值的大小来适应约定。 两种形式 小数点在数符后面 小数点在数值后 根据小数点的位置把计算机分为两类：小数定点机、整数定点机。 定点机 小数定点机（范围） 整数定点机（范围） 原码 -(1-2^-n^)~+(1-2^-n^) -(2^n^-1)~+(2^n^-1) 补码 -1~+(1-2^-n^) -2^n^~+(2^n^-1) 反码 -(1-2^-n^)~+(1-2^-n^) -2^n^~+(2^n^-1) 浮点表示为啥引入浮点数表示 编程困难，程序员要调节小数点的位置 数的表示范围小，为了表示两个大小相差很大的数据，需要很长的机器字长。 数据存储单元的利用率低 浮点数的表示形式 表示：N=S×r^j^ 浮点数的一般形式 S尾数(小于等于1、可正可负) j阶码(可正可负) r尾数的基值 如r=2 N=11.0101=0.110101×2^10^（10二进制） 浮点数的表示范围 前半部分为阶码，后半部分为尾数 发生上溢时做错误处理，发生下溢时 按机器零(0)处理 练习 为了满足最大精度，必须让尾数尽可能长。 2^15^=32768。15&lt;2^4^。所以阶码给4位，两个符号位。剩余都给尾数部分。所以m=4，n=18. 浮点数的规格化形式 ​ r=2：尾数最高位为1 ​ r=4：尾数最高2位不全为0 ​ r=8：尾数最高3位不全为0 基数不同，浮点数的规格化形式不同。 浮点数的规格化 r=2 左规 尾数左移一位，阶码减1 右规 尾数右移一位，阶码加1 r=4 左规 尾数左移二位，阶码减1 右规 尾数右移二位，阶码加1 基数r越大，可表示的的浮点数的范围越大，浮点数的精度越低 举例 19=16+2+1=10011 除138右移7位 0.0010011 定点表示：0.0010011000 浮点规格化表示：x=0.1001100000×2^-10^ 定点机中：[x]原 = [x]补= [x]反 = 0.0010011000 浮点机种：[x]原 = 1, 0010;0. 1001100000、[x]补 = 1, 1110; 0. 1001100000、[x]反 = 1, 1101;0. 1001100000 分号隔开阶码和尾数 机器零 当浮点数尾数为0时，不论其阶码为何值按机器零处理 当浮点数阶码等于或小于它所表示的最小数时，不论尾数为何值，按机器零处理 如5位补码(含符号位)1,0000表示-16，无论尾数，都为0 当阶码用移码，尾数用补码表示时，机器零为0,0000;0.00…0 有利于机器中“判0”电路实现 IEEE 754标准 该阶码的偏置值必普通移码的偏置值少1，范围为-126~127，没有全0和全1。 尾数规格化表示：非“0”的有效位最高位一定为“1”(隐含)，所以可以省略一位来提高精度。 754标准对实数有三种规定。 符号位S 阶码 尾数 总位数 短实数 1 8 23 32 长实数 1 11 52 64 临时实数 1 15 64 80 6.3定点运算移位运算机器用语：数据相对于小数点移动。 左移：绝对值扩大。右移：绝对值缩小 小数点是设计时规定的，无法移动 移位规则 符号位不变 算数移位的硬件实现： 真值为正(左移)：符号位不变，所以构成一个循环。数值位左移最高位丢弃(向下箭头表示)，最低位补0(0箭头表示) 真值为正(右移)：符号位自我复制，并把自身0给右边一位。最低位丢掉 负数的原码(左移)：符号位不动，高位丢弃，低位补零。 负数的原码(右移)：符号位不动，低位丢弃，高位补零。 负数的补码(左移)：符号位不动，高位丢弃，低位补零 负数的补码(右移)：符号位自我复制并且右移，低位丢弃 负数的反码(左移)：符号位不动，高位丢弃，低位补1 复数的反码(右移)：符号位自我复制并且右移 ，低位丢弃 真值为正 负数的原码 复数的补码 负数的反码 若左移丢1 出错 出错 正确(若丢0出错) 正确 若右移丢1 影响精度 影响精度 影响精度 正确 算术移位：有符号数的移位(算数位不参与) 逻辑移位：无符号数的移位(算数位参与) 加减法运算加法： 整数 [A]补+[B]补=[A+B]补(mod 2^n+1^) 小数 [A]补+[B]补=[A+B]补(mod 2) 减法(A-b=A+(-B))： 整数 [A-B]补=[A+(-B)]补=[A]补+[-B]补 (mod 2^n+1^) 小数 [A-B]补=[A+(-B)]补=[A]补+[-B]补 (mod 2) 对于整数来说mod 2^n+1^不论正负数，他的补码形式都可以用x+2^n+1^来表示，根据该规则不用区分加数被加数和正负数。把A的补码表示成2^n+1^+A。如果A为小数形式可以变为2+A。因为正数的话多出来的高位会自动丢弃 连同符号位一起相加，符号位产生的进位自然丢掉 溢出判断 一位符号位判溢出：参加的两个数符号相同，其结果的符号与原操作数的符号不同，即为溢出 最高有效位的进位⊕符号位的进位=1 最高有效位的进位：数值部分运算的进位 符号位的进位：两个1，或符号位一个1最高有效位一个1。 如果用一位符号位判溢出，在硬件上要记录符号位的进位和最高有效位的进位。然后送入异或电路，如果输出为1表示发生了溢出。 ⊕表示异或逻辑运算，只有两个变量相异才为1，相同为0 两个符号位判溢出（符号位是2位不是1位） 小数：[x]补= x 1&gt;x≥0 4+x 0&gt;x≥-1 (mod4) 若双符号位相同：未溢出；若双符号位不同：溢出。 最高符号位代表真正符号位，第二位实际是溢出值 推广： 小数：可以以2^k^作为模，那么它的补码符号位部分就占了k位。 整数：可以以2^n+m^作为模，符号位m位 补码加减法的硬件配置 加法器：来完成运算。 A(ACC寄存器)：保存被加数 X(寄存器)：保存加数(或减数)的补码 GA、GS：两个标记，如果做加法GA置1，如果减法GS置1。 求补控制逻辑：用来完成B的补码到-B的补码的过程。如果是减法就每位取反，包括符号位。 加一操作可以利用另一个加法器，或直接用图上加法器加完再运算原加法。但是这样会非常麻烦 以下我略懂(日后看)：B的补码到-B的补码过程中，每位取反非常容易可以在加法器和寄存器之间加一个反向器。末尾加一通过第一位送过来的进位把它置1来实现末尾加1的操作 乘法运算计算机如何做二进制的乘法运算？ 分析笔算乘法 可以用异或电路完成符号位的单独处理 可以把乘数放入一位的寄存器中，每判断一位是否为1。判断完后寄存器的值右移一位。来完成某一位是否加被乘数 4个位积相加，用累加。加的时候第二寄存器的值要左移一位和原来的位积相加。实际上可以将被乘数的位置不懂，位积每次相加的时候右移一位来替代被乘数左移。 用两个寄存器保存乘积的值，来保证位数扩大一倍 改进笔算乘法 将被乘数A+0，再右移一位，等到新的部分积，再部分积+被乘数(若为0则+0，若为1则加A)，再右移一位，以此类推 小结 乘法 运算可用 加和移位实现。n(n为位数) = i，加 i 次，移 i 次 由乘数的末位决定被乘数是否与原部分积相加。0丢弃1相加 乘数时放入乘商寄存器中，乘法的累加值的高位放入ACC寄存器，ACC数值部分长度随着右移加长。那它的低位被移到了MQ寄存器中，MQ寄存器保存的乘数也在逐渐右移。被乘数只与ACC寄存器中保存的高位相加，MQ中的低位不操作。 X寄存器保存被乘数不需要移位功能。但MQ和ACC都需要移位功能。 全加器：要实现被乘数和部分积的高位相加的操作。需要n+1 原码的乘法运算 符号位和数值位分开运算 原码一位递推公式(类似第2步改进乘法笔算) 因为运算采用的是绝对值运算，所以移位时用的是逻辑右移(带符号位)。因为如果运算进位是进到符号位，绝对值符号位初始值为0。 符号位异或操作，数值部分按绝对值相乘 特点： 绝对值运算 用移位的次数判断乘法是否结束 例： 硬件配置 A：n+1位，其中有一位最高位并不是最高位，他保存的是低位数值部分相加以后向高位的进位 X：保存被乘数，计算过程中被乘数保持不变 Q(MQ)：乘商寄存器，计算刚开始时这里保存的乘数的数值位，随着计算的进行一边计算一边移位。他的高位部分逐渐被累加和的低位部分占据，乘数的低位部分，每次移位都会遗留移位，直到完成n次移位所有的数值位部分都移掉。运算结束。 计算器C：用来记录移位次数。数值部分位n，它就位n每次移位-1。为0时结束 S：符号位，通过异或方式给S置值 GM：乘法标志 移位和加控制：由Q的最低位控制 控制门：当Q最低位为1时，控制门开打，被乘数送往加法器。如果是0，控制门把0送入加法器和A累加或者不送入，由移位和加控制直接进行移位操作。 A、X、Q均为n+1位：Q实际n位就够了，但是计算机中，寄存器不是专用做乘法，还有很多其它应用。 补码的乘法运算(完全不懂，再看) 补码一位乘运算规则(被乘数：[x]补、乘数[y]补) 被乘数任意，乘数为正：与原码乘相似，但加和移位按补码规则运算。乘积符号自然形成 公式：[x×y]补=[x]补×[y]补，y0=0 被乘数任意，乘数为负：乘数去掉符号位，操作与(被乘数任意，乘数为正)一样，最后加[-x]补，校正 公式：[x×y]补=[x]补×0.y1…yn+[-x]补，y0=1 改进公式(统一)：[x×y]补=[x]补×0.y1…yn+[-x]补×y0 因为分情况判断会造成硬件非常复杂。 两位乘教材上自己看 Booth算法(被乘数、乘数符号任意) 到最后就类似原码的乘法 最后一步是不需要乘2^-1^所以不移位。[zn]为每步的部分积 关键是实现yi+1-yi：用译码器 译码器输入为yi和yi+1，输出四根线00、01、10、11。其中11和00做相同操作，做一个或操作。 yi yi+1 yi+1-yi 操作 0 0 0 右移1位 0 1 1 +[x]补，右移1位 1 0 -1 +[-x]补，右移1位 1 1 0 右移1位 举例：符号位给2位，为了满足数值进位。移位的过程是按照补码的规则 Booth算法硬件配置 A(ACC累加器)：存放部分积和最后的积高位部分 Q(MQ寄存器)：保存乘数 X：保存x(被乘数) 移位和加控制逻辑：判断加什么 都是n+2位寄存器。这里用的双符号位。 小结： 整数与小数乘法完全相同，只需将逗号替代小数点 原码乘 符号位 单独处理。补码乘 符号位 自然形成。 原码乘去掉符号位运算 即为无符号数乘法 不同的乘法运算需有不同的硬件支持 除法运算 分析笔算除法 商符单独处理：容易实现 用异或电路就可以 心算上商：在计算机里完成移位和比较的过程。 余数不动低位补”0”减去右移一位的除数：n位加法器无法完成该操作，要用2n位的加法器实现。 上商位置不固定 笔算除法和机器除法的比较 笔算除法 机器除法 商符单独处理 符号位异或形成 心算上商 |x|-|y|&gt;0 上商1、|x|-|y|&lt;0 上商0 余数不动低位补“0” 减右移一位的除数 余数左移一位低位补“0”减除数 2倍字长加法器 1倍字长加法器 上商位置不固定 在寄存器最末位上商(然后每次上商都把商值得寄存器左移一位) 在笔算中，是除数右移会导致长度太长，所以机器中可以采用余数左移 原码除法 ⊕：异或运算 约定： 小数定点除法 x* ＜ y* 整数定点除法 x* ＞ y* 如果遇到，可以停止计算，说明发生了溢出 被除数不等于0 除数不能为0：除数不能为0否则系统会发生异常 恢复余数法 上商5次：第一次是小数前面得0 ) 不恢复余数法(加减交替法) 2Ri表示余数左移1位 其余和恢复余数法一致，但减完后若上商0则左移一位加而不是减。 上商n+1：第一次上商来判断溢出 硬件实现 A：保存被除数的余数 X：保存除数 Q：保存商 移位和加控制逻辑：通过上商的最后一位来确认左移后是加还是减除数。 C：用移位的次数或加法的次数来控制除法操作停止 GD：除法标志 S：符号位 V：是否发生溢出 A、X、Q均为n+1位 6.4浮点四则运算乘除法运算可以根据定点运算和浮点的加减法运算自学(不考) 浮点加减运算 阶码一致才能运算。 对阶 求阶差：Δj=jx-jy= = 0 jx=jy 已对齐 &gt; 0 jx&gt;jy x向y看齐降低x阶码使他和y的阶码相同或y向x看齐 &lt; 0 jx&lt;jy x向y看齐增加x阶码使他和y的阶码相同或y向x看齐 尾数右移比左移 合理，移位左移数据位丢失误差大 小阶向大阶看齐 对阶：将阶码对齐，相应移位 尾数求和 规格化：尽可能提高浮点数的表示精度 定义：若尾数基值r=2，1/2≤|S|&lt;1。若r=4，1/4≤|S|&lt;1 以此类推 规格化数的判断： S&gt;0 规格化形式 S&lt;0 规格化形式 真值 0.1xx…x 真值 -0.1xx…x 原码 0.1xx…x 原码 1.1xx…x 补码 0.1xx…x 补码 1.0xx…x 反码 0.1xx…x 反码 1.0xx…x 原码：不论正负数，第一数位为1 补码：符号位和第一数位不同 特例： 左规(补码)：尾数左移一位，阶码减1，直到数符和第一位数不同为止 右规：当尾数溢出(&gt;1)时，需右规，即尾数出现01.xx…x或10.xx…x时，尾数右移一位，阶码+1。 01.的时候其实真正符号位是0,1为数值位 舍入：在 对阶 和 右规 过程中，可能出现 尾数末位丢失 引起误差，需考虑舍入 0舍1入法：类似四舍五入 恒置“1”法：不论舍弃什么值，末尾都为1 舍入：数据的长度超过计算机中存储数据的物理器件能保存的数据的长度。 溢出判断：整个浮点数溢出 -1/2不是规格化数据，所以取不到 下溢，阶码小于-128，阶码为10，xx…x 上溢，阶码大于127，阶码为01，xxx…x 6.5算术逻辑单元前面介绍的运算硬件电路在计算机中被集成到算术逻辑单元中 ALU电路ALU电路是一个组合逻辑电路，没有记忆功能。输入消失，输出端的运算结果也会消失。为了对输出的运算结果保存，并且使运算稳定，在输入端Ai、Bi和输出端连接寄存器。 Ai、Bi：表示参加运算的数据 Fi：输出结果 Ki：决定做什么运算 自主学习四位ALU 74181 在74181当中，控制端M如果输入低电平(0)表示算术运算，如果是高电平(1)逻辑运算。另外四个控制端S0S3取不同值，可做不同运算。 快速进位链并行加法器(略讲后面会细讲) 图上：n+1个全加器构成的并行加法器 两个n+1位的数可以利用该加法器以并行的方式完成加法运算。 每个全加器三个输入 Ci：低位向相邻高位的进位 Ai、Bi：对应了参与两个数的相应位 Si：本位和，加法和的结果，指出运算结果某一位是1或0 在Si和Ci的算术过程中，Ai和Bi都是已知的，只有Ci-1是未知的。所以Ci-1的产生速度提高就能提高运算器的速度。 Ci根据重叠律让AiBiCi-1乘3分别与前面的结合提取公因式 结论：若Ai、Bi都为1，那么Ci就为1。若Ai、Bi至少一个为1，Ci-1才会进位 因此di=AiBi 本地进位(AiBi叫本地进位，由本地参与运算的两个数据相应的位产生进位) ti=Ai+Bi 传送条件，如果ti=1那么Ci-1的结果会被传送到Ci 则Ci=di+tiCi-1 A的反+A=1 重叠律：A+A+A=A。 串行进位链 进位链：传送进位的电路 串行进位链：进位以串行的方式进行传送 根据非(A 或B) = (非A) 且(非B)可以转化式子 根据德摩根定律中非(A 或B) = (非A) 且(非B)化简 并行加法器 用到了与或非门 电路实现参照算式，大方框最后一步是非门，小方框1是非门。 与门一般是与非门+非门。考虑到成本和内部电路 单重分组跳跃进位链 n位全加器分若干小组，小组中的进位同时产生，小组与小组之间采用串行进位。 双重分组跳跃进位链 n位全加器分若干大组，大组中又包含若干小组。每个大组中小组的最高位进位同时产生。大组与大组之间采用串行进位 大组进位分析 图1为公式推导，图2为第2大组中每个小组的进位，图3为具体小组的电路实现，图4大组内进位过程，图5为两个大组结合进位过程 第8组进位是C3。组成是最右边C0、C1、C2。 Di和T5都是该小组本地产生，不依赖于外来进位 通过公式推导，使得让原来依赖C3、C7…都改换成依赖C-1。小组的进位直接依赖C-1 图上可以看出来T8和D8都是2.5T后同时产生的。 书p289第一句话关键，看懂就懂了 七、指令系统7.1机器指令机器指令指计算机系统的CPU能直接识别并执行的操作命令。 一个处理器能执行的所有的机器指令称为指令集。 指令集是计算机系统软件和硬件的交界面。 指令的字长：一条指令它的长度的位数。固定或可变 指令的一般格式 格式：操作码字段+地址码字段 操作码：指出机器做什么操作。在很多机器的指令集中操作码还要指出对什么数据做操作。另外在一些机器中操作码还指出了操作数的寻址方式。 长度固定：用于指令字长较长的情况，RISC(精简指令集计算机)。 如IBM 370 操作码8位 长度可变 在实际上操作码字段可以分开，在不同位置表示 如x86处理器 如：IBM360指令系统中，加法操作因为数据类型不一样表示的基值不一样，一个加法指令一共8条。分别对应定点数和浮点数，浮点数的尾数进制是2还是16等 扩展操作码技术 方法： 保留编码的码点作为扩展标志 操作码的位数随地址数的减少而增加 若前4位或8位等，全1表示扩展。后面的几位表示扩展的操作码 OP：操作码。A1、A2、A3：地址码 短操作码不能是长操作码的前缀。(数据结构里有讲) 三地址：A1、A2、A3。两地址：A2、A3。一地址：A3 高频指令用短操作码，低频指令用长操作码。 利用操作码中某一位作为扩展标志 地址码 四地址 OP：操作码 8位 A1 第一操作数地址 6位 A2 第二操作数地址 6位 A3 结果的地址 6位 A4 下一条指令地址 6位 取指令、取A1、取A2、保存A3。所以需要四次访存。取A4就是取指令 寻址范围 2^6^ = 64 在现代计算机中，采用PC来表示下一条要取得或执行的指令。PC代替A4就变为三地址指令。原来一个A是6位地址，替代后就是一个A8位地址 三地址 都是8位 寻址范围 2^8^ = 256 用A1或A2代替A3，将结果保存到原操作数的地址中，可以进一步扩大地址码位数。成二地址 二地址 寻址范围 2^12^ = 4K 3访存或4访存 可以将保存在指定寄存器中，进一步减少访存次数。如保存到ACC 若其中一个操作数需要在ACC中有，另一个操作数在内存。结果保存到ACC，进一步简化到一地址 一地址 寻址范围 2^12^ = 4K 两次访存 零地址 如：对ACC数据操作。在ACC采用隐含寻址的方式。比如清零、给ACC数据取反、或者对其中某一类数据进行操作或判断是否全1，全0、堆栈类型的计算机加法类型的操作只要有操作码即可(栈顶两个数据加，结果保存到栈顶)。 指令字长 取决于：操作码的长度、操作数地址的长度、操作数地址的个数 指令字长固定：等于存储字长或短于存储字长 指令字长可变：按字节的倍数变化 小结 当用一些硬件资源代替指令字中的地址码字段后 可扩大指令的寻址范围 可缩短指令字长(指令是包括操作码和地址码) 可减少访存次数 当指令的地址字段为寄存器时 ​ 三地址 OP R1, R2 , R3 ​ 二地址 OP R1 , R2 ​ 一地址 OP R1 可缩短指令字长(寄存器个数少如16个4位足够) 指令执行阶段不访存 7.2操作数类型和操作类型操作数类型 操作数：指令要进行处理的数据 地址：如：跳转指令中操作数部分就是地址或相对地址。绝对地址无符号数，相对地址是有符号数 数字：定点数、浮点数、十进制数 字符：用ASCII表示 逻辑数：逻辑运算 数据在存储器中的存放方式 大端：高字节在低地址 小端：低字节在低地址 存储字长64位(CPU在访存过程中通过一次访问内存最多能拿到64位的数据)、机器字长32位(那64位就是双字) 半字：一个字节的一半 存储方式： 从任意位置开始存储 优点：不浪费存储资源 缺点：除了访问一个字节之外，访问其它任何类型的数据，都可能花费两个存储周期的时间。读写控制比较复杂。 从一个存储字的起始位置开始访问 优点：无论访问何种类型的数据，在一个周期内 均可完成，读写控制简单。 缺点：浪费了宝贵的存储资源 边界对准方式(从地址的整数倍位置开始访问) 数据存放的起始地址是数据长度（按照编址单位进行计算）的整数倍 操作类型(汇编学了就成了) 数据传送 源 目的 例如 寄存器 寄存器 MOVE 寄存器 存储器 STORE、MOVE、PUSH 存储器 寄存器 LOAD、MOVE、POP 存储器 存储器 MOVE 特殊类型的数据传送指令：置”1“、清”0“ 算术逻辑操作 加、减、乘、除、增 1、减 1、求补、浮点运算、十进制运算 与、或、非、异或、位操作、位测试、位清除、位求反 如：8086 ADD SUB MUL DIV INC DEC CMP NEG AAA AAS AAM AAD AND OR NOT XOR TEST 移位操作 算术移位、逻辑移位 循环移位（带进位和不带进位） 转移 无条件转移 JMP 条件转移(分支指令) 结果为零转 （Z = 1）JZ 结果溢出转 （O = 1）JO 结果有进位转 （C = 1）JC 跳过一条指令 SKP 调用和返回 陷阱(Trap)与陷阱指令 意外事故的中断 一般不提供给用户直接使用，在出现事故时，由CPU自动产生并执行(隐指令) 设置供用户使用的陷阱指令 提供给用户使用的陷阱指令，完成系统调用 如 8086 INT TYPE 软中断 输入输出 如果I/O端口的编址空间被作为内存编制空间的一部分，就不需要输入输出指令，直接用访问存储器或内存的指令，就可以对外部设备输入输出。 若外部设备有自己的独立地址空间或单独编址就需要单独的输入输出指令。对外部设备进行保存。 入： 端口到CPU的寄存器 如：IN AX,n、IN AX,DX 出：CPU的寄存器到端口 如：OUT n,AL、OUT DX,AX 7.3寻址方式寻址方式：确定本条指令的操作数地址或下一条要执行指令的指令地址 寻址方式：指令寻址、数据寻址 指令寻址 顺序寻址：(PC)+1—&gt;PC 跳跃寻址：由转移指令指出 数据寻址 形式地址：指令字中的地址 有效地址：操作数的真实地址(要用寻址方式和形式地址进行一定的运算才能得到有效地址) 为了讲解方便，以下约定：指令字长=存储字长=机器字长 数据寻址方式 立即寻址：形式地址给出的就是操作数。 #：立即寻址的特征 特点： 指令执行阶段不访存 A的位数限制了立即数的范围 直接寻址 EA=A 有效地址就是形式地址 LDA指令：将内存单元的数据取入CPU中保存在ACC。只是模型机规定不是所有机器都这样。 特点： 执行阶段访问一次存储器 A的位数决定了该指令操作数的寻址范围 操作数的地址不易修改(必须修改A) 隐含寻址 操作数地址隐含在操作码中或参与运算的数据所在的位置由操作码直接给出 蓝色的寻址特征是指后面的A的寻址方式。该指令是加法需要两个操作数，并且将加法结果保存，指令只给出一个操作数，另一个操作数隐藏在ACC当中。 优势： 指令字中少了一个地址字段，可缩短指令字长 如：8086的MUL指令(乘法指令)被乘数隐含在 AX（16位）或 AL（8位）中。MOVS指令(字符串操作)源操作数的地址隐含在 SI 中目的操作数的地址隐含在 DI 中 间接寻址 操作数的地址保存在某一个内存单元当中。 有效地址由形式地址简介提供 间接寻址有两种形式： 一次间址(两次访存)：通过访问形式地址获得有效地址，再通过有效地址获得操作数。可扩大寻址范围，也便于编制程序。 多次间址(多次访存)：根据A找到一个地址A1，前面的1是一个标识，表示该地址依然是一个间接地址。在多次之后找到标识为0才能找到有效地址。再找到操作数。 间接寻址例：在主程序调用子程序时，子程序的最后的跳转指令的地址是主程序调用主程序的下一个地址。 特点： 可扩大寻址范围 便于编制程序 寄存器寻址 EA=Ri 有效地址为寄存器编号 优势： 执行阶段不访存，只访问寄存器，执行速度快 寄存器个数有限，可缩短指令字长 寄存器间接寻址 EA = ( Ri) 有效地址在寄存器中 根据寄存器编号找到有效地址，根据有效地址在内存中找到操作数。 特点： 有效地址在寄存器中， 操作数在存储器中，执行阶段访存 便于编制循环程序 基址寻址 采用专用寄存器作基址寄存器 EA = ( BR ) + A BR为基址寄存器 基址寄存器和变址寄存器可以用来解决程序在装入内存时，逻辑地址到物理地址的映射 利用ALU(加法器)将BR和A相加等到操作数在内存单元中的地址。 特点： 可扩大寻址范围 有利于多道程序(多道程序分时开始执行时程序的起始地址可以放在BR中，在执行过程中动态形成操作数地址，这种方式在计算机体系结构里被称为程序的动态定位) BR 内容由操作系统或管理程序确定(用户无法自行修改) 在程序的执行过程中 BR 内容不变，形式地址 A 可变 采用通用寄存器作基址寄存器 特点： 由用户指定哪个通用寄存器作为基址寄存器 基址寄存器的内容由操作系统确定 在程序的执行过程中 R0 内容不变，形式地址 A 可变 变址寻址 EA = ( IX ) +A IX 为变址寄存器（专用） 通用寄存器也可以作为变址寄存器 特点： 可扩大寻址范围 IX 的内容由用户给定 在程序的执行过程中 IX 内容可变，形式地址 A 不变 便于处理数组问题(A作数组的起始地址，IX作下标) 例：设数据块首地址为 D，求 N 个数的平均值 直接寻址 LDA取D中数据取到ACC ADD使ACC数据与给出的内存地址得数据相加 DIV 除法操作：立即数寻址方式 ，结果保存在ACC。再保存到指定内存单元中 变址寻址 LDA #0：ACC清零 立即数寻址方式 LDX #0：X清零 X为变址寄存器 ADD X,D：此时D为数组首地址 INX：使得变址寄存器得值+1 CPX #N：变址寄存器得值和N进行比较 BEN M：前条指令如果不等跳转到ADD。 相对寻址 EA = ( PC ) + A：相对当前的PC值 A 是相对于当前指令的位移量（可正可负，补码） PC的值+A的值得到内存单元的地址 特点： A 的位数决定操作数的寻址范围 程序浮动(程序在内存单元中，它的存储位置发生变化) 广泛用于转移指令 举例：设数据块首地址为 D，求 N 个数的平均值 *-3：让PC值-3(用补码表示)。可以直接得到跳转指令成功的话下条指令的地址。 举例：按字节寻址的相对寻址 在现代计算机中，一条指令还未取完或执行完，PC的值已经发生了变化。所以偏移地址应该为06H 堆栈寻址 堆栈：先进后出 硬堆栈(堆栈计算机内常用)：由多个寄存器作为栈顶，如果操作的话，操作数均来自栈顶，结果保存在栈顶 软堆栈：指定的存储空间。 栈顶地址由SP指出。 通常情况下堆栈的栈底是地址最高的，栈顶是低地址。 操作 进栈：（SP）-1—&gt;SP 出栈：（SP）+1—&gt;SP SP的修改与主存编制方法有关：如果数据长度不是一个编址单元，那么就不一定是减一或加一 按字编址：+-1 按字节编址： 存储字长16(二字节)：+-2 存储字长32(四字节)：+-4 例： 7.4指令格式举例设计指令格式时应考虑的各种因素 指令系统的 兼容性：新指令集最好可以不用修改原有程序就能使用 其它因素 操作类型：指令个数、操作的难易程度、指令的使用频率 数据类型：确定哪些数据类型可参与操作 指令格式：指令字长是否固定，操作码位数、是否采用扩展操作码技术，地址码位数、地址个数、寻址方式类型 寻址方式：指令寻址、操作数寻址 寄存器个数：寄存器的多少直接影响指令的执行时间 例：IBM 360的五种指令格式 RR格式：寄存器-寄存器，两个寄存器参加操作，结果保存在其中一个寄存器中 RX格式：寄存器-存储器，X位变址寄存器，B为基址寄存器。D为偏移地址 RS格式：应用于数据的存储操作，在寄存器和内存之间进行成组的数据传送。R1到R3(包括)成组传输到内存中，采用基址寻址方式 SI格式：两地址，地址长32位 SS格式：存储器和存储器当中数据进行操作，在内存中进行数据传输。 IBM 360 操作码长度都为8位 例：Intel 8086(复杂指令集计算机) 指令字长 地址格式 1 ~ 6 个字节 INC AX 1 字节 MOV WORD PTR[0204], 0138H 6 字节 地址格式 7.5RISC技术RISC：精简指令集计算机 CISC：复杂指令集计算机 RISC 的主要特征 选用使用频度较高的一些 简单指令，复杂的指令不用硬件实现，由简单指令组合 指令 长度固定、指令格式种类少、寻址方式少 只有 LOAD / STORE 指令访存(只有这两指令进行访存)：其它指令的操作只能在寄存器与寄存器之间进行，结果也只能保存在寄存器中。 CPU 中有多个 通用 寄存器 采用 流水技术 一个时钟周期 内完成一条指令 采用 组合逻辑 实现控制器(硬件方式来实现) CISC 的主要特征 系统指令 复杂庞大，各种指令使用频度相差大 指令 长度不固定、指令格式种类多、寻址方式多 访存 指令 不受限制 CPU 中设有 专用寄存器 大多数指令需要 多个时钟周期 执行完毕 采用 微程序 控制器 RISC和CISC 的比较 RISC更能 充分利用 VLSI 芯片的面积 RISC 更能 提高计算机运算速度 指令数、指令格式、寻址方式少，通用 寄存器多，采用 组合逻辑 ，便于实现 指令流水 RISC 便于设计，可 降低成本，提高 可靠性 RISC 不易 实现 指令系统兼容 八、CPU 的结构和功能8.1CPU的结构CPU的功能 控制器的功能 取指令 分析指令 执行指令，发出各种操作命令(由这些操作命令控制相应部件完成指令要求操作) 控制程序输入及结果的输出— 总线管理 处理异常情况和特殊请求 运算器的功能 实现算术运算和逻辑运算 CPU的功能需求：指令控制、操作控制、时间控制、处理中断、数据加工 CPU结构框图 控制总线：CPU向各个设备发出控制命令，外部设备向CPU提出的请求以及外部设备的状态。 数据总线：向外部设备写入或读取 寄存器： PC：指出要取的指令地址 IR：指令寄存器，从内存中取出的指令放入CPU中的IR 还有其它寄存器 CU：操作控制、时间控制，对指令进行移码再给定时刻给出给定的操作命令 ALU：数据加工。 中断系统：做中断处理 CPU的寄存器 用户可见寄存器 通用寄存器：存放操作数，也可作 某种寻址方式所需的 专用寄存器 数据寄存器：存放操作数（满足各种数据类型如整数、浮点数），两个寄存器拼接存放双倍字长数据（如乘法时用ACC和MQ） 地址寄存器 ：存放地址，其位数应满足最大的地址范围。用于特殊的寻址方式 段基值 栈指针(如段寄存器，堆栈寄存器) 条件码寄存器：存放条件码，做程序分支的依据(如正、负、零、溢出、进位等来判断是否跳转) 用户不可见寄存器：在流水线结构的计算机中，流水段之间的流水段寄存器都是用户不可见 控制和状态寄存器 控制寄存器 MAR：主存地址寄存器(保存存储器所需的地址) MDR：主存数据寄存器 除了M(主存)剩下四个都是控制寄存器 MAR、MDR、IR用户不可见 PC用户空间 状态寄存器 状态寄存器：存放条件码 类似条件码寄存器 PSW寄存器(程序状态字寄存器)：存放程序状态字 程序状态字：在中断或子程序调用过程中为了让程序正确返回断点，保存的现场断点等。中断各种各样，为了应对各种情况，设计者把软硬件状态相关的寄存器集合成一个大的寄存器，就是程序状态字。普遍较长，有些上千位。可以利用交换程序状态字的方式来完成程序现场的切换 控制单元 CU 和中断系统 CU ：产生全部指令的微操作命令序列(包括先后顺序) CU的设计方法： 组合逻辑设计：速度快。硬连线逻辑 微程序设计：简单，适用于复杂功能的指令设计。存储逻辑 中断8.4讲 8.2 指令周期指令周期：取出并执行一条指令所需的全部时间或解释一条指令的全部时间。 完成一条指令过程：取指周期(取指、分析)、执行周期(执行)。不同CPU完成一条指令有不同的阶段，这里仅仅是一个例子。 每条指令的指令周期不同 只有取指周期，无执行周期。如：NOP(空操作) 取指周期和执行周期相同。如：ADD mem(在内存单元中取出操作数和ACC寄存器中的数据相加，结果保存在ACC中)，因为访存时间往往占比最大，取指需要访存一次，取操作数需要访存一次，所以所需时间基本相同。 取指周期和执行周期时间不同。如MUl mem(在内存单元中取出操作数和ACC寄存器中的数据相乘，结果保存在ACC中) 具有简介寻址的指令周期：间址周期是获取操作数的有效地址 带有中断周期的指令周期：执行周期结束时，需要确认是否有中断请求，如果有需要去响应。响应的过程(保存断点，形成中断程序的入口地址等)都由中断周期完成 指令周期流程 CPU工作周期的标志 指令周期的不同阶段，控制器要做不同操作，因此控制器要在不同阶段发出不同的控制命令，也需要知道当前处于哪个阶段。 取值周期取的指令要送入IR。间址周期取得地址要送如IR得地址码部分或MDR的地址码部分。执行周期取得操作数要放入CPU中的寄存器。中断周期要把程序断点保存到内存单元指定位置。 用触发器来标识当前周期 具体如何标识，老师也没有讲的很清楚。 指令周期的数据流 取值周期数据流 取操作：PC把地址送如MAR，MAR将地址送入地址总线，再由地址总线送入存储器。 读操作：读命令由CU控制，CU将控制信号送入控制总线，再由控制总线送入存储器。存储器来执行读操作，把相应数据送入数据总线，再送入MDR。再送入IR。 下一条指令的地址就是当前PC+1。由CU控制加1。为下一步做准备。 间址周期数据流(间接寻址) 从MDR(或IR)中取出地址码部分送入MAR。进行内存单元访问，取出操作数的地址，MAR把地址送入地址总线，再送入存储器。CU发出读操作送入控制总线，再送入存储器。存储器完成读操作后将数据送入数据总线再送入MDR。这时MDR保存的有效地址。 执行周期数据流(第九章详解) 不同指令的执行周期数据流不同 中断周期数据流 保持断点：CU给出地址放入MAR，MAR经过地址总线送入存储器，CU再经过控制总线将写命令送入存储器。这样PC就能将断点(中断后的下一条指令，实际是保存当前PC的值)送入MDR，再经过数据总线保存到存储单元中。 形成中断服务程序的入口地址：8.4节详细介绍。这里只要知道中断服务程序的入口地址由CU给出写入PC。 硬件关中断 8.3指令流水提高机器速度 提高发出速度 高速芯片 Cache 多体并行(多存储体) 提高 I/O 和主机之间的传送速度 中断 DMA 通道 I/O处理机 提高运算器速度 高速芯片 改进算法 快速进位链 提高整机处理能力 高速器件 改进系统结构，开发系统的并行性 并行的概念： 并发：两个或两个以上事件在 同一时间段 发生 同时：两个或两个以上事件在 同一时刻 发生 并行性的等级： 过程级(粗粒度)：程序或进程并行。通常软件实现 指令级(细粒度)：两条或多条指令之间都处于被执行的状态，也可以是指令内部操作并行。通常硬件实现。 指令流水原理 指令的串行执行：总有一个部件空闲 指令的二级流水：取指和执行阶段时间上完全重叠，指令周期减半，速度提高1倍。 影响指令流水效率加倍的因素： 执行时间&gt;取指时间 指令部件缓冲区，用于缓冲取址部件取回的指令，如果速度过快，就在缓冲区进行缓冲，如果指令指令部件空闲，就可以到缓冲区取指令。 条件转移指令 对指令流水的影响 必须等 上条 指令执行结束，才能确定 下条 指令的地址 可以采用分支预测法。 指令的六级流水 FI：取指令 DI：指令译码 CO：形成操作数地址 FO：取操作数 EI：执行 WO：结果写回 影响指令流水线性能的因素 结构相关：不同指令争用同一功能部件产生资源冲突。 如：一条指令利用运算器计算下条指令地址，另外一条一条利用运算器来完成指定运算。 FI、FO、WO都要使用到内存单元，会造成资源冲突。 解决方法：停顿、指令存储器和数据存储器分开、指令预取技术(适用于访存周期短的情况) 数据相关：不同指令因重叠操作，可能改变操作数的 读/写 访问顺序 写后读相关(RAW)：对某个存储单元或存储器先写操作后读操作。 读后写相关(WAR) 写后写相关(WAW) 解决方法：后推法(前一条指令完成第二条指令才开始)、采用旁路技术(从前指令的运算器输出后直接送入后指令的运算器) 控制相关：由转移指令引起 如果CPX比较相等顺序执行，不相等就跳转到M 转移指令会使得并行的一些指令作废 流水线性能 吞吐率：单位时间内 流水线所完成指令 或 输出结果 的 数量 ​ 设m段的流水线各段时间为Δt 最大吞吐率：满负荷运转，没有发生资源冲突，数据相关，控制相关等。 如果满负荷运转，每经过一个Δt就会有一个结果输出 实际吞吐率：实际一段时间内完成指令条数 m×Δt为第一条指令，(n-1)×Δt为后面的指令 加速比Sp：m 段的 流水线的速度 与等功能的 非流水线的速度 之比 这里给出的公式都是理想型的。实际m 段的 流水线的速度的时间 与等功能的 非流水线的速度的时间 之比 效率：流水线中各功能段的 利用率 建立时间：第一条指令进入流水到结果输出 排空时间：最后一条指令进入流水线到结果输出 由于流水线有 建立时间 和 排空时间，因此各功能段的 设备不可能 一直 处于 工作 状态。 空间：指流水段。 时间：流水段的运行。 效率=工作面积 除 (T时间×S空间) 流水线的多发技术 超标量技术： 每个时钟周期内可 并发多条独立指令 配置多个功能部件 不能调整 指令的 执行顺序通过编译优化技术，把可并行执行的指令搭配起来 超流水线技术： 在 一个时钟周期 内 再分段。在一个时钟周期内 一个功能部件使用多次 不能调整 指令的 执行顺序靠编译程序解决优化问题 在流水线的设计过程中，流水段之间要加入锁存器，每个流水段的结果保存到锁存器作为下个流水段执行时它的操作信号、控制信号或操作数据。 但在超流水线技术中，依然有锁存器，但一个流水段的再细分是没有锁存器。 不同指令在同一流水段中，相互的信号不能叠加 超长指令字技术： 由编译程序 挖掘 出指令间 潜在 的 并行性(根据计算机中执行部件的数量和种类，指令之间也不能有相关性)，将 多条 能 并行操作 的指令组合成 一条具有 多个操作码字段 的 超长指令字（可达几百位） 采用 多个处理部件 图上黑色为执行部件，执行部件有多个，如取数，存数，定点运算，浮点运算。 流水线结构 指令流水线结构： 完成一条指令分 6 段， 每段需一个时钟周期(不同类型机器实现方式不同，这里只是参考) 运算流水线： 8.4中断系统概述 引起中断的因素 人为设置的中断：如 转管指令 程序性事故：溢出、操作码不能识别、除法非法 硬件故障 I/O 设备 外部事件：用 键盘中断 现行程序 中断请求标记和中断判优逻辑 中断请求标记 INTR(中断触发器) 一个请求源 一个INTR 中断请求标记触发器 多个INTR 组成 中断请求标记寄存器 每位依次：是否发生电源掉电。是否过热等等。每位标识一个中断源。 可以 INTR 分散 在各个中断源的 接口电路中 或 INTR 集中 在 CPU 的中断系统 内 中断判优逻辑 硬件实现（排队器） 分散 在各个中断源的 接口电路中(第五章中链式排队器) 集中 在CPU内 或外部某个专门用于判优的部件 INTPi输出1的要求是前面中断请求高的都没有中断请求。只有一位是1其它都是0。优先级高的若为1会将1传递给后面的，使得后面都为0。 软件实现（程序查询） 按优先级的顺序，依次判断是否有中断请求，如果有转入相应的服务程序入口地址，如果没有就判断下一优先级的中断请求 中断服务程序入口地址的寻找 硬件向量法：硬件的方式来形成中断向量地址 根据哪个中断源，确定执行哪个中断服务程序。用中断向量地址去找到中断服务程序的入口地址。 中断服务程序的入口地址有两种方法给出 在中断向量地址的存储单元中存放一条跳转指令其中包含了中断服务程序的入口地址 给出向量地址后，在内存单元中指定的位置保存的中断服务程序的入口地址，取回后送入PC中，去执行中断服务程序。 特点：速度快、设计灵活性低 软件查询法 SKP：跳过下一条指令。SKP DZ 1#功能为：查询第一号中断源他的触发器D为0还是1。如果为1就执行相应中断服务程序。如果为1就跳过这条命令。 中断响应 响应中断的条件 假如CPU只能支持单重中断(CPU在响应某个中断源的中断请求并且开始执行中断源的中断服务程序的情况下，即使有新的中断源发出中断服务请求CPU也不能进行响应) 当允许中断触发器 EINT=1时 才能运行中断源发出的中断请求。 响应中断的时间 通常情况下执行阶段结束以后才能响应中断请求。但有些复杂指令执行时间长，为了及时的处理一些异常，允许CPU在执行过程中进行中断响应。 指令执行周期结束时刻由CPU发查询信号。查询信号会发到每个中断源中的中断请求触发器，查询信号会驱动中断请求触发器，将触发器输出端置1，再把中断请求信号发入排队器。 中断隐指令 保护程序断点： 断点存于 特定地址（0号地址）内 断点进栈 寻址服务程序入口地址 硬件向量法：将中断向量地址送入PC。PC中保存的向量地址包含了中断服务程序的入口地址或一条跳转指令(会跳转到中断服务程序) 软件查询法：将中断识别程序入口地址 M送入PC 硬件关中断：在单重中断机器的执行中断服务程序过程中有新的中断源会打断当前的中断服务程序的执行。 在多重中断CPU中采用关中断方式也是为了保存程序断点保存程序现场。 中断允许触发器置0 IN中断标记：CPU当前是否允许响应新的中断请求 EINT 允许中断标记 R—S触发器：都为R—S触发器 中断允许触发器输出为1，另外要有中断请求(排队器送出的信号中至少有一个为1，实际中断排队器输出信号如果有中断请求，只有一根线是1，所以用或门表示中断请求，而且1对应的就是中断响应优先级最高的中断请求)。两者都为1表示允许相应中断，而且有中断请求。那么这时通过S端把中断标记寄存器置1，一旦置1，那么中断允许触发器就置0。另外中断排队器排出的结果还要送给向量地址形成部件用来形成向量地址送给PC，为执行中断服务程序做准备 隐指令表示这三个操作都是由计算机硬件来完成的，但是并不是在某条具体指令的驱动下完成的。 保存现场和恢复现场 保护现场 保存断点：由隐指令来做 中断隐指令一共三个操作：保存断点、形成中断服务程序的入口地址、硬件关中断 保存寄存器内容：通过中断服务程序完成 恢复现场：由中断服务程序完成 如：在保护现场过程中，保存寄存器内容可以用push指令把寄存器内容压入堆栈，恢复时用出栈指令 PUSH、POP、IRET都是相应指令 多重中断 概念：CPU在执行中断服务程序的过程中，如果有新的中断源提出了中断请求，并且新的中断源并且它的优先级比正在处理的它的优先级更高就要进行响应 实现多重中断的条件 CPU内部有一个允许中断触发器，在中断服务时要响应中断服务程序，EINT要提前被打开。 优先级别高 的中断源 有权中断优先级别低 的中断源 例：在执行主程序过程中，中断源B、C同时提出中断请求，响应优先级高的B。执行结束后返回主程序，这时中断源C还在CPU只要发出查询信号CPU主程序的执行要再次中断，响应中断源C的中断请求。在执行过程中，即使低优先级的D发出中断请求，CPU不会响应继续执行C。返回主程序，再响应D，执行D时，优先级更高的A提出中断请求，CPU就执行中断服务程序A，结束后再执行D，D结束后返回主程序。 屏蔽技术 (第五章有介绍)可以通过中断屏蔽技术，设置中断屏蔽字，来改变中断服务的优先级，从而提高系统设计和响应的灵活性 屏蔽触发器的作用：设置中断屏蔽字 MASK：中断屏蔽触发器 INTR：保存中断屏蔽字 D：完成触发器。 图左：D表示设备已经完成工作向CPU提出中断请求。该中断请求能提出的条件是这个中断源还未被屏蔽。那么MASK的Q端输出应该为0表示未屏蔽。在D为1，MASK的非端输出也为1时，才能向中断请求触发器在CPU查询信号的作用下使中断请求触发器输出为0表示不能通过这个电路向CPU发出中断请求。 图右：如果排队器集中在CPU或某个部件中，就可以采用该方法。实际上该排队器可以和中断屏蔽触发器结合使用。MASKi为各个中断源对应的屏蔽信号。正在执行某个中断服务请求，该中断服务请求就对应了一个屏蔽字。字的长度和中断源的个数相等。每个MASKi对应了中断屏蔽字的一位。如果MASKi=1表示对应的中断源的中断服务请求不会被响应，也无法提出。这里MASKi为1，那么MASKi的非就为0。那么INTPi输出为0就无法进入中断排队器。 屏蔽字 假如有16个中断源，每个中断源都对应了一个屏蔽字。每个屏蔽字表示当这个中断源它的中断服务程序在执行的过程中是否允许某一个中断源它提出的中断服务请求进入到中断排队器中排队。如果对应值为1就表示屏蔽，0表示开放 屏蔽技术可改变处理优先等级 处理优先级，可改变(通过重新设置屏蔽字) 中断响应优先级，中断屏蔽字(由硬件电路(排队器)给出)不能改变。 在修改之前：A、B、C、D同时发出中断请求，A响应级别最高，主程序不能屏蔽任何中断，所以中断屏蔽字为全0。响应A执行A的中断服务程序，在执行A过程中，会把中断屏蔽字置为全1。尽管B、C、D还有中断服务请求但不会被响应。然后执行B的中断服务程序，C的中断服务程序，D的中断服务程序。 在修改后，中断处理的优先级为A、D、C、B：A、B、C、D同时发出中断请求进入中断排队器排队，A响应级别最高，响应A执行A的中断服务程序，在执行A过程中，会把中断屏蔽字置为全1。B、C、D不能打断A的执行，结束后返回主程序。中断屏蔽字改为全0。此时B优先级最高，响应B，执行B过程中中断屏蔽字C、D都是开放的。C、D提出的中断服务请求能够进入中断排队器进行排队，C优先级更高，响应C。中断屏蔽字置为C对应的屏蔽字，C只能屏蔽C本身和B，所以D还能发出中断服务请求并且进入中断排队器。就执行D中断服务程序。结束后返回C，再结束后返回B，直到处理完 屏蔽技术的其它作用 可以人为地屏蔽某个中断源的请求 新屏蔽字的设置 保护现场：利用push指令，把一些寄存器的值保护起来，以便返回时用到。 置屏蔽字 开中断：要提前开中断，为了能够实现多重中断。 关中断：恢复现场之前关闭 恢复现场 恢复屏蔽字：来使得恢复现场过程不被打断 开中断 中断返回 多重中断的断点保护 断点进栈：由中断隐指令(硬件)完成 断点存入“0”(带引号，可以是一个给定的地址)地址：中断隐指令完成 中断周期 保持断点：0地址送入MAR、命令存储器写操作、断点写入0地址。断点在PC中(保存了下一条要执行的地址，指的是当前执行的程序的下一条指令的地址)。PC值送入MDR。MDR再送入主存进行保存 如果一直保存在指定地址，那么多重保存会使得后面断点冲掉前面断点的保存 例 SERVE：中断服务程序的入口地址 将ACC寄存器内容保存到SAVE中 LDA 0：取数操作，将地址为0的内存单元中的数据放入ACC寄存器。 STA RETURN：将上操作取出的值保存到RETURN单元。 0地址内容转存：转存的就是断点，通过转存把程序断点保护 JMP @ RETURN：跳转到RETURN保存的地址，就是程序的断点。 九、控制单元的功能控制单元是计算机系统的控制核心，在控制单元的控制之下，整个计算机系统才能正确、持续、稳定的运行 9.1微操作命令分析在取值、间址、分析、执行、中断的过程中，控制单元要发出哪些微控制命令。 微操作命令：这些命令在指令解释过程中由控制单元发出的一些指令，这些指令所要完成的动作和整条指令要完成的功能相比小得多，所以叫微操作命令。 在第七章已经讲解了完成一条指令可以分为4个工作周期：取指周期、间址周期、执行周期、中断周期 取址周期取值过程中不需要ALU，所以图上未给出。 PC把包含的指令地址送入MAR，再经过地址总线送入存储器 然后由控制单元向存储器发出读命令，读出的数据由存储器通过数据总线送入MDR再由MDR送入IR中，指令就被取到IR寄存器。 在取值周期还要完成译码任务，就是确定该指令具体做什么操作。是由指令操作码部分给出。所以把指令的操作码部分送入CU，由CU确定操作。 结束后PC+1 间址周期通过间址周期把操作数的地址从存储器中取出放入指令寄存器中所保存的指令的地址码部分。 先将指令形式地址送入MAR，也就是IR中地址码部分。再由MAR通过地址总线传输到存储器的地址线上。要实现该操作，控制器要发出将IR的地址码部分送给MAR的控制信号，再由控制器向存储器发出读操作命令。 存储器接收到地址和读操作命令后，在指定的内存单元中，取出操作数，通过数据总线，传输给MDR 被取出的地址再送入IR中。这时IR中地址码部分就是操作数的物理地址。 执行周期 非访存类指令 CLA(对ACC清零)：控制器将0送入ACC COM(将ACC取反)：也是一条控制命令 SHR(算术右移)：右移左边的数据写入右侧。同时最高位ACC0再写回ACC0(最高位补原来符号位) CSL(循环左移)：最高为移到最低位，右边数据写入左边，ACC0写到ACCn(最后一位) STP(停机指令)：将停机标志G置零 访存指令 加法指令(ADD X)：ADD是操作码 X为其中一个数的地址码 Ad(IR)—&gt;MAR：将IR中地址码部分送入MAR 1—&gt;R：CU发出读命令。 M(MAR)—&gt;MDR：读命令给出后把MAR中保存的地址作为存储器地址，把数据取出。 (ACC) + (MDR)—&gt;ACC ：将ACC内容和MDR内容相加 存数指令 STA X：把ACC中数据保存到内存单元X中 Ad(IR)—&gt;MAR：把IR中保存的指令的地址码部分送入MAR进行访存 1—&gt;W：写命令 ACC—&gt;MDR：ACC中内容送入MDR寄存器 MDR—&gt;M(MAR)：写入MAR寄存器指定的内存单元中完成写操作 取数指令 LDA X：把内存单元X的数据取出保存在ACC寄存器 Ad (IR)—&gt;MAR：把IR中的地址码部分送入MAR 1—&gt;R：发出读命令 M (MAR)—&gt;MDR：把MAR指定的内存单元的内容送入MDR中 MDR—&gt;ACC：把MDR寄存器内容存入ACC 转移指令 无条件转移 JMP X Ad (IR)—&gt;PC：把IR中地址码部分送入PC 条件转移 BAN X(举例一种如果上次计算结果值为负就转移) ：通过判断ACC最高位A0是正是负。如果是1就是将IR保存的地址码部分送入PC跳转成功。如果A0为0表示非负，PC送入PC跳转不成功接着执行下一条 三类指令的指令周期： 中断周期 保存断点 存入”0”地址 0—&gt;MAR：0送入MAR 1—&gt;W：控制单元向存储器发出写命令 PC—&gt;MDR：保存PC内容送入MDR MDR—&gt;M(MAR)：把MDR的内容保存到MAR指定的内存单元中 程序断点进栈 ( SP ) - 1—&gt;MAR：形成新的栈顶地址送入MAR 1—&gt;W：控制单元向存储器发出写命令 PC—&gt;MDR：保存PC内容送入MDR MDR—&gt;M(MAR)：把MDR的内容保存到MAR指定的内存单元中 1表示立即数或有效(不清)，1—&gt;W表示立即进行W操作 形成中断服务程序的入口地址(这里采用硬件向量法)：向量地址保存到PC中 关中断：把0送到EINT中断允许触发器中 9.2控制单元的功能控制单元的外特性控制单元的输入输出信号 输出信号包括了CPU内部的控制信号，控制CPU内部件的执行，另外还有送到系统总线的控制信号，如控制外部设备总线的操作。 输入信号包括来自于指令寄存器的指令的操作码部分。还有时钟信号控制单元在时钟信号的控制之下进行工作还有各种标志，这些标志为指令正确执行必须要有的。如：跳转指令它的运行结果的标志是本条指令是否跳转的依据。 输入信号 时钟 CU受时钟控制 各种微操作命令在时钟信号的控制之下，在指定的时间点被发出 一个时钟脉冲，发一个操作命令或一组需同时执行的操作命令 指令寄存器：OP ( IR ) CU 控制信号 与操作码有关 保存了要执行的指令，操作码部分必须送入CU中，由控制单元进行译码，指出这条指令要做什么操作，以便指令执行阶段对不同的指令发出不同的控制信号 标志 CU 受标志控制 外来信号 如： INTR 中断请求 HRQ 总线请求 输出信号 CPU内部的各种控制信号 Ri—&gt;Rj：寄存器和寄存器之间的数据传输 (PC) + 1—&gt;PC：控制PC+1 ALU ＋、－、与、或 ……：控制运算器做数据运算和逻辑运算 送至控制总线的信号 IO/M：低电平访问I/O，高电平访问存储器 控制信号举例不采用CPU内部总线的方式 即：CPU内部的各个部件采用分散连接的方式 取指令：PC要送到MAR，告诉要取指令的地址。MAR要把地址送入内存，取回的指令送到MDR，再被送到IR寄存器。如果取回的是数据要送入AC(ACC)中。如果是加法指令取回的数据可能直接送入ALU。 若是间接寻址，拿回的是操作数的地址，那MDR要把地址送入MAR中，以便把操作数从内存单元中取出。 IR寄存器的操作码部分要送给CU，进行译码。 时钟要送入CU中，以控制控制单元发出各种类型的控制信号 这些控制信号控制ALU做各种操作 以ADD @ X(间接寻址的方式)为例 图1取指周期、图2间址周期、图3执行周期 取值周期：操作发起从PC开始，由CU控制PC和MAR之间的数据通路C0把PC内容送给MAR。再把数据经过C1控制电路送出，送给内存单元的地址线。同时CU要发出一个读命令告诉CPU要进行读操作。取回的指令，从内存单元经过C2放入MDR中，再由MDR经过C3送入IR寄存器。IR的操作码部分经过C4送入CU，进行译码，最后PC+1。这里从C0到C4五个控制信号都由CU产生 间址周期：指令已经取回，指令在IR和MDR都有保存。形式地址从MDR(或IR)获得。MDR将指令的地址码部分通过C5送入MAR寄存器，在通过C1送到存储器地址线。然后控制单元发出读命令，通过C2读到的操作数的地址送入到MDR，再由C3把MDR中保存的操作数的地址保存如IR的地址码部分。 执行周期：操作数的地址现在保存在MDR(和IR)中。C5由CU发出指令将MDR内容送入MAR。再通过C1把MAR的地址，送入内存单元的地址线。再由CU发出读操作命令，读入的数据通过C2被送入MDR。C6和C7打开把操作数送入ALU。ALU通过控制信号得知做加法操作。在控制信号的控制之下完成加法，并通过C8把结果保存到C8 )) 采用 CPU 内部总线方式 Y：作为ALU输入的一个寄存器 Z：保存ALU的输出 以ADD @ X取值为例 图1取指周期、图2间址周期、图3执行周期 取指周期：PC通过控制信号PCo(OUT缩写)把保存的值送入CPU内部总线，再通过MARi送入MAR。MAR把指令地址送入地址线，CU发出读命令送入存储器。读出的指令通过数据线送入MDR中，再经过MDRo送到CPU内部总线，再经过IRi送入IR。IR保存的指令的操作码部分送入CU进行译码，PC+1。 间址周期：MDR通过MDRo把形式地址送入CPU内部总线，再经过MARi送入MAR中。再由MAR送入地址线。CU把1送给R(发出读操作)。读回的内容经过数据线送入MDR中，然后MDR输出控制信号有效通过内部总线再由IRi送入IR。 执行周期：MDR通过MDRo把保存的操作数的地址再经过MARi送到MAR再经过地址线送到内存。CU发出读命令信号驱动内存读操作。通过数据线送到MDR。将MDR保存的操作数通过MDRo经过CPU内部总线再Yi的控制之下送入Y寄存器。Y保存的数据送入ALU，AC保存的数据通过内部总线送入ALU。CU控制ALU做加法操作。结果保存到Z。Z再经过内部总线，送入AC。 )) 多级时序系统机器周期 概念：所有指令执行过程中的一个基准时间 考虑因素：每条指令的执行步骤，每一步骤所需的时间 基准时间的确定： 以完成最复杂指令功能的时间为准 以访问一次存储器的时间为基准。通常访存操作耗时最长 若指令字长=存储字长，取指周期=机器周期 12m晶振的51单片机时钟周期为1/12us，1机器周期等于12个时钟周期，所以机器周期为1us，而指令周期等于1-4（大概）个机器周期 时钟周期 一个机器周期内可完成若干个微操作 每个微操作需一定时间(可能一个时钟周期内完成，也可能多个) 将一个机器周期分成若干个时间相等的时间段（节拍、状态、时钟周期） 时钟周期是控制计算机操作的最小单位时间 用时钟周期控制产生一个或几个微操作命令 T0、T1、T2、T3：不同的节拍，在节拍的上升点，可以利用上升点让CU产生不同的控制命令让CPU内部的各个部件以及计算机的其他部件发出响应操作 节拍是机器中最小的时间单位 这边略微不清楚 多级时序系统 指令周期、机器周期、节拍(状态)组成多级时序系统 PPT上无指令周期 一个指令周期包含若干个机器周期 一个机器周期包含若干个时钟周期 机器周期包含的节拍数不同，指令周期包含的机器周期不同 机器速度与机器主频的关系 在机器周期所含时钟周期数 相同 的前提下，两机 平均指令执行速度之比 等于 两机主频之比 机器速度 不仅与 主频有关 ，还与机器周期中所含时钟周期（主频的倒数）数 以及指令周期中所含的 机器周期数有关。 控制方式产生不同微操作命令序列所用的时序控制方式 同步控制方式：任一微操作均由统一基准时标的时序信号控制 采用定长的机器周期：每个机器周期含有相同的节拍数 以 最长 的微操作序列和 最复杂 的微操作作为 标准 采用不定长的机器周期：机器周期内，节拍数不等 采用中央控制和局部控制相结合的方法(与总线类似) 一部分操作由中央控制节拍来控制，延长的部分由局部控制节拍控制 局部控制的节拍宽度与中央控制的节拍宽度一致 异步控制方式：无基准时标信号、无固定的周期节拍和严格的时钟同步、采用应答方式 联合控制方式：同步与异步相结合 大部分情况下用同步，特殊情况下有一些微操作，它的完成时间很难确定就采用异步控制 人工控制方式： Reset：机器恢复起始状态 连续 和 单条 指令执行转换开关：让指令一条一条走或连续 符合停机开关： 十、控制单元的设计10.1组合逻辑设计组合逻辑控制单元框图CU 外特性 节拍发生器：控制CU发出顺序，时间。产生多个节拍信号。在每个节拍信号的起始端CU可产生给定的控制命令 0到2^n-1^只有一条线是高电平 C0Ck为发出的控制信号。同时一个或几个有效。几个有效表示可以并行操作或有先后顺序但在一个节拍内能完成 节拍信号 节拍信号是在时钟控制下产生的 节拍信号的宽度或高电平的长度是一个时钟周期 在第一个时钟周期发出T0第二个时钟周期发出T1依次。 微操作的节拍安排假设：采用同步控制方式，一个机器周期内有3个节拍（时钟周期），CPU 内部结构采用非总线方式。 C0到C12共13个控制信号 一个周期包含的节拍数跟这个机器周期中需要产生的控制信号的数量以及控制信号的复杂程度，都有直接关系。不同机器的节拍不同。 安排微操作时序的原则 原则一：微操作的 先后顺序不得 随意 更改 如：只有把指令取到IR之后才能把指令的操作码送入CU译码 原则二：被控对象不同 的微操作 尽量安排在 一个节拍 内完成 就是说，可以并行执行的微操作微操作之间没有先后顺序。这样的微操作尽可能安排在同一节拍中。 原则三：占用 时间较短 的微操作尽量 安排在 一个节拍 内完成并允许有先后顺序 取值周期微操作的节拍安排 T0(第一个节拍)：将PC指令送入MAR，发出读命令 ID(instruction decoder)：指令译码器 T2：将IR中指令操作码部分送到CU进行译码 间址周期微操作的节拍安排 T0：IR的地质部份送入MAR，CU发出读命令 执行周期微操作的节拍安排 执行周期每条指令做的操作都不一样 CLA：ACC清零。前两节拍什么都不做 COM：ACC按位取反 SHR：算术右移 CSL：循环左移 STP：停机 ADD X：把X内存单元中保存的内容和ACC内容相加，结果保存到ACC STA X：把ACC的数据存入存储单元X中 LDA X：取内存单元中地址X的数据保存到ACC中 JMP X：跳转到给定的X BAN X：分支指令，如果上一条指令的计算结果小于0，就跳转到X的执行指令。如果大于0 顺序执行下条指令 中断周期微操作的节拍安排 都由中断隐指令来完成 T0： 0—&gt;MAR：把保存断点地址保存到MAR。 1—&gt;W：写命令 硬件关中断：给中断允许触发器置0 T1：PC—&gt;MDR T2： MDR—&gt;M(MAR) 向量地址—&gt;PC 组合逻辑设计步骤列出操作时间表 对应指令需要该操作标记1。 取指周期 如果I(间址特征)有效，就要把IND设为1表示进入间址周期。如果无效，取值完直接进入执行阶段 间址周期 在取值阶段，CLA和COM已经做了1—&gt;EX 执行周期 因为执行阶段操作比较复杂，这里列出了比较多 写出微操作命令的最简表达式 哪些指令在哪个工作周期在什么节拍在什么状态，要执行某个微操作。这样按逻辑表达式写出微操作。再根据逻辑表达式对表达式化简。 再根据表达式画出逻辑图。 特点： 思路清晰，简单明了 庞杂，调试困难，修改困难 速度快（RISC） 10.2微程序设计微程序设计概述把能并行的微操作命令，储存起来变成一条微指令。每个节拍对应一条微指令。多条微指令就构成了机器指令。 微指令的格式，如果在某个节拍中要发出一个或几个控制信号，如果控制信号有效用1标识。每个位表示某一个微操作命令。 微指令构成了微程序，由微程序控制完成一条指令的执行过程。一条机器指令对应一个微程序 把微指令或微程序保存在只读存储器(ROM)中。 根据读出的微指令的有效微指令位置发出响应的控制信号，这种方式称为存储逻辑的方式。 1、其实就是将可以并行的微操作合并，然后用一个微指令指代 2、然后如果执行该微指令，就相当于并行执行多个微操作 4、如果该微指令中有多个1，就说明在一个节拍中有多个微操作并行 5、因为微指令可以自由编程，实现微操作的多种组合 6、进而可以在不改变逻辑电路的前提下，于指令集中增添新指令 微程序控制单元框图及工作原理 微程序控制单元的基本框图 核心：控制存储器，微程序微指令都保存在这。 CMAR(控制存储器地址寄存器)：微指令地址保存在这。 地址译码：将CMAR的地址译码送入控制存储器。控制存储器是只读的，就可以将响应的微指令读出。 CMDR(control memory data register)：从控制存储器独处的微指令放入CMDR。 微地址形成部件：接受指令寄存器的操作码部分。 顺序逻辑：CMAR中地址有多个来源，要用顺序逻辑从多个来源中选一个正确的来源送入CMAR。 数据流：操作码送入微地址形成部件由它形成这条指令在执行阶段所对应的微程序在控制存储器中的地址。然后送入顺序逻辑，由它在多个地址中进行选择。选择正确的地址送入CMAR。再经过译码后送入控制存储器，从给定的地址中读出一条微指令，把它送入CMDR。将下地址送入顺序逻辑。顺序逻辑就给出了下条微指令地址。顺序逻辑就从为地址形成部件或下地址中选一个。 微程序控制单元框图及工作原理 每条微指令，右框部分为下地址部分 M+2的下地址不是M+3，微地址形成部件根据取来的指令的操作码形成，该指令在执行阶段所在的微程序在控制存储器中保存到什么地方。所以M+2的下地址不能直接标识，而是由硬件电路来形成。 P+2结束后如果没有中断就要进行下一条指令，回到M。 中断周期结束后，要转入下条指令。所以他的下地址为M 工作原理 取指阶段：执行取指微程序 M—&gt;CMAR：把控制存储器中M的内容送入CMAR(控制存储的地址寄存器)，由CMAR指出第一条微指令在控制存储器的首地址。 CM(CMAR)—&gt;CMDR：把控制存储器中保存的微指令取出送入CMDR。由CMDR发出命令 此时CMDR保存的就是由操作控制和顺序控制构成的微指令。操作控制部分的1对应了节拍1中将PC的值送入MAR和发出读命令。 形成下条微指令地址Ad(CMDR)—&gt;CMAR：下地址M+1通过顺序逻辑的选择送入CMAR。 CM(CMAR)—&gt;CMDR：取下条微指令，把CMAR取出的地址指向的控制存储器的单元内保存的微指令取出，再次放入CMDR中。由CMDR发命令 命令对应的是：M(MAR)—&gt;MDR和(PC)+1—&gt;PC 形成下条微指令Ad(CMDR)—&gt;CMAR：M+2 CM(CMAR)—&gt;CMDR：取下条微指令，由CMDR发命令 命令对应的是：MDR—&gt;IR 下地址为XXX表示下条微指令地址由下地址阶段指出，要进入间址阶段或执行阶段。如果是执行阶段，就由操作码，根据操作码由微地址形成部件来形成要执行的指令。 执行阶段：执行LDA微程序 OP(IR)—&gt;微地址形成部件—&gt;CMAR：由指令寄存器操作码字段送入微地址形成部件由它来形成下条指令地址。送入CMAR。 CM(CMAR)—&gt;CMDR：把执行阶段的第一条微指令地址取出送给CMDR。由CMDR发命令 命令对应的是：Ad(IR)—&gt;MAR和读操作 Ad(CMDR)—&gt;CMAR：形成下条微指令地址 CM(CMAR)—&gt;CMDR：把下条微指令地址取出送给CMDR。发出命令 命令对应的是：M（MAR）—&gt;MDR Ad(CMDR)—&gt;CMAR：形成下条微指令地址 CM(CMAR)—&gt;CMDR：把下条微指令地址取出送给CMDR。发出命令 命令对应的是：MDR—&gt;AC Ad(CMDR)—&gt;CMAR：形成下条微指令地址M 取值阶段：和第一步一样 总结：全部微指令存在CM中，程序执行过程中只需把指令从CM中读出。如果不考虑间址和中断。每条指令它的执行过程都需要执行取值微程序执行执行微程序，循环往复。 关键： 微指令的 操作控制字段如何形成微操作命令 微指令的 后续地址如何形成 微指令的编码方式(控制方式)直接编码(直接控制)方式 在微指令的操作控制字段中，每一位代表一个微操作命令。 所有执行一共需要多少微操作命令，那么它的操作控制字段就可以设置为多少位。 字段直接编码方式 将微指令的控制字段分成若干 “段”，每段经译码后发出控制信号。 经过译码后，只有一位是有效信号。如果1有效，那么输出端只有一位是1。每一位都表示在这段中对应的一个微操作。同组内所有微操作是互斥的，只能一个发出微操作命令。不同组发出的微操作命令可能可以并行。 字段间接编码方式 每个字段的译码结果，不仅和本字段的输入有关。而且和其它输入的译码结果相关。 混合编码 直接编码和字段编码（直接和间接）混合使用。常用的直接编码，不常用间接编码。 其它 微指令序列地址的形成 微指令的 下地址字段 指出 根据机器指令的 操作码 形成 增量计数器 (CMAR) + 1 —&gt; CMAR：执行阶段和取指阶段很多下条指令就是当前+1。如果使用该方法，下地址字段可以省略。 分支转移 通过测试网络 测试源：状态和条件 测试网络：对地位地址进行变换。然后和高位结合送入CMAR 可以用于微程序在小范围内的跳转和条件转移 由硬件产生微程序入口地址 如计算机开机。第一条微指令地址由专门硬件产生 中断周期 由 硬件 产生 中断周期微程序首地址 间址阶段所对应的微程序的首地址在控制存储器中是固定的。 后续微指令地址形成方式原理图 下地址由微指令顺序控制字段给出 由OP操作码字段经过微地址形成部件给出对应的这条指令的执行阶段所对应的微程序在控制单元的首地址 CMAR+1，顺序执行 第1条微指令等，由硬件完成 分支逻辑，确定是否转移。由分支逻辑从4个信号中选择一个作为CMAR的输入送入CMAR。 CMAR中的地址，经过译码后选定控制存储器中给定的存储单元。将内容读出放入CMDR。CMDR就可以给出相应控制信号 微指令格式水平型微指令：一次能定义并执行多个并行操作 如：直接编码、字段直接编码、字段间接编码、直接和字段混合编码 垂直型微指令：类似机器指令操作码 的方式，由微操作码字段规定微指令的功能。 一次只能定义一个操作(比较复杂操作)。 两种微指令格式的比较 水平型微指令比垂直型微指令 并行操作能力强，灵活性强 水平型微指令执行一条机器指令所要的微指令 数目少，速度快 水平型微指令 用较短的微程序结构换取较长的微指令结构 水平型微指令与机器指令 差别大 静态微程序设计和动态微程序设计静态：微程序无须改变，采用ROM 动态：通过改变微指令和微程序改变机器指令，有利于仿真，采用EPROM 毫微程序设计 概念：微程序操作如果较为复杂，并且该操作内部的毫微操作也有一定的时间先后顺序。就可以用毫微程序来解释这条微指令 微程序设计 用 微程序解释机器指令 毫微程序设计 用 毫微程序解释微指令 毫微指令与微指令 的关系好比 微指令与机器指令 的关系 毫微程序控制存储器的基本组成 指向CMAR1为3种地址输入 CMDR1：控制编码部分和指令的操作码编码方式类似，节省空间。通过微指令的地址码部分给出对应的毫微程序的地址送入CMAR2 串行微程序控制和并行微程序控制 微程序设计举例写出对应机器指令的微操作及节拍安排 假设：CPU 结构与组合逻辑相同，都采用非总线的方式 取指阶段微操作分析 T0：PC—&gt;MAR 1—&gt;R T1：M(MAR)—&gt;MDR (PC)+1—&gt;PC T2：MDR—&gt;IR OP(IR)—微地址形成部件 读取指令 OP(IR)—&gt;微地址形成部件—&gt;CMAR Ad(CMDR)—&gt;CMAR 取指阶段的微操作及节拍安排：T1、T2、T3负责取微指令 T0：PC—&gt;MAR 1—&gt;R T1：Ad(CMDR)—&gt;CMAR T2：M(MAR)—&gt;MDR (PC)+1—&gt;PC T3：Ad(CMDR)—&gt;CMAR T4：MDR—&gt;IR OP(IR)—微地址形成部件 T5：OP(IR)—&gt;微地址形成部件—&gt;CMAR 执行阶段 非访存指令 访存指令 转移类指令 以上：全部微操作 20个、微指令 38条 确定微指令格式 微指令的编码方式：微指令的编码方式 后续微指令的地址形成方式：由机器指令的操作码通过微地址形成部件形成、由微指令的下地址字段直接给出 微指令字长： 由20个微操作：确定操作控制字段最少 20 位 由 38 条微指令：确定微指令的 下地址字段 为 6 位 微指令字长 可取 20 ＋ 6 ＝ 26 位 微指令字长的确定： 38 条微指令中有 19 条用于形成后续微指令地址 其中1条：OP(IR)—&gt;微地址形成部件—&gt;CMAR 18条：Ad(CMDR)—&gt;CMAR 若Ad(CMDR)直接送控存地址线，或多路选择器。就省去了了输至 CMAR 的时间，省去了 CMAR。OP(IR)—&gt;微地址形成部件—&gt;CMAR 同理。这样19条都可省略。38-19=19。 可省去 19 条微指令：38 － 19 ＝ 19操作控制字段最少取 18 位 可省去 2 个微操作：20 － 2 ＝ 18下地址字段最少取 5 位 考虑到一定的余量：去操作控制字段：24位。下地址字段6位。共30位 省去了 CMAR 的控制存储器 编写微指令码点","categories":[],"tags":[]},{"title":"Git笔记","slug":"Git笔记","date":"2020-09-25T05:17:54.000Z","updated":"2021-07-08T07:55:17.925Z","comments":true,"path":"2020/09/25/Git笔记/","link":"","permalink":"http://example.com/2020/09/25/Git%E7%AC%94%E8%AE%B0/","excerpt":"","text":"一、简介1.1安装Linux自带，Windows在官网下载安装 安装步骤 安装到一个非中文没有空格得目录下 Select Components(默认即可)：选择部件 Additional icons：添加桌面图标 Windows Explorer integration：右键显示Git Bash和Git GUI Git FLS：大文件支持 Associate .git* configuration files with the default text editor：打开git配置文件默认编辑器 Associate .sh files to be run with Bash：是否使用Git打开.sh文件 Use a TrueType font in all console windows：字体的使用 Check daily for Git for Windows updates：每天检查更新 Select Start Menu Folder(默认即可)：安装程序目录 Choosing the default editor used by Git(默认即可)：选择默认编辑器，建议VIM Adjusting your PATH environment(选第一个)：设置PATH环境 完全不修改PATH环境变量，仅在Git bash中使用Git 在Windows的命令行使用Git。被认为是安全的 在Windows命令行能使用可选的Unix工具和Git。可能会覆盖Windows一些命令。 Choosing HTTPS transport backend(选SSL)：远程链接方式 Configuring the line ending conversions(选第一个)： 兼容Windows和unix风格的换行符：Git会将LF转化为CRLF 略 Configuring the terminal emulator to use with Git Bash(选第一个) 使用MinTTY默认终端 使用Windows默认终端 Configuring extra options(选前两项)： 启用文件缓存 启用Git授权管理器 略 读条 View Release Notes(可以不选)：查看更新文档。 1.2结构 本地库：历史版本 暂存区：临时存储 工作区：写代码 本地库和远程库 远程库的复制：fork 远程库提交：要pull request，再审核才能merge 本地库复制远程库：clone 本地库推送远程库：push 二、Git命令行操作2.1本地库初始化和设置签名git init：初始化一个空的仓库。在.git目录里会存放本地库相关的子目录和文件 签名： 可以通过命令设置签名的两个级别： 项目级别/仓库级别：仅在当前本地库范围内有效 设置保存到当前仓库的.git/config文件内 系统用户级别(往往这一个就够了)：登录当前操作系统的用户范围 设置保存在~/.gitconfig文件内 不允许没有签名。 登录代码托管中心的账户密码和设置签名的用户名、Email地址没有任何关系。 123456#仓库级别设置签名git config user.name 用户名 #设置用户名git config user.email 邮箱地址 #设置邮箱地址#系统用户级别设置签名git config --global user.name 用户名 #设置用户名git config --global user.email 邮箱地址 #设置邮箱地址 2.2基本操作状态查看12git status #查看工作区、暂存区状态#结果会显示，在哪个分支，提交的，未放入暂存区的内容和暂存区内容 添加123git add [file name] #将工作区的“新建/修改”添加到暂存区#fule name：指定的文件名#add时可能会warning：CRLF转化为LF 1git rm --cached &lt;file&gt; #从暂存区撤回 提交1234git commit -m \"commit message\" [file name] #将暂存区的内容提交到本地库#commit message：提交的具体信息#如果命令没有写-m \"commit message\"，会跳转到VIM编辑器，在第一行写入对应信息即可 如果不是首次创建可以直接commit 查看历史记录123456git log#查看提交记录#显示提交的hash值 作者信息 时间 和提交信息#太多时 按空格键翻页，b向上翻页，q退出git log --pretty=oneline#每条日志漂亮的一行显示git log --oneline#每条日志漂亮的一行显示 hash更简短git reflog#比--online多了HEAD@&#123;HEAD移动到当前版本需要多少步&#125; 历史前进后退本质：移动HEAD指针 方式： 基于索引值操作 git reset --hard hash值：移动到对应索引值的版本。 hash值可以是–online和reflog的简短的 使用^符号：只能后退 git reset --hard HEAD^：后退一步 git reset --hard HEAD^^：后退两步，以此类推 使用~符号：只能后退 git reset --hard HEAD~：后退一步 git reset --hard HEAD~3：后退三步，以此类推 reset命令的三个参数 --soft： 仅仅在本地库移动HEAD 指针 soft后退可以理解为，暂存区的提交后退，回到还未提交状态 --mixed：在本地库移动 HEAD、指针重置暂存区 mixed后退可以理解为，暂存区和本地库后退，回到还未add状态 --hard：在本地库移动 HEAD 指针、重置暂存区、重置工作区 hard后退可以理解为，都回到对应版本 比较文件差异123git diff [文件名]#将工作区中的文件和暂存区进行比较git diff [本地库中历史版本] [文件名]#将工作区中的文件和本地库历史记录比较 #不带文件名比较多个文件 修改一行git会认为删除再添加一行 2.3分支操作创建分支1git branch [分支名] 查看分支1git branch -v 切换分支1git checkout [分支名] 合并分支1234#第一步：切换到接受修改的分支（被合并，增加新内容）上git checkout [被合并分支名]#第二步：执行 merge 命令git merge [有新内容分支名] 冲突解决123456#冲突表现 等号上面为当前分支内容 等号下为另一分支内容&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADxxxxxxxxx=======xxxxxxxxxx&gt;&gt;&gt;&gt;&gt;&gt;&gt; 分支名 解决冲突： 编辑文件，删除特殊符号 把文件修改到满意的程度，保存退出 git add [文件名] git commit -m &quot;日志信息&quot; 以往的commit会带具体文件名，这次不用带文件名。否则会报错 三、Git远程仓库连接3.1基操GitHub 创建远程仓库地址别名12git remote -v #查看当前所有远程地址别名 fetch：取回地址 push：推送地址git remote add [别名] [远程地址]#别名指的是给远程地址取得别名。远程地址在GitHub上仓库获取 推送1git push [别名] [分支名] #如git push origin master 别人push需要添加入团队，在仓库的Settings的Collaborators，然后输入输入她的用户名，复制链接发生给他。让他接受即可。 https连接没有记住密码的功能，但win10会有记住凭据的功能，所以不用二次输入账号密码。如果要切换账号，需要找到对应凭据删除即可。 克隆1git clone [远程地址]#克隆会自动初始化，也会创建 origin 远程地址别名 拉取pull=fetch+merge 123git fetch [远程库地址别名] [远程分支名]#抓取下来不会合并，要切换到对应的远程仓库分支才能看。一般操作比较复杂的时候使用git merge [远程库地址别名/远程分支名]#合并抓取的远程分支git pull [远程库地址别名] [远程分支名] 远程冲突解决 如果不是基于 GitHub 远程库的最新版所做的修改，不能推送，必须先拉取。 拉取下来后如果进入冲突状态，则按照“分支冲突解决”操作解决即可。 3.2跨团队操作复制仓库在要复制的仓库右上角的fork点击即可。 Pull Request提出：在发出方对应的GitHub端仓库，点击Pull requests—&gt;New pull request—&gt;Create pull request。写出对应信息，发送。 接收端：在接收方对应的GitHub端仓库，电机Pull requests就能看到对应消息。 可在该界面审核代码、对话、Merge pull request(合并代码)。 3.3SSH免密登录 进入当前用户的家目录 $ cd ~ 删除.ssh 目录 $ rm -rvf .ssh 运行命令生成.ssh 密钥目录 $ ssh-keygen -t rsa -C 登录GitHub的邮箱 -C：C必须大写 进入.ssh 目录查看文件列表 $ cd .ssh、$ ls -lF，会有id_rsa和id_rsa.pub两个文件 查看 id_rsa.pub 文件内容 $ cat id_rsa.pub 复制 id_rsa.pub 文件内容，登录 GitHub，点击用户头像→Settings→SSH and GPG keys→New SSH keys。把复制内容粘贴到Key内，title随意 创建远程地址别名git remote add origin_ssh 仓库的ssh链接测试 四、其它4.1忽略文件官方参考忽略文件、Java版本 在~/.gitconfig 文件中引入忽略配置文件 12[core] excludesfile = 忽略配置文件的绝对路径 路径使用/","categories":[],"tags":[{"name":"git","slug":"git","permalink":"http://example.com/tags/git/"}]},{"title":"manjaro配置开发环境","slug":"manjaro配置开发环境","date":"2020-09-25T05:13:43.000Z","updated":"2021-07-08T07:55:42.439Z","comments":true,"path":"2020/09/25/manjaro配置开发环境/","link":"","permalink":"http://example.com/2020/09/25/manjaro%E9%85%8D%E7%BD%AE%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/","excerpt":"","text":"安装配置虚拟机环境manjaro快速安装centos虚拟机vagrant命令失败请检查是否在对应目录下，一般是家目录。 uname -r查看版本号，5.7.17-2-MANJARO表示57 sudo pacman -S virtualbox选择对应模块，这里是57就是linux57-virtualbox-host-modules sudo pacman -Ss virtualbox-ext-oracle安装扩展包 sudo gpasswd -a 用户名 vboxusers：添加当前用户到vboxusers sudo modprobe vboxdrv： sudo pacman -S vagrant 重启 vagrant：验证是否安装成功 vagrant init centos/7：centos/7是仓库里名字对应，会在~下创建vagrantfile vagrant up：启动虚拟机，会下载并启动 网络问题可能会下载超时，我采用的是把下载的地址在迅雷下载，然后把box文件用vagrant box add centos/7 ~/virtualbox.box添加，然后vagrant up vagrant ssh：可以直接连接虚拟机 exit：退出 #也可以根据信息连接 default: SSH address: 127.0.0.1:2222 default: SSH username: vagrant default: SSH auth method: private key 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354 - vagrant和root用户的密码默认为&#96;vagrant&#96;12. 虚拟机默认网络是*网络地址转换-端口转发*对之后的操作不便。可以采用修改虚拟机内网络配置或直接修改Vagrantfile文件，这里采取直接修改Vagrantfile文件。修改&#96;config.vm.network &quot;private_network&quot;,ip:&quot;192.168.56.10&quot;&#96; - 端口转发：每个虚拟机内软件的端口都需要映射到宿主机上，需要配置主机端口和子系统端口。过于繁琐 - Win：Windows查看网卡，根据VirtualBox的虚拟网卡，设置IP地址，最后一部分不一样即可。 - Linux：使用&#96;ifconfig&#96;命令没有找到对应网卡，就设置了与已有网卡不冲突的地址。13. &#96;vagrant reload&#96;：重新加载14. 然后&#96;ping IP地址&#96;能ping通即可15. 我与遇到虚拟空间40G实际空间1.2G，很快就空间不足，然后在设置—&gt;存储—&gt;存储介质—&gt;右键控制器:IDE—&gt;硬盘—&gt;刷新即可## 开发环境我将mvn放在了&#96;&#x2F;home&#x2F;guanhe&#x2F;workspace&#x2F;maven&#96;下。仓库位置&#96;&#x2F;home&#x2F;guanhe&#x2F;workspace&#x2F;maven&#x2F;.m2&#x2F;repository&#96;&#96;&#96;&#96;xml&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;settings xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;SETTINGS&#x2F;1.0.0&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;SETTINGS&#x2F;1.0.0 http:&#x2F;&#x2F;maven.apache.org&#x2F;xsd&#x2F;settings-1.0.0.xsd&quot;&gt; &lt;localRepository&gt;&#x2F;home&#x2F;guanhe&#x2F;workspace&#x2F;maven&#x2F;.m2&#x2F;repository&lt;&#x2F;localRepository&gt; &lt;pluginGroups&gt; &lt;&#x2F;pluginGroups&gt; &lt;proxies&gt; &lt;&#x2F;proxies&gt; &lt;servers&gt; &lt;&#x2F;servers&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;&#x2F;id&gt; &lt;mirrorOf&gt;central&lt;&#x2F;mirrorOf&gt; &lt;name&gt;aliyun maven&lt;&#x2F;name&gt; &lt;url&gt;http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;repositories&#x2F;central&#x2F;&lt;&#x2F;url&gt; &lt;&#x2F;mirror&gt; &lt;&#x2F;mirrors&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;JDK-1.8&lt;&#x2F;id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;&#x2F;activeByDefault&gt; &lt;jdk&gt;1.8&lt;&#x2F;jdk&gt; &lt;&#x2F;activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;&#x2F;maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;&#x2F;maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;&#x2F;maven.compiler.compilerVersion&gt; &lt;&#x2F;properties&gt; &lt;&#x2F;profile&gt; &lt;&#x2F;profiles&gt;&lt;&#x2F;settings&gt; 离线安装idea插件： 下载，解压，放到/home/guanhe/program下。激活码 插件下载网址（下载的版本，最好下和自己idea版本对应的），选择settings，选择install from disks 安装VsCode 下载，解压，放到/home/guanhe/program下。 12sudo touch /home/guanhe/桌面/visualstudiocode.desktopsudo nano /home/guanhe/桌面/visualstudiocode.desktop sudo vi visualstudiocode.desktop 123456789[Desktop Entry]Name&#x3D;Visual Studio CodeComment&#x3D;Multi-platform code editor for linuxExec&#x3D;&#x2F;home&#x2F;guanhe&#x2F;program&#x2F;VSCode-linux-x64&#x2F;bin&#x2F;codeIcon&#x3D;&#x2F;home&#x2F;guanhe&#x2F;program&#x2F;VSCode-linux-x64&#x2F;resources&#x2F;app&#x2F;resources&#x2F;linux&#x2F;code.pngType&#x3D;ApplicationStartupNotify&#x3D;trueCategories&#x3D;TextEditor;Development;Utility;MimeType&#x3D;text&#x2F;plain; 在桌面右键Allow launching 安装VsCode插件 点击左侧栏Extensions图标搜索安装 Auto Close Tag Auto Rename Tag Chinese ESlint HTML CSS Support HTML Snippets JavaScript ES6 Live Server open in brower Vetur 重启 配置git 12345678910111213141516 配置用户名git config --global user.name \"username\" //(名字，随意写)# 配置邮箱git config --global user.email \"邮箱@qq.com\" // 注册账号时使用的邮箱# 配置ssh免密登录ssh-keygen -t rsa -C \"邮箱@qq.com\"#三次回车后生成了密钥cat ~/.ssh/id_rsa.pub#浏览器登录码云后，个人头像上点设置、然后点ssh公钥、随便填个标题，然后将id_rsa.pub填入# 测试ssh -T git@gitee.com测试成功 安装node 下载解压到/opt/module/ vi /etc/profile 1export PATH=/opt/module/node-v12.18.3-linux-x64/bin:$PATH npm config set registry http://registry.npm.taobao.org/","categories":[],"tags":[{"name":"marjora","slug":"marjora","permalink":"http://example.com/tags/marjora/"},{"name":"virtualbox","slug":"virtualbox","permalink":"http://example.com/tags/virtualbox/"}]},{"title":"docker笔记","slug":"docker笔记","date":"2020-09-25T05:11:40.000Z","updated":"2021-07-08T08:01:56.877Z","comments":true,"path":"2020/09/25/docker笔记/","link":"","permalink":"http://example.com/2020/09/25/docker%E7%AC%94%E8%AE%B0/","excerpt":"","text":"一、安装Docker1.1安装环境：centos 内核版(uname -r查看)：3.10以上 参考 卸载旧版本 12345678sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 安装需要的安装包 1sudo yum install -y yum-utils 设置镜像仓库 12345678#国外的sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo#国内的sudo yum-config-manager \\ --add-repo \\ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 安装docker相关 12345#更新yum索引，centos8不用fastsudo yum makecache fastsudo yum install docker-ce docker-ce-cli containerd.io#核心 cli客户端 io容器#ce表示社区版 ee表示企业版 如果不想安装最新版，可以使用yum list docker-ce --showduplicates | sort -r查看历史版本。然后使用sudo yum install docker-ce-&lt;VERSION_STRING&gt; docker-ce-cli-&lt;VERSION_STRING&gt; containerd.io指定版本安装 启动测试 1234sudo systemctl start dockerdocker version#可以判断是否启动成功sudo docker run hello-world#测试引擎 如果有Hello from Docker就表示成功docker images#查看镜像 配置用户权限和开机自启动 123456# 如果还没有 docker group 就添加一个sudo groupadd docker# 将自己的登录名($&#123;USER&#125; )加入该 group 内。然后退出并重新登录就生效啦sudo gpasswd -a $&#123;USER&#125; docker# sudo gpasswd -a vagrant dockersudo systemctl enable docker #开机自启动 (如果)卸载docker 12sudo yum remove docker-ce docker-ce-cli containerd.io#卸载sudo rm -rf /var/lib/docker#删除资源 这是docker的默认工作路径 1.2配置阿里云镜像加速在阿里云控制台页面左侧产品与服务—&gt;弹性计算—&gt;容器镜像服务—&gt;最左下镜像加速器。打开相应的操作文档 配置： 1234567891011#创建文件夹sudo mkdir -p /etc/docker#创建daemon.json并输入相应内容sudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123; \"registry-mirrors\": [\"https://dzwpjcek.mirror.aliyuncs.com\"]&#125;EOF#重启sudo systemctl daemon-reloadsudo systemctl restart docker 1.3原理运行流程：开始后，会在Docker在本机寻找镜像，判断是否有该镜像。有就运行，没有就去下载，然后去寻找是否找到相应镜像，没有就返回错误，有就下载并运行。 Docker是C-S结构。Docker的守护进程运行在主机上 DockerServer接收到Docker-Client指令，执行响应命令。 后台守护进程会创建容器。 二、Docker常用命令2.1帮助命令123docker [命令] --help #查看帮助docker version #看版本docker info # 官方帮助文档 2.2镜像命令查看镜像1234567891011docker images #查看镜像#显示结果。#REPOSITORY 镜像的仓库源#TAG 镜像标签#IMAGE ID 镜像id#CREATED 镜像的创建时间#SIZE 镜像大小#常用可选项 #-a,--all 列出所有#-q,--quiet 只显示镜像id 搜索镜像在官网查看详细说明 123docker search 要搜索内容#常用可选项# --filter，-f 如--filter=STARS=3000 列出STARS大于3000的镜像 下载镜像12docker pull 镜像名#下载镜像，默认下最新版docker pull mysql:5.7#例指定版本 指定版本必须官方库支持，在Supported tags and respective Dockerfile links内 Docker下载镜像时分层下载。如果下次下载与以往有重叠，就可直接使用 删除镜像12docker rmi -f 镜像id#删除指定容器，多个用空格隔开docker rmi -f $(docker images -aq)#删除全部 2.3容器命令有镜像才能创建容器 新建容器并启动123456789101112131415docker run [可选参数] 镜像名#可选参数#--name=\"name\" 给容器取名，用来区分#-d 后台运行#-it 使用交互式方式运行，进入容器查看内容#-p 指定容器的端口(不指定就是随机)# -p ip:主机端口:容器端口# -p 主机端口:容器端口# -p 容器端口# 容器端口# --rm 用完即删除，一般用来测试# --volumes-from 继承指定的容器装载卷(与他一致)，但被继承容器无了，依然存在(类似备份)#例启动centos，并进入#镜像名后可以根命令，如ls -aldocker run -it centos /bin/bash 查看运行容器1234docker ps #列出当前正在运行的容器# -a 再加上历史运行过容器# -n=? 显示最近创建的容器 n=1表示一个# -q 只显示容器编号 退出容器12exit #停止并退出 如果是启动后再进入，使用并不会退出ctrl+P+Q #大写模式下用，容器不停止退出 删除容器123docker rm 容器id #删除指定容器，不能删除正在运行容器docker rm -f $(docker ps -aq) #删除全部容器docker ps -a -q | xargs docker rm -f #删除所有容器 启动和停止容器1234docker start 容器id #启动容器docker restart 容器id #重启容器docker stop 容器id #停止正在运行容器dicjer kill 容器id #强制停止容器 2.4常用其它命令后台启动容器1234docker run -d 容器名#常见问题：启动后，使用docker ps，发现停止了#容器后台运行必须有一个前台进程，docker如果发现没用应用就会自动停止#如nginx，tomcat等启动后，发现自己没提供服务，就会立刻停止 查看日志12docker logs -tf 容器id#查看容器全部日志docker logs -tf --tail 10 容器id#查看最后10条日志 查看容器内进程1docker top 容器id#显示容器内进程信息 查看镜像元数据1docker inspect 容器id 进入正在运行容器12docker exec -it 容器id bashshell #进入时开启的是新终端#例 docker exec -it deas45das4 /bin/bash 1docker attach 容器id#进入容器，不会启动新进程 从容器内拷贝文件到主机1docker cp 容器id:容器内路径 主机路径 提交镜像将下载运行的镜像，通过修改。可以提交一个新的镜像。 1234docker commit -m=\"提交的描述信息\" -a=\"作者\" 容器id 目标镜像名：[TAG] #tag可以是自己取得版本号#如docker commit -a=\"paidaxing\" -m=\"add webapps app\" 当前容器的id tomcat02:1.0 压缩解压1234#可以将镜像压缩发给别人docker save --helpdocker load --help#自学 2.5简单例子安装Nginx 搜索镜像 下载镜像 运行 docker run -d --name nginx1 -p 3344:80 nginx：后台启动nginx命名nginx1，端口号80映射到主机的3344. 安装ES+Kibana123docker run -d --name elasticsearch1 -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" elasticsearch:7.6.2curl localhost:9200#查看是否成功docker stats#查看容器所占性能 12#增加内存限制$ docker run -d --name elasticsearch02 -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -e ES_JAVA_OPTS=\"-Xms64m -Xmx512m\" elasticsearch:7.6.2 安装redis12345678910# 在虚拟机中mkdir -p /mydata/redis/conf touch /mydata/redis/conf/redis.conf #先创建文件，否则挂载的时候会默认当成目录docker pull redisdocker run -p 6379:6379 --name redis \\-v /mydata/redis/data:/data \\ -v /mydata/redis/conf/redis.conf:/etc/redis/redis.conf \\-d redis redis-server /etc/redis/redis.conf 12345678#修改配置文件vim /mydata/redis/conf/redis.#写入内容appendonly yes#重启docker restart redis 1234567# 直接进去redis客户端。测试持久化docker exec -it redis redis-cliset a bexitdocker restart redisdocker exec -it redis redis-cliget a 12#自启动sudo docker update 容器id --restart=always 2.6可视化portainer(先用)Docker的图形化界面管理工具，提供一个后台面板。 12#-v将容器一些数据挂载到本机 --pri…授权访问 docker run -d -p 8088:9000 --restart=always -v /var/run/docker.sock:/var/run/docker --privileged=true portainer/portainer 然后页面登录就行。 Rancher(CI/CD)三、容器数据卷为了使得删除容器数据也不丢失，就要将数据存在本地。容器之间也是可以数据共享。 启动挂载容器数据卷1234docker run -it -v -p# -it 交互式进入# -v volume卷技术# -p 主机端口 12#如 主机内地址:容器内地址docker run -it -v /home/ceshi:/home centos centos /bin/bash 安装MySQL12345678910docker pull mysql:5.7# 挂载docker run -d -p 3310:3306 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql1 mysql:5.7##-d 后台运行#-p 端口映射#-v 卷挂载#-e 环境配置 MYSQL_ROOT_PASSWORD 配置MySQL密码#--name 容器名字 我的虚拟机linux用的： 123456docker run -p 3306:3306 --name MyMysql \\-v /mydata/mysql/conf:/etc/mysql \\-v /mydata/mysql/log:/var/log/mysql \\-v /mydata/mysql/data:/var/lib/mysql \\-e MYSQL_ROOT_PASSWORD=000000 \\-d mysql:5.7 进入mysql 1sudo docker exec -it 31983e213c96 /bin/bash 查看mysql文件 1whereis mysql 修改配置文件 1234567891011121314151617sudo vi /mydata/mysql/conf/my.conf [client]default-character-set=utf8[mysql]default-character-set=utf8[mysqld]init_connect='SET collation_connection = utf8_unicode_ci'init_connect='SET NAMES utf8'character-set-server=utf8collation-server=utf8_unicode_ciskip-character-set-client-handshakeskip-name-resolve保存(注意评论区该配置不对，不是collection而是collation)docker restart MyMysql 12#自启动sudo docker update MyMysql --restart=always 具名和匿名挂载12345678-v 容器内路径#-v只写容器内路径，没写容器外路径就是匿名挂载docker run -p --name nginx1 -v /etc/nginx nginx #没给地址取名，匿名挂载docker volume ls #查看所有volume# 通过-v 卷名:容器内路径#卷毛是不以\"/\"开头 所有docker容器内的卷，在没指定目录情况下都在/var/lib/docker/volumes/卷名/_data下 123-v 容器内路径 #匿名挂载-v 卷名:容器内路径 #具名挂载-v /宿主机路径:容器内路径 #指定路径挂载 拓展： 1234# ro：readonly 只读 只能在容器外改变，容器内无法改变# rw：readwrite 读写 默认docker run -p --name nginx1 -v juming:/etc/nginx:ro nginxdocker run -p --name nginx1 -v juming:/etc/nginx:rw nginx 结论：容器之间配置信息的传递，数据卷容器的生命周期一直持续到没有容器使用为止。若使用-v持久化到本地，这时候 本地的数据是不会删除 四、Dockerfile4.1基础知识dockerfile是用来构建docker镜像的文件！命令参数脚本 以文件的方式指定命令，创建新镜像。 每个保留关键字(指令)都必须是大写字母 执行从上到下顺序执行 #表示注释 每条指令都会创建提交一个新的镜像层 dockerfile是面向开发的。发布项目，做镜像，需要编写dockerfile文件。 官方默认命名Dockerfile，如果不指定默认寻找该文件 4.2简单使用 创建dockerfile文件 12345678910#创建一个dockerfile文件，名字随意#指令大写#每一个指令都会创建体检一个新的镜像层，并提交FROM centos #以centos做基础VOLUME [\"volume1\",\"volume2\"] #匿名挂载卷CMD echo \"---end---\" #命令行打印CMD /bin/bash #使用bash控制台 构建docker build -f dockerfile文件的路径 -t 镜像 . 可以查看镜像，然后启动 4.3DockerFile指令 构建时命令 FROM：基础镜像，从这里开始构建 MAINTAINER：作者 姓名+邮箱 COPY：类似ADD，将文件拷贝到镜像 ADD：添加压缩包，会自动解压 RUN：镜像构建时要运行的命令 ONBUILD：当构建一个被继承DockerFile时会运行ONBUILD指令 .dockerignor 连接工作目录命令 WORKDIR：设置镜像工作目录 USER 启动时执行命令 CMD：指定容器启动时运行命令，只有最后一个会失效可被替代 CMD [&quot;ls&quot;,&quot;-a]：带参数有”[]” ENV：构建时设置环境变量 EXPOSE：指定对外端口 VOLUME：挂载卷，挂载主机目录 ENTRYPOINT：和CMD类似，可以追加命令 ENTRYPOINT：运行时后加命令或参数，会追加到后面 CMD：运行时加命令或参数，会替代最后一条 4.4构建找官方dockerfile学习。在Docker Hub内搜索任意镜像，找到Supported tags and respective Dockerfile links下任意一个版本点击就会跳转到dockerfile文件。 12345678910111213141516#centos7.7FROM scratch#最基础镜像ADD centos-7-x86_64-docker.tar.xz / #添加centos7LABEL \\ #添加标签 org.label-schema.schema-version=\"1.0\" \\ org.label-schema.name=\"CentOS Base Image\" \\ org.label-schema.vendor=\"CentOS\" \\ org.label-schema.license=\"GPLv2\" \\ org.label-schema.build-date=\"20200809\" \\ org.opencontainers.image.title=\"CentOS Base Image\" \\ org.opencontainers.image.vendor=\"CentOS\" \\ org.opencontainers.image.licenses=\"GPL-2.0-only\" \\ org.opencontainers.image.created=\"2020-08-09 00:00:00+01:00\"CMD [\"/bin/bash\"] 编写dockerfile文件 docker build构建镜像 docker run运行镜像 docker push发布镜像(DockerHub、阿里云镜像仓库等) 4.5实操centos配置有vim等命令的centos 123456789101112131415#dockerfile文件FROM centosMAINTAINER kuangshen&lt;dianyang12138@163.com&gt;#作者ENV MYPATH /usr/local #配置一个环境变量WORKDIR $MYPATH#工作目录 进去后的位置 默认根目录RUN yum -y install vim #安装vimRUN yum -y install net-tools EXPOSE 80#暴露端口CMD echo $MYPATHCMD echo \"---end---\"CMD /bin/bash 构建：docker build -f centos-dockerfile -t 生成的镜像名:版本号 . history：docker history 镜像索引号可以查看镜像如何生成的 Tomcat 准备jdk和tomcat的压缩包 编写dockerfile文件 1234567891011121314151617181920FROM centosMAINTAINER 作者&lt;邮箱&gt;COPY readme.txt /usr/local/readme/txt #讲说明文本复制到对应路径下ADD jdk….tar.gz /usr/local/ #将jdk解压复制到对应路径下ADD apache-tomcat….tar.gz /usr/local #将tomcat解压复制到对应路径下ENV MYPATH /usr/localWORKDIR $MYPATHENV JAVA_HOME /usr/local/jdkENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tool.jarENV CATALINA_HOME /usr/local/apacheENV CATALINA_BASH /usr/local/apacheENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOMEEXPOSE 8080CMD /usr/local/apache-tomcat/bin/startup.sh &amp;&amp; tail -F /usr/local/apache-tomcat/bin/logs/catalina.out 构建docker build -t diytomcat . 启动 测试 发布 五、发布镜像5.1DockerHub 在DockerHub上注册 登录 1234docker login --help #查看对应帮助# -u 用户名# -p 密码docker login -u 账号 #回车 提交镜像 1docker push 镜像名 5.2阿里云镜像仓库 登录阿里云 找到容器镜像服务 创建命名空间：右上角创建 创建容器镜像：代码源选本地仓库 点开仓库就能看到操作流程","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"}]},{"title":"操作系统","slug":"操作系统","date":"2020-06-13T08:21:32.000Z","updated":"2021-07-08T08:56:16.141Z","comments":true,"path":"2020/06/13/操作系统/","link":"","permalink":"http://example.com/2020/06/13/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"系统的启动x86 PC的开机流程 x86 PC刚开机时CPU处于实模式 实模式和保护模式对应，实模式的寻址CS:IP和保护模式不一样 开机时，CS=0xFFFF IP=0x0000 寻址0xFFFF0(ROM BIOS映射区) 检查RAM、键盘、显示器等 将磁盘0磁道0扇区读入内存的0x7c00处。就是引导扇区 设置cs=0x07c0，ip=0x0000 0x7c00处存放的代码就是从磁盘引导扇区读入的512个字节 引导扇区就是启动设备的第一个扇区 boot模块 引导扇区代码：bootsect.s .s为汇编代码 如果采用C语言经过编译可能会产生出无法控制的东西，如不能控制int变量具体在内存的哪个位置。 汇编的每条指令都变成了真正的机器指令 程序说明：这段程序是先将引导扇区的代码读入，再将setup的代码读入。 第一个扇区是boot扇区，后面紧跟着4个setup扇区，然后再是OS扇区 123456789101112131415161718192021222324252627282930313233343536373839404142.globl begtext,begdata,begbss,endtext,enddata,endbss.text &#x2F;&#x2F;文本段，.text等是伪操作符，告诉编译器产生文本段，.text用于标识文本段的开始位置。此处的.text .data .bss表明3个段重叠，不分段begtext:.data &#x2F;&#x2F;数据段begdata:.bss &#x2F;&#x2F;未初始化数据段begbss:entry start &#x2F;&#x2F;关键字entry告诉链接器 程序入口start: &#x2F;&#x2F;SETUPSEG&#x3D;0x0920 mov ax,#BOOTSEG mov ds,ax &#x2F;&#x2F;BOOTSEG&#x3D;0x07c0，将ds置为7c0 mov ax,#INITSEG mov es,ax &#x2F;&#x2F;INITSEG&#x3D;0x9000，将es置为9000 mov cx,#256 sub si,si sub di,di &#x2F;&#x2F;将si和di置0 rep movw &#x2F;&#x2F;重复移动256个字，cx为256。就是将0x07c0:0x000的256个字移动到0x9000:0x0000，为了给后面os模块留位置 jmpi go,INITSEG &#x2F;&#x2F;将go赋给ip，INITSGE赋给CS。go指的是go段的偏移地址go: mov ax,cs &#x2F;&#x2F;cs&#x3D;0x9000 mov ds,ax mov es,ax mov ss,ax mov sp,#0xff00loadsetup: &#x2F;&#x2F;载入setup模块 mov dx,#0x000 mov cx,#0x0002 mov bx,0x0200 mov ax,#0x0200+SETUPLEN int 0x13 &#x2F;&#x2F;BIOS中断，0x13是BIOS读磁盘扇区的中断：ah&#x3D;0x02-读磁盘，al&#x3D;扇区数量(SETUPLEN&#x3D;4)，ch&#x3D;柱面号，cl&#x3D;开始扇区号，dh&#x3D;磁头号，dl&#x3D;驱动器号，es:bx&#x3D;内存地址 jnc ok_load_setup &#x2F;&#x2F;&#x2F;读到0x90200也就是0x90000的512字节后 mov dx,#0x0000 mov dx,#0x0000 int 0x13 j load_setup ok_load_setup: &#x2F;&#x2F;载入setup模块 mov dl,#0x00 mov ax,#0x0800 int 0x13 mov ch,#0x00 mov sectors,cx mov ah,#0x03 xor bh,bh int 0x10&#x2F;&#x2F;读光标 mov cx,#24 mov bx,#0x0007 mov bp,#msg1 mov ax,#1301 int 0x10&#x2F;&#x2F;显示字符，显示的内容是bp所在的内存数据,可以通过修改msg1位置的内容显示不同的效果 mov ax,#SYSSEG &#x2F;&#x2F;SYSSEG&#x3D;0x1000 mov es,ax call read_it &#x2F;&#x2F;读入systm模块 jmpi 0,SETUPSEG read_it: mov ax,es cmp ax,#ENDSEG jb ok1_read retok1_read: mov ax,sectors sub ax,sread &#x2F;&#x2F;sread是当前磁道已读扇区数 call read_track &#x2F;&#x2F;读磁道 msg1:内容是”loading system” setup模块 setup.s，将完成os启动前的设置。用来获取硬件信息。操作系统要开始建立 123456789101112131415161718192021222324252627start: mov ax,#INITSEG mov ds,ax mov ah,#0x03 xor bh,bh int 0x10&#x2F;&#x2F;取光标位置dx mov [0],dx mov ah,#0x88 int 0x15 mov [2].ax ... &#x2F;&#x2F;用ah的参数使用15中断(获取物理内存)然后放入ax，再赋给[2]用来间接寻址，段地址是9000，所以最后是90002 cli &#x2F;&#x2F;不允许中断 mov ax,#0x0000 clddo_move: mov es,ax add ax,#0x1000 cmp ax,#0x9000 jz end_move mov ds,ax sub di,di sub si,si mov cx,#0x8000 rep &#x2F;&#x2F;将system模块移到0地址 movsw jmp do_move end_move: mov ax,#SETUPSEG mov ds,ax lidt idt_48 lgdt gdt_48 &#x2F;&#x2F;设置保护模式的中断和寻址(初始化表) &#x2F;&#x2F;这里省略了很多idt_48:.word 0 .word 0,0gdt_48:.word 0x800 .word 512+gdt,0x9gdt: .word 0,0,0,0 &#x2F;&#x2F;一个word16位，4个word，每个表项64位 .word 0x07FF,0x0000,0x9A00,0x00c0 .word 0x07FF,0x0000,0x9200,0x00c0 &#x2F;&#x2F;setup在最后进入保护模式mov ax,#0x0001 mov cr0,ax &#x2F;&#x2F;cr0的最后一位如果是0就16位模式，如果是1保护模式jmpi 0,8 &#x2F;&#x2F;把0赋给ip 8赋给cs，如果跳到80就是操作系统开始的地址，会死机，非法指令。应该跳到0地址。在保护模式下，找的应该是第八个表项的0地址 cs:ip的寻址方式(16位机)，最多只能寻址1M，远远不够。所以需要改变寻址方式，启动32位的寻址模式，也就是保护模式 保护模式下的地址翻译和中断处理： 寻址方式：用gdt来做，是硬件上的(软件也可以做到，但是硬件更快)。cs为选择子用来放查表(GDT表)的下标(索引)，真正的基址放在表项中，在加上IP 表中内容解释由硬件规定好 中断处理：保护模式下，int n，也是在表项(IDT表)下去找，找到中断处理函数的入口地址 GDT的低位是从右下到左上。根据图可知0x07FF 0x0000 0x9A00 0x00C0得出的基址是0x00000000。就是0地址，这时候0地址已经是system模块，操作系统开始的位置。 16位模式和32位模式本质区别是CPU内部的解释程序不一样 内存地址 长度 名称 0x90000 2 光标位置 0x90002 2 扩展内存数(1M以后的内存) 0x9000C 2 显卡参数 0x901FC 2 根设备号 system模块 system是由许多文件编辑而成，我们需要控制文件先后执行的顺序就需要用到makefile。 通常把操作系统编译后的东西叫做镜像(image)， head.s为system的第一个文件。再次初始化idt和gdt表。setup因为需要``jmpi 0,8`所以临时初始化idt和gdt表。这次是真正工作。 进入保护模式后，32位汇编和16位汇编不一样了。 汇编： as86汇编：能产生16位代码的intel 8086(386)汇编 GNU as汇编：产生32位代码，使用AT&amp;T系统V语法 内嵌汇编：在gcc编译x.c会产生中间结果as汇编文件x.s 在.c文件中有些指令需要严格控制，就要用到内嵌汇编 内嵌汇编共四部分：汇编语句模板、输出部分、输入部分、破坏描述部分 各部分用:隔开，汇编语句模板必不可少，其他可选。使用了后面的部分而前面部分为空，也要用:，相应部分内容为空 head.s结束后跳转到main.c 12345after_page_tables: push1 $0 push1 $0 push1 $0 push1 $L6&#x2F;&#x2F;设置main参数 3个0 分别是envp、argv、argc push1 $_main jmp set_paging &#x2F;&#x2F;进入mianL6: jmp L6 &#x2F;&#x2F;死循环，如果main结束了 就死机了setup_paging: 设置页表 ret 123456789void main(void)&#123; mem_init(); trap_init(); .....//init用作内存、中断、cpu、设备、时钟等初始化 sti(); move_to_user_mode(); if(!fork())&#123;init();&#125;//永远不会停止&#125; 123456789101112//初始化mem_map数组未使用的置为0void mem_init(long start_mem,long end_mem)//end_mem从前面的90002处拿到&#123; int i; for(i=0;i&lt;PAGING_PAGES;i++) mem_map[i] = USED;//标记操作系统占用的内存 i = MAP_NR(start_mem); end_mem -= start_mem; end_mem &gt;&gt;=12;//4k while(end_mem -- &gt; 0) mem_map[i++] = 0;//每4K置0，作为一片&#125; 操作系统接口命令行：本质命令程序 这部分我以前了解过，就省略了 图形按钮 图形按钮本质利用了消息队列 图形界面：消息框架程序+消息处理程序 系统调用 POSIX：Portable Operating System Interface of Unix(IEEE制定的一个标准族) 可以在网上查找POSIX手册，可以查到能够使用的系统调用 X通常指Unix 系统调用：系统的函数 分类 POSIX定义 描述 任务管理 fork 创建一个进程 execl 运行一个可执行程序 pthread_create 创建一个线程 文件系统 open 打开一个文件或目录 EACCES 返回值，表示没有权限 mode_t st_mode 文件头结构：文件属性 系统调用的实现 不能让应用程序随意调用数据、jmp。 将内核程序和用户程序隔离 CS:IP的cs最低两位表示：0表示内核态3表示用户态 1、2表示os服务 区分内核态和用户态：一种处理器“硬件设计” 将内存分割成用户段和核心段 内核态可以访问如何数据、用户态不能访问内核数据。对于指令也一样 三个段寄存器：CPL(当前特权级)、DPL(目标内存段特权级)、RPL DPL用来描述目标段。就在系统初始化(head.s做的)的GDT表中。DPL=0； CPL：就是CS的低二位。用户程序的时候为3，系统调用时为0 DPL≥CPL、DPL≥RPL：老师直接把我说懵了 硬件也提供了“主动进入内核的方法”：中断指令 int (对于x 86来说) int指令将cs中CPL改成0，”进入内核”。这是用户程序发起的调用内核代码的唯一方式(int 0x80) 系统调用的核心： 用户程序中包含一段包含int指令的代码 操作系统写中断处理，获取想调程序的编号 操作系统根据编号执行相应代码 12#include &lt;unistd.h&gt;_syscall3(int, write, int, fd, const char *buf, off_t, count) 以print为例看下执行流程 这里需要补充下宏的知识和内嵌汇编知识 write函数的实现 12345678910111213141516171819202122#include&lt;stdio.h&gt;#define _syscall3(type,name,atype,a,btype,b,ctype,c)\\type name(atype a, btype b, ctype c) \\&#123; long __res;\\__asm__ volatile(\"int 0x80\":\"=a\"(__res):\"\"(__NR_##name),\\\"b\"((long)(a)), \"c\"((long)(b)), \"d\"((long)(c)))); if (__res &gt;= 0) return\\(type)__res; errno = -__res; return -1; &#125;//这个数字实际上是系统调用号。因为所有进入内核的指令都是int 80，该数字就是用来区分进入后具体操作#define __NR_write 4 //一堆连续正整数(数组下标, 函数表索引)//宏展开之后int write(int fd, const char* buf off_t, count) &#123; long __res; //这里__NR__write前面空的限制字符的意思是与前面保持一致，也为=a __asm__ volatile(\"int 0x80\":\"=a\"(__res) : \"\"(__NR_write), \"b\"((long)(fd)), \"c\"((long)(off_t)), \"d\"((long)()))); if (__res &gt;= 0) return(int)__res; errno = -__res; return -1; &#125; int 0x80中断处理的实现 12void sched_init(void)&#123; set_system_gate(0x80,&amp;system_call); &#125;//在初始化时就规定了int0x80执行system_call函数 123456789//该方法核心就是初始化idt表。//gate指的是中断处理门，idt的每个表项就叫中断处理门#define set_system_gate(n, addr) \\_set_gate(&amp;idt[n],15,3,addr); //idt是中断向量表基址是一个全局变量。用n来找到80对应地址。15,3分别转给type和dpl，addr就是上面的&amp;system_call#define _set_gate(gate_addr, type, dpl, addr)\\__asm__(\"movw %%dx,%%ax\\n\\t\" \"movw %0,%%dx\\n\\t\"\\ \"movl %%eax,%1\\n\\t\" \"movl %%edx,%2\":\\:\"i\"((short)(0x8000+(dpl&lt;&lt;13)+type&lt;&lt;8))),\"o\"(*(( \\char*)(gate_addr))),\"o\"(*(4+(char*)(gate_addr))),\\\"d\"((char*)(addr),\"a\"(0x00080000))//这一串内嵌汇编，就是用来将数值组成一个表项 这时cs为8，ip为system_call的地址。 只能用int0x80进入内核时cpl肯定等于3。dpl也-3，所以能进入。 cs=8时cpl=0，dpl=3 中断处理程序system_call.s 123456789101112nr_system_calls&#x3D;72.globl _system_call_system_call: cmpl $nr_system_calls-1,%eaxja bad_sys_callpush %ds push %es push %fspushl %edx pushl %ecx pushl %ebx &#x2F;&#x2F;调用的参数movl $0x10,%edx mov %dx,%ds mov %dx,%es &#x2F;&#x2F;内核数据。0x08是内核的代码段0x10是内核的数据段movl $0x17,%edx mov %dx,%fs &#x2F;&#x2F;fs可以找到用户数据call _sys_call_table(,%eax,4) &#x2F;&#x2F;a(,%eax,4)&#x3D;a+4*eax。eax保存的就是__NR__writepushl %eax &#x2F;&#x2F;返回值压栈，留着ret_from_sys_call时用... &#x2F;&#x2F;其他代码ret_from_sys_call: popl %eax, 其他pop, iret _sys_call_table+4*%eax就是相应系统调用处理函数入口 。 *4是因为，每个函数的指针恰好是4个字节 一开始cpl=3，dpl=0是无法进入，然后调用int 0x80这时cpl=3，dpl=3就可以进入。再执行system_call再之后CPL=3就可以访问所有的内存地址 CPU用PCB来描述进程和静态程序的不一样 PCB用来记录进程信息的数据结构 多进程的组织：PCB+状态+队列 有一个进程中执行，有一些进程等待执行，有一些进程在等待某事件 操作系统会有多个队列，就绪队列等待执行，磁盘等待队列 等 如：启动磁盘读写： pCur.state=&#39;W&#39;修改状态。将pCur放入DiskWaitQueue再schedule() 1234schedule()&#123; pNew = getNext(ReadyQueue);//调度，找到下个进程 switch_to(pCur,pNew);//切换进程，参数为当前PCB和新的PCB&#125; 123456789101112switch_to(pCur,pNew) &#123; pCur.ax = CPU.ax; pCur.bx = CPU.bx; ... pCur.cs = CPU.cs; pCur.retpc = CPU.pc; CPU.ax = pNew.ax; CPU.bx = pNew.bx; ... CPU.cs = pNew.cs; CPU.retpc = pNew.pc; &#125; 交替的三个部分：队列操作+调度+切换 进程调度： FIFO：先进先出 Priority：优先级 多个进程可能会对同一块内存操作。解决办法：限制对目标地址的读写，多进程的地址空间分离(使用映射表)：内存管理的主要内存 进程执行时的内存地址，不是真的地址，而是映射表基础上的地址 多进程之间的合作：进程同步(合理的推进顺序) 线程：保留了并发的优点，又避免了进程之间切换的代价 线程之间是共享资源的，切换时不需要保存现场。 进程 = 资源 + 指令执行序列 每个执行序列都要有自己的栈。将栈指针esp(CPU内的物理寄存器)存入TCB，一个全局的数据结构。 进程的执行序列实际就是内核级线程 显示调用yield，切换栈，和jmp。回来的yield不需要jmp 内存的栈模型向下增长 所以两个线程的样子：两TCB、两栈、切换的PC放入栈 12345678//创建线程的核心就是用程序做出TCB、栈、PC入栈。关联TCB和栈void ThreadCreate(A)&#123; TCB *tcb=malloc(); *stack=malloc(); *stack = A;//100 tcb.esp=stack;&#125; 用户级线程：总结：先创建两个线程，然后再执行的时候通过调用yield来切换线程。 缺陷：一旦一个线程卡了，别的线程也卡，因为切换到别的进程去执行 优势：不涉及内核级线程，兼容性强些 内核级线程： 优势：并发性更好，一个线程卡了可以执行另一个线程 切换进程实际上就是切换内核级线程 进程需要访问内存分配资源，都需要系统资源，内核态来进行，所以没有用户级进程 只有操作系统支持核心级线程多核才有用 每个CPU都有自己的mmu(内存映射) 多处理器有多个mmu 多核共享一个mmu i7却每个核都有一套mmu linux下并未对进程线程分别做抽象，都是利用task_struct来描述具体调度的一个单元 多个执行序列用一套映射 就是线程 一旦有中断，操作系统就通过硬件找到内核栈。将刚才的SS、SP、EFLAGS(标志寄存器)、CS、PC压栈。iret返回将五个寄存器弹出 切换：通过TCB，切换TCB，再通过切换后的TCB找到内核栈指针，然后通过ret切换到某个内核程序，最后再用cs:pc切到用户程序 123456789void ThreadCreate(...)&#123; TCB tcb=get_free_page();//申请一段内存作TCB *krlstack = ...;//申请一段内存作内核栈，初始化(可以申请用户态内存作为用户栈，将指针置好) *userstack传入; //用户栈 填写两个stack; tcb.esp=krlstack;//tcb关联内核栈 tcb.状态=就绪; tcb入队; &#125; linux0.11不支持内核级线程，但和进程非常像，只是没有资源和映射表 可以通过自己写yield代码，规定什么时候调度 内核级线程switch_to五段论 中断入口：进入切换 中断处理：引发切换 启动磁盘读或时钟中断等可能会引起堵塞 sehedule：找到TCB switch_to：内核栈切换 中断出口：二级切换 iret返回：从内核栈到用户栈 以fork()为例 fork()是创建线程系统调用，会引起中断 在执行A()时，遇到fork函数，然后通过库调用中断INT 0x80。 用户栈：ret指向B 内核栈：执行INT后，SS:SP指向用户栈再将下条指令的CS:IP压入。 12345678//伪代码示例main()&#123; A(); B();&#125;A()&#123; fork()&#125; 调用system_call 123456&#x2F;&#x2F;将用户态的一系列寄存器压栈，这里刚调用INT进入内核态，所以要记录用户态信息。_system_call: push %ds..%fs pushl %edx... call sys_fork pushl %eax 123456movl _current,%eax &#x2F;&#x2F;当前线程置给eax，_current是PCBcmpl $0,state(%eax) &#x2F;&#x2F;state(%eax)是state+eax，也就是PCB中的state。这条指令就是看PCB中的state是否等于0。jne reschedule &#x2F;&#x2F;若非0则调度cmpl $0,counter(%eax) &#x2F;&#x2F;看counter(时间片)是否为0je reschedule &#x2F;&#x2F;若为0则调度ret_from_sys_call: &#x2F;&#x2F;切换完成后进行中断返回，来完成内核栈到用户栈的切换 在linux0.11中，state=0是运行中，非0表示阻塞 时间片用完也要进行切换，后面会学 123reschedule: pushl $ret_from_sys_call jmp _schedule 调度 1234void schedule(void)&#123; next=i; switch_to(next); //这时候next已经是下一个线程的TCB，或进程的PCB&#125; switch_to这里用的是TSS(任务结构段)，而不是真的用内核态。详细看实验四 TSS在写代码比较简单但执行时间相对较长 TR：操作系统固有的寄存器，作TSS描述符的选择子。 段内就是一个任务的内容，这里的任务内容就是指所有寄存器等信息。相当于给你计算机拍了快照 ljmp：长跳转指令，段之间跳转，先将是一个任务拍个快照放入当前指向的段中，再将新的段加载。 就是将选择符置给TR TSS实际就是PCB的一个子段 EIP：返回本次调用后，下一条指令的地址 12345678#define switch_to(n) //n就是下个进程对应的CS &#123;struct &#123;long a,b;&#125; __asm__( \"movw %%dx,%1\\n\\t\" \"ljmp %0\\n\\t\" // ::\"m\"(*&amp;__tmp.a), \"m\"(*&amp;__tmp.b), \"d\"(_TSS(n)) //_TSS(n)是新的TR，置给edx 中断返回 1234ret_from_sys_call:popl %eax &#x2F;&#x2F;返回值 popl %ebx ...pop %fs ...iret &#x2F;&#x2F;重要 1234567_sys_fork:push %gs; pushl %esi...pushl %eaxcall _copy_process &#x2F;&#x2F;所需的参数都在内核栈addl $20,%espret 12345int copy_process(int nr,long ebp,long edi,long esi,long gs,long none,long ebx,long ecx,long edx, long fs,long es,long ds,long eip,long cs,long eflags,long esp,long ss)//这里所需的参数也就是父进程在用户态的样子 copy_process细节：创建栈。 需要申请内存空间、创建TCB、创建内核栈和用户栈、填写两个stack、关联栈和TCB 填写这两个栈主要是将eip压栈，而这里用的是TSS，所以可以不需要 12345678910111213141516171819p=(struct task_struct *)get_free_page(); //申请一页内存，不能用malloc他是用户态代码，现在在内核中。是指就是在mem_map中找到一个为0的项，用来做PCB//申请内存空间 p-&gt;tss.esp0 = PAGE_SIZE + (long) p;//p是这一页的初始地址，PAGE_SIZE是4Kp-&gt;tss.ss0 = 0x10;//内核数据段//创建内核栈 p-&gt;tss.ss = ss &amp; 0xffff;p-&gt;tss.esp = esp;//创建用户栈(和父进程共用栈)p-&gt;tss.eip = eip;p-&gt;tss.cs = cs &amp; 0xffff;//将执行地址cs:eip放在tss中 p-&gt;tss.eax = 0;p-&gt;tss.ecx = ecx; //执行时的寄存器也放进去了 ，这下面是内存部分暂时不用理解p-&gt;tss.ldt = _LDT(nr);set_tss_desc(gdt+(nr&lt;&lt;1) + FIRST_TSS_ENTRY, &amp;(p-&gt;tss));set_ldt_desc(gdt+(nr&lt;&lt;1) + FIRST_LDT_ENTRY, &amp;(p-&gt;ldt));//内存跟着切换 p-&gt;state = TASK_RUNNING; 两个内核栈可以关联同一个用户栈 子进程完成中断返回后，执行mov res,%eax时eax的值为0，但父进程中断返回后，执行该指令eax不为0(自己看代码)。 if(!fork()) {...}当父进程返回不为0就不会执行里面的代码，子进程返回为0就执行里面的代码 linux0.11不支持创建内核态线程 因为不支持，所以ThreadCreate(*A)传入A函数如何执行没有讲。只讲了如何创建进程运行自己的程序，就相当于执行A函数。 1234567int main(int argc, char * argv[])&#123; while(1) &#123; scanf(“%s”, cmd); if(!fork()) &#123; exec(cmd); //这里执行cmd，就相当于创建线程传入的A函数 &#125; wait(0); &#125; exec的系统调用 1234system_call: push %ds .. %fs pushl %edx.. call sys_execve 在内核态中断返回的时候，fork的子程序应该执行新程序的入口部分。 12345&#x2F;&#x2F;将中断返回之前的入口程序地址赋给eip，这样弹出栈的时候，执行入口程序地址_sys_execve: lea EIP(%esp),%eax &#x2F;&#x2F;esp是当前栈顶指针，eip是偏移，相加赋给eax。这里EIP是0x1C，正好就是栈内eip的位置 pushl %eax &#x2F;&#x2F;eax压栈 call _do_execve 12345int do_execve( * eip,...&#123; p += change_ldt(...; eip[0] = ex.a_entry; //将入口地址置给eip。 eip[3] = p; ... //将p置给esp，设置栈 入口地址是从磁盘上的可执行程序的文件头中读取，文件头是编译的时候写好的 1234struct exec &#123; unsigned long a_magic;unsigned a_entry; //这就是入口地址 &#125;; L13 以实现交替打出A B为例 123456//用户代码开始main()&#123; if(!fork())&#123;while(1)printf(“A”);&#125; if(!fork())&#123;while(1)printf(“B”);&#125; wait();&#125; 123456789101112&#x2F;&#x2F;翻译成汇编就是main()&#123; mov __NR_fork, %eax int 0x80 100: mov %eax, res cmpl res,0 jne 208 200: printf(“A”) jmp 200 208: ... 304: wait()&#125; 1set_system_gate(0x80,&amp;system_call); 123&#x2F;&#x2F;int0x80 进入实际就是调用system_callsystem_call: call sys_call_table(,%eax,4) 再之后sys_fork再copy_process(负责做出新的栈新的PCB，将PCB中的TSS都写好，将eax置0)开始返回，这时候打印的程序可以执行了但不能正真执行。 1234567891011copy_process()&#123;... &#125;&#x2F;&#x2F;ret到哪里?sys_fork: ... call copy_process ... ret &#x2F;&#x2F;到哪里?system_call: ...call sys_call_table(,%eax,4) cmpl $0,state(current) jne reschedule &#x2F;&#x2F;中断返回的时候，进行调度，可以正真执行打印程序 iret &#x2F;&#x2F;到哪里?main: int 0x80 100: mov %eax, res cmpl res,0 父进程再同样的创造打印B的程序。再进入等待状态 12345678main()&#123; ... wait(); &#x2F;&#x2F;又是mov __NR_wait int 0x80system_call: call sys_waitpidsys_waitpid() &#x2F;&#x2F;exit.c中 current-&gt;state&#x3D;TASK_INTERRUPTIBLE; &#x2F;&#x2F;将自己的状态设置为等待 schedule(); &#x2F;&#x2F;调度 123456schedule()&#123; if ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; c) //修改状态 c = (*p)-&gt;counter, next = i; ... switch_to(next); //切换线程&#125; switch_to：通过读硬件手册发现TSS可以换成任务的切换。 通过时钟中断，来交替运行A、B线程 12void sched_init(void) //在sched.c中&#123; set_intr_gate(0x20,&amp;timer_interrupt); 123void _timer_interrupt:...call do_timer 1234void do_timer(...) &#123; if((--current-&gt;counter&gt;0) return;//当时钟减为0时调度current-&gt;counter=0;schedule(); &#125; CPU调度策略这里的调度就是获得next FIFO：先进先出 Priority：优先级 不同任务的特点不同 IO约束型：IO任务多。如读写任务 CPU约束性：CPU运算任务多。如GCC 几个基本的调度策略 FCFS(First Come,First Served)：先来先服务 改进：SJF短作业优先。 这样改进虽然整体时间不变，但是短的任务提前完成，整体的感受会更好 RR：按时间片来轮转调度 每时间片结束就切换下一个任务 时间片大：响应时间太长。时间片小：吞吐量小 折衷：时间片10-100ms，切换时间0.1-1ms 当有关心响应时间的程序和关心周转时间的程序同时存在时。可以设立前台任务和后台任务两个队列，前台RR，后台SJF。没有前台任务时才调度后台任务 优先级调度可能会造成饥饿导致一个进程一直无法执行 linux0.11的调度函数schedule() 123456789101112void Schedule(void) //在kernel/sched.c中&#123; while(1) &#123; c=-1; next=0; i=NR_TASKS; p=&amp;task[NR_TASKS];//将p设置为最后一位的地址，这实际是PCB数组的末位 while(--i)&#123; if((*p-&gt;state == TASK_RUNNING&amp;&amp;(*p)-&gt;counter&gt;c) //--i就是从后往前移。如果state为RUNNING(就绪)并且counter&gt;c 这里的c为-1 c=(*p)-&gt;counter, next=i; &#125;//设置c和next if(c) break; //上面循环结束找到了最大的counter，跳出循环，执行switch_to //如果就绪态的c都为0，for就将所有进程的counter右移一位(除以2)再加counter初值。这样不是就绪态不为0的c优先级会略高一些。这样阻塞时间越久的线程优先级可能会越高 for(p=&amp;LAST_TASK;p&gt;&amp;FIRST_TASK;--p) (*p)-&gt;counter=((*p)-&gt;counter&gt;&gt;1) +(*p)-&gt;priority; &#125; switch_to(next);&#125; 该算法就是基于counter作优先级和时间片来轮转 counter无限阻塞后，counter也不会无限大，count=p+p/2+p/4+…。无穷级数收敛于2p counter的时间片作用 12345//当前线程counter--减到0时调度void do_timer(...) //在kernel/sched.c中&#123; if((--current-&gt;counter&gt;0) return;current-&gt;counter=0;schedule(); &#125; 1234&#x2F;&#x2F;每次时钟中断都执行do_timer_timer_interrupt: &#x2F;&#x2F;在kernel&#x2F;system_call.s中 ... call _do_timer 12void sched_init(void) &#123;set_intr_gate(0x20, &amp;timer_interrupt); 这个算法，折中了大多数任务需求，既照顾前台程序，又照顾到后台程序 进程同步、信号量、临界区 信号量： 1234567struct semaphore &#123; int value; //记录资源个数 PCB *queue;//记录等待在该信号量上的进程&#125;P(semaphore s); //消费资源V(semaphore s); //产生资源 信号量解读写的生产者-消费者问题 12345678910111213141516171819semaphore full = 0; semaphore empty = BUFFER_SIZE;//缓冲区为空的个数，初始值semaphore mutex = 1;//互斥信号量 若为1才能进，为0不能进Producer(item) &#123; P(empty);//看他是否为0 P(mutex); 读入in;将item写入到in的位置上; V(mutex); V(full); &#125;Consumer() &#123; P(full); P(mutex); 读入out;从文件中的out位置读出到item;打印item; V(mutex); V(empty); &#125; 前两步P函数不能调换位置，不然可能会导致死锁 临界区：一次只允许一个进程进入的该进程的那一段代码 基本原则：互斥进入：如果一个进程在临界区中执行，则其它进程不允许进入 好的临界区的保护原则 有空让进：若有进程要求进入空闲临界区，应尽快让它进入 有限等待：不能无限等待 相当于给那一段代码上锁 这部分内容和Java中的多线程内容类似 临界区保护法(软件解法) 轮换法：满足互斥进入，不满足有空让进 标记法：由一个变量来标记，可能会造成死锁 非对称标记法：结合了标记和轮换。这就是Peterson算法 满足互斥进入、满足有空让进、满足有限等待 但只满足两个进程 面包店算法：能实现，但是太复杂 123456choosing[i] = true; num[i] = max(num[0], …, num[n-1])+1;//每次取号都比已取的最大号+1choosing[i] = false; for(j=0; j&lt;n; j++) &#123; while(choosing[j]);//如果有人在选号 也等待while ((num[j] != 0) &amp;&amp; (num[j], j)&lt;(num[i], i])); &#125;//号小的先执行临界区num[i] = 0;//离开时，号为0剩余区 硬件解法 阻止另一个进程调用。通过一个函数阻止另一个进程被调度 CPU内有INTR寄存器(中断寄存器)，CPU每执行一条指令，都会看下INTR若为1，就进入中断。一旦cli()CPU就不去看INTR，不进入中断。 缺点：多核的时候，不好使。 1234cli();临界区sti();剩余区 硬件原子指令法 1234567//一次性执行完毕，boolean TestAndSet(boolean &amp;x)&#123; boolean rv = x; x = true; return rv;&#125; 1234while(TestAndSet(&amp;lock)) ;临界区lock = false;剩余区 实际代码例 12345678910111213141516main()&#123;sd=sem_open(“empty”);//(1)申请信号量，这个empty就是信号量名字 //执行五次把数写出。这里的代码只是实例，实际可以做别的 for(i=1 to 5)&#123; sem_wait(sd);//查看是否有缓冲区 write(fd,&amp;i,4);//在文件写五个数，每个4字节 &#125;&#125;sys_sem_wait(int sd)&#123; cli(); if(semtable[sd].value -- &lt; 0)&#123; 设置自己为阻塞;将自己加入semtable[sd].queue中; schedule(); &#125; sti();&#125; 123456789101112//内核中，获取信号量的伪代码typedef struct &#123; char name[20];//每个信号量的名字，如果使用同一个信号量就用同样的名字 int value;//信号量对应的值 task_struct * queue;//信号量对应的队列&#125; semtable[20];//系统调用实现sys_sem_open(char *name)&#123; 在semtable中寻找name对上的;没找到则创建;返回对应的下标; &#125; linux0.11读磁盘例 12345//在内核sys_read调用的就是breadbread(int dev,int block)&#123; struct buffer_head * bh;//获得一块空闲缓存，缓冲区是有信号量的ll_rw_block(READ,bh);//启动读命令wait_on_buffer(bh);//在缓冲区阻塞 12345678lock_buffer(buffer_head*bh)&#123; cli(); //b_lock就是缓冲区中的信号量，没有负数最小为0while(bh-&gt;b_lock)??? sleep_on(&amp;bh-&gt;b_wait);bh-&gt;b_lock = 1;//1表示上锁，没读完，中断会给它解锁sti(); &#125; 1234567891011//传入一个指向队首的指针的指针void sleep_on(struct task_struct **p)&#123; struct task_struct *tmp;//这个tmp是放在当前进程的内核栈 //这两句就是将自己放入阻塞队列 tmp = *p;//tmp指向前一个进程 *p = current;//然后将*p指向当前进程 //当切回当前线程的时候，就能通过tmp找到前一个，这样形成一个队列 current-&gt;state = TASK_UNINTERRUPTIBLE;//设置自己状态 schedule(); if (tmp) tmp-&gt;state=0;&#125; 唤醒进程部分 1234//读中断最后会开锁static void read_intr(void)&#123;...end_request(1); 123end_request(int uptodate)&#123;...unlock_buffer(CURRENT-&gt;bh);//开锁 123unlock_buffer(struct buffer_head * bh)&#123;bh-&gt;b_lock=0;//开锁wake_up(&amp;bh-&gt;b_wait);&#125; 1234567//传入的指针就是上面的，指向的当前线程wake_up(struct task_struct **p)&#123; if (p &amp;&amp; *p) &#123; (**p).state=0; //就绪态 *p=NULL; &#125;&#125; sleep_on最后三句代码 123schedule();//唤醒后tmp也会执行scheduleif (tmp)//如果队列中还有下个线程，将它设置为就绪态tmp-&gt;state=0; 信号量一旦来了，往往后面的进程优先级会更高，这样就能保证后面先执行 死锁 死锁的4个必要条件 互斥使用(Mutual exclusion) 不可抢占(No preemption)：资源只能只愿放弃 请求和保持(Hold and wait)：进程必须占有资源，再去声请 循环等待(Circular wait)：存在一个环 死锁的处理 死锁预防：破坏死锁出现的条件 一次性申请所有需要的资源，不会占有资源再去申 请其它资源 缺点1: 需要预知未来，编程困难 缺点2: 许多资源分配后很长时间后才使用，资源利用率低 对资源类型进行排序，资源申请必须按 序进行，不会出现环路等待 缺点: 仍然造成资源浪费 死锁避免：检测每个资源请求，如果造成死锁就拒绝 银行家算法：每次判断资源是否能够让他执行，算出安全序列 缺点，执行效率低O(mn^2^) 1234567891011121314151617int Available[1..m]; //每种资源剩余数量int Allocation[1..n,1..m]; //已分配资源数量int Need[1..n,1..m];//进程还需的各种资源数量int Work[1..m]; //工作向量bool Finish [1..n]; //进程是否结束//算出安全序列Work = Available; Finish[1..n] = false; while(true)&#123; for(i=1; i&lt;=n; i++)&#123; if(Finish[i]==false &amp;&amp; Need[i]£Work)&#123; Work = Work + Allocation[i]; Finish[i] = true; break;&#125; else &#123;goto end;&#125; &#125;&#125;End: for(i=1;i&lt;=n;i++) if(Finish[i]==false) return “deadlock”; 死锁检测+恢复：检测到死锁出现时，让一些进程回滚，让出资源 可以在发现死锁时再处理，回滚等，但会造成其它一系列问题 死锁忽略：就好像没有出现死锁一样 Linux和Windows都采用死锁忽略方法。 死锁忽略的处理代价最小 这种机器上出现死锁的概率比其他机器低 死锁可以用重启来解决，PC重启造成的影响小 死锁预防让编程变得困难 内存管理重定位：修改程序中的地址(是相对地址) 逻辑地址-&gt;物理地址 重定位时机 编译时重定位 在实际系统中很难完成。在一些嵌入系统等可能会用到 载入时重定位一旦载入内存就不能动了 运行时重定位是最合适的 基地址(放在PCB中，用时放入基址寄存器)，每执行一条指令都算出物理地址 往往程序在载入后还要移动，如swap时(将进程移到磁盘上，在磁盘读取进程)。 分段：程序实际由若干部分组成，每个段有各自的特定 寻址方式：&lt;段号,段内偏移&gt; 分段移动时，能提高内存使用效率 这时PCB放的是进程段表，一开始的GDT表放的就是操作系统的进程段表。进程1的段表就是LDT表。 GDT表存放LDT表的位置 分页：用来解决内存分区导致的内存效率问题(内存碎片) 将内存等分为多个页。对每段内存请求，系统一页一页分给这个段 在mem_map中就是4k一页 分页也需要页表cr3，具体计算由mmu做 如0x2240，一页4k，2240右移12位，得出0x2，第2页，根据表找到物理地址的第3页，3*4k物理地址为0x3240。 多级页表和快表 页小了，能提高内存空间利用率，但页表就大了。 解决 只记录用到的页 缺点：页表的页号不连续，就要比较，查找，需要多次访存，会严重影响效率 多级页表 页目录号+页号+Offset。只需要存储用到的页目录号，这样就省去了存放对应页号的内存 例：一个页表：2^`0^个目录项*4字节地址=4k.如果用到3个页表只需要3+1(目录页)=4。4*4k=16k。如果是单级则需要4k*2^10^*2^10^=4M。 问题：提高了空间效率，但每多一级就多一次访存。这就要引入快表来解决。 快表： TLB是一组相联快速存储，是寄存器。可以快速找到逻辑页对应的物理页号 可以通过硬件实现一次比对即可找到 TLB条目数通常是在[64,102] 程序的地址访问存在局部性(空间局部性)：如循环结构 有效访问时间 = HitR×(TLB+MA) + (1-HitR)×(TLB+2MA) hitR：命中率 MA：内存访问时间 TLB：TLB时间 段页结合的管理 用户给出的地址，经过段地址翻译，再经过页地址翻译，找到物理地址。 一个实际的段、页式内存管理 思路： 先在虚拟内存区域割出一段区域来给用户的代码段、数据段、栈段 建立段表，假装程序放入虚拟内存 在物理内存找页 建立页表 开始使用 代码分析 分配虚存、建段表：fork()-&gt;sys_fork-&gt;copy_process-&gt;copy_mem 12345678//p就是pcbint copy_mem(int nr, task_struct *p)&#123; unsigned long new_data_base;new_data_base=nr*0x4000000; //64M*nr nr就是进程第几个，每个进程占64m虚拟地址空间，互不重叠set_base(p-&gt;ldt[1],new_data_base);//pcb的ldt代码段设置为new_data_baseset_base(p-&gt;ldt[2],new_data_base);//数据段也设置为同样//这里是因为操作系统比较简单，数据段代码段用同一套 ldt是每个进程的段表 分配内存、建页表 1234int copy_mem(int nr, task_struct *p)&#123; unsigned long old_data_base; old_data_base=get_base(current-&gt;ldt[2]); copy_page_tables(old_data_base,new_data_base,data_limit);//复制父进程页表 123456789//from就是父进程的32位虚拟地址，10位页目录号10位页号12位偏移int copy_page_tables(unsigned long from,unsigned long to, long size) &#123; from_dir = (unsigned long *)((from&gt;&gt;20)&amp;0xffc);//应该是(from&gt;&gt;22)*4每项4字节 to_dir = (unsigned long *)((to&gt;&gt;20)&amp;0xffc);//子进程页目录 size = (unsigned long)(size+0x3fffff)&gt;&gt;22; for(; size--&gt;0; from_dir++, to_dir++)&#123; from_page_table=(0xfffff000&amp;*from_dir); to_page_table=get_free_page();//分配一个物理内存页给子进程,get_free_page就是给在mem_map找到0的页给他 *to_dir=((unsigned long)to_page_table)|7;将创建的页地址赋给它 12345678//复制父进程的页表拷贝给子进程的页表。这样就指向同一块物理地址for(;nr--&gt;0;from_page_table++,to_page_table++)&#123; this_page = *from_page_table; this_page&amp;=~2;//父子进程共享，子进程这边设置成只读 *to_page_table=this_page; *from_page_table=this_page; this_page -= LOW_MEM; this_page &gt;&gt;= 12; mem_map[this_page]++; &#125; 只要页表和段表设置好，执行指令时MMU(硬件)自动完成。 在实际使用时候，子进程过去发现是只读的，就会重新申请一页，进而实现和父进程的隔离 内存的换入 用换入、换出实现“大内存”。内存不足够，可用磁盘做内存 mmu查页表发现缺页，就发生中断，进行页错误处理程序。在磁盘找到内容，找到空白页读入。当mmu发现缺页引起中断可以在硬件上不让pc加1。回来接着执行该指令。 请求调页、请求调段：实际都是请求调页 全球调页流程：发现缺页是mmu自动做的不需要我们编写代码 第一步应该是从缺页中断开始 14号中断：Page fault 12void trap_init(void)&#123; set_trap_gate(14, &amp;page_fault); &#125; 12#define set_trap_gate(n, addr) \\ _set_gate(&amp;idt[n], 15, 0, addr); //初始化中断向量表 12345678910111213141516171819202122232425262728&#x2F;&#x2F;先压栈保存现场。.globl _page_fault xchgl %eax,(%esp) pushl %ecx pushl %edx push %ds push %es push %fs movl $0x10, %edx &#x2F;&#x2F;ds es fs等置为0x10，进入内核栈 mov %dx, %ds mov %dx, %es mov %dx, %fs movl %cr2, %edx &#x2F;&#x2F;cr2是放页错误线性地址的寄存器。虚拟也叫线性。 pushl %edx pushl %eax &#x2F;&#x2F;将寄存器压栈，这里是作为参数传入后面的call调用 testl $1, %eax jne 1f call _do_no_page jmp 2f1: call _do_wp_page &#x2F;&#x2F;保护2: add $8, %esp pop %fs pop %es pop %ds pop %edx pop %ecx pop %eax iret 读磁盘建立映射 12345678void do_no_page(unsigned long error_code,unsigned long address)&#123; address&amp;=0xfffff000; //页面地址 tmp=address–current-&gt;start_code; //页面对应的偏移 if(!current-&gt;executable||tmp&gt;=current-&gt;end_data)&#123; get_empty_page(address); return; &#125; page=get_free_page();//获取物理空闲页 bread_page(page, current-&gt;executable-&gt;i_dev, nr);//读磁盘，读到page，current-&gt;executable-&gt;i_dev就是具体的文件 put_page(page, address);//将物理页和页表建立映射 12345678910111213unsigned long put_page(unsigned long page, //物理地址unsigned long address)&#123; unsigned long tmp， *page_table; page_table=(unsigned long *)((address&gt;&gt;20)&amp;ffc); //找到页目录项 if((*page_table)&amp;1) page_table=(unsigned long*)(0xfffff000&amp;*page_table); else&#123; tmp=get_free_page(); *page_table=tmp|7; page_table=(unsigned long*)tmp;&#125; page_table[(address&gt;&gt;12)&amp;0x3ff] = page|7;//将物理页放到page_table。建立映射 return page; &#125; 内存换出 选择一页淘汰，换出到磁盘。 淘汰算法：评价准则：缺页次数 FIFO页面置换：先来先出 MIN算法：选最远将使用的页淘汰，是最优方案 无法知道后面需要用到哪个页 LRU算法(用过去预测未来)：选最近最长一段时间没有使用的页淘汰 利用了程序的局部性特点 LRU的实现： 实现1：每页维护一个时间戳，每用到该页，时间戳+1，选择时间戳最小的页。 但实现是很困难的，每执行一条指令的时候都要修改时间戳，而且时间戳非常有可能溢出 实现2：维护一个页码栈，选栈底页淘汰 仍然需要修改栈，代价仍然大 近似实现3(二次机会算法、Clock算法)： 将时间计数变为是和否，每个页加一个引用位，每访问一页时，硬件自动置1(R位)。选择淘汰页时，是1清0，继续扫描是0淘汰 Clock算法改进： Clock算法缺陷：缺页机会很少，很多时间全是1。就退化成了FIFO算法 实现：再来一个扫描指针，用来清除R位置0，移动速度要快。另一个慢些的指针用来淘汰页。 进程分配页框(帧frame) 当缺页数超过一定限度的的时候，CPU利用率急剧下降，将这一现象称为颠簸 解法1：可以动态调整，当缺页次数多后，增加分配数 解法2：一个程序有局部性，覆盖这个局部需要的页框数。就分配给他。 这个局部需要多少页框是很难求出来的，现在往往用到的算法是求工作集 IO与显示器外设无论里面有多少调代码本质是out xx,al。 CPU发出指令给外设控制器中的寄存器写内容，外设控制器会根据寄存器的内容来操作硬件。外设准备好后会向CPU发出中断。 控制器就是对应一个端口。 不同的控制器的内容的格式和语义、寄存器的地址都不系统。操作系统要给用户提高简单的视图—文件视图，更方便 设备驱动系统主要的三件事 形成文件视图 发出out指令 形成中断处理 以print为例 12345int fd = open(“/dev/xxx”);//打开外设文件for (int i = 0; i &lt; 10; i++) &#123;write(fd,i,sizeof(int));&#125;close(fd); 1234int sys_write(unsigned int fd, char *buf, int count)&#123; struct file* file; file = current-&gt;filp[fd];//current是当前进程。 inode = file-&gt;f_inode; //incode就是文件中取出的信息 12345//父进程shell最开始创立void init(void)&#123; open(“dev/tty0”,O_RDWR,0);dup(0);dup(0);//打开tty0文件，拷贝到1，2位置。所以0，1，2都是tty0文件 execve(\"/bin/sh\",argv,envp)&#125; 12345int sys_open(const char* filename, int flag)&#123; i=open_namei(filename,flag,&amp;inode);//inode就可以读到文件具体哪些信息 cuurent-&gt;filp[fd]=f; //第一个空闲的fd f-&gt;f_mode=inode-&gt;i_mode; f-&gt;f_inode=inode;//根据inode发出命令 f-&gt;f_count=1; return fd; &#125; 1234int sys_write(unsigned int fd, char *buf,int cnt)&#123; inode = file-&gt;f_inode; if(S_ISCHR(inode-&gt;i_mode))//看设备是否为字符设备，外设分字符设备和块设备 return rw_char(WRITE,inode-&gt;i_zone[0], buf, cnt); ///读写字符，izone[0]就是主设备号 12345int rw_char(int rw, int dev, char *buf, int cnt)&#123; // crw_ptr call_addr=crw_table[MAJOR(dev)]; //根据dev主设备号查表。表存放的是函数指针，找到对应处理函数 call_addr(rw, dev, buf, cnt); ...&#125; 1234//找到第4个是rw_ttyx函数static crw_ptr crw_table[]=&#123;...,rw_ttyx,&#125;;typedef (*crw_ptr)(int rw, unsigned minor, char *buf, int count) 12345//这里以显示器为例，就是往显示器上写static int rw_ttyx(int rw, unsigned minor, char *buf, int count)&#123; return ((rw==READ)? tty_read(minor,buf):///是否为读，如果读就执行tty_read tty_write(minor,buf));//写函数&#125; 123456789101112131415int tty_write(unsigned channel,char *buf,int nr)&#123; struct tty_struct *tty;tty=channel+tty_table;//tty是根据表找到的一项 sleep_if_full(&amp;tty-&gt;write_q);//如果往q(queue)就是缓冲区里写 满了，就睡眠 ... char c, *b=buf; //如果q没满就往里放 while(nr&gt;0&amp;&amp;!FULL(tty-&gt;write_q)) &#123; c = get_fs_byte(b);//b就是buf，工作在用户态内存，所以要从用户态内存取出，赋给c if(c==‘\\r’)&#123;PUTCH(13,tty-&gt;write_q);continue;&#125; if(O_LCUC(tty)) c = toupper(c); b++; nr--; PUTCH(c,tty-&gt;write_q);//将c放入队列 &#125; //输出完事或写队列满! tty-&gt;write(tty); &#125; 12345//根据结构体查对应函数struct tty_struct&#123; void (*write)(struct tty_struct *tty); struct tty_queue read_q, write_q; &#125; 12struct tty_struct tty_table[] = &#123;&#123;con_write,&#123;0,0,0,0,””&#125;,&#123;0,0,0,0,””&#125;&#125;,&#123;&#125;,…&#125;//用con_write网里写 123456void con_write(struct tty_struct *tty)&#123; GETCH(tty-&gt;write_q,c);//从缓冲区取出c //将c写给显示器 if(c&gt;31&amp;&amp;c&lt;127)&#123;__asm__(“movb _attr,%%ah\\n\\t”//将属性赋给ah “movw %%ax,%1\\n\\t”::”a”(c),//将ax赋给pos，pos就是显卡的控制器的寄存器，c字符赋给al ”m”(*(short*)pos):”ax”); pos+=2;&#125;//每写完一些线显存就+2 有的外设控制器可以和内存统一编址这时候用mov命令，如果是独立编址用out命令 设备驱动就是根据设备信息注册相应函数。 pos的来源：在con_init() 12#define ORIG_X (*(unsigned char*)0x90000) //初始光标列号#define ORIG_Y (*(unsigned char*)0x90001) //初始光标行号 1void con_init(void)&#123;gotoxy(ORIG_X,ORIG_Y);&#125; 123static inline void gotoxy()&#123; pos=origin+y*video_size_row +(x&lt;&lt;1);//根据传入参数算出pos&#125; printf整个过程总结： 键盘 123//键盘中断初始化void con_init(void) //应为键盘也是console的一部分&#123; set_trap_gate(0x21, &amp;keyboard_interrupt); &#125; 12345.globl _keyboard_interrupt_keyboard_interrupt: inb $0x60,%al //inb读入一个字节 与outb对应 从端口0x60读扫描吗 call key_table(,%eax,4) //调用key_table+eax*4，不同的扫描码调不通函数 ... push $0 call _do_tty_interrupt 123key_table: .long none,do_self,do_self,do_self &#x2F;&#x2F;扫描码00-03 显示字符通常用do_self .long do_self, ...,func, scroll, cursor 等等 1234#if defined(KBD_US)key_map: .byte 0,27 .ascii “1234567890-&#x3D;“ ... shift_map: .byte 0,27 .ascii “!@#$%^&amp;*()_+” ... &#x2F;&#x2F;按shift的按键#elif defined(KBD_GR) ... 1234567mode: .byte 0do_self: lea alt_map,%ebx testb $0x20,mode &#x2F;&#x2F;alt键是否同时按下 jne 1f lea shift_map,%ebx testb $0x03,mode jne 1f lea key_map,%ebx &#x2F;&#x2F;key_map就对应键盘1: 123456781: movb (%ebx,%eax),%al &#x2F;&#x2F;这里ebx和eax在上面已经将map赋给他们了 扫描码索引，ASCII码àal orb %al,%al je none &#x2F;&#x2F;没有对应的ASCII码 testb $0x4c,mode &#x2F;&#x2F;看caps是否亮 je 2f cmpb $’a,%al jb 2f cmpb $’&#125;,%al ja 2f subb $32,%al &#x2F;&#x2F;变大写2:testb $??,mode &#x2F;&#x2F;处理其他模式，如ctrl同时按下3:andl $0xff,%eax call put_queue&#x2F;&#x2F;放入缓冲区none:ret 1234struct tty_queue *table_list[]=&#123;&amp;tty_table[0].read_q, &amp;tty_table[0].write_q;...&#125;; 1234put_queue: movl _table_list,%edx&#x2F;&#x2F;table_list就是用上面的read_q movl head(%edx),%ecx&#x2F;&#x2F;得到read_q的head输出到缓存队列的头部1:movb %al,buf(%edx,%ecx) 回显 12void do_tty_interrupt(int tty) //上面传来的是0&#123; copy_to_cooked(tty_table+tty); &#125;//处理下字符，放入队列 1234567void copy_to_cooked(struct tty_struct *tty)&#123; GETCH(tty-&gt;read_q,c); if(L_ECHO(tty))&#123; //回显，也可以不回显 PUTCH(c,tty-&gt;write_q); //将c放入缓存队列 tty-&gt;write(tty); &#125; //立刻显示到屏幕上 PUTCH(c,tty-&gt;secondary); //完成copy_to_cooked ... wake_up(&amp;tty-&gt;secondary.proc_list);&#125; 磁盘生磁盘的使用认识磁盘 磁盘访问单位是扇区 扇区大小：512字节 扇区大小是传输时间和碎片浪费的折中 如何磁盘读写一个字节：控制器-&gt;寻道-&gt;旋转-&gt;传输 将磁头移动到指定磁道上 磁道开始旋转，转到相应地方后， 再一转，磁生电发出电信号。读到内存缓冲区 写：也是一转，电生磁 需要往磁盘控制器写：柱面、磁头、扇区、缓存位置 最直接的使用磁盘 123void do_hd_request(void)&#123; ...hd_out(dev,nsect,sec,head,cyl,WIN_WRITE,...); port_write(HD_DATA,CURRENT-&gt;buffer,256);&#125; 1234567void hd_out(drive, nsect, sec, head, cyl, cmd...)&#123; port = HD_DATA; //数据寄存器端口(0x1f0) //下面指令就是将数据写入磁盘控制器的寄存器。移位等操作是将数据化成相应的格式 outb_p(nsect,++port); outb_p(sect,++port); outb_p(cyl,++port); outb_port(cyl&gt;&gt;8,++port); outb_p(0xA0|(drive&lt;&lt;4)|head, ++port); outb_p(cmd, ++port); &#125; 但是这样使用磁盘过于麻烦，所以操作系统需要一层层抽象 一、通过盘块号读写磁盘 程序发block给磁盘驱动，通过磁盘驱动算出cyl、head、sec(CHS)发给磁盘控制器C´(Heads´Sectors) + H´Sectors + S 磁盘访问时间 = 写入控制器时间 + 寻道时间 + 旋转时间 + 传输时间 寻道时间往往占大头，所以相邻的此块应尽量在同一磁道上 我们通常访问连续的盘块 从扇区到盘块：传输时间基本可以忽略不记，这样可以大幅度提高读写速度。 扇区越大空间利用率越低，读写速度越高 12345static void make_request()&#123; struct requset *req;req=request+NR_REQUEST;req-&gt;sector=bh-&gt;b_blocknr&lt;&lt;1;//根据盘块号来算出扇区号 ，这里一个盘块2个扇区add_request(major+blk_dev,req); &#125; //将请求放入队列 1234567void do_hd_request(void)&#123; unsigned int block=CURRENT-&gt;sector; //除法算出chs。S = block%Sectors __asm__(“divl %4”:”=a”(block),”=d”(sec):”0”(block),“1”(0),”r”(hd_info[dev].sect)); __asm__(“divl %4”:”=a”(cyl),”=d”(head):”0”(block),“1”(0),”r”(hd_info[dev].head)); hd_out(dev,nsect,sec,head,cyl,WIN_WRITE,...);//nsect就是每个盘块的扇区数... &#125; 二、多进程通过队列访问磁盘 进程发给请求队列，磁盘驱动从队列取出块号，再来操作。 调度算法 FCFS(先来先服务)：程序是无序来的，会导致重复的寻道时间 SSTF磁盘调度：短寻道优先，近的优先访问 缺点：磁头总在中间转动 SCAN磁盘调度(电梯算法)：SSTF+中途不回折。 1234567//上文的make_request调用的加入队列方法 static void add_request(struct blk_dev_struct *dev, struct request *req)&#123; struct requset *tmp=dev-&gt;current_request; req-&gt;next=NULL; cli(); //关中断(互斥) for(;tmp-&gt;next;tmp=tmp-&gt;next) if((IN_ORDER(tmp,req)||!IN_ORDER(tmp,tmp-&gt;next))&amp;&amp;IN_ORDER(req,tmp-&gt;next)) break;//IN_ORDER是比大小第二个大为true req-&gt;next=tmp-&gt;next; tmp-&gt;next=req; sti();&#125; 123#define IN_ORDER(s1, s2) \\((s1)-&gt;dev&lt;(s2)-&gt;dev)||((s1)-&gt;dev == (s2)-&gt;dev\\&amp;&amp; (s1)-&gt;sector&lt;(s2)-&gt;sector)) 生磁盘使用总结： 进程“得到盘块号” ，算出扇区号(sector) 用扇区号make req，用电梯算法add_request 用哪块内存缓冲区，这一部分非常大的提速了磁盘读写，暂不涉及 进程sleep_on 磁盘中断处理 do_hd_request算出cyl,head,sector hd_out调用outp(…)完成端口写 生磁盘到文件三、引入文件 用户眼里文件的本质是字符流 磁盘上文件是连接盘块 存放方式 顺序结构：不易动态增长 链式结构：读写较慢，如果要读其中一块，必须把前面的块都读了 索引结构：用一块做=作索引块，记录在其余几块。可以随机读哪块 实际系统用的是多级索引，通常做三级，可以存放非常大的文件 实现工作流程 先知道哪段字符：file中的一个读写指针，就是开始地址(fseek就是来修改它)，加上count 找到要写的盘块号：通过inode找到盘块号 将盘块号、buff等形成request放入“电梯” 1234567//fd文件描述符，buf内存缓冲区，count读写字符个数int sys_write(int fd, const char* buf, int count)&#123; struct file *file = current-&gt;filp[fd];//file的指针 struct m_inode *inode = file-&gt;inode; if(S_ISREG(inode-&gt;i_mode)) return file_write(inode, file, buf, count); &#125; file_write实现 123456int file_write(struct m_inode *inode, struct file *filp, char *buf, int count)&#123; off_t pos; if(filp-&gt;f_flags&amp;O_APPEND) //如果是追加 pos=inode-&gt;i_size; else pos=filp-&gt;f_pos; //读写指针 123456789while(i&lt;count)&#123; block=create_block(inode, pos/BLOCK_SIZE);//根据读写位置和inode得出盘块号 bh=bread(inode-&gt;i_dev, block);//bread算出扇区号放入\"电梯\"队列，并且自己阻塞 //不断修改pos，形成流 int c=pos%BLOCK_SIZE; char *p=c+bh-&gt;b_data; bh-&gt;b_dirt=1; c=BLOCK_SIZE-c; pos+=c; //一旦写完成post增加。 ... while(c--&gt;0) *(p++)=get_fs_byte(buf++); brelse(bh); &#125;filp-&gt;f_pos=pos; &#125; 123456789101112131415//create_block就是调用_bmapint _bmap(m_inode *inode, int block, int create)&#123; //(0-6):直接数据块，(7):一重间接，(8):二重间接 &#125;。如果是直接数据块就读出，如果是索引就去找 if(block&lt;7)&#123; if(create&amp;&amp;!inode-&gt;i_zone[block])&#123; inode-&gt;i_zone[block]=new_block(inode-&gt;i_dev); inode-&gt;i_ctime=CURRENT_TIME; inode-&gt;i_dirt=1; &#125; return inode-&gt;i_zone[block]; &#125; block-=7; if(block&lt;512)&#123; bh=bread(inode-&gt;i_dev,inode-&gt;i_zone[7]); return (bh-&gt;b_data)[block]; &#125; ... inode还能用来表示设备文件 12345678struct m_inode&#123; //读入内存后的inode unsigned short i_mode; //文件的类型和属性 ... unsigned short i_zone[9]; //指向文件内容数据块 struct task_struct *i_wait; unsigned short i_count; unsigned char i_lock; unsigned char i_dirt; ... &#125; 文件系统思路：根据给出的文件路径名，解析为文件的FCB(inode)，再根据FCB获得盘号 查了下FCB是文件控制块，记录文件的信息 根目录放在固定位置 数据盘块集合，放着目录下文件名+FCB的编号，通过编号算出FCB的位置。 根目录放在inode数组第一项。inode位图对应位置，置1还是置0表示有或无。引导块，有引导分区才有。超级块记录i节点位图和盘块位图的大小。 总结 用户读某个文件 op(“路径”)：通过解析找到根目录，再根据根目录逐层找到对应内容的inode 通过FCB和文件找到对应盘块 写入电梯队列 磁盘中断，从队列中取出盘号，算出chs 写磁盘控制器outp(syl,head,sector) 目录实现1234//open的核心就是找到inode。int sys_open(const char* filename, int flag)&#123; i=open_namei(filename,flag,&amp;inode);//根据filename解析路径，写到inode返回... &#125; 12int open_namei(...)&#123; dir=dir_namei(pathname,&amp;namelen,&amp;basename);//目录解析 12static struct m_inode *dir_namei()&#123; dir=get_dir(pathname); &#125; 1234567891011121314static struct m_inode *get_dir(const char *pathname)&#123; if((c=get_fs_byte(pathname))==‘/’)&#123;//如果以根开头就从根开始，如果不以`/`开头，就从当前目录开始 inode=current-&gt;root; pathname++;&#125; //root在mount的时候就在shell中有了 else if(c) inode=current-&gt;pwd; while(1)&#123; if(!c) return inode; //函数的正确出口 bh=find_entry(&amp;inode,thisname,namelen,&amp;de);//从根据根目录的inode找到根目录的数据项，找到那一项 int inr=de-&gt;inode; //inr就是目录项中的索引节点号 int idev=inode-&gt;i_dev; inode=iget(idev,inr); //根据目录项读取下一层inode &#125;&#125; 根目录的源头 在挂载时，就有了 1inode = current-&gt;root; 123void init(void)&#123; setup((void *) &amp;drive_info); ...&#125; 123456sys_setup(void * BIOS)//在kernel/hd.c中&#123; hd_info[drive].head = *(2+BIOS); hd_info[drive].sect = *(14+BIOS); mount_root(); ... &#125; 12345void mount_root(void)//在fs/super.c中&#123; mi=iget(ROOT_DEV,ROOT_INO));//根据根目录的inode编号得出FCB #define ROOT_INO 1 current-&gt;root = mi; //根目录的FCB赋给root&#125; 1234567//iget获取inodestruct m_inode * iget(int dev, int nr)&#123; struct m_inode * inode = get_empty_inode(); inode-&gt;i_dev=dev; inode-&gt;i_num=nr; read_inode(inode);//通过read_read return inode;&#125; 1234567static void read_inode(struct m_inode *inode)&#123; struct super_block *sb=get_super(inode-&gt;i_dev);; //得到超级块 lock_inode(inode); block=2+sb-&gt;s_imap_blocks+sb-&gt;s_zmap_blocks+(inode-&gt;i_num-1)/INODES_PER_BLOCK;//通过超级块算出目标的盘号 bh=bread(inode-&gt;i_dev,block);//从磁盘上读取 inode=bh-&gt;data[(inode-&gt;i_num-1)%INODES_PER_BLOCK];//从盘块上拿出目标inode unlock_inode(inode); &#125; find_entry的目录解析代码 1234struct dir_entry&#123; unsigned short inode; //i节点号char name[NAME_LEN]; //文件名 &#125; 123456789101112131415static struct buffer_head *find_entry(struct m_inode **dir, char *name, ..., struct dir_entry ** res_dir)&#123; int entries=(*dir)-&gt;i_size/(sizeof(struct dir_entry)); int block=(*dir)-&gt;i_zone[0];//找到直接索引块,配合前面文件的读取来理解，一级二级索引没详细讲 *bh=bread((*dir)-&gt;i_dev, block);//然后读出来 struct dir_entry *de =bh-&gt;b_data;//将缓冲区data取出 //挨个去匹配，能匹配直接返回 while(i&lt;entries) &#123; if(match(namelen,name,de))&#123; *res_dir=de; return bh; &#125; de++; i++; &#125; &#125; 1234567891011121314//根据一级索引二级索引还是直接数据块，一层层读下去while(i&lt;entries) //entries是目录项数&#123; if((char*)de&gt; = BLOCK_SIZE+bh-&gt;b_data)&#123; brelse(bh); block=bmap(*dir,i/DIR_ENTRIES_PER_BLOCK); bh=bread((*dir)-&gt;i_dev,block); de=(struct dir_entry*)bh-&gt;b_data; &#125; //读入下一块上的目录项继续match if(match(namelen,name,de))&#123; *res_dir=de;return bh; &#125; de++; i++; &#125; 不懂： L12 52分，父进程中断返回为什么不为0。(老师说自己看代码，实验四做完或许会理解)、 为什么要在copy_process内将eax置0？ L12 49分，内存部分代码。(后面讲到内存再看) L12 60分，老师说lea指令部分是前面赋给eax，但是我看的都是后面赋给前面 image-20210310184110121.png，略微没看懂。直接索引块是否就是直接数据块L32 16分20中的i_zone[0]","categories":[],"tags":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}]},{"title":"数据结构与算法","slug":"数据结构与算法","date":"2020-01-08T13:16:45.000Z","updated":"2021-01-05T06:45:52.000Z","comments":true,"path":"2020/01/08/数据结构与算法/","link":"","permalink":"http://example.com/2020/01/08/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/","excerpt":"数据结构复杂度","text":"数据结构复杂度 程序=算法+数据结构 对算法的优劣的评判 正确性、可读性、健壮性 时间复杂度(time complexity)：估算程序执行次数 空间复杂度(space complexity)： 时间复杂度大O表示法(Big O)用大O描述复杂度，表示数据规模n对应的复杂度 忽略常熟、系数、低阶 9 &gt;&gt; O(1) 2n + 3 &gt;&gt; O(n) n^2^ + 2n &gt;&gt;O(n^2^) 4n^3^ + 3n^2^ ++ 22n &gt;&gt;O(n^3^) nlog2n + log2n &gt;&gt;O(nlogn) 复杂度：2^n^&gt;n^数字^&gt;nlogn&gt;n&gt;logn 如果n以两倍数增加或减少则为log2n，如果为5倍数则是log5n 因为log2n = log29 * log9n，将常数忽略，所以，所以log都不用写下标，统称log 如果有两个循环，分别为n和k，则表示为O(n+k) 空间复杂度也是用大O表示法 申请n个基础变量就为O(n)，忽略基础变量的不同字节数 fib函数的时间复杂度分析 以5为例，以共五层，第一层为5，第二层为4和3，第三层为3，2，2，1，第四层为2，1，1，0，1，0最下一层为1，0，合并第四第五层，就是1+2+4+8=2^0^+2^1^2^2^+2^3^=2^4^-1=2^n-1^-1=0.5*2^n^-1 &gt;&gt; O(2^n^) 复杂度分析 最好复杂度 平均复杂度：最好到最坏相加/n。多数情况为o(1)极端情况为o(n)平均复杂度为o(1) 最坏复杂度 动态数组 数组：数组是一种顺序存储的线性表，所有元素的内存地址是连续的 链表、栈、队列 动态数组的扩容倍数和缩容时机设计不得当的话，有可能会导致复杂度震荡 动态数组接口设计 12345678910int size(); //数组大小boolean isEmpty();//判断是否为空boolean contains(E element);//是否有该元素void add(E element);//添加元素E get(int index);//获得index索引的元素E set (int index,E element);//在index位置上设置为元素void add(int index, E element);//在index位置上添加元素，其他元素后移E remove(int index);//一处index位置上的元素int indexOf(E element);//获取元素的索引void clear(); //清空 打印数组时重写toString方法时，建议使用StringBuilder拼接字符串 内部工具函数与元素 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//元素的数量private int size;//所有的元素private E[] elements;//默认创建数组大小private static final int DEFAULT_CAPACITY = 10;//元素未找到返回-1private static final int ELEMENT_NOT_FOUND = -1;//数组的创建public ArrayList(int capaticy) &#123; capaticy = (capaticy &lt; DEFAULT_CAPACITY) ? DEFAULT_CAPACITY : capaticy; //无法直接用泛型创建数组，可以使用Object数组，然后强转 elements = (E[]) new Object[capaticy];&#125;public ArrayList() &#123; this(DEFAULT_CAPACITY);&#125;//检查索引是否越界private void rangeCheck(int index) &#123; if (index &lt; 0 || index &gt;= size) &#123; outOfBounds(index); &#125;&#125;//数组越界异常private void outOfBounds(int index) &#123; throw new IndexOutOfBoundsException(\"Index:\" + index + \", Size:\" + size);&#125;//检查添加索引是否越界private void rangeCheckForAdd(int index) &#123; if (index &lt; 0 || index &gt; size) &#123; outOfBounds(index); &#125;&#125;//扩容函数private void ensureCapacity(int capacity) &#123; int oldCapacity = elements.length; if (oldCapacity &gt;= capacity) return; // 新容量为旧容量的1.5倍，1+0.5，位运算更快 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); E[] newElements = (E[]) new Object[newCapacity]; for (int i = 0; i &lt; size; i++) &#123; newElements[i] = elements[i]; &#125; elements = newElements;&#125; 删除元素 思路：从最后一个元素开始依次向前移动一位，直到，需要删除元素位置即可。最后一个元素置为null 12345678910public E remove(int index) &#123; rangeCheck(index); E old = elements[index]; for (int i = index + 1; i &lt; size; i++) &#123; elements[i - 1] = elements[i]; &#125; elements[--size] = null; return old;&#125; 添加元素 思路： 在指定位置插入元素：从最后一个元素开始依次向后移动一位，直到，需要添加元素的位置即可，然后将该位置的值修改为需要添加的元素 在末尾插入元素：调用上函数，指定位置为末尾(size) 123456789101112public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacity(size + 1); for (int i = size; i &gt; index; i--) &#123; elements[i] = elements[i - 1]; &#125; elements[index] = element; size++;&#125;public void add(E element) &#123; add(size, element);&#125; 获得元素索引 思路：依次对元素进行对比，找出相同元素。特别注意null。 123456789101112public int indexOf(E element) &#123; if (element == null) &#123; for (int i = 0; i &lt; size; i++) &#123; if (elements[i] == null) return i; &#125; &#125; else &#123; for (int i = 0; i &lt; size; i++) &#123; if (element.equals(elements[i])) return i; // n &#125; &#125; return ELEMENT_NOT_FOUND;&#125; 清空 思路：所有置为null(用于gc)，size置为0 123456public void clear() &#123; for (int i = 0; i &lt; size; i++) &#123; elements[i] = null; &#125; size = 0;&#125; 动态数组添加到最后一个位置的时候，虽然不需要挪动元素，但是如果遇到需要扩容的情况，需要复制所有元素，所以最坏时间复杂度也是0(n) ArrayList可以通过引入first指针来优化，使得挪动的元素最多是n/2 链表动态数组会造成大量的空间浪费，链表是可以做到用多少申请多少 这里可以将链表和动态数组的相同方法抽出做接口 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public interface List&lt;E&gt; &#123; static final int ELEMENT_NOT_FOUND = -1; /** * 清除所有元素 */ void clear(); /** * 元素的数量 * @return */ int size(); /** * 是否为空 * @return */ boolean isEmpty(); /** * 是否包含某个元素 * @param element * @return */ boolean contains(E element); /** * 添加元素到尾部 * @param element */ void add(E element); /** * 获取index位置的元素 * @param index * @return */ E get(int index); /** * 设置index位置的元素 * @param index * @param element * @return 原来的元素ֵ */ E set(int index, E element); /** * 在index位置插入一个元素 * @param index * @param element */ void add(int index, E element); /** * 删除index位置的元素 * @param index * @return */ E remove(int index); /** * 查看元素的索引 * @param element * @return */ int indexOf(E element);&#125; 链表的基本元素 123456789101112private Node&lt;E&gt; first;//指向第一个元素private Node&lt;E&gt; last;//指向最后一个元素的next//节点元素private static class Node&lt;E&gt; &#123; E element; Node&lt;E&gt; prev; Node&lt;E&gt; next; public Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.prev = prev; this.element = element; this.next = next; &#125; 链表不需要构造函数，因为链表不需要指定大小，需要既可以添加 链表代码一定要注意边界条件 虚拟头节点：为了代码更加简洁清晰，引入虚拟头节点，不存储数据 链表在实际操作中，因为添加和删除节点时，需要先找到该节点，所以复杂度往往是o(n) 双向链表gc root 被栈指针(局部变量)指向的对象 双向链表的添加 静态链表用数组模拟，每个元素存放两个数据：值、下一个元素的索引 链表尾的索引值用-1表示，如果为双向链表，就存储头节点下标 栈Java中的Stack继承Vector(类似ArrayList，线程安全) 队列优先考虑用双向链表实现，因为会频繁的操作头尾元素 双端队列双端队列就是两端都可以添加删除 队列底层是可以用链表或者数组实现 循环队列可以在两端添加删除 20 232 树节点的度：子树的个数(子节点的个数) 树的度：所有节点度中的最大值 叶子节点：度为0的节点 层数：根节点第1层，它的子节点在第二层，以此类推(有些教程从0开始) 节点的深度：该节点到根节点唯一路径的节点总数 节点的高度：当前节点到最远叶子节点(当前节点下的叶子节点)的路径(往下看) 树的深度：所有节点深度中的最大值 树的高度：所有节点高度中的最大值 树的高度==树的深度 二叉树(Binary Tree)特点： 每个节点度最大为2 左子树和右子树有顺序 即使某节点只有一颗子树，也要区分左右子树 非空二叉树的第i层，最多有2^i-1^层(i≥1) 在高度为h的二叉树上最多有2^h^-1个结点(h≥1) 对于任意一个非空二叉树，如果叶子结点的个数为n0，度为2的节点个数为n2那么n0=n2+1。 二叉树的边数=n1+n2或n-1 真二叉树(Proper Binary Tree)：所有节点的度不是0就是2 满二叉树(Full Binary Tree)：所有节点的度不是0就是2，且所有的叶子节点都在最后一层 同样高度的二叉树中，满二叉树的叶子节点数最多，总节点数最多 完全二叉树(Complete Binary Tree)：对节点从上至下、左至右开始编号，其所有编号都能与相同高度的满二叉树中的编号对应 叶子节点只会出现最后 2 层，最后 1 层的叶子结点都靠左对齐 完全二叉树从根结点至倒数第 2 层是一棵满二叉树 满二叉树一定是完全二叉树，完全二叉树不一定是满二叉树 面试题：完全二叉树768节点，求叶子节点数 思路1：根据n=n0+n1+n2和n0=n2+1得出n=2n0+n1-1，完全二叉树的n1不是0就是1.所以得出384 思路2：最下层：768-512+1=257。倒数第二层：256-(257/2+1)=127。这里除不同向下取整。257+127=384。 国外教程上Full Binary Tree指的是真二叉树，Perfect Binary Tree指的是满二叉树 面试题 如果一棵完全二叉树有 768 个节点，求叶子节点的个数 ​ 假设叶子节点个数为 n0，度为 1 的节点个数为 n1，度为 2 的节点个数为 n2 ​ 总结点个数 n = n0 + n1 + n2，而且 n0 = n2 + 1 n = 2n0 + n1 – 1 完全二叉树的 n1 要么为 0，要么为 1 ​ n1为1时，n = 2n0，n 必然是偶数 ​ 叶子节点个数 n0 = n / 2，非叶子节点个数 n1 + n2 = n / 2 ​ n1为0时，n = 2n0 – 1，n 必然是奇数 ​ 叶子节点个数 n0 = (n + 1) / 2，非叶子节点个数 n1 + n2 = (n – 1) / 2 叶子节点个数 n0 = floor( (n + 1) / 2 ) = ceiling( n / 2 ) 非叶子节点个数 n1 + n2 = floor( n / 2 ) = ceiling( (n – 1) / 2 ) 因此叶子节点个数为 384 遍历 前序遍历（Preorder Traversal） ：根节点、前序遍历左子树、前序遍历右子树 递归：很好想 中序遍历（Inorder Traversal） ：中序遍历左子树、根节点、中序遍历右子树 递归：很好想 后序遍历（Postorder Traversal） ：后序遍历左子树、后序遍历右子树、根节点 递归：很好想 层序遍历（Level Order Traversal）：从上到下、从左到右依次访问每一个节点 队列(默写)：将根节点入队，循环执行将队头节点A出队访问，将A的左子节点入队，右子节点入队。直到队列为空 计算二叉树高度(迭代法)：用层序遍历的方法，每次遍历完一层记录队列size，这时的size就是这一层的节点数。并且高度加1。 判断是否为完全二叉树：树为空返回false。不为空层序遍历二叉树，left为null并且right不为null返回false。left不为null并且right不为null，入队。left为null并且right不为null，那么这两种情况接下来所有节点都为叶子节点才为完全二叉树。 根据结果重构二叉树 前序遍历+中序遍历可以确定唯一的二叉树： 后序+中序可以确定唯一的二叉树： 前序+后序不可以确定唯一二叉树，除非找到他是真二叉树：因为前序的根在最前，后序的根在最后。如果左子树或右子树一个为空，无法确定到底是哪个树为空 如前序：4 2 1 3 6 5，中序：1 2 3 4 5 6 前序遍历的第一个必为根节点，咱中序遍历中找到根节点，确定1 2 3为左子树，4 5 6为右子树 根据前序知左子树1 2 3中2为根节点，根据中序1为左节点 3为右节点。 右子树一样 前驱节点 前驱节点：中序遍历时的前一个节点 如果有左子树，那么前驱节点就是，``node.left.right.right…`，直到right为null 如果无左子树，有父节点，那么前驱节点就是，node.parent.parent…，直到node是parent为止 有可能无前驱 后继结点 后继结点：中序遍历时的后一节点 如果有右子树，后继结点为node.right.left.left.…，直到left为null 如果无右子树，有父节点，后继结点为node.parent.parent…，直到node为parent的左子树为止。 可能无后继结点。 删除节点 度为0和1都比较简单。 如果度为2，就是找左子树的前驱节点或右子树的后继结点，取代即可。就转化为删除度为1或0的节点 如果是度为2的节点，前驱或后继节点的度只可能为1或0 二叉搜索树(Binary Search Tree)BST：二叉查找树、二叉排序树 任意一个节点的值都大于其左子树所有节点的值 任意一个节点的值都小于其右子树所有节点的值 它的左右子树也是一棵二叉搜索树 二叉搜索树存储的元素必须具备可比较性，不允许为null 平衡二叉搜索树(Balanced Binary Search Tree)常见平衡二叉搜索树：AVL树、红黑树 AVL树 平衡因子：其结点的左右子树高度差 AVL树的每个节点的平衡因子只可能是-1、0、1。超过一称为失衡 添加可能会导致失衡，可能使所有祖先节点都失衡，但父节点和非祖先节点不可能失衡 四种失衡情况 ![img](数据结构与算法/LR – RR左旋转LL右旋转.png) ![img](数据结构与算法/RL – LL右旋转RR左旋转.png) 删除节点 删除操作只可能会导致父节点失衡。 度为0和1都比较简单。 如果度为2，就是找左子树的前驱节点或右子树的后继结点，取代即可。就转化为删除度为1或0的节点 红黑树红黑树必须满足五条性质 节点为red或black 根节点是black 叶子节点(外部节点，空节点)都为black red节点的子节点都是black red节点的父节点都是black 从根节点刀叶子节点的所有路径上不能有两个连续的red节点 从任一节点到叶子节点的所有路径都包含相同数目的black 红黑树等价4阶B树。black节点与他的red子节点融合即为一个B树节点。红黑树的black节点数和4阶B树的节点数相同 红黑树的最大高度：2*log2(n+1) 平均时间复杂度 搜索：O(logn) 添加 AVL：O(logn) 红黑：O(1)次的旋转操作 删除：O(logn)，O(1)次的旋转操作 AVL：O(logn) 红黑：O(1)次的旋转操作 对比AVL树，在添加删除时候，修复的操作。红黑树效率更高。AVL最坏情况是2倍logn 红黑树在删除时，也可能发生递归，依次网上旋转，但根据统计，这不可能发生。反正就不可能老师也没明说。结论最多三次 总结：若搜索次数多，选AVL树。若搜索、插入、删除差不多选红黑树。 红黑树的平均统计性能优于AVL树 添加 已知：B树中，新元素必定添加到叶子节点中 添加节点时，默认为红节点，这样只有第四条性质可能不满足 添加的时候，叶子节点只有可能4中情况：红黑红、黑红、红黑、黑 最下排的节点，每个节点添加可能性，一共12种 有四种是，parent为黑。就完全满足性质，不需要做任何处理 剩下八种不满足性质4，parent为红。 LL/RR情况修复：父节点染黑，祖父染红。然后让祖父节点成为父节点的子节点，让原祖父节点的父节点指向父节点。 判定条件：叔父(父节点的兄弟节点)节点不是红色 parent染成黑，grand染成红 grand进行单旋操作 LL；右旋转 RR：左旋转 LR/RL情况修复：让自身成为父节点和祖父节点的父节点。 判定条件：叔父节点不是红色 自己染黑，grand染红(父节点本身就是红) 进行双旋操作 LR：parent左旋转，grand右旋转 RL：parent右旋转，grand左旋转 上溢LL：叔父节点为红色 parent、uncle染成黑色 grand向上合并 将grand染红，当作新添加的节点处理 grand向上合并时，可能继续发生上溢，若一直溢到根节点，只需将根节点染黑即可。 上溢RR：叔父节点为红色 parent、uncle染黑 grand染红向上合并，当作新添加的节点 上溢RL parent、uncle染黑 grand染红向上合并，当作新添加的节点 上溢：LR parent、uncle染黑 grand染红向上合并，当作新添加的节点 红黑树中没有平衡因子的概念，红黑树不存在失去平衡，只需要满足五条性质即可 删除 在B树中，真正被删除的元素都在叶子节点中， 如果删除的是红色节点，性质依然满足，不需要其它任何操作 有三种情况 拥有2个红子节点的黑节点 不会被直接删除，会找他的子节点代替删除 前驱或后继节点代替，恰好子节点就是前驱和后继节点 拥有一个红节点的黑节点 判定条件：用以替代的子节点是红 将替代的子节点染黑 黑叶子节点：黑色叶子节点被删除后，相当于在B树该节点没有元素，发生下溢 判定条件：用以替代的子节点是黑(不存在) 情况1：兄弟能借 兄弟为黑且他的子节点至少一个是红 步骤 叶子节点被删除后，导致B树节点下溢 如果兄弟节点至少有一个红节点且兄弟节点为黑 旋转，将居中的元素代替父节点以及颜色，父节点下来，左右子节点染黑。 当兄弟节点有两个红子节点，就有两种旋转方式，选其一即可。 情况2：兄弟黑不能借 判定条件：兄弟为黑没有1个红子节点 父节点下溢 若父节点为红：将兄弟染红，父节点染黑即可。 若父节点为黑：将兄弟染红，父节点染黑即可。将父节点当作被删除的节点处理即可。 情况3：兄弟为红 让兄弟的孩子变成自己的兄弟。让原来的红兄弟，变成祖父节点，父节点指向原兄弟节点的子节点。这样又回到了情况1。 黑色兄弟不可能有黑色子节点，因为它处在最后一层。 B树B树是一种多路搜索树，多用于文件系统和数据库实现 特点 1个节点可以存储超过2个元素，可以拥有超过2个子节点 拥有二叉搜索树的一些性质 平衡，每个节点的字数高度一致 n阶B树：表示节点最多有n个子节点，每个节点存储元素个数≤n-1，根节点至少1个，非跟节点至少m/2(向上取整)-1 添加 必定添加到叶子节点，如果叶子节点超过数量限制，就找中间值，提到父节点，进行上溢，如果父节点还是溢出，依次上溢，如果根节点依然上溢，就提出一个新的根节点。 删除 叶子节点中，直接删除。 非叶子节点，找前驱或者后继元素，覆盖即可 非叶子节点的前驱或后继必然在叶子节点中 如果删除后叶子结点的值的数量低于限制，发生下溢 下溢解决： 如果下溢节点临近的兄弟节点，有至少 ┌ m/2 ┐ 个元素，可以向其借一个元素(最大的) 将父节点的元素 b 插入到下溢节点的 0 位置（最小位置） 用兄弟节点的元素 a（最大的元素）替代父节点的元素 b 原来a节点的右子节点也要跟着他移动，但会移到左节点 如果下溢节点临近的兄弟节点，只有 ┌ m/2 ┐ − 1 个元素将父节点的元素 b 挪下来跟左右子节点进行合并 合并后的节点元素个数等于┌ m/2 ┐ + ┌ m/2 ┐ − 2，不超过 m − 1 这个操作可能会导致父节点下溢，依然按照上述方法解决，下溢现象可能会一直往上传播 哈夫曼编码又称霍夫曼编码，现代压缩算法的基石。 现在压缩算法不咋用这了 步骤： 先计算出每个字母的出现频率（权值） 利用这些权值，构建一棵哈夫曼树（又称为霍夫曼树、最优二叉树） 以权值作为根节点构建 n 棵二叉树，组成森林 在森林中选出 2 个根节点最小的树合并，作为一棵新树的左右子树，且新树的根节点为其左右子树根节点之和 从森林中删除刚才选取的 2 棵树，并将新树加入森林 重复 2、3 步骤，直到森林只剩一棵树为止，该树即为哈夫曼树 例：ABBBCCCCCCCCDDDDDDEE left为0，right为1，可以得到对应的哈夫曼编码 A B C D E 1110 110 0 10 1111 这样构建的不会出现歧义 总结 n 个权值构建出来的哈夫曼树拥有 n 个叶子节点 每个哈夫曼编码都不是另一个哈夫曼编码的前缀 哈夫曼树是带权路径长度最短的树，权值较大的节点离根节点较近 带权路径长度：树中所有的叶子节点的权值乘上其到根节点的路径 长度。与最终的哈夫曼编码总长度成正比关系。 集合特点：不存放重复的元素 可以用链表或平衡二叉搜索树 添加：通过判断是否有该元素，有就覆盖，无就添加。 局限性：使用平衡二叉搜索树需要元素具有可比较性 用链表或平衡二叉搜索树的接口判断是否有该元素。 映射(Map)也叫字典 由红黑树底层实现的map，由于不需要value具有可比较性，所以是一个一个的比较找出。 也可以用Map来实现set，这时候value的泛型为Object。value传null值。 Java的TreeSet底层就是用TreeMap来实现。 Java的TreeMap底层用的是红黑树 Java官方没单独的红黑树实现，是直接写在需要用的地方 哈希表也叫散列表 哈希表内部的数组元素，也叫Bucket(桶)，整个数组叫Buckets或Bucket Array 添加、搜索、删除流程类似 利用哈希函数生成key对应的index。O(1) 根据index操作定位数组元素。O(1) 哈希冲突：2个不同的key，计算出相同的结果 解决哈希冲突常见方法 开放定址法：按照一定规则向其他地址探测，直到遇到空桶。(找其它所以对应的桶) 再哈希法：设计多个哈希函数 链地址法：通过链表将同一index的元素串起来 JDK1.8：默认使用单向链表将元素串起来。在添加元素时，可能会转化为红黑树来存储元素。 如(jdk8)：当哈希表容量≥64且单向链表的节点数大于8时 当红黑树节点少到一定数时，转化为单向链表 JDK1.8的哈希表使用链表+红黑树解决哈希冲突 哈希表中哈希函数的大致实现步骤 先生成key的哈希值(整数) 再让key的哈希值跟数组的大小进行相关运算，生成索引值 为了提高效率可以用&amp;运算，前提是数组的长度设计为2的幂。return hash_code(key)&amp;(table.length-1); 在Java中，HashMap的key必须实现了hashCode、equals方法，也允许key为null 整数：值当作哈希值 浮点数：将存储的二进制格式转化为整数 Long：return (int)(value ^ (value &gt;&gt;&gt; 32)) Double：long bits = doubleToLongBits(value); return (int)(bits^(bits &gt;&gt;&gt; 32)); 字符串： 如jack可以表示为j*n^3^+a*n^2^+c*n^1^+k*n^0^等价于[(j*n+a)*n+c]*n+k jdk中乘数n为31。31不仅仅是奇素数而且，jvm会31*i可以优化为(i&lt;&lt;5)-i 素数和其它数相乘结果比其它方式更容易产生唯一性，减少哈希冲突 Double和Long充分利用高32位和低32位混合计算出哈希值。value和它又移32位进行亦或运算。 &amp;和|容易发生hash冲突。 &gt;&gt;&gt;：符号右移，忽略符号位，空位都以0补齐 &gt;&gt;：算数右移 instanceof如果是子类，返回也是true。obj.getClass()!=getClass()不是 HashMap中红黑树节点比较代码 1234567891011121314151617181920212223private int compare(K k1, K k2, int h1, int h2) &#123; // 比较哈希值 int result = h1 - h2; if (result != 0) return result; // 比较equals if (Objects.equals(k1, k2)) return 0; // 哈希值相等，但是不equals if (k1 != null &amp;&amp; k2 != null &amp;&amp; k1.getClass() == k2.getClass() &amp;&amp; k1 instanceof Comparable) &#123; // 同一种类型并且具备可比较性 if (k1 instanceof Comparable) &#123; return ((Comparable) k1).compareTo(k2); &#125; &#125; // 同一种类型，哈希值相等，但是不equals，但是不具备可比较性 // k1不为null，k2为null // k1为null，k2不为null return System.identityHashCode(k1) - System.identityHashCode(k2);&#125; 查找、添加、删除时如不具备可比较性，并且哈希值相同。或equals为false但compareTo结果为0。不能通过内存地址来查找，应该遍历红黑树上所有节点。因为内存地址不同，但equals结果可能为true。 jdk上也会扫描所有节点 装填因子(Load Factor)：节点总数量/哈希表桶数组长度，也叫负载因子 在JDK8的HashMap中，装填因子超过0.75，就扩容到原来两倍 equals规范 自反性：x.equals(x)返回true 对称性：非null的x，y。y.equals(x)==x.equals(y) 传递性：a=b b=c =&gt;a=c 一致性：多次调用结果一致 任何非null的x，x.equals(null)必须返回false TreeMap和HashMap 元素具备可比较性且要求升序遍历选TreeMap 无序遍历选HashMap 推荐的最佳素数 LinkedHashMap：在HashMap的基础上维护其添加顺序的链表(红黑树依然在)。跨树的。不用管index。 JDK的源码 LinkedHashMap： 有头节点，尾节点 每当创建新节点都会放到末尾 HashMap 当容量达到1&lt;&lt;30就不再允许扩容 默认装填因子0.75 DEFAULT_INITIAL_CAPACITY默认大小：1&lt;&lt;4 当链表节点数量TREEIFY_THRESHOLD超过8(大于8)就转化成红黑树。 UNTREEIFY_THRESHOLD当节点数小于6，红黑树转化为链表。 MIN_TREEIFY_CAPACITY：转化为红黑树，容量最小为64 堆堆是一种树状的数据结构(不要跟内存模型中”堆空间”混淆)。 分为： 二叉堆 多叉堆 索引堆 二项堆 斐波那契堆 左倾堆 斜堆 常用于解决Top k问题 重要心智：任意节点的值总≥(≤)子节点的值 若任意节点的值总≥子节点的值称：最大堆、大根堆、大顶堆 若任意节点的值总≤子节点的值称：最小堆、小根堆、小顶堆 二叉堆二叉堆的逻辑结构就是一颗完全二叉树，也叫完全二叉堆。物理结构一般用数组实现即可 索引 i 的规律（ n 是元素数量） i = 0 ，根节点 i &gt; 0 ，它的父节点的索引为 floor( (i – 1) / 2 ) 若2i + 1 ≤ n – 1，它的左子节点的索引为 2i + 1 大于就无左子节点 若2i + 2 ≤ n – 1 ，它的右子节点的索引为 2i + 2 大于就无右子节点 添加 先添加到数组的末尾位置也就是叶子节点，然后与父节点比较。如果不符合就交换位置，符合就停止，然后循环比较。 这样添加需要会导致重复覆盖，可以先进行比对，确定位置后，再覆盖。 该过程叫上滤 时间复杂度：O(logn) 删除 拿到最后一个元素，交换位置，然后删除最后一个元素。 再将换后的新元素，依次向下比较，如果不符合就交换位置，符合就停止 该过程叫下滤 时间复杂度：O(logn) 也可以像添加一样优化 如果某一个元素为叶子节点，那么它之后所有元素都是叶子节点 根据完全二叉树，非叶子节点个数为n/2向下取整。可以直接写为size&gt;&gt;1 批量建堆 自上而下的上滤：O(nlogn) 从索引1开始每个元素都上滤 仅叶子节点就近n/2个，而且每个深度都为logn 自下而上的下滤：O(n) 从size&gt;&gt;1-1到0为止 假设满树，总数为n，高位h，那么n=2^h^-1 所有节点树高之和位H(n)=2^0^(h-0)+2^1^(h-1)+2^2^(h-2)……+2^h-1^[h-(h-1)]=h*(2^h^-1)-[(h-2)*2^h^+2]=2n-log2(n+1)=O(n) ) 下滤效率较高 Top K问题 全排序时间复杂度：O(nlogn) 二叉堆时间复杂度：O(nlogk) 步骤： 新建一个小顶堆 扫描n个整数 前k个数入堆 从k+1开始，如果大于堆顶元素，就replace 优先级队列用堆来实现 优先级高的 可以用最大堆或最小堆来实现 Java官方使用的是最小堆。越小优先级越高 最大堆是越大优先级越高 Trie也叫字典树、前缀树、单词查找树 搜索效率主要与字符串长度有关 多叉树，一个节点一个字符，根节点为空 节点需要有一个标记，来标记此节点是否为结束位 缺点：内存消耗大 补充右旋转又叫zig，旋转后的状态叫zigged 左旋转叫zag ，旋转后的状态叫zagged 四则运算表达式分三种： 前缀表达式：又称波兰表达式 中缀表达式 后缀表达式：又称逆波兰表达式 前缀 中缀 后缀 + 1 2 1 + 2 1 2 + + 2 * 3 4 2 + 3 * 4 2 3 4 * + + 9 * - 4 1 2 9 +(4 - 1) * 2 9 4 1 -2 * + 若将表达式的操作数作为叶子节点，运算符作为父节点。刚好组成二叉树。 前序遍历就是前缀表达式 中序遍历就是中缀表达式 后序遍历就是后缀表达式 二叉树的非递归遍历非递归的前序遍历：一路往左，并且将右节点入栈，左到底后，将栈顶元素弹出，然后循环这逻辑 非递归的中序遍历：一路往左，依次将当前节点入栈，到底后出栈，访问它的右节点，然后对该节点也执行上面的逻辑，依次循环。 非递归的后序遍历：将当前节点入栈，将右节点入栈，将左节点入栈，将栈顶(不弹出)的右节点入栈，左节点入栈 算法排序 名称 最好时间复杂度 最坏时间复杂度 平均时间复杂度 额外空间复杂度 In-place 稳定性 冒泡排序（Bubble Sort） O(n) O(n^2^) O(n^2^) O(1) √ √ 选择排序（Selection Sort） O(n^2^) O(n^2^) O(n^2^) O(1) √ x 插入排序（Insertion Sort） O(n) O(n^2^) O(n^2^) O(1) √ √ 归并排序（Merge Sort） O(nlogn) O(nlogn) O(nlogn) O(1) x √ 快速排序（Quick Sort） O(nlogn) O(n^2^) O(nlogn) O(logn) √ x 希尔排序（Shell Sort） O(n) O(n^4/3^)~O(n^2^) 取决于步长 O(1) √ x 堆排序（Heap Sort） O(nlogn) O(nlogn) O(nlogn) O(1) √ x 计数排序（Counting Sort） O(n + k) O(n + k) O(n + k) O(n + k) x √ 基数排序（Radix Sort） O(d ∗ (n + k)) O(d ∗ (n + k)) O(d ∗ (n + k)) O(n + k) x √ 桶排序（Bucket Sort） O(n + k) O(n + k) O(n + k) O(n + m) x √ 冒泡、选择、插入、归并、快速、希尔、堆排序，属于比较排序（Comparison Sorting） in-place：原地算法，不依赖额外资源，输出覆盖输入。一般为O(1)空间复杂度 k为序列内max-min d为最大值的位数 冒泡排序可以记录最后依次交换的位置，用来减少比较次数。 选择排序在序列中找到最大元素与末尾元素交换。忽略该元素 平均性能略优于冒泡，但最好情况下依旧很差 堆排序将序列进行原地建堆，重复执行以下操作，直到堆元素数量为1 交换堆顶元素与尾元素 堆元素减1 对0位置进行一次siftDown操作 插入排序插入排序类似于扑克牌的排序 执行流程： 在执行过程中，插入排序会将序列分为2部分。 头部是已经排好的序列，尾部是待排序的 从头开始扫描每个元素 每扫描到一个元素，就插入到头部合适的位置 实现，尾部向前排，可向前依次交换实现 也可以用二分搜索相应的位置插入来优化，为了稳定性，需要二分搜索返回第一个大于该元素的位置。 逆序对：如&lt;2,3,8,6,1&gt;的逆序对为：&lt;2,1&gt; &lt;3,1&gt; &lt;8,1&gt; &lt;8,6&gt; &lt;6,1&gt;。 逆序对数量越多，插入排序的时间复杂度越高 当逆序对极少时，效率极高 归并排序步骤 不断地将当前序列平均分割成2个子序列，直到不能再分割为止(只剩一个元素) 不断地将两个序列合并成一个有序序列 两边从头开始，哪个大按序加入序列。 https://leetcode-cn.com/problems/merge-sorted-array/ https://leetcode-cn.com/problems/merge-two-sorted-lists/comments/ https://leetcode-cn.com/problems/merge-k-sorted-lists/ 较快于堆排序 休眠排序开辟与序列长度数量的线程数，根据要排序数值大小，使得睡多久 段子，莫尝试 快速排序最坏情况可以有方法来降低它出现的概率 比归并和堆排序更快 执行步骤 在序列中选择一个轴点元素(pivot) 假设每次选择0位置为轴点元素 利用pivot将序列一分为二个子序列 小于pivot的元素放pivot左 大于pivot的元素放pivot右 等于pivot的元素放pivot左右都可 再对这两个子序列进行1，2步操作 直到不能再分割为止 快排本质：逐渐将每个元素都转换为轴点元素 实现 序列设置begin和end，左闭右开，end在最后一个元素之后。备份轴点(begin)。扫描元素，从右(end)开始如果元素比轴点大end–。如果比轴点小，将end元素覆盖begin元素且begin++并且改为从左往右扫描。如果遇到比轴点元素大，将begin元素覆盖end元素且end–，改扫描方向。如果遇到比轴点元素小，begin++；直到begin和end重合，再将备份元素覆盖此位置。 与轴点元素相同的元素，如果选择只做减减或加加容易出现最差情况。所以一般都放到另一边，然后调转方向 复杂度 时间复杂度 最好情况：轴点左右元素数量均匀T(n)=2*T(n/2)+O(n)=O(nlogn) 最差情况：轴点左右元素数量极度不均匀T(n)=T(n-1)+O(n)=O(n^2^) 空间复杂度：由于递归调用，空间复杂度为O(logn)，不稳定排序 希尔排序也称递减增量排序 将序列看作一个矩阵，分成m列，逐列进行排序，m逐渐减为1，当m为1时，整个序列完全有序。 在m逐渐变为1的过程中，逆序对的数量在减少，因此希尔排序底层一般使用插入排序对每列进行排序。 矩阵的列数取决于步长序列 如，步长序列为{1,3,5,23,65……}表示依次分成65列，23列，5列，3列，1列 步长序列不同，执行效率不同 希尔本人给出的步长序列为n/2^k^，如n为16时，序列为{1,2,4,8} 复杂度 希尔本人给出的步长序列，最坏情况时间复杂度是O(n^2^) 已知的最好步长序列，最坏情况的时间复杂度是O(n^4/3^) k为0，1，2，3，4，5如果k超过数据规模就结束 K为偶数：9(2^k^-2^k/2^)+1 K为奇数：8*2^k^-6*2^(k+1)/2^+1 计数排序计数、桶、基数都不是基于比较排序，典型的空间换时间，有些时候，平均时间复杂度可以比O(nlogn)更低 核心思想：统计每个整数在序列中出现的次数，来推导出每个整数在有序序列的索引 用数组，下标表示数字，如果出现一次，数组[下标]++ 缺点：稀疏序列极浪费空间 改进：数组长度设置为max-min、记录值为出现次数加上前个下标的值(就是前面的所有元素出现的次数)这样能快速获取其索引与出现次数。然后对照原队列，从右往左依次找到相应下标，算出索引值。每算出一个数值的索引，将它对应下标的值减1。 改进后是在计数后，再加步骤，将下标的值修改，然后对照原队列算出索引值。这样稳定性就不会被破坏 基数排序步骤：依次对个位数、十位数、百位数、千位数……进行排序 个位数、十位数、百位数的取值范围固定0~9，可以使用计数排序进行排序 也可以用二维数组，第一个下标为当前位数的值，第二个下标表示出现的第几个数 桶排序常见递推式与复杂度 递推式 复杂度 T(n) = T(n/2) + O(1) O(logn) T(n) = T(n − 1) + O(1) O(n) T(n) = T(n/2) + O(n) O(n) T(n) = 2 ∗ T(n/2) + O(1) O(n) T(n) = 2 ∗ T(n/2) + O(n) O(nlogn) T(n) = T(n − 1) + O(n) O(n^2^) T(n) = 2 ∗ T(n − 1) + O(1) O(2^n^) T(n) = 2 ∗ T(n − 1) + O(n) O(2^n^) 并查集需求：设计一个数据结构能 连接两个村庄 查询两个村庄是否有连路 并查集能够做到俩个操作时间复杂度都为O(α(n))，α(n)&lt;5 并查集核心操作：查找(Find)、合并(Union) 两种实现思路 Quick Find find的时间复杂度：O(1) union的时间复杂度：O(n) Quick Union find的时间复杂度：O(logn)可以优化到O(α(n))，α(n)&lt;5 union的时间复杂度：O(logn)可以优化到O(α(n))，α(n)&lt;5 Quick Union 存储：用数组存储元素，下标表示该元素，值表示该元素连接的根节点的下标元素。 根节点存储自身下标 查找时只要看下它的值是不是一样就行了。 连接时，将其中一个集合的所有元素改为合并的另一个集合的根的下标 Quick Union 不直接连接根节点，连接直接指向的节点，所以值存储的直接相连的值的下标 优化 基于size的优化：元素少的树嫁接到元素多的树 增加一个数组 类型为数组 记录每个元素的size 基于rank的优化：矮树 嫁接到 高树 增加一个数组 类型为数组 记录每个元素的高度 路径压缩，在find时将路径上的所有节点直接指向根节点 递归实现，最后返回根节点来赋值。 优化强，但实现成本高 路径分裂：每个节点指向它的祖父节点 路径减半：每隔一个节点都指向它祖父节点 扩充到任意类型 将类型转化为整型，或者给类型加整型属性 链表+map：链表做节点，map存各个节点用于迅速定位 总结：建议使用Quick Union基于rank的优化加上路径分裂或路径减半 图(Graph)由顶点(vertex)和边(edge)组成，表示为G=(V,E) G为图，V为顶点集，E为边集 顶点集有穷且非空 任意顶点之间都可用边来表示它们的关系，E可为空 有向图：边有明确方向 有向无环图(DAG)：一个有向图从任意顶点出发无法经过若干条边回到该顶点。 出度：该点作为起点的边数 入度：该点作为终点的边数 平行边 无向图中，关联同一对顶点 有向图中，关联同一对顶点，且方向相同 多重图：有平行边或自环的图 自环：自己指向自己 简单图：既无平行边也无自环的图 无向完全图：无向图，且任意俩个顶点之间都有边 n个顶点的无向完全图有n(n-1)/2条边 有向完全图：任意俩顶点间存在方向相反的两条边 稠密图：边数接近或等于完全图 稀疏图：边数远少于完全图 有权图：边拥有权值 连通图：无向图中任意两个顶点都是连通的 连通：两顶点存在可相互抵达的路径 连通分量：无向图的极大连通子图 连通图只有一个连通分量，自身 强连通图：有向图中任意两个顶点都是连通的 强连通分量：有向图的极大强连通子图 图的实现方案 邻接矩阵 一维数组存放顶点信息 二维数组存放边信息 横竖都表示顶点，相交为0表示无法通往该顶点，相交为1表示能通往 若为有权图，也可以存放权值 更适合稠密图 邻接表 ：链表，后面只连接有边的顶点 遍历 广度优先搜索(BFS) 将起点加入队列，然后取出队列第一个元素，加入它能一步到达的顶点(需要排除已经加入过的)。然后循环直到队列为空 记录已经加入的节点，可以使用任意集合，在加入队列的时候，就要加入集合 深度优先搜索(DFS)：一条道走到底，然后往回退看有没有别的路。直到走完 用set记录已经访问过的节点，然后递归他所有子节点，直到访问完 非递归思路 从节点(弹出的节点或初始节点)出度中任意选择一条 将边的from和to入栈 弹出to，打印to 将to加入到已访问过的范围中 break AOV网大工程可分为多个小工程，小工程之间的先后顺序联系构成AOV网 标准的AOV网必须是一个有向无环图(简称DAG) 拓扑排序 前驱活动：有向边起点的活动称为终点的前驱活动 后继活动：有向边终点的活动称为起点的后继活动 拓扑排序：将AOV网中所有活动排成一个序列，使得每个活动的前驱活动都在后继活动前。 卡恩算法 所有入度为0的顶点放入列表中，然后将顶点从图中去掉 重复操作1，直到找不到入度为0的点 若列表中元素个数与顶点总数相等，表面排序完成 若列表中元素个数少于顶点总数，则说明有环，无法拓扑排序 实现： 遍历找到所有入度为0的点，入队列。建表，存储顶点和其对应的入读数 出队，遍历其出度，拿到它的终点。更新表，将对应的点的入度-1。若减后入度为0，就将它入队列。循环2 AOE网络自学下 https://leetcode-cn.com/problems/course-schedule-ii/ 生成树也称支撑树 连通图的极小连通子图，它含有图中全部n个点，恰好只有n-1条边。 最少的边到达所有顶点 最小生成树：所有生成树中，总权值最小的那颗 适合有权的连通图 求最小生成树的2个经典算法 Prim(普里姆算法) 切分：把图中的节点分为两部分，称为一个切分 横切边：如果一个边的两个端点，分别属于切分的两部分，这个边称为横切边 切分定理：给定任意切分，横切边中权值最小的边必然属于最小生成树 算法步骤： 假设图为G=(V,E)有权的连通图。准备两个集合S{u0}和A 找到切分C = (S,V-S)的最小横切边(u0,v0)，并入集合A，同时将V0并入集合S。循环直到S=V或A=n-1(n为顶点数) u0初始为任意顶点，V0为横切边的另一端点 切分过程中，可能会将图，切分为三个连通图，这时候也需要一个连通图一个连通图的来 Kruskal(克鲁斯克尔算法) 算法步骤：将所有边根据权值大小排序，前两小的边，必为最小生成树的边，第三个开始，判断加入是否形成环，如果形成环就舍去，如果没有则加入。直到边数为顶点数-1 判断是否形成环，可以用并查集来实现。 set如果存节点的话，可能会导致有多个图，图内连通，但之间没有相连 最短路径两顶点之间权值之和最小的路径(有向图、无向图均可，不能有负权环) 有向图有负权边，无负权环，存在最短路径 无向图不能有负权边 三个经典算法 单源最短路径算法 Dijkstra(迪杰斯特拉算法)： 前提：不能有负权边 时间复杂度：可优化至O(ElogV)，E为边数量，V为节点数 建表，找附近直达的所有点，找最短路径，然后更新，更新表。 松弛操作：更新2顶点间的最短路径。(拉起一个点后，可能会使得到达其它点的路径有更短的，更新) ) Bellman-Ford(贝尔曼-福特算法) 能检查出负权边和负权环 步骤：对所有的边进行V-1次松弛操作，得到所有可能的最短路径 时间复杂度：O(EV)，E边数，V节点数 负权环没有最短路径，每轮松弛后，路径都能更短些。在经历V-1次松弛后，再松弛一次，路径依然能更短。 多源最短路径算法 Floyd(弗洛伊德算法) 时间复杂度：O(V^3^)，效率比Dijkstra好 原理 从任意顶点i到j的最短路径不外乎两种 i直接到j i经过若干点到j 假设dist(i,j)为顶点i到j的最短距离 对每个顶点k，检查dist(i,k)+dist(k,j)&lt;dist(i,j)是否成立 若成立，则dist(i,j)=dist(i,k)+dist(k,j) 遍历完所以节点k，dist(i,j)便是i到j的最短路径 算法递归尾调用：函数的最后一个动作是调用函数 一些编译器能对尾调用进行一些优化，以节省栈空间 尾调用优化也叫尾调用消除 消除尾递归中的尾调用，更加容易 JVM会消除尾递归中的尾调用，但不会消除一般的尾调用 回溯通过选择不同的岔路口来通往目的地。 每步都选择一条路出发，能进则进，不能则回退上一步，换条路试试 DFS就是典型的回溯 https://leetcode-cn.com/problems/permutations/ https://leetcode-cn.com/problems/permutations-ii/ https://leetcode-cn.com/problems/combination-sum/ https://leetcode-cn.com/problems/combination-sum-ii/ https://leetcode-cn.com/problems/subsets/ https://leetcode-cn.com/problems/subsets-ii/ 八皇后问题 在国际象棋棋盘上拜访八个皇后，使其不能互相攻击。即任意两皇后不能处于同一行、同一列、同一斜线上。有多少种摆法？ https://leetcode-cn.com/problems/n-queens/ https://leetcode-cn.com/problems/n-queens-ii/ 暴力解法：任意选八个格子，检查每种可能性。大概有4.4*10^9^种 暴力优化解法：每行脂肪一个皇后，有8^8^种，检查每种摆法可能性 回溯法：先确定第一个皇后的位置(任意)，然后在剩下能摆的位置任意摆放一个，直到不能拜访再回溯，再拜访。(可能会回溯到第一个皇后摆放的位置) 细节：一行只能有一个皇后，所以一行一行的摆。拜过皇后的列不能再摆。斜方向可以算出来。然后使用回溯。 左上到右下：同一斜线上row-col+n-1值相同，n为几个皇后 右上到左下：row+col即可 可以通过使用位运算，来替代使用数组的空间。(只适合8皇后以下) 通过&amp;(1&lt;&lt;列)的操作，若与的结果为0表示无 贪心贪心策略，贪婪策略 每部都采取当下最优解(局部最优解) 应用：哈夫曼树、Prim、Kruskal、Dijkstra 缺点：往往不能得到最优解 01背包 问题：有 n 件物品和一个最大承重为 W 的背包，每件物品的重量是 𝑤i、价值是 VI。在保证总重量不超过 W 的前提下，将哪几件物品装入背包，可以使得背包的总价值最大？ 每件物品只有 1 件，也就是每个物品只能选择 0 件或者 1 件，因此称为 0-1背包问题 https://leetcode-cn.com/problems/assign-cookies/ https://leetcode-cn.com/problems/minimum-number-of-arrows-to-burst-balloons/ https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/ https://leetcode-cn.com/problems/can-place-flowers/ https://leetcode-cn.com/problems/candy/ 分治解决规模为 n 的问题，分解成 a 个规模为 n/b 的子问题，然后在 O (n^d^) 时间内将子问题的解合并起来 算法运行时间为：T (n) = aT (n/b) + O (n^d^) ，a &gt; 0, b &gt; 1, d ≥ 0 最大子序列 思路：将序列均匀分为2个序列。那么最大的子序列要么在左边要么在右边，要么在中间。 实现：中间的最大序列就是中间往左右延申 123456789101112131415161718192021int maxSubArray(int[] nums, int begin, int end) &#123; if (end - begin &lt; 2) return nums[begin]; int mid = (begin + end) &gt;&gt; 1; int leftMax = nums[mid - 1]; int leftSum = leftMax; for (int i = mid - 2; i &gt;= begin; i--) &#123; leftSum += nums[i]; leftMax = Math.max(leftMax, leftSum); &#125; int rightMax = nums[mid]; int rightSum = rightMax; for (int i = mid + 1; i &lt; end; i++) &#123; rightSum += nums[i]; rightMax = Math.max(rightMax, rightSum); &#125; return Math.max(leftMax + rightMax, Math.max( maxSubArray(nums, begin, mid), maxSubArray(nums, mid, end)) );&#125; 大数乘法 将n位数分为n/2位来算 下图为n/2*n/2的优化 动态规划可以理解为一种从低向上的记忆性递归 常规思路： 定义状态(状态是原问题、子问题的解)： 如定义dp(i)的含义 设置初始状态(边界) 如设置dp(0)的值 确定状态转移方程 如确定dp(i)和dp(i-1)的关系 将复杂问题拆解为若干个简单的子问题，每个子问题只解决一次，保存它的解，最后推导出原问题的解 可以用动态规划解决的问题，通常有两个特征 最优子结构(最优化原理)：通过求解子问题的最优解，可以获得原问题的最优解 无后效： 某阶段的状态一旦确定，则此后过程的演变不再受此前各状态及决策的影响（未来与过去无关） 在推导后面阶段的状态时，只关心前面阶段的具体状态值，不关心这个状态是怎么一步步推导出来的 零钱兑换 https://leetcode-cn.com/problems/coin-change/ 动态规划思路 1234567891011121314151617181920212223//n为金钱总额，faces为有的硬币面额int coins5(int n, int[] faces) &#123; if (n &lt; 1 || faces == null || faces.length == 0) return -1; int[] dp = new int[n + 1]; for (int i = 1; i &lt;= n; i++) &#123; int min = Integer.MAX_VALUE; for (int face : faces) &#123; if (i &lt; face) continue; int v = dp[i - face]; //如果i-face的值是无法凑的，就跳过 ///若i-face的值是大于别的min的，也跳过 if (v &lt; 0 || v &gt;= min) continue; min = v; &#125; //能到这说明for一直是continue，无法凑到该面值，赋-1 if (min == Integer.MAX_VALUE) &#123; dp[i] = -1; &#125; else &#123; dp[i] = min + 1; &#125; &#125; return dp[n];&#125; 最大连续子序列 前面分治做过，动态规划也能做 状态定义：假设dp(i)是以nums[i]结尾的最大连续子序列和(nums为整个序列) 实现细节：若dp(i-1)为负数，那么dp(i-1)就是单独它一个数，若为正数或零则相加 空间和时间复杂度：O(n) 空间复杂度，可以不存前面的值，优化到O(1) 最长上升子序列(LIS) 问题 思路：nums为序列 状态定义：dp(i) 是以 nums[i] 结尾的最长上升子序列的长度，i ∈ [0, nums.length) 要以nums[i]结尾 状态转移方程： 当 nums[i] &gt; nums[j]。nums[i] 可以接在 nums[j] 后面，形成一个比 dp(j) 更长的上升子序列，长度为 dp(j) + 1 当 nums[i] ≤ nums[j]，nums[i] 不能接在 nums[j] 后面，跳过此次遍历（continue） dp(i) = max { dp(i), dp(j) + 1 } 初始状态：所有的 dp(i) 默认都初始化为 1 最长上升子序列的长度是所有 dp(i) 中的最大值 max { dp(i) }，i ∈ [0, nums.length) 总结思路：dp(i) 是以 nums[i] 结尾的最长上升子序列的长度，确定dp(i)是遍历dp(n) n&lt;i，如果nums[n]&lt;nums[i]，则可以接在后面长度为dp(n)+1，若不能，则跳过。选出最大的就是dp(i)的值。最后遍历每个子序列的值，max就是答案 空间复杂度：O(n)，时间复杂度：O (n^2^) 二分搜索思路： 时间复杂度可以优化到O(nlogn) 思路：从左往右处理每个元素，新建一个同样长度的数组 如果数组种没有元素比它大就按序往后，将该元素放置 如果从左数过来数组中元素大于等于当前处理的元素，则覆盖 当处理完所有牌，数组有元素的个数就是最长上升子序列的长度 这样处理的过程中，数组一直是升序的。只要比较数组中有值的最后的一个元素就可以知道数组中有没有比他大的元素。所以可以使用二分查找的方法，来找到对应数组的元素。 1234567891011121314151617181920int lengthOfLIS(int[] nums) &#123; if (nums == null || nums.length == 0) return 0; int len = 0; int[] top = new int[nums.length]; for (int num : nums) &#123; int begin = 0; int end = len; while (begin &lt; end) &#123; int mid = (begin + end) &gt;&gt; 1; if (num &lt;= top[mid]) &#123; end = mid; &#125; else &#123; begin = mid + 1; &#125; &#125; top[begin] = num; if (begin == len) len++; &#125; return len;&#125; 最长公共子序列 [问题] 思路：nums1是序列1，nums2是序列2 状态定义：dp(i, j) 是【nums1 前 i 个元素】与【nums2 前 j 个元素】的最长公共子序列长度 状态转移方程： 若nums1[i – 1] = nums2[j – 1]，那么 dp(i, j) = dp(i – 1, j – 1) + 1 若nums1[i – 1] ≠ nums2[j – 1]，那么 dp(i, j) = max { dp(i – 1, j), dp(i, j – 1) } 初始状态：dp(i, 0)、dp(0, j) 初始值均为 0 这个题目，动态规划该思路大致想来是对的，细想又觉得有些地方不是很理解 实现 12345678910111213141516171819202122232425262728public int longestCommonSubsequence(String text1, String text2) &#123; if (text1 == null || text2 == null) return 0; char[] chars1 = text1.toCharArray(); if (chars1.length == 0) return 0; char[] chars2 = text2.toCharArray(); if (chars2.length == 0) return 0; char[] rowsChars = chars1, colsChars = chars2; //将二维数组优化为一维数组，再选择较短的做列，优化一维数组的空间 if (chars1.length &lt; chars2.length) &#123; colsChars = chars1; rowsChars = chars2; &#125; int[] dp = new int[colsChars.length + 1]; for (int i = 1; i &lt;= rowsChars.length; i++) &#123; int cur = 0; //leftTop来记录需要用到的值 for (int j = 1; j &lt;= colsChars.length; j++) &#123; int leftTop = cur; cur = dp[j]; if (rowsChars[i - 1] == colsChars[j - 1]) &#123; dp[j] = leftTop + 1; &#125; else &#123; dp[j] = Math.max(dp[j], dp[j - 1]); &#125; &#125; &#125; return dp[colsChars.length];&#125; 最长公共子串 子串与子序列不同，子串必须是连续的 思路：与最长上升子序列类似。2 个字符串分别是 str1、str2(i ∈ [1, str1.length]、j ∈ [1, str2.length]) 状态定义：dp(i, j) 是以 str1[i – 1]、str2[j – 1] 结尾的最长公共子串长度 状态转移方程： 若str1[i – 1] = str2[j – 1]，那么 dp(i, j) = dp(i – 1, j – 1) + 1 若str1[i – 1] ≠ str2[j – 1]，那么 dp(i, j) = 0 初始状态：dp(i, 0)、dp(0, j) 初始值均为 0 最长公共子串的长度是所有 dp(i, j) 中的最大值 max { dp(i, j) } 有了最长上升子序列的经验，这题很容易联想到 实现： 优化：将二维数组优化为一维数组，再选择较短的做列，优化一维数组的空间。从左往右算。 如果从右往左算，还要记录个leftTop的值 1234567891011121314151617181920212223242526int lcs(String str1, String str2) &#123; if (str1 == null || str2 == null) return 0; char[] chars1 = str1.toCharArray(); if (chars1.length == 0) return 0; char[] chars2 = str2.toCharArray(); if (chars2.length == 0) return 0; char[] rowsChars = chars1, colsChars = chars2; if (chars1.length &lt; chars2.length) &#123; colsChars = chars1; rowsChars = chars2; &#125; int[] dp = new int[colsChars.length + 1]; int max = 0; for (int row = 1; row &lt;= rowsChars.length; row++) &#123; for (int col = colsChars.length; col &gt;= 1; col--) &#123; if (chars1[row - 1] != chars2[col - 1]) &#123; dp[col] = 0; &#125; else &#123; dp[col] = dp[col - 1] + 1; max = Math.max(dp[col], max); &#125; &#125; &#125; return max;&#125; 01背包 思路：values 是价值数组，weights 是重量数组 状态定义：假设 dp(i, j) 是 最大承重为 j、有前 i 件物品可选 时的最大总价值，i ∈ [1, n]，j ∈ [1, W] 状态转移方程： 若 j &lt; weights[i – 1]，那么 dp(i, j) = dp(i – 1, j) 若 j ≥ weights[i – 1]，那么 dp(i, j) = max { dp(i – 1, j), dp(i – 1, j – weights[i – 1]) + values[i – 1] } 初始状态：dp(i, 0)、dp(0, j) 初始值均为 0 状态转移方程就是分两种情况： 当目前的最大承重都无法放下第i件物品时，那么dp(i, j)值就为dp(i-1,j) 当目前能放下该第i件物品时，那么dp(i, j)值就有两种情况，就是该物品放了，或者没放。没方就是dp(i-1,j)，放了就是dp(i-1,j-weight[i-1])+values[i-1]。dp(i-1,j-weight[i-1])就是能放下该物品时剩下空间的最大总价值 优化：只用一维数组，并且从左往右算 从左往右算并不是优化，如果从右往左递推，会覆盖掉前面的内容，而后面的操作是可能要用到前面的值的。所以先进行后面的操作。 123456789101112int maxValue(int[] values, int[] weights, int capacity) &#123; if (values == null || values.length == 0) return 0; if (weights == null || weights.length == 0) return 0; if (values.length != weights.length || capacity &lt;= 0) return 0; int[] dp = new int[capacity + 1]; for (int i = 1; i &lt;= values.length; i++) &#123; for (int j = capacity; j &gt;= weights[i - 1]; j--) &#123; dp[j] = Math.max(dp[j], values[i - 1] + dp[j - weights[i - 1]]); &#125; &#125; return dp[capacity];&#125; 01背包恰好装满 只需要更改初始状态即可 dp(i, 0) = 0，总重量恰好为 0，最大总价值必然也为 0 dp(0, j) = –∞（负无穷），j ≥ 1，负数在这里代表无法恰好装满 当选择不拿的时候，i往前一步一步往0靠(直到靠到初始值负无穷)，就是负值。当拿的时候，如果不是恰好装满时会出现极小值+一个数也是负数。俩者取最大还是负数 当选择拿的时候且恰好装满，是一个值加一个恰好装满的值(该值若是初始状态则是0) 12345678910111213141516//返回-1表示无法恰好装满int maxValueExactly(int[] values, int[] weights, int capacity) &#123; if (values == null || values.length == 0) return 0; if (weights == null || weights.length == 0) return 0; if (values.length != weights.length || capacity &lt;= 0) return 0; int[] dp = new int[capacity + 1]; for (int j = 1; j &lt;= capacity; j++) &#123; dp[j] = Integer.MIN_VALUE; &#125; for (int i = 1; i &lt;= values.length; i++) &#123; for (int j = capacity; j &gt;= weights[i - 1]; j--) &#123; dp[j] = Math.max(dp[j], values[i - 1] + dp[j - weights[i - 1]]); &#125; &#125; return dp[capacity] &lt; 0 ? -1 : dp[capacity];&#125; 布隆过滤器是一个空间效率高的概率性高的概率型数据结构，可以用告诉你：一个元素一定不存在或者可能存在 优点：查询和空间效率极高 缺点：有一定误判率、删除困难 本质：一个很长的二进制向量和一系列随机映射函数(Hash函数) 哈希函数作用：若干个哈希函数，每个哈希函数生成一个索引 添加：将每个哈希函数生成的索引位置设为1 查询：若每个哈希函数生成的索引位置都为1则存在，有一个不为1就不存在 添加、查询的时间复杂度都为：O(K)，K为哈希函数的个数 空间复杂度为：O(m)，m为二进制位的个数 误判率：二进制位的个数m、哈希函数的个数k、数据规模n。可以算出误判率 当数据规模足够大的时候，0.5和1都可以忽略 已知误判率p、数据规模n，求二进制位的个数m、哈希函数的个数k 谷歌的布隆过滤器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111//简易完整的实现，可以看下学习下源码public class BloomFilter&lt;T&gt; &#123; /** * 二进制向量的长度(一共有多少个二进制位) */ private int bitSize; /** * 二进制向量 */ private long[] bits; /** * 哈希函数的个数 */ private int hashSize; /** * @param n 数据规模 * @param p 误判率, 取值范围(0, 1) */ public BloomFilter(int n, double p) &#123; if (n &lt;= 0 || p &lt;= 0 || p &gt;= 1) &#123; throw new IllegalArgumentException(\"wrong n or p\"); &#125; double ln2 = Math.log(2); // 求出二进制向量的长度 bitSize = (int) (- (n * Math.log(p)) / (ln2 * ln2)); // 求出哈希函数的个数 hashSize = (int) (bitSize * ln2 / n); // bits数组的长度 bits = new long[(bitSize + Long.SIZE - 1) / Long.SIZE]; // 每一页显示100条数据, pageSize // 一共有999999条数据, n // 请问有多少页 pageCount = (n + pageSize - 1) / pageSize &#125; /** * 添加元素1 */ public boolean put(T value) &#123; nullCheck(value); // 利用value生成2个整数 int hash1 = value.hashCode(); int hash2 = hash1 &gt;&gt;&gt; 16; boolean result = false; for (int i = 1; i &lt;= hashSize; i++) &#123; int combinedHash = hash1 + (i * hash2); if (combinedHash &lt; 0) &#123; combinedHash = ~combinedHash; &#125; // 生成一个二进位的索引 int index = combinedHash % bitSize; // 设置index位置的二进位为1 if (set(index)) result = true; // 101010101010010101 // | 000000000000000100 1 &lt;&lt; index // 101010111010010101 &#125; return result; &#125; /** * 判断一个元素是否存在 */ public boolean contains(T value) &#123; nullCheck(value); // 利用value生成2个整数 int hash1 = value.hashCode(); int hash2 = hash1 &gt;&gt;&gt; 16; for (int i = 1; i &lt;= hashSize; i++) &#123; int combinedHash = hash1 + (i * hash2); if (combinedHash &lt; 0) &#123; combinedHash = ~combinedHash; &#125; // 生成一个二进位的索引 int index = combinedHash % bitSize; // 查询index位置的二进位是否为0 if (!get(index)) return false; &#125; return true; &#125; /** * 设置index位置的二进位为1 */ private boolean set(int index) &#123; long value = bits[index / Long.SIZE]; int bitValue = 1 &lt;&lt; (index % Long.SIZE); bits[index / Long.SIZE] = value | bitValue; return (value &amp; bitValue) == 0; &#125; /** * 查看index位置的二进位的值 * @return true代表1, false代表0 */ private boolean get(int index) &#123; long value = bits[index / Long.SIZE]; return (value &amp; (1 &lt;&lt; (index % Long.SIZE))) != 0; &#125; private void nullCheck(T value) &#123; if (value == null) &#123; throw new IllegalArgumentException(\"Value must not be null.\"); &#125; &#125;&#125; 跳表又叫跳跃表、跳跃列表，在有序链表的基础上增加了“跳跃”的功能 对比平衡树 实现和维护更简单 搜索、删除、添加的平均时间复杂度是O(logn) 原理：在链表的基础上，增加了能跳跃的点 首节点是虚拟节点，不存实际的数据 搜索、删除、添加：都是先从最顶层开始找，如果小于或为空则返回从下个层开始找，如果大于依然从最顶层开始找，循环前面步骤。如果等于，或下面没有层了就停止。 每个节点都存储的是K-V对。K具有可比较性 实现细节： 最高层数、有效层数：规定最高到几层、实际用的几层(记录下个节点 ) 最高层的层数为，平均有1/p元素 层数用数组实现，在获取时遍历该数组就行了 跳表节点层数的确定：随机，只要不超过最高层数即可。这样做的效率也是能达到logn的 123456789//p的值一般为0.5或0.25，redis里p为0.25private static final double P = 0.25;private int randomLevel() &#123; int level = 1; while (Math.random() &lt; P &amp;&amp; level &lt; MAX_LEVEL) &#123; level++; &#125; return level;&#125; 在删除和添加结点的时候，需要知道新添加的节点的若干个前驱节点。可以创建一个有效层数的数组，在搜索添加位置的过程中将它的前驱节点保存在数组中。方便之后遍历来更改前驱节点的指向。 补充 跳表的层数 元素层数恰好等于1的概率为1-p 大于等于2的概率为p，恰好为2的概率为p*(1-p) 大于等于3的概率为p^2^，恰好为3的概率为p^2^*(1-p) 一个元素的平均层数为1/(1-p) 复杂度 每层元素数 一层固定有n个 二层平均有n*p个 三层平均有n*p^2^个 k层平均有n*p^k^个 搜索时，每层链表的预期查找步数最多为1/p，总的查找步数为)，时间复杂度O(logn) B+树B树变体，常用于数据库和操作系统的文件系统中 MySQL的索引就是基于B+树实现的 特点 分为内部节点和叶子节点两种节点 叶子节点就是最底下一层，内部节点就是非叶子节点 内部节点只存储key，不存储具体数据 叶子节点存储key和具体数据 所有的叶子节点形成一条有序链表 m阶B+树非根节点的元素数量X 元素数量如果为x，子节点数量也为x MySQL为了减小IO操作数量，把一个节点的大小设计为最小读写的大小(一个扇区) InnoDB的最小读写单位是16k 对于B树，B+树的优势是 每个节点存储的key数量更多，树的高度更低 B树节点存K-V。B+树的分支比B树更多 查询速度稳定，高效。区间查询更高效 B+树的叶子节点是有序链表，区间查询速度快 B树区间查询需要中序遍历，效率较低 B*树：B+树的变体，给内部节点增加了指向兄弟节点的指针 m阶B*树的非根节点的元素数量x 串就是字符串，由若干个字符组成的有限序列 概念： 前缀(prefix)： 真前缀(proper prefix) 后缀(suffix) 真后缀(proper suffix) 模式串(Pattern) 文本串(Text) 以thank举例： 几个经典的串匹配算法：蛮力、KMP、Boyer-Moore、Rabin-Karp、Sunday pl为patternlength，tl为textlength 蛮力(Brute Force)以字符为单位，从左到右移动模式串，直到匹配成功。 蛮力1：用两个值记录，pi和ti。相同的时候两值++，若匹配失败pi=0，ti-=(pi-1)将ti置开始匹配位置的下个位置 蛮力2：用两个值记录，pi和ti。不匹配的时候ti++，pi=0。匹配时pi++比较时比pi+ti和pi 时间复杂度O(nm) KMP相较于蛮力算法，KMP的精妙之处：充分利用了此前比较过的内容，可以很聪明地跳过一些不必要的比较位置。 通过next表来实现快速向后移动 next[pi]是 pi 左边子串的真前缀后缀的最大公共子串长度。然后长度都向后移一位，首字符设置为-1 例： 我认为该算法主要是利用模式串的真前缀和真后缀，重复的部分来实现更优秀的模式匹配","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"},{"name":"数据结构","slug":"数据结构","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"kafka笔记","slug":"kafka笔记","date":"2020-01-03T11:40:21.000Z","updated":"2020-01-03T11:40:30.876Z","comments":true,"path":"2020/01/03/kafka笔记/","link":"","permalink":"http://example.com/2020/01/03/kafka%E7%AC%94%E8%AE%B0/","excerpt":"","text":"https://www.orchome.com/5","categories":[],"tags":[]},{"title":"python笔记","slug":"python笔记","date":"2019-12-22T12:12:41.000Z","updated":"2021-07-08T07:56:22.520Z","comments":true,"path":"2019/12/22/python笔记/","link":"","permalink":"http://example.com/2019/12/22/python%E7%AC%94%E8%AE%B0/","excerpt":"","text":"变量、常量、注释变量名推荐 驼峰体：ageOfName 下划线：age_of_name 常量：全部大写，放在最上面。可以改变，但是不要去改变。约定俗成 AGE_OF_NAME 注释： #：单行注释 ‘’’内容’’’：多行注释 “”“内容”“”：多行注释 基础类型、输入基础类型 str：字符串 123s1='1's2=\"1\"s3='''3''' #三引号可以写换行的字符串， str+str：拼接 str*int：重复 非空即使true int：64位上-2**63~2**63-1 bit_lenth：有效的二进制长度 bool：True、False 非零就是True list：[1,2,3] range：类似于列表，自定制数字范围的数字列表 tuple：不可变(1,2,3) dict：{&#39;name&#39;:&#39;wo&#39;} set：交集 可变（不可哈希）：list dict set 不可变（可哈希）：str bool int tuple 12int(str)#强转str(int) type()来判断数据类型 str的操作方法索引、切片、步长12345678910111213str=\"左手右手，一个慢动作\"print(str[1])#手，下标从0开始print(str[-1])#作，-1从最后一个开始print(str[1:4])#手右手，顾头不顾腚print(str[:3])#左手右，0可以省略print(str[1:-1])#手右手，一个慢动print(str[1:])#保到最后，不用写print(str[::2])#步长为2，隔一个取一个print(str[::-1])#倒叙# 按索引：s1[index]# 按照切片： s1[start_index: end_index+1]# 按照切片步长： s1[start_index: end_index+1:2]# 反向按照切片步长： s1[start_index: end_index后延一位:2] 其他常用操作str的操作不会对本身做更改，只会返回新的字符串 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182s = 'taiBAifdsa'# 不会对原字符串进行任何操作，都是产生一个新的字符串# upper lowerprint(s.upper()) # 全转为小写print(s.lower()) # 全转为大写# startswith endswithprint(s.startswith('t')) # True判断是否已开头print(s.startswith('taiBAi')) # True# 了解print(s.startswith('B', 3, 6)) # 判断s的第三到第五的新字符串是不是以B开头# replacemsg = '蔡徐坤，蔡徐坤，蔡徐坤，蔡徐坤'print(msg.replace('蔡徐坤', '菜虚鲲')) # 默认全部替换print(msg.replace('蔡徐坤', '菜虚鲲', 2)) # 只替换俩个# strip:裁剪空白(空格，\\t \\n)s4 = ' \\n蔡徐坤\\t 'print(s4.strip())# 了解# 可以去除指定的字符s4 = 'rre蔡eecs徐dr坤qsd'print(s4.strip('qrsed'))# split 非常重要# 默认按照空格，全部分割，返回一个列表s6 = ':蔡徐坤:蔡徐坤:蔡徐坤'print(s6.split(':', 2)) # ['', '蔡徐坤', '蔡徐坤:蔡徐坤'] 2表示分割前两个# join 非常好用list = [\"蔡坤\", \"蔡徐\"]s1 = '蔡徐坤'print('1'.join(s1)) # 蔡1徐1坤print('1'.join(list)) # list只能为字符串# print(s2,type(s2))# l1 = ['太白', '女神', '吴超']# # 前提：列表里面的元素必须都是str类型# s3 = ':'.join(l1)# print(s3)# counts8 = 'sdfsdagsfdagfdhgfhgfhfghfdagsaa'print(s8.count('a')) # 5 计算a出现的次数# format: 格式化输出# # 第一种用法：print('我叫&#123;&#125;今年&#123;&#125;性别&#123;&#125;'.format('大壮', 25, '男'))# 第二种用法：数字是后面参数的位置print('我叫&#123;0&#125;今年&#123;1&#125;性别&#123;2&#125;我依然叫&#123;0&#125;'.format('大壮', 25, '男'))# 第三种用法：键值对方式print('我叫&#123;name&#125;今年&#123;age&#125;性别&#123;sex&#125;'.format(age=100, sex='男', name='大壮'))# is 系列：name = '100①一Ⅰ三四'print(name.isalnum()) # True 字符串由字母或数字组成，能识别不同的语言的数字print(name.isalpha()) # 字符串只由字母组成print(name.isdecimal()) # 字符串只由十进制组成#in 判断str内是否有s = \"我最爱蔡徐坤，奥里给\"print(\"蔡徐坤\" in s)#Trueprint(\"蔡徐奥里给\" in s)#Falseprint(\"蔡徐奥里给\" not in s)#Truestr = \"tea good bad\"print(str.capitalize()) # Tea good bad首字母大写str = \"tea3good bad\"print(str.title()) # Tea3Good Bad 每个单词首字母大写，只要是非字母隔开都算str = \"AAbbCCDDEeFGsda\"print(str.swapcase()) # aaBBccddeEfgSDA 大小写翻转str = \"蔡徐坤\"print(str.center(10)) # 蔡徐坤print(str.center(10, \"=\")) # ===蔡徐坤====# find，找到就返回第一个，找不到就返回-1print(str.find('坤')) # 2# index,找到就返回第一个，找不到就报错 列表操作增删改查123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869li = [100, '蔡徐坤', True, [1, 2, 3]]# 列表内什么数据都能存# 切片 （顾头不顾腚）规则参考str切片print(li[:2]) # [100, '蔡徐坤']print(li[1::2]) # ['蔡徐坤', [1, 2, 3]]print(li[1:4]) # ['蔡徐坤', True, [1, 2, 3]]# 列表的创建# 方式一l1 = [1, 2, '蔡徐坤']# 方式二 不常用l1 = list()l1 = list('奥里给i的蔡徐坤')print(l1) # ['奥', '里', '给', 'i', '的', '蔡', '徐', '坤']# 方式三：列表推导式 后面讲# 增删改查l1 = ['蔡徐坤', '影流之主', '奥里给', '巨魔', '哈撒给']# 增：# append:追加l1.append('xx') # 不能打印它print(l1)# insert 插入l1.insert(2, 'wusir') # 从0开始在2的位置插入wusirprint(l1)# extend 迭代着追加l1.extend('abcd') # 会将['a', 'b', 'c', 'd']这个列表迭代加入l1.extend(['蔡徐坤', ]) # 会骄傲如'蔡徐坤'整体print(l1)# 删# pop 按照索引位置删除# l1.pop(-2) # 按照索引删除 （返回的是删除的元素）print(l1.pop())# remove 指定元素删除,如果有重名元素，默认删除从左数第一个l1.remove('a')print(l1)# clear(了解)l1.clear() # 清空print(l1)# del# 按照索引删除l1 = ['蔡徐坤', '影流之主', '奥里给', '巨魔', '哈撒给']del l1[-1]print(l1) # ['蔡徐坤', '影流之主', '奥里给', '巨魔']# 按照切片(步长)删除del l1[::2]print(l1) # ['影流之主', '巨魔']# 改# 按照索引改值l1[0] = '名人'# 按照切片改（了解）l1[2:] = ['死丢比特', '阿泽西', '奥巴马']print(l1) # ['名人', '巨魔', '死丢比特', '阿泽西', '奥巴马']# 按照切片修改（步长）（了解）l1[::2] = '123' # 一定要一一对应不然会报错print(l1) # ['1', '巨魔', '2', '阿泽西', '3']# 查：# 索引，切片（步长）for i in l1: print(i) 补充12345678910111213list = [21, 5, 7, 31, 1]list.sort() # 升序list.sort(reverse=True) # 降序list.reverse() # 反转list += list # 列表相加list *= 2 # 翻倍del list[1::2] # 删除奇数索引print(list) # [1, 7, 31, 5, 21, 1, 7, 31, 5, 21]# 倒着删除奇数索引for index in range(len(list) - 1, -1, -1): if index % 2 == 1: list.pop(index)print(list) # [1, 31, 21, 7, 5] range1234range(5) # [0, 1, 2, 3, 4]顾头不顾腚range(5, 10) # [5, 6, 7, 8, 9]range(5, 10, 2) # [5, 7, 9]range(10, 5, -2) # [10, 8, 6] dict详细介绍键只能为不可变类型，值可以是任意的 字典在3.5及其之前，是无序的 3.6之后会按照建立字典的顺序排列 3.7之后是有序的 查询速度快 创建1234567891011121314151617181920212223242526# 创建字典的几种方式：# 方式1:dic = dict((('one', 1),('two', 2),('three', 3)))#dic = dict([('one', 1),('two', 2),('three', 3)])print(dic) # &#123;'one': 1, 'two': 2, 'three': 3&#125;# 方式2:dic = dict(one=1,two=2,three=3)print(dic) # &#123;'one': 1, 'two': 2, 'three': 3&#125;# 方式3:dic = dict(&#123;'one': 1, 'two': 2, 'three': 3&#125;)print(dic) # &#123;'one': 1, 'two': 2, 'three': 3&#125;# 方式5: 后面会讲到先了解dic = dict(zip(['one', 'two', 'three'],[1, 2, 3]))print(dic)# 方式6: 字典推导式 后面会讲到# dic = &#123; k: v for k,v in [('one', 1),('two', 2),('three', 3)]&#125;# print(dic)# 方式7:利用fromkey后面会讲到。# dic = dict.fromkeys('abcd','蔡徐坤')# print(dic) # &#123;'a': '蔡徐坤', 'b': '蔡徐坤', 'c': '蔡徐坤', 'd': '蔡徐坤'&#125; 增12345678910111213141516# 通过键值对直接增加dic = &#123;'name': '蔡徐坤', 'age': 18&#125;dic['weight'] = 75 # 没有weight这个键，就增加键值对print(dic) # &#123;'name': '蔡徐坤', 'age': 18, 'weight': 75&#125;dic['name'] = 'barry' # 有name这个键，就成了字典的改值print(dic) # &#123;'name': 'barry', 'age': 18, 'weight': 75&#125;# setdefaultdic = &#123;'name': '蔡徐坤', 'age': 18&#125;dic.setdefault('奥里给') # '奥里给': Nonedic.setdefault('height', 175) # 没有height此键，则添加。有此键则不变print(dic) # &#123;'name': '蔡徐坤', 'age': 18, 'height': 175&#125;# 它有返回值dic = &#123;'name': '蔡徐坤', 'age': 18&#125;ret = dic.setdefault('name')print(ret) # 蔡徐坤 删12345678910111213141516171819202122# pop 通过key删除字典的键值对，有返回值，可设置返回值。dic = &#123;'name': '蔡徐坤', 'age': 18&#125;ret1 = dic.pop('n',\"cxk\")#如果不设置第二个次数，无这个值就会报错。设置了，就会返回设置的值print(ret1,dic)#popitem 3.5版本之前，popitem为随机删除，3.6之后为删除最后一个，有返回值dic = &#123;'name': '蔡徐坤', 'age': 18&#125;ret = dic.popitem()print(ret,dic) # ('age', 18) &#123;'name': '蔡徐坤'&#125;#clear 清空字典dic = &#123;'name': '蔡徐坤', 'age': 18&#125;dic.clear()print(dic) # &#123;&#125;# del# 通过键删除键值对dic = &#123;'name': '蔡徐坤', 'age': 18&#125;del dic['name']print(dic) # &#123;'age': 18&#125;#删除整个字典del dic 改12345678910111213141516171819# 通过键值对直接改dic = &#123;'name': '蔡徐坤', 'age': 18&#125;dic['name'] = 'barry'print(dic) # &#123;'name': 'barry', 'age': 18&#125;# updatedic = &#123;'name': '蔡徐坤', 'age': 18&#125;dic.update(sex='男', age=175)print(dic) # &#123;'name': '蔡徐坤', 'age': 175, 'sex': '男'&#125;dic = &#123;'name': '蔡徐坤', 'age': 18&#125;dic.update([(1, 'a'),(2, 'b')])print(dic) # &#123;'name': '蔡徐坤', 'age': 18, 1: 'a', 2: 'b'&#125;dic1 = &#123;\"name\":\"jin\",\"age\":18,\"sex\":\"male\"&#125;dic2 = &#123;\"name\":\"alex\",\"weight\":75&#125;dic1.update(dic2)print(dic1) # &#123;'name': 'alex', 'age': 18, 'sex': 'male', 'weight': 75&#125;print(dic2) # &#123;'name': 'alex', 'weight': 75&#125; 查1234567891011121314151617181920212223# 通过键查询# 直接dic[key](没有此键会报错) 不推荐dic = &#123;'name': '蔡徐坤', 'age': 18&#125;print(dic['name']) # 蔡徐坤 # getdic = &#123;'name': '蔡徐坤', 'age': 18&#125;v = dic.get('name')print(v) # '蔡徐坤'v = dic.get('name2', '没有此键') # 第二个参数设置未找到时的返回值，如果没有设置，并且找不到返回None# keys() 可以通过list(dic.keys())转化为listdic = &#123;'name': '蔡徐坤', 'age': 18&#125;print(dic.keys()) # 返回所有的键 dict_keys(['name', 'age'])# values() 可以通过list(dic.values())转化为listdic = &#123;'name': '蔡徐坤', 'age': 18&#125;print(dic.values()) # 返回所有的值 dict_values(['蔡徐坤', 18])# items() 可以通过list(dic.values())转化为list，元素为元组dic = &#123;'name': '蔡徐坤', 'age': 18&#125;print(dic.items()) # 返回所有的键值对 dict_items([('name', '蔡徐坤'), ('age', 18)]) 补充12345678910111213dic = dict.fromkeys([1, 2, 3, 4], \"12\") # 不同的键，同一个值print(dic) # &#123;1: '12', 2: '12', 3: '12', 4: '12'&#125;dic = dict.fromkeys([1, 2, 5, 6], [])#同一引用dic[1].append(1)print(dic)#&#123;1: [1], 2: [1], 5: [1], 6: [1]&#125;dic = dict.fromkeys('123123', 21)for k in dic: if '1' in k: dic.pop(k) # 字典迭代时不能改变字典大小for key in list(dic.keys()): # 改进，将键分离出来 if '1' in key: dic.pop(key) 集合set里面元素为不可变元素，集合是无序的(1-33是有序的) 作用： 列表去重 关系测试：交集、并集…… 创建1234set1 = set(&#123;1, 2, 'barry'&#125;)set2 = &#123;1, 2, 'barry'&#125;# &#123;&#125;代表空字典set() # 表示空集合 增、删、改12345678910111213141516171819202122232425set1 = &#123;'alex', 'wusir', 'ritian', 'egon', 'barry'&#125;set1.add('景女神')print(set1)# update：迭代着增加set1.update('A')print(set1)set1.update('老师')print(set1)set1.update([1, 2, 3])print(set1)set1 = &#123;'alex', 'wusir', 'ritian', 'egon', 'barry'&#125;set1.remove('alex') # 删除一个元素print(set1)set1.pop() # 随机删除一个元素print(set1)set1.clear() # 清空集合print(set1)del set1 # 删除集合print(set1) # NameError: name 'set1' is not defined 交并差1234567891011121314151617181920212223#交集。（&amp; 或者 intersection）set1 = &#123;1,2,3,4,5&#125;set2 = &#123;4,5,6,7,8&#125;print(set1 &amp; set2) # &#123;4, 5&#125;print(set1.intersection(set2)) # &#123;4, 5&#125;#并集。（| 或者 union）set1 = &#123;1,2,3,4,5&#125;set2 = &#123;4,5,6,7,8&#125;print(set1 | set2) # &#123;1, 2, 3, 4, 5, 6, 7,8&#125;print(set2.union(set1)) # &#123;1, 2, 3, 4, 5, 6, 7,8&#125;#差集。（- 或者 difference）set1 = &#123;1,2,3,4,5&#125;set2 = &#123;4,5,6,7,8&#125;print(set1 - set2) # &#123;1, 2, 3&#125;print(set1.difference(set2)) # &#123;1, 2, 3&#125;#反交集。 （^ 或者 symmetric_difference）set1 = &#123;1,2,3,4,5&#125;set2 = &#123;4,5,6,7,8&#125;print(set1 ^ set2) # &#123;1, 2, 3, 6, 7, 8&#125;print(set1.symmetric_difference(set2)) # &#123;1, 2, 3, 6, 7, 8&#125; 子差集 12345678set1 = &#123;1,2,3&#125;set2 = &#123;1,2,3,4,5,6&#125;print(set1 &lt; set2)print(set1.issubset(set2)) # 这两个相同，都是说明set1是set2子集。print(set2 &gt; set1)print(set2.issuperset(set1)) # 这两个相同，都是说明set2是set1超集。 去重1list(set(list)) frozenset`可以将集合变为不可变类型。frozenset(list) 元组不可变类型 123456789101112ele = (1)print(type(ele)) # &lt;class 'int'&gt;ele = (\"1\")print(type(ele)) # &lt;class 'str'&gt;ele = ([1, 2, 3])print(type(ele)) # &lt;class 'list'&gt;ele = (&#123;1, 23&#125;)print(type(ele)) # &lt;class 'set'&gt;ele = (&#123;\"1\": \"1\"&#125;)print(type(ele)) # &lt;class 'dict'&gt;ele = (1,)print(type(ele)) # &lt;class 'tuple'&gt; 操作123456789101112131415161718192021222324#切片tu1 = ('a', 'b', '蔡徐坤', 3, 666)print(tu1[0]) # 'a'print(tu1[-1]) # 666print(tu1[1:3]) # ('b', '蔡徐坤')print(tu1[:-1]) # ('a', 'b', '蔡徐坤', 3)print(tu1[::2]) # ('a', '蔡徐坤', 666)print(tu1[::-1]) # (666, 3, '蔡徐坤', 'b', 'a')# 可以利用for循环查询tu1 = ('a', 'b', '蔡徐坤', 3, 666)for i in tu1: print(i)#找索引，没有findtu = ('蔡徐坤', [1, 2, 3, ], 'WuSir', '女神')print(tu.index('蔡徐坤')) # 0#计总数tu = ('蔡徐坤', '蔡徐坤', 'WuSir', '吴超')print(tu.count('蔡徐坤')) # 2tu1 = (1,2,3,4,84,5,2,8,2,11,88,2)print(len(tu1)) 输入1username=input('请输入') 流程控制if123456if 条件: 语句elif 条件： else: 语句 只要是能转化为bool值，任何都能判断 while1234while 条件: 语句else: #条件不成立 语句 break：跳出循环，不执行else continue：跳过本次循环 123456# len :获取可迭代对象的元素总个数s1 = '帅哥蔡徐坤'index = 0while index &lt; len(s1): print(s1[index]) index += 1 for1234567891011#iterable可迭代对象'''有限循环for 变量 in iterable: pass'''s1 = '帅哥蔡徐坤'for i in s1: print(i)# for也有break continue# for else: while else:用法一样。 格式化输出%s 占位符 %d %i替换数字 %r 万能原模原样输出来 %f 浮点数 %x — hex 十六进制%d — dec 十进制%d — oct 八进制 1msg = \"%s=%s=%s\" % (\"1\", \"2\", \"3\") 格式化输出中，只想输出%要写%% 123456import math# width = 10,precise = 3,align = leftprint(\"PI = %10.3f\" % math.pi)# 3.142# width = 10,precise = 3,align = rigthprint(\"PI = %-10.3f\" % math.pi)#3.142 新格式化输出python3.6之后可以使用 123456789101112131415161718192021222324252627282930313233343536373839name = \"蔡徐坤\"age=10str=f\"name=&#123;name&#125;,age=&#123;age&#125;\"#大小写F都可以print(f'&#123;3*21&#125;') # 63name = 'barry'print(f\"全部大写：&#123;name.upper()&#125;\") # 全部大写：BARRY# 字典也可以teacher = &#123;'name': '蔡徐坤', 'age': 18&#125;msg = f\"The teacher is &#123;teacher['name']&#125;, aged &#123;teacher['age']&#125;\"print(msg) # The comedian is 蔡徐坤, aged 18# 列表也行l1 = ['蔡徐坤', 18]msg = f'姓名：&#123;l1[0]&#125;,年龄：&#123;l1[1]&#125;.'print(msg) # 姓名：蔡徐坤,年龄：18.#函数def sum_a_b(a,b): return a + ba = 1b = 2print('求和的结果为' + f'&#123;sum_a_b(a,b)&#125;')#多行fname = 'barry'age = 18ajd = 'handsome'speaker = f'Hi &#123;name&#125;.'\\ f'You are &#123;age&#125; years old.'\\ f'You are a &#123;ajd&#125; guy!'print(speaker)# ! , : &#123; &#125; ;这些标点不能出现在&#123;&#125; 这里面。# print(f'&#123;;12&#125;') # 报错# 所以使用lambda 表达式会出现一些问题。# 解决方式：可将lambda嵌套在圆括号里面解决此问题。 运算符算术运算除了加减乘除，还有//去整除的商**幂 python里也有//=、+=等等 逻辑运算and=&amp;&amp;、or=||、not=! 优先级：not&gt;and&gt;or ==、is区别、代码块is、==区别id是虚拟内存地址 1234# id 唯一标识id(\"sad\")# ==判断的是 值是否相同# is判断的是地址值是否相同 代码块Python程序是由代码块构造的。块是一个python程序的文本，他是作为一个单元执行的。 代码块：一个模块，一个函数，一个类，一个文件等都是一个代码块。 而作为交互方式输入的每个命令都是一个代码块。 两个机制，同一个代码块下，有一个机制，不同代码块，遵循另一个机制 同一代码块同一个代码块的初始化对象的命令时，会检查是否其值是否已经存在，如果存在，会将其重用。 适用对象： int（float），str，bool。 int(float):任何数字在同一代码块下都会复用。 bool:True和False在字典中会以1，0方式存在，并且复用。 str：几乎所有的字符串都会符合缓存机制，具体规定如下 非乘法得到的字符串都满足代码块的缓存机制： 123s1 = '坤坤@！#*ewq's2 = '坤坤@！#*ewq'print(s1 is s2) # True 乘法得到的字符串分两种情况： 乘数为1时，任何字符串满足代码块的缓存机制： 1234b1 = '坤坤@5847395QQ0743895*&amp;^%$#((&amp;_+(())' *1a1 = '坤坤@5847395QQ0743895*&amp;^%$#((&amp;_+(())' *1print(a1 is b1) # True 乘数&gt;=2时：仅含大小写字母，数字，下划线，总长度&lt;=20，满足代码块的缓存机制： 123s1 = 'old_' * 5s2 = 'old_' * 5print(s1 is s2) # True 优点：能够提高一些字符串，整数处理人物在时间和空间上的性能；需要值相同的字符串，整数的时候，直接从‘字典’中取出复用，避免频繁的创建和销毁，提升效率，节约内存 不同代码块Python自动将-5~256的整数进行了缓存，当你将这些整数赋值给变量时，并不会重新创建对象，而是使用已经创建好的缓存对象。 python会将一定规则的字符串在字符串驻留池中，创建一份，当你将这些字符串赋值给变量时，并不会重新创建对象， 而是使用在字符串驻留池中创建好的对象。 其实，无论是缓存还是字符串驻留池，都是python做的一个优化，就是将~5-256的整数，和一定规则的字符串，放在一个‘池’（容器，或者字典）中，无论程序中那些变量指向这些范围内的整数或者字符串，那么他直接在这个‘池’中引用，言外之意，就是内存中之创建一个。 int（float），str，bool int：范围是-5~256 str:字符串 字符串的长度为0或者1，默认都采用了驻留机制（小数据池）。 字符串的长度&gt;1,且只含有大小写字母，数字，下划线时，才会默认驻留。 用乘法得到的字符串，分两种情况。 乘数为1时： 仅含大小写字母，数字，下划线，默认驻留 含其他字符，长度&lt;=1,默认驻留。 含其他字符，长度&gt;1,默认驻留。 乘数&gt;=2时： 仅含大小写字母，数字，下划线，总长度&lt;=20,默认驻留。 深浅copy浅拷贝只会拷贝壳，对象里每一个属性的引用还是原来的 深拷贝连属性引用也不是原来的了 1234567l1 = [1, 2, 3]l2 = l1.copy() # 浅拷贝#深拷贝import copy# python对深copy做了一个优化，不可变的数据类型，沿用同一个copy.deepcopy([1, 2, 3, 4, [2, 3, 4, [1, 2, 3]]]) 编码进阶bytes类型与字符串类型，几乎一模一样，可以看看bytes类型的源码，bytes类型可以用的操作方法与str相差无几. 12345s1 = \"蔡徐坤\"b1 = s1.encode('utf-8')print(b1, type(b1)) # b'\\xe8\\x94\\xa1\\xe5\\xbe\\x90\\xe5\\x9d\\xa4' &lt;class 'bytes'&gt;s2 = b1.decode('utf-8')print(s2) # 蔡徐坤 文件操作简介1234f = open('d:\\test.txt',mode='r',encoding='utf-8')content = f.read()print(content)f.close() 接下来就是对上面代码的解释： f: 就是一个变量，一般都会将它写成f,f_obj,file,f_handler,fh,等，它被称作文件句柄。 open：是Python调用的操作系统（windows,linux,等）的功能。 ‘d:\\test.txt’: 这个是文件的路径。 \\为转义字符，如果需要用的话可以用\\\\替代\\或者在字符串前加r。表示、不用转义 mode： 就是定义你的操作方式：r为读模式。 encoding: 不是具体的编码或者解码，他就是声明：此次打开文件使用什么编码本。一般来说：你的文件用什么编码保存的，就用什么方法打开，一般都是用utf-8（有些使用的是gbk）。 f.read():你想操作文件，比如读文件，给文件写内容，等等，都必须通过文件句柄进行操作。 close(): 关闭文件句柄（可以把文件句柄理解成一个空间，这个空间存在内存中，必须要主动关闭）。 共有函数 12345f1.read() # 读取全部f1.read(5) # 读取5个字符f1.readlines() # 将文件每一行作为一个元素，返回listfor line in f1: print(line) # 一个line就是一行 读取时，每行最后都有一个\\n可以用strip()函数，去除\\n 模式 描述 r 以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。 rb 以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。 r+ 打开一个文件用于读写。文件指针将会放在文件的开头。 rb+ 以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。 w 打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 wb 以二进制格式打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 w+ 打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 wb+ 以二进制格式打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 a 打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 ab 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 a+ 打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。 ab+ 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。 如果你在读写模式下，先写后读，那么文件就会出问题，因为默认光标是在文件的最开始，你要是先写，则写入的内容会讲原内容覆盖掉，直到覆盖到你写完的内容，然后在后面开始读取。 其他操作 seek(n)光标移动到n位置,注意: 移动单位是byte,所有如果是utf-8的中文部分要是3的倍数 移动到开头:seek(0) 移动到结尾:seek(0,2) seek的第二个参数表示的是从哪个位置进行偏移,默认是0,表示开头,1表示当前位置,2表示结尾 tell()获取光标位置 flush()强制刷新，一般写文件时使用 readable()、writeable() with打开文件 1234567#有点：不用手动关闭with open(r'd:\\test.log', encoding='utf-8') as f1: print(f1.read())#可以写多个with open(r'd:\\test.log', encoding='utf-8') as f1, \\ open(r'd:\\test.log', encoding='utf-8') as f2: print(f1.read()) 自动关闭文件句柄，是有一段时间的，这个时间不固定，所以这里就会产生问题，如果你在with语句中通过r模式打开t1文件，那么你在下面又以a模式打开t1文件，此时有可能你第二次打开t1文件时，第一次的文件句柄还没有关闭掉，可能就会出现错误,他的解决方式只能在你第二次打开此文件前，手动关闭上一个文件句柄。 文件的修改 将硬盘存放的该文件的内容全部加载到内存，在内存中是可以修改的，修改完毕后，再由内存覆盖到硬盘（word，vim，nodpad++等编辑器） 将硬盘存放的该文件的内容一行一行地读入内存，修改完毕就写入新文件，最后用新文件覆盖源文件。（用for） 123import osos.remove('移除的文件路径') # 移除文件os.rename(\"old Name\", \"new Name\") # 文件重命名 函数python中的函数，加()才执行，不加()只会指向函数的内存地址，可以当变量来使用 结构和调用函数体内不要写print 123456789def meet(): # 代码功能 return # 终止函数，可以无返回值def meet1(): return 1 # 返回def meet2(): return 1,2,\"2sa\" #(1, 2, '2sa') &lt;class 'tuple'&gt;a,b,c = meet2()#拆包获取meet() # 定义之后才能使用 123#三元运算符a = 10 if 10 &gt; 20 else 20print(a) # 20 123# 传参时位置参数一定要在关键字参数之前def st(age, name=\"sad\"): print(1)#如果只有一行代码，就可以写在一行st(age=1,name=\"1\") *args：接收所有参数，为元组 **kwargs：：接收所有关键字参数：为字典 参数问题12def func(a, b, *args, name='蔡徐坤', c, **kwargs): # 顺序要这样，c是只能用关键字传值 print 传参时，在可迭代对象前加*会打散放入*args 在字典对象前加**会打散放入**kwargs 123456789101112dic1 = &#123;'name': '蔡徐坤', 'age': 18&#125;dic2 = &#123;'hobby': '喝茶', 'sex': '男'&#125;def func(**kwargs): print(kwargs) # &#123;'name': '蔡徐坤', 'age': 18, 'hobby': '喝茶', 'sex': '男'&#125;func(**dic1,**dic2)s1 = 'alex'l1 = [1, 2, 3, 4]tu1 = ('武sir', '蔡徐坤', '女神',)def func(*args): print(args) # ('a', 'l', 'e', 'x', 1, 2, 3, 4, '武sir', '蔡徐坤', '女神')func(*s1,*l1,*tu1) 默认参数为可变参数问题 12345def fun(a, list=[]):#函数默认值为可变变量，一直会指向一个。反复使用 list.append(a) return listfun(1)print(fun(\"2\")) # [1, '2'] 名称空间python一共三种名称空间，按照加载顺序排列 内置名称空间（built-in） 全局名称空间 局部名称空间 取值顺序 就近原则 单项不可逆 如果是全局得，只能从全局开始找 局部-&gt;全局-&gt;内置 作用域、 全局作用域：内置名称空间、全局名称空间 局部作用域：局部名称空间 局部作用域可以引用全部作用域，不能改变 因为python解释器在读取到局部变量时，如果有对变量的修改动作，解释器会认为局部已经定义过这个局部变量，就会在局部找变量。 局部空间得局部空间也是一样 LEGB原则（就近原则） L：local E：eclose G：global B：builtin 12345# 特殊错误，记住con = 1def fun(): print(con) con = 2#在函数中如果定义了一个变量，但是在定义之前引用了，解释器认为语法出错 内置函数 globals()：返回的是字典，全局作用域的所有内容 locals()：返回的是字典，当前作用域的所有内容 global、nonlocal 12345678910111213name=1def func(): global name#声明为全局变量，修改全局变量 name ='11'func()print(name)def wrapper(): count=1 def inner(): nonlocal count#nonlocal不能操作全局变量，内层函数对外层函数的局部变量进行修改 count+=1 inner()wrapper() 迭代、生成可迭代对象可迭代对象：内部含有__iter__方法的对象，可迭代对象 123list = 1print(dir(list)) # 获取一个对象的所有方法print('__iter__' in dir(obj)) # 判断是否为可迭代对象 优点 存储的数据直接能显示，直观 拥有的方法多，操作便捷 缺点 占用内存 不能直接通过for循环，不能直接取值（索引，key） 迭代器可以直接for循环 可迭代对象内部先转化为迭代器，再用for 迭代器在python中，内部含有__Iter__方法并且含有__next__方法的对象就是迭代器。 可迭代对象转化为迭代器 12obj = l1.__iter__() obj = iter(s1) 迭代器取值 1234s1 = \"sdasda\"ite = iter(s1)#越界报错print(next(ite))#sprint(ite.__next__())#d 判断是否为迭代器 1234567891011121314151617181920o1 = 'alex'o2 = [1, 2, 3]o3 = (1, 2, 3)o4 = &#123;'name': '蔡徐坤','age': 18&#125;o5 = &#123;1, 2, 3&#125;f = open('file',encoding='utf-8', mode='w')print('__iter__' in dir(o1)) # Trueprint('__iter__' in dir(o2)) # Trueprint('__iter__' in dir(o3)) # Trueprint('__iter__' in dir(o4)) # Trueprint('__iter__' in dir(o5)) # Trueprint('__iter__' in dir(f)) # True# hsagnprint('__next__' in dir(o1)) # Falseprint('__next__' in dir(o2)) # Falseprint('__next__' in dir(o3)) # Falseprint('__next__' in dir(o4)) # Falseprint('__next__' in dir(o5)) # Falseprint('__next__' in dir(f)) # Truef.close() 优点 节省内存： 迭代器在内存中相当于只占一个数据的空间：因为每次取值都上一条数据会在内存释放，加载当前的此条数据。 惰性机制：next一次，取一个值，绝不过多取值。 缺点： 不能直观的查看里面的数据。 取值时不走回头路，只能一直向下取值。 生成器生成器本质就是迭代器 获取生成器三种方式 生成器函数 生成器表达式 python内部提供 123456789101112131415def func(): print(111) yield 2 yield 3 yield 4# 一个next对应一个yield，第一次next才会执行yieldret = func() # 这里不会执行next(ret) # 这里才会取值 执行next(ret)print(next(ret)) # 4def func(): yield from [1,2,3,4,5,\"sad\"]#加上fromhi将list中的数据，扁平化返回ret=func()print(next(ret)) send发送 1234567891011def gen(name): # print(f'&#123;name&#125; ready to eat') while 1: food = yield 222 # 给food赋值，如果无发送值，则为None,yield返回222 print(f'&#123;name&#125; start to eat &#123;food&#125;')dog = gen('alex')next(dog) # 第一次必须用next让指针停留在第一个yield后面next(dog)# 与next一样，可以获取到yield的值ret = dog.send('蔡徐坤')#先发送再往下走print(\"woqiao\",ret) next和sen的区别 相同点： send 和 next()都可以让生成器对应的yield向下执行一次。 都可以获取到yield生成的值。 不同点： 第一次获取yield值只能用next不能用send（可以用send(None)）。 send可以给上一个yield置传递值。 列表推导式 循环模式：[变量(加工的变量) for 变量 in iterable] 筛选模式：[变量(加工的变量) for 变量 in iterable if 条件] 循环模式 12345ls = [i for i in range(10)]print(ls)#[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]lst = [f'python&#123;i&#125;' for i in range(1,10)]print(lst)#['python1', 'python2', 'python3', 'python4'... 筛选模式 12multiples = [i for i in range(10) if i % 3 is 0]print(multiples) # [0, 3, 6, 9] 列表推导式缺陷： 只能构建笔记复杂且有规律的列表 超过三层循环才能构建成功的，不建议 查找错误（debug模式）不行 字典推导式 1234lst1 = ['jay', 'jj', 'meet']lst2 = ['周杰伦', '林俊杰', '郭宝元']dic = &#123;lst1[i]: lst2[i] for i in range(len(lst1))&#125;print(dic) 集合推导式 123lst = [1, 2, 3, -1, -3, -7, 9]s = &#123;abs(i) for i in lst&#125;print(s) 生成器表达式 12#生成器表达式gen = (i**2 for i in range(10)) 推导式是iterable 表达式是iterator 内置函数一共68个内置函数 了解：all() any() bytes() callable() chr() complex() divmod() eval() exec() format() frozenset() globals() hash() help() id() input() int() iter() locals() next() oct() ord() pow() repr() round() 重点：abs() enumerate() filter() map() max() min() open() range() print() len() list() dict() str() float() reversed() set() sorted() sum() tuple() type() zip() dir() 暂时无法使用： classmethod() delattr() getattr() hasattr() issubclass() isinstance() object() property() setattr() staticmethod() super() 思维导图 了解1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#eval：执行字符串类型的代码，并返回最终结果。eval('print(666)') # 666#exec:可以处理代码流。msg=\"\"\"for i in range(10): print(i)\"\"\"exec(msg)#eval处理会报错#hash：获取一个对象（可哈希对象：int，str，Bool，tuple）的哈希值。print(hash(12322))#help：函数用于查看函数或模块用途的详细说明。print(help(list))print(help(str.split))#callable：函数用于检查一个对象是否是可调用的。如果返回True，object仍然可能调用失败；但如果返回False，调用对象ojbect绝对不会成功。name = 'alex'def func(): passprint(callable(name)) # Falseprint(callable(func)) # True#int：函数用于将一个字符串或数字转换为整型。#float：函数用于将整数和字符串转换成浮点数。#complex：函数用于创建一个值为 real + imag * j 的复数或者转化一个字符串或数为复数。如果第一个参数为字符串，则不需要指定第二个参数print(complex(\"1+2j\")) # (1+2j)print(complex(1,2)) # (1+2j)#bin：将十进制转换成二进制并返回。#oct：将十进制转化成八进制字符串并返回。#hex：将十进制转化成十六进制字符串并返回。#divmod：计算除数与被除数的结果，返回一个包含商和余数的元组(a // b, a % b)。#round：保留浮点数的小数位数，默认保留整数。#pow：求x**y次幂。（三个参数为x**y的结果对z取余）print(divmod(7,2)) # (3, 1)print(round(7/3,2)) # 2.33print(round(7/3)) # 2print(round(3.32567,3)) # 3.326print(pow(2,3)) # 两个参数为2**3次幂print(pow(2,3,3)) # 三个参数为2**3次幂，对3取余。#bytes：用于不同编码之间的转化。s = '你好'bs = s.encode('utf-8')print(bs)s1 = bs.decode('utf-8')print(s1)bs = bytes(s,encoding='utf-8')print(bs)b = '你好'.encode('gbk')b1 = b.decode('gbk')print(b1.encode('utf-8'))#ord:输入字符找该字符编码的位置#chr:输入位置数字找出其对应的字符# ord 输入字符找该字符编码的位置print(ord('a'))print(ord('中'))# chr 输入位置数字找出其对应的字符print(chr(97))print(chr(20013))#repr:返回一个对象的string形式（原形毕露）。# %r 原封不动的写出来name = 'taibai'print('我叫%r'%name)# repr 原形毕露print(repr('&#123;\"name\":\"alex\"&#125;'))print('&#123;\"name\":\"alex\"&#125;')#all：可迭代对象中，全都是True才是True#any：可迭代对象中，有一个True 就是True 重点123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102#print() 屏幕输出。def print(self, *args, sep=' ', end='\\n', file=None): # known special case of print \"\"\" print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False) file: 默认是输出到屏幕，如果设置为文件句柄，输出到文件 sep: 分隔符，打印多个值之间的分隔符，默认为空格 end: 每一次打印的结尾，默认为换行符 flush: 立即把内容输出到流文件，不作缓存 \"\"\" #int():pass#str():pass#bool():pass#set(): pass#list() 将一个可迭代对象转换成列表#tuple() 将一个可迭代对象转换成元组#dict() 通过相应的方式创建字典。#abs() 返回绝对值#sum() 求和l1 = [i for i in range(10)]print(sum(l1))#45print(sum(l1,100))#145#min() 求最小值#根据绝对值取最小a=min([-1, -2, -3], key=abs) # key可以传函数名print(a)dic = &#123;'a': 3, 'b': 2, 'c': 1&#125;print(min(dic)) # 默认按照键排序print(min(dic, key=lambda x: dic[x])) # 根据值排序#max() 最大值与最小值用法相同。#reversed() 将一个序列翻转, 返回翻转序列的迭代器 l = reversed('你好') # l 获取到的是一个生成器print(list(l))ret = reversed([1, 4, 3, 7, 9])print(list(ret)) # [9, 7, 3, 4, 1]#bytes() 把字符串转换成bytes类型s = '你好太白'bs = s.encode('utf-8')print(bs) # b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd\\xe6\\xad\\xa6\\xe5\\xa4\\xa7's1 = bs.decode('utf-8')print(s1) # 你好太白s = '你好'bs = bytes(s, encoding='utf-8')print(bs)# 将字符串转换成字节bs1 = str(bs, encoding='utf-8')print(bs1)# 将字节转换成字符串#zip() 拉链方法。函数用于将可迭代的对象作为参数,将对象中对应的元素打包成一个个元组,然后返回由这些元祖组成的内容,如果各个迭代器的元素个数不一致,则按照长度最短的返回l1 = [1, 2, 3, 4, 5]tu1 = (\"蔡徐坤\", \"笨比\", \"奥里给\", \"死丢比特\")s1 = \"一二三四五\"obj = zip(l1, tu1, s1)#取短的for i in obj: print(i)#(1, '蔡徐坤', '一')#(2, '笨比', '二')#(3, '奥里给', '三')#(4, '死丢比特', '四')#sorted排序函数，返回一个新的列表a = [(\"奥里给\", 3), (\"蔡徐坤\", 5), (\"礼拜\", 2), (\"杜甫\", 13), (\"sqq\", 33)]print(sorted(a, key=lambda x: x[1]))#filter筛选过滤，根据function返回的True或者False来判断是否保留此项数据#filter(function, iterable)lst = [&#123;'id': 1, 'name': 'alex', 'age': 18&#125;, &#123;'id': 1, 'name': 'wusir', 'age': 17&#125;, &#123;'id': 1, 'name': 'taibai', 'age': 16&#125;, ]ls = filter(lambda e: e['age'] &gt; 16, lst)print(list(ls))#[&#123;'id': 1, 'name': 'alex', 'age': 18&#125;, &#123;'id': 1, 'name': 'wusir', 'age': 17&#125;]#map#返回迭代器#语法: map(function,iterable) 可以对可迭代对象中的每一个元素进映射,分别取执行function#计算列表中每个元素的平方,返回新列表lst = [1,2,3,4,5]def func(s): return s*smp = map(func,lst)print(mp)print(list(mp))#改写成lambdalst = [1,2,3,4,5]print(list(map(lambda s:s*s,lst)))#计算两个列表中相同位置的数据的和lst1 = [1, 2, 3, 4, 5]lst2 = [2, 4, 6, 8, 10]print(list(map(lambda x, y: x+y, lst1, lst2)))#reduce python3不是内置函数了from functools import reducedef func(x,y): return x + y# reduce 的使用方式:# reduce(函数名,可迭代对象) # 这两个参数必须都要有,缺一个不行ret = reduce(func,[3,4,5,6,7])print(ret) # 结果 25 匿名函数函数名 = lambda 参数:返回值 所有类型的形参都可以加，但是一般使用匿名函数只是加位置参数，其他的用不到。 12func = lambda x,y: x if x &gt; y else yprint(func(3,100)) 闭包保证程序的安全 闭包：内层函数对外层函数的非全局变量的引用，就会形成闭包 123456789def make_averager(): l1=[]#自由变量 会一直保留 def averager(new_value): l1.append(new_value) return sum(l1)/len(l1) return averagerfunc=make_averager()print(func(1))print(func(3)) 代码判断闭包 12#判断是否为闭包func.__code__.co_freevars#查看自由变量名，如果有就是闭包 其余了解参数 12345678# 函数名.__code__.co_freevars 查看函数的自由变量print(avg.__code__.co_freevars) # ('series',)# 函数名.__code__.co_varnames 查看函数的局部变量print(avg.__code__.co_varnames) # ('new_value', 'total')# 函数名.__closure__ 获取具体的自由变量对象，也就是cell对象。# (&lt;cell at 0x0000020070CB7618: int object at 0x000000005CA08090&gt;,)# cell_contents 自由变量具体的值print(avg.__closure__[0].cell_contents) # [] 装饰器装饰器：在不改变原被装饰的函数的源代码以及调用方式下，为其添加额外的功能。 装饰器本质就是闭包 1234567891011121314151617import timedef timer(func): # func = index def inner(): start_time = time.time() func() end_time = time.time() print(f'此函数的执行效率为&#123;end_time-start_time&#125;') return innerdef index(): print(\"冲冲冲\") time.sleep(3) print(\"冲不动了\")index = timer(index)index()#冲冲冲#冲不动了#此函数的执行效率为3.0012567043304443 装饰器语法糖：@+装饰器函数名 1234567891011121314import timedef timer(func): # func = index def inner(): start_time = time.time() func() end_time = time.time() print(f'此函数的执行效率为&#123;end_time-start_time&#125;') return inner@timer#@+装饰器函数名def index(): print(\"冲冲冲\") time.sleep(3) print(\"冲不动了\")index() 标准装饰器 1234567def wrapper(func): def inner(*args,**kwargs): '''执行被装饰函数之前的操作''' r= func(*args,**kwargs) '''执行被装饰函数之后的操作''' return r return inner 带参装饰器 就是在原来的装饰器基础上再包装一层，用来传参，返回装饰器 12345678910def xxx(*args): def wrapper(func): def inner(*args,**kwargs): ret = func(*args,**kwargs) return ret return inner return wrapper@xxx('参数') # == @wrapperdef func(): pass 样例 123456789101112131415161718192021222324252627282930#用装饰器传入值，能控制写到哪个文件夹# 写了很多的函数# 添加日志 : 在 时间 调用了什么函数import timedef logger(path): def log(func): def inner(*args,**kwargs): ret = func(*args,**kwargs) with open(path,mode='a',encoding='utf-8') as f: msg = '%s 执行了%s'%(time.strftime('%Y-%m-%d %H:%M:%S'),func.__name__) f.write(msg) return ret return inner return log@logger('auth.log')def login(): print('登录的逻辑')@logger('auth.log')def register(): print('注册的逻辑')@logger('auth.log') # ret = log('auth.log') show_goods = ret(show_goods)def show_goods(): print('查看所有商品信息')@logger('buy.log')def add_goods(): print('商品加入购物车') 模块 内置模块 第三方模块 自定义模块 __name__：在脚本方式运行时，为__main__，以导入方式运行时，就是模块名字 123456def main(): #这里写本模块测试的代码 passif(__name__==\"__main__\"): main() __file__：当前文件的绝对路径 系统导入模块的路径 内存中：如果之前引入成功过某个模块，直接使用以及存在的模块 内置路径下：python解释器的lib文件夹下。 site-packages：放第三方模块 PYTHONPATH:import时寻找模块的路径 sys.path：是一个路径的列表 添加寻找模块的路径 12345import sysprint(__file__) # 当前文件的绝对路径import ospath = os.path.dirname(__file__) # 本文件的文件夹路径sys.path.append(path + \"/aa\") #添加引入路径 模块导入方式 import xxx：导入模块的所有成员 import aaa,bbb：导入多个模块的所有成员，不建议 from xxx import a：从xxx模块导入a成员 from xxx import *：导入模块的所有成员，不用写模块前缀 from xxx import a as b：把a改名为b import xxx as a：给模块取别名为a 导入后执行三件事 在内存中创建相应的名称空间 被导入模块有独立的名称空间，比如global引入也无法改变不同模块的值 执行名称空间的可执行代码 通过模块名.的方式引入代码 __all__是一个列表，用于表示本模块可以被外部使用的成员名。 123456a, b, c, d, e, f, g, h = 1__all__ = [ 'a', 'b', 'c'] 相对导入 .：表示当前路径 ..：上一级路径 123from ..z import zz#在父路径的z文件夹导入zz模块from . import abc#在当前文件夹下导入abc模块from ..z.zz import *#导入父路径的z文件夹下的zz模块 如果引入的模块它的成员也是引用的要用模块名.模块引用的引用名.成员名 模块循环/嵌套导入抛出异常：相互依赖，抛出异常。尽量避免。如果出现多个模块都需要共享的数据，可以将共享的数据集中存放到某一个地方 常用模块查看可用成员 12import xxxdir(xxx) python内置模块200多种 第三方模块6000多种 random random.random()：获取[0,1)内的浮点数 random.randint(a,b)：获取[a,b]内的一个整数 random.uniform(a,b)：获取[a,b)内的浮点数 random.shuffle(x)：混洗。将参数指定的数据中的元素打乱。参数必须为可变的数据类型 random.sample(x,k)：在x中随机抽取k个数据，组成列表返回 time time.time()：获取时间戳，秒数 time.gmtime()： 获取格式化时间对象（欧洲的） time.localtime()： 获取当地时间 tm_year：年 tm_mon：月, tm_mday：日, tm_hour：时, tm_min：分, tm_sec：秒, tm_wday：一周的第几天, tm_yday：一年的第几天, tm_isdst夏令时，现在已经取消了 time.gmtime(1)：时间元年过一秒的时间对象 time.strftime(“%Y %m %d %H:%M”)： 2019 12 28 18:42 Y表示2019，y表示19 time.strptime(“2019 12 28”,’%Y %m %d’)： 解析时间 time.mktime(time.localtime())：时间对象-&gt;时间戳 time.sleep(3)：暂停当前程序，3秒 datetime年月日：date、时分秒：time 1234567891011121314import datetimed = datetime.date(2019, 12, 28) # 指定年月日d.yeard.monthd.dayt = datetime.time(15, 48, 56) # 指定时分秒 time类无法参与运算t.hourt.minutet.seconddt = datetime.datetime(2019, 12, 28, 15, 48, 56) # 指定年月日时分秒1print(dt) # 2019-12-28 15:48:56td = datetime.timedelta(days=1) # 时间变化量res = d + td # d加一天 os当前执行这个python文件的工作目录相关的工作路径 os.getcwd() 获取当前工作目录，即当前python脚本工作的目录路径 os.chdir(“dirname”) 改变当前脚本工作目录；相当于shell下cd os.curdir 返回当前目录: (‘.’) os.pardir 获取当前目录的父目录字符串名：(‘..’) 和文件夹相关 os.makedirs(‘dirname1/dirname2’) 可生成多层递归目录 os.removedirs(‘dirname1’) 若目录为空，则删除，并递归到上一级目录，如若也为空，则删除，依此类推 os.mkdir(‘dirname’) 生成单级目录；相当于shell中mkdir dirname os.rmdir(‘dirname’) 删除单级空目录，若目录不为空则无法删除，报错；相当于shell中rmdir dirname os.listdir(‘dirname’) 列出指定目录下的所有文件和子目录，包括隐藏文件，并以列表方式打印 和文件相关 os.remove() 删除一个文件 os.rename(“oldname”,”newname”) 重命名文件/目录 os.stat(‘path/filename’) 获取文件/目录信息 和操作系统差异相关 os.sep 输出操作系统特定的路径分隔符，win下为”\\“,Linux下为”/“ os.linesep 输出当前平台使用的行终止符，win下为”\\t\\n”,Linux下为”\\n” os.pathsep 输出用于分割文件路径的字符串 win下为;,Linux下为: os.name 输出字符串指示当前使用平台。win-&gt;’nt’; Linux-&gt;’posix’ 和执行系统命令相关 os.system(“bash command”) 运行shell命令，直接显示 os.popen(“bash command).read() 运行shell命令，获取执行结果 os.environ 获取系统环境变量 path系列，和路径相关 os.path.abspath(path)返回path规范化的绝对路径,/开头默认当前盘符 os.path.split(path) 将path分割成目录和文件名二元组返回 os.path.dirname(path) 返回path的目录。其实就是os.path.split(path)的第一个元素 os.path.basename(path) 返回path最后的文件名。如何path以／或\\结尾，那么就会返回空值，即os.path.split(path)的第二个元素。 os.path.exists(path) 如果path存在，返回True；如果path不存在，返回False os.path.isabs(path) 如果path是绝对路径，返回True os.path.isfile(path) 如果path是一个存在的文件，返回True。否则返回False os.path.isdir(path) 如果path是一个存在的目录，则返回True。否则返回False os.path.join(path1[, path2[, …]]) 将多个路径组合后返回，第一个绝对路径之前的参数将被忽略 os.path.getatime(path) 返回path所指向的文件或者目录的最后访问时间 os.path.getmtime(path) 返回path所指向的文件或者目录的最后修改时间 os.path.getsize(path) 返回path的大小 sys sys.argv：命令行参数List，第一个元素是程序本身路径。可以获取脚本后加的参数 sys.exit(n)：退出程序，正常退出时exit(0),错误退出sys.exit(1) sys.version：获取Python解释程序的版本信息 sys.path：返回模块的搜索路径，初始化时使用PYTHONPATH环境变量的值 sys.platform：返回操作系统平台名称 sys.setrecursionlimit(limit)：设置递归的最大次数 sys.modules：查看已经加载的模块 json与内存的序列化和反序列化 json.dumps(obj)：序列化 json.loads(str)：反序列化 1234567891011import jsondic =[1,['a','b','c'],3,&#123;'k1':'v1','k2':'v2'&#125;]str_dic = json.dumps(dic) #序列化：将一个字典转换成一个字符串print(type(str_dic),str_dic) #&lt;class 'str'&gt; [1, [\"a\", \"b\", \"c\"], 3, &#123;\"k1\": \"v1\", \"k2\": \"v2\"&#125;]#可以嵌套#注意，json转换完的字符串类型的字典中的字符串是由\"\"表示的#元组序列化后变成了列表dic2 = json.loads(str_dic) #反序列化：将一个字符串格式的字典转换成一个字典#注意，要用json的loads功能处理的字符串类型的字典中的字符串必须由\"\"表示print(type(dic2),dic2) #&lt;class 'list'&gt; [1, ['a', 'b', 'c'], 3, &#123;'k1': 'v1', 'k2': 'v2'&#125;] 与文件的序列化和反序列化 12345678910import jsonf = open('json_file.json','w')dic = &#123;'k1':'v1','k2':'v2','k3':'v3'&#125;json.dump(dic,f) #dump方法接收一个文件句柄，直接将字典转换成json字符串写入文件f.close()# json文件也是文件，就是专门存储json字符串的文件。f = open('json_file.json')dic2 = json.load(f) #load方法接收一个文件句柄，直接将文件中的json字符串转换成数据结构返回f.close()print(type(dic2),dic2) 通常一个文件只存一个json。如果想存多个，可以通过\\n来实现 picklepython的序列化和反序列化 内存 123456789101112import pickle # 所有数据类型dic = &#123;'k1': 'v1', 'k2': 'v2', 'k3': 'v3'&#125;str_dic = pickle.dumps(dic) # bytes类型dic2 = pickle.loads(str_dic) # 反序列化# 还可以序列化对象import pickledef func(): print(666)ret = pickle.dumps(func)#可以序列化函数f1 = pickle.loads(ret) # f1得到 func函数的内存地址f1() # 执行func函数 文件 1234567891011121314151617181920212223242526import pickledic = &#123;(1, 2): 'oldboy', 1: True, 'set': &#123;1, 2, 3&#125;&#125;f = open('pick序列化', mode='wb')pickle.dump(dic, f)f.close()with open('pick序列化', mode='wb') as f1: pickle.dump(dic, f1)dic1 = &#123;'name': 'oldboy1'&#125;dic2 = &#123;'name': 'oldboy2'&#125;dic3 = &#123;'name': 'oldboy3'&#125;f = open('pick多数据', mode='wb')pickle.dump(dic1, f)pickle.dump(dic2, f)pickle.dump(dic3, f)f.close()f = open('pick多数据', mode='rb')while True: try: print(pickle.load(f)) except EOFError: breakf.close() 可以但不推荐使用多次 hashlibsha：后面数字越大，加密越复杂，安全系数越大，耗时越长 12345678import hashlibmd5 = hashlib.md5() # 获取一个新的md5加密对象amd5= hashlib.md5(\"盐\")#创建对象时加盐hashlib.sha224()#获取加密对象md5.update('abc中文'.encode('utf-8'))#加密不返回res=md5.hexdigest()#返回加密结果res=md5.digest()#二进制加密结果 update多次调用，就是在之前的基础上，再加密，结果是不同的。 如update(&quot;111&quot;.encode(&#39;utf-8&#39;))再update(&quot;222&quot;.encode(&#39;utf-8&#39;))和update(&quot;111222&quot;.encode(&#39;utf-8&#39;))是一样的 collections namedtuple: 生成可以使用名字来访问元素内容的tuple deque: 双端队列，可以快速的从另外一侧追加和推出对象 Counter: 计数器，主要用来计数 OrderedDict: 有序字典 defaultdict: 带有默认值的字典 123456789101112131415import collectionstp = collections.namedtuple('这里是描述信息', ['元组的参数1', '参数2', '参数3'])t = tp(1, 2, 3) # 设置值print(t.元组的参数1) # 通过参数名引用print(t[1]) # 通过索引引用d = collections.defaultdict(int, name='Andy', age=10) # 第一个参数，确认返回值print(d['asdas']) # 取不到返回第一个参数构造的值，并且添加进去def a(): return 10collections.defaultdict(a) # 用自己的方法传入# 传入可hash的，返回计数c = collections.Counter('asdassadsadasdasdsa')print(c) # Counter(&#123;'a': 7, 's': 7, 'd': 5&#125;)c.most_common(2) # 以列表的方式返回(值，数)的元组 shutil shutil.copyfileobj(fsrc, fdst[, length])：将文件内容拷贝到另一个文件中 shutil.copyfile(src, dst)：拷贝文件 shutil.copymode(src, dst)：仅拷贝权限。内容、组、用户均不变 shutil.copystat(src, dst)：仅拷贝状态的信息，包括：mode bits, atime, mtime, flags shutil.copy(src, dst)：拷贝文件和权限 shutil.copy2(src, dst)：拷贝文件和状态信息 shutil.ignore_patterns(*patterns)：忽略什么文件，往往作为参数传入 shutil.copytree(src, dst, symlinks=False, ignore=None)：递归的去拷贝文件夹 shutil.rmtree(path[, ignore_errors[, onerror]])：递归的去删除文件 shutil.move(src, dst)：递归的去移动文件，它类似mv命令。 shutil.make_archive(base_name, format,...)：创建压缩包并返回文件路径 base_name： 压缩包的文件名，也可以是压缩包的路径。只是文件名时，则保存至当前目录，否则保存至指定路径 format： 压缩包种类，“zip”, “tar”, “bztar”，“gztar” root_dir： 要压缩的文件夹路径（默认当前目录） owner： 用户，默认当前用户 group： 组，默认当前组 logger： 用于记录日志，通常是logging.Logger对象 12345678910111213141516171819import shutilshutil.copy2('D:\\python_learn\\lianjia.html', 'D:\\python_learn\\lianjia_bk.html')#拷贝shutil.copytree(\"outer\", \"outer3\", ignore=shutil.ignore_patterns(\"__init__.py\",\"sag\"))#忽略文件，可以放规则shutil.rmtree(\"folder1\",ignore_errors=True)#忽略错误shutil.move('folder1', 'folder2')shutil.move(\"folder1\",\"folder2\", copy_function=shutil.copy2)#移动文件，total, used, free = shutil.disk_usage(\".\")#查看磁盘使用空间，也可以传c:\\\\print(\"当前磁盘共: %iGB, 已使用: %iGB, 剩余: %iGB\"%(total / 1073741824, used / 1073741824, free / 1073741824))shutil.make_archive('压缩文件夹的名字', 'zip','待压缩的文件夹l路径')shutil.unpack_archive('要解压的文件',r'解压到的路径') logging12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import logging# 输出内容是有等级的 : 默认处理warning级别以上的所有信息logging.debug('debug message') # 调试logging.info('info message') # 信息logging.warning('warning message') # 警告logging.error('error message') # 错误logging.critical('critical message') # 批判性的# 1.无论你希望日志里打印哪些内容,都得你自己写,没有自动生成日志这种事儿logging.basicconfig# 输出到屏幕logging.basicConfig( format='%(asctime)s - %(name)s - %(levelname)s[line :%(lineno)d]-%(module)s: %(message)s', datefmt='%Y-%m-%d %H:%M:%S %p',)logging.warning('warning message test2')logging.error('error message test2')logging.critical('critical message test2')# 输出到文件,并且设置信息的等级logging.basicConfig( format='%(asctime)s - %(name)s - %(levelname)s[line :%(lineno)d]-%(module)s: %(message)s', datefmt='%Y-%m-%d %H:%M:%S %p', filename='tmp.log', level=logging.DEBUG # 默认追加可以用filemode改成覆盖)# 同时向文件和屏幕上输出 和 乱码fh = logging.FileHandler('tmp.log', encoding='utf-8') # 输出到文件sh = logging.StreamHandler() # 输出到屏幕logging.basicConfig( format='%(asctime)s - %(name)s - %(levelname)s[line :%(lineno)d]-%(module)s: %(message)s', datefmt='%Y-%m-%d %H:%M:%S %p', level=logging.DEBUG, handlers=[fh, sh] # 这里可以配置多个，可以输出到多个文件)# logging.debug('debug 信息错误 test2')# logging.info('warning 信息错误 test2')# logging.warning('warning message test2')# logging.error('error message test2')# logging.critical('critical message test2')# 做日志的切分import timefrom logging import handlerssh = logging.StreamHandler()rh = handlers.RotatingFileHandler('myapp.log', maxBytes=1024*1024, backupCount=5) # 按照大小做切割1024kb，只保留5个文件，如果切到第六个，就删除第一个文件fh = handlers.TimedRotatingFileHandler(filename='x2.log', when='s', interval=5, encoding='utf-8')#按时间切割when表示按秒切，h为按小时。logging.basicConfig( format='%(asctime)s - %(name)s - %(levelname)s[line :%(lineno)d]-%(module)s: %(message)s', datefmt='%Y-%m-%d %H:%M:%S %p', level=logging.DEBUG, handlers=[fh, rh, sh]) logging.basicConfig()函数中可通过具体参数来更改logging模块默认行为，可用参数有： filename：用指定的文件名创建FiledHandler，这样日志会被存储在指定的文件中。 filemode：文件打开方式，在指定了filename时使用这个参数，默认值为“a”还可指定为“w”。 format：指定handler使用的日志显示格式。 datefmt：指定日期时间格式。 level：设置rootlogger（后边会讲解具体概念）的日志级别 stream：用指定的stream创建StreamHandler。可以指定输出到sys.stderr,sys.stdout或者文件 (f=open(‘test.log’,’w’))，默认为sys.stderr。若同时列出了filename和stream两个参数，则stream参数会被忽略。 format参数中可能用到的格式化串： %(name)s Logger的名字 %(levelno)s 数字形式的日志级别 %(levelname)s 文本形式的日志级别 %(pathname)s 调用日志输出函数的模块的完整路径名，可能没有 %(filename)s 调用日志输出函数的模块的文件名 %(module)s 调用日志输出函数的模块名 %(funcName)s 调用日志输出函数的函数名 %(lineno)d 调用日志输出函数的语句所在的代码行 %(created)f 当前时间，用UNIX标准的表示时间的浮 点数表示 %(relativeCreated)d 输出日志信息时的，自Logger创建以 来的毫秒数 %(asctime)s 字符串形式的当前时间。默认格式是 “2003-07-08 16:49:45,896”。逗号后面的是毫秒 %(thread)d 线程ID。可能没有 %(threadName)s 线程名。可能没有 %(process)d 进程ID。可能没有 %(message)s用户输出的消息 logger对象配置 123456789101112131415161718192021import logginglogger = logging.getLogger()# 创建一个handler，用于写入日志文件fh = logging.FileHandler('test.log',encoding='utf-8') # 再创建一个handler，用于输出到控制台 ch = logging.StreamHandler() formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')fh.setLevel(logging.DEBUG)fh.setFormatter(formatter) ch.setFormatter(formatter) logger.addHandler(fh) #logger对象可以添加多个fh和ch对象 logger.addHandler(ch) logger.debug('logger debug message') logger.info('logger info message') logger.warning('logger warning message') logger.error('logger error message') logger.critical('logger critical message') logger配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778\"\"\"logging配置\"\"\"import osimport logging.config# 定义三种日志输出格式 开始standard_format = '[%(asctime)s][%(threadName)s:%(thread)d][task_id:%(name)s][%(filename)s:%(lineno)d]' \\ '[%(levelname)s][%(message)s]' #其中name为getlogger指定的名字simple_format = '[%(levelname)s][%(asctime)s][%(filename)s:%(lineno)d]%(message)s'id_simple_format = '[%(levelname)s][%(asctime)s] %(message)s'# 定义日志输出格式 结束logfile_dir = os.path.dirname(os.path.abspath(__file__)) # log文件的目录logfile_name = 'all2.log' # log文件名# 如果不存在定义的日志目录就创建一个if not os.path.isdir(logfile_dir): os.mkdir(logfile_dir)# log文件的全路径logfile_path = os.path.join(logfile_dir, logfile_name)# log配置字典LOGGING_DIC = &#123; 'version': 1, 'disable_existing_loggers': False, 'formatters': &#123; 'standard': &#123; 'format': standard_format &#125;, 'simple': &#123; 'format': simple_format &#125;, &#125;, 'filters': &#123;&#125;, 'handlers': &#123; #打印到终端的日志 'console': &#123; 'level': 'DEBUG', 'class': 'logging.StreamHandler', # 打印到屏幕 'formatter': 'simple' &#125;, #打印到文件的日志,收集info及以上的日志 'default': &#123; 'level': 'DEBUG', 'class': 'logging.handlers.RotatingFileHandler', # 保存到文件 'formatter': 'standard', 'filename': logfile_path, # 日志文件 'maxBytes': 1024*1024*5, # 日志大小 5M 'backupCount': 5, 'encoding': 'utf-8', # 日志文件的编码，再也不用担心中文log乱码了 &#125;, &#125;, 'loggers': &#123; #logging.getLogger(__name__)拿到的logger配置 '': &#123; 'handlers': ['default', 'console'], # 这里把上面定义的两个handler都加上，即log数据既写入文件又打印到屏幕 'level': 'DEBUG', 'propagate': True, # 向上（更高level的logger）传递 &#125;, &#125;,&#125;def load_my_logging_cfg(): logging.config.dictConfig(LOGGING_DIC) # 导入上面定义的logging配置 logger = logging.getLogger(__name__) # 生成一个log实例 logger.info('It works!') # 记录该文件的运行状态if __name__ == '__main__': load_my_logging_cfg() 目录结构1234567- bin - start.py- conf- core- db- lib- log re模块、正则表达式正则表达式正则测试网站 元字符 匹配内容 \\w 匹配一位字母（包含中文）或数字或下划线 \\W 匹配一位非字母（包含中文）或数字或下划线 \\s 匹配任意的空白符（\\t，空格等） \\S 匹配任意非空白符 \\d 匹配一位数字 \\D p匹配非数字 \\A 从字符串开头匹配 \\z 匹配字符串的结束，如果是换行，只匹配到换行前的结果 \\n 匹配一个换行符 \\t 匹配一个制表符 ^ 匹配字符串的开始 $ 匹配字符串的结尾 . 匹配任意字符，除了换行符，当re.DOTALL标记被指定时，则可以匹配包括换行符的任意字符。 […] 匹配字符组中的字符 [^…] 匹配除了字符组中的字符的所有字符 * 匹配0个或者多个左边的字符。 + 匹配一个或者多个左边的字符。 ？ 匹配0个或者1个左边的字符，{}后非贪婪方式。 {n} 精准匹配n个前面的表达式。 {n,m} 匹配n到m次由前面的正则表达式定义的片段，贪婪方式 a|b 匹配a或者b。 () 匹配括号内的表达式，也表示一个组 \\b 单词结尾 \\ 转义 [xxx]：一个[]表示只匹配一个，内部写要匹配的字符。根据ascii进行范围比对。如果要匹配abc中的任意一个，就是[abc]或者 [0-9]表示匹配0到9任一字符 [a-zA-Z]：所有大小写 ^ab&amp;：表示匹配ab其他都不匹配 ing\\b：以ing结尾的单词 W{}：用来约束左边的符号。 \\d{2,}：匹配数字至少2个 贪婪匹配：在量词允许的情况下，按最多的匹配内容 \\d{3,}4：如果一个字符串出现多个4，一直会匹配到最后一个4 \\d{3,}?4：在量词后加?表示非贪婪模式。匹配到第一个4 \\：转义如\\\\表示\\ 在[]里，.、()等没有特殊意义，就表示该符号，但是-需要转义要用\\- ?问号常用到非贪婪匹配 12345678910import reres = re.findall('9(\\d)(\\d)', '19740asdsa596115rrs') # 找到所有print(res) # [('7', '4'), ('6', '1')]res = re.search('9(\\d)(\\d)', '19740asdsa56115rrs') # 找到第一个对象就返回if res: print(res) # &lt;re.Match object; span=(1, 4), match='974'&gt; print(res.group(0)) # 974 print(res.group(1)) # 7 print(res.group(2)) # 4 re模块 findall：按照完整的正则进行匹配，但只显示括号里匹配到的内容。没有括号显示所有 如果多个括号列表返回，元素为匹配到的括号元组 search：按照完整的正则进行匹配。反对一个对象 group()：返回第一个匹配到完整显示 group(1)：返回匹配到的第一个括号，2、3…按照顺序 ?:是可以不显示 ?P&lt;name&gt;：取名 (?P=name)：引用取名的，如果不相同就匹配不上 \\1：表示引用第一组的内容，但是\\1有特殊含义，所有往往在字符串前加r。用的少 123456789101112131415161718192021222324252627# (?P&lt;名字&gt;正则表达式)# ret.group('名字')# 分组命名的引用import reexp= '&lt;abc&gt;akd7008&amp;(&amp;*)hgdwuih&lt;/abb&gt;008&amp;(&amp;*)hgdwuih&lt;/abd&gt;'ret= re.search('&lt;(?P&lt;tag&gt;\\w+)&gt;.*?&lt;/(?P=tag)&gt;',exp)print(ret)import reexp= '&lt;abc&gt;akd7008&amp;(&amp;*)hgdwuih&lt;/abc&gt;008&amp;(&amp;*)hgdwuih&lt;/abd&gt;'ret= re.search(r'&lt;(\\w+)&gt;.*?&lt;/\\1&gt;',exp)ret= re.search('&lt;(\\w+)&gt;.*?&lt;/\\\\1&gt;',exp)print(ret)import reret=re.findall(r\"\\d+\\.\\d+|(\\d+)\",\"1-2*(60+(-40.35/5)-(-4*3))\")print(ret)ret = ['1', '2', '60', '', '5', '4', '3','','']ret.remove('')print(ret)ret = filter(lambda n:n,ret)print(list(ret))# 分组命名(?P&lt;组名&gt;正则) (?P=组名)# 有的时候我们要匹配的内容是包含在不想要的内容之中的,# 只能先把不想要的内容匹配出来,然后再想办法从结果中去掉 re不常用方法 12345import rere.split('[|]','sa|dsadd')#根据正则表达式切割保留，带括号会保留re.sub('\\d+','数字','sads45dfs566dd3556sadsa',2)#根据正则替换2次。sads数字dfs数字dd3556sadsare.subn('\\d+','数字','sads45dfs566dd3556sadsa')#返回替换后的和次数元组('sads数字dfs数字dd数字sadsa', 3)re.match('\\d+','123sdasa')#相当于在正则之前加了^。&lt;re.Match object; span=(0, 3), match='123'&gt; re编译和迭代 123456789import reret = re.compile('\\d+') # 编译正则表达式ret.search(\"传入字符串\\'sadsa56165\\'\")# 节省时间ret = re.finditer('\\d+', \"sad516das11d56as4dsa561das531fa6w465s3a21d321as5f1ds531gs56ad1ads65f4a684fa9d\")for i in ret: print(i.group())# 两个可以结合使用 递归python最大递归深度1000层 修改最大递归深度 12import syssys.setrecursionlimit(100000) 面向对象基础语法对象初始化调用__init__方法，通过self.属性名添加属性。 属性的增删改查 12345678910111213141516class Person: print(11) # 类内部会依次执行，方法不会执行 def __init__(self, name, sex, job): # 必须这么叫，不能改变，属性都写在这 print('init我被调用了') self.name = name self.sex = sex self.job = jobit = Person(\"蔡徐坤\", \"女性\", \"艺人\") # 类名()会调用__init__方法。会将self返回print(it.name)print(it.__dict__['sex'])it.sss=1#可以增加属性print(it.__dict__)del it.sssprint(it.__dict__) 实例化所经历的步骤 类名() 之后的第一个事儿 :开辟一块儿内存空间 调用__init__把空间的内存地址作为self参数传递到函数内部 所有的这一个对象需要使用的属性都需要和self关联起来 执行完init中的逻辑之后,self变量会自动的被返回到调用处(发生实例化的地方) 对象会存储类指针，指向类 类中的变量是静态变量对象中的变量只属于对象本身,每个对象有属于自己的空间来存储对象的变量当使用对象名去调用某一个属性的时候会优先在自己的空间中寻找,找不到再去对应的类中寻找如果自己没有就引用类的,如果类也没有就报错对于类来说,类中的变量所有的对象都是可以读取的,并且读取的是同一份变量 1234567891011class Person: def __init__(self, name, sex, job): print('init我被调用了') self.name = name self.sex = sex self.job = job def xd(self, action): # 这个self就是实例化的对象 print(self.name + \"在\" + str(action))it = Person(\"蔡徐坤\", \"女性\", \"艺人\")it.xd(\"舔狗\") # 会自动传入selfPerson.xd(it, \"舔狗\") # 这样也是可以调用的 组合：就是对象作为另一个对象的属性 直接写在类下的是静态变量 12345678910111213141516171819class A: Country = '中国' # 静态变量/静态属性 存储在类的命名空间里的 def __init__(self,name,age,country): # 绑定方法 存储在类的命名空间里的 self.name = name self.age = age self.country = country def func1(self): print(self) def func2(self):pass def func3(self):pass def func4(self):pass def func5(self):passa = A('alex',83,'印度')b = A('wusir',74,'泰国人')a.Country = '日本人'#对象调用静态变量无法修改，这里是增加属性print(a.Country)#日本人print(b.Country)#中国print(A.Country)#中国 单继承 123456789class D: def func(self): print('in D')class C(D):passclass A(C): def func(self): print('in A')class B(A):passB().func() 多继承 12345678#多继承class B: def func(self):print('in B')class A: def func(self):print('in A')class C(B,A):passC().func() 调用父类的方法时要用,父类名.方法名(self,其他参数)。 一个类有多个父类,在调用父类方法的时候,按照继承顺序,先继承的就先寻找 方法和函数的区别 1234567891011121314from types import FunctionType,MethodType# FunctionType : 函数# MethodType : 方法class A: def func(self): print('in func')print(A.func) # 函数a = A()print(a.func) # 方法print(isinstance(a.func,FunctionType))print(isinstance(a.func,MethodType))print(isinstance(A.func,FunctionType))print(isinstance(A.func,MethodType)) 特殊的类属性 类名.__name__：类的名字 类名.__doc__：类的文档字符串 类名.__base__：类的第一个父类 类名.__bases__：类的所有父类（元组） 类名.__dict__：类的字典属性 类名.__module__：类定义所在的模块 类名.__class__：实例对于的类 123456789101112131415class A: role = '法师' def func1(self):pass def func2(self):passclass B:passclass C(B,A):passprint(A.__base__)#&lt;class 'object'&gt;print(C.__base__)#&lt;class '__main__.B'&gt;print(C.__bases__)#(&lt;class '__main__.B'&gt;, &lt;class '__main__.A'&gt;)print(A.__dict__)print(A.__name__)#Aprint(A.__class__)#&lt;class 'type'&gt;大部分类的类型都是typeprint(B.__class__)#&lt;class 'type'&gt;print(C.__class__)#&lt;class 'type'&gt;print(C.__module__)#__main__ object类 类祖宗所有在python3当中的类都是继承object类的，object中有init所有的类都默认的继承object。 用pickle将对象存储与读取 1234567891011121314151617181920class Course: def __init__(self,name,period,price): self.name = name self.period = period self.price = pricepython = Course('python','6 moneth',21800)linux = Course('linux','5 moneth',19800)go = Course('go','4 moneth',12800)import picklewith open('pickle_file','ab') as f: pickle.dump(linux,f) pickle.dump(go,f)with open('pickle_file','rb') as f: while True: try: obj = pickle.load(f) print(obj.name,obj.period) except EOFError: break 对象必须在python已定义，不然会报错 进阶语法 新式类：继承Object对象的 经典类：不继承Object对象的 python3默认继承Object，python3没有经典类 多继承时 新式类：C3算法 经典类：深度搜索，一条道走到黑，再回头 C3算法如果是单继承 那么总是按照从子类-&gt;父类的顺序来计算查找顺序如果是多继承 需要按照自己本类,父类1的继承顺序,父类2的继承顺序,…merge的规则 :如果一个类出现在从左到右所有顺序的最左侧,并且没有在其他位置出现,那么先提出来作为继承顺序中的一个或 一个类出现在从左到右顺序的最左侧,并没有在其他顺序中出现,那么先提出来作为继承顺序中的一个如果从左到右第一个顺序中的第一个类出现在后面且不是第一个,那么不能提取,顺序向后继续找其他顺序中符合上述条件的类 12345678910111213A为B、C的父类B为D的父类C为B的父类D、E为F的父类F(D,E) &#x3D; merge(D(B) + E(C)) &#x3D; [F] + [DBAO] + [ECAO] F &#x3D; [DBAO] + [ECAO] FD &#x3D; [BAO] + [ECAO] FDB &#x3D; [AO] + [ECAO] FDBE &#x3D; [AO] + [CAO] FDBEC&#x3D; [AO] + [AO] FDBECA&#x3D; [O] + [O] FDBECAO 步骤解读 本身永远在最前面 然后看找第一个是D，然后往后找，发现没有重复的D，就提出D 然后左边第一个是B，再往后找，没有重复的B，提出B 然后左边第一个是A，有重复。再找，就是E，往后E无重复。提出E 然后左边第一个是A，有重复，再找，就是C，往后C无重复，提出C 左边第一个是A，并且后面所有列的第一个都是A，那么提出A 左边第一个是O，并且后面所有列的第一个都是O，那么提出O 只要知道经典类和新式类继承方式不同，如果一个类的继承顺序看不懂，可以用类名.mro()。查看继承顺序 抽象类 类似Java的接口类，用来规定开发规范 通过未实现抛异常的方式，若子类继承，未实现的话，调用方法会抛异常 1234class Payment: # 抽象类 def pay(self,money): '''只要你见到了项目中有这种类,你要知道你的子类中必须实现和pay同名的方法''' raise NotImplementedError('请在子类中重写同名pay方法') 用abc模块，约束实现。用装饰器的方式，约束子类。如果子类继承却未实现接口，那么子类就无法被实例化 1234567891011121314from abc import ABCMeta,abstractmethodclass Payment(metaclass=ABCMeta): @abstractmethod def pay(self,money): '''只要你见到了项目中有这种类,你要知道你的子类中必须实现和pay同名的方法''' raise NotImplementedError('请在子类中重写同名pay方法')class Alipay(Payment): def __init__(self,name): self.name = name def pay(self,money): dic = &#123;'uname':self.name,'price':money&#125; # 想办法调用支付宝支付 url连接 把dic传过去 print('%s通过支付宝支 付%s钱成功'%(self.name,money)) 推荐用抛异常的方式，因为依赖abc模块有依赖性，如果abc模块没了，项目就跑不动了 鸭子类型 我们把实现了一个类型的方法，叫做鸭子类型 如实现了__iter__、__next__叫做迭代器。就可以迭代。就是鸭子类型 如实现了__len__方法就可以调用len()就是鸭子类型 爬虫环境的准备安装anaconda，直接取官网下载，然后一步一步安装即可。 安装jupyter直接pip install jupyter然后用jupyter notebook启动。 Anaconda是一个集成环境（基于机器学习和数据分析的开发环境） 基于浏览器的一种可视化开发工具：jupyter notebook 可以在指定目录的终端中录入jupyter notebook指令，然后启动服务。 cell是分为不同模式的： Code:编写python代码 markDown：编写笔记 快捷键： 添加cell：a，b 删除cell：x 执行：shift+enter tab： 切换cell的模式： m y 打开帮助文档：shift+tab Anaconda的使用，Anaconda如果有菜单有图标就代表安装成功，命令行没有可能是环境没配 在Anaconda中启动jupyter无法选择路径，要在Environments-&gt;base(root)选择启动按钮–&gt;open Terminal，然后在终端打开 基础爬虫：就是通过编写程序模拟浏览器上网，然后让其去互联网上爬取数据的过程爬虫的分类： 通用爬虫：抓取互联网中的一整张页面数据 聚焦爬虫：抓取页面中的局部数据 增量式爬虫：用来监测网站数据更新的情况，以便爬取到网站最新更新出来的数据反爬机制反反爬策略 爬虫合法问题 爬取数据的行为风险的体现： 爬虫干扰了被访问网站的正常运营； 爬虫抓取了受到法律保护的特定类型的数据或信息。 规避风险： 严格遵守网站设置的robots协议； 在规避反爬虫措施的同时，需要优化自己的代码，避免干扰被访问网站的正常运行； 在使用、传播抓取到的信息时，应审查所抓取的内容，如发现属于用户的个人信息、隐私或者他人的商业秘密的，应及时停止并删除。robots协议：文本协议 在网站www.xxx.com/robots.txt查看文本协议 robots协议特性：防君子不防小人的文本协议 requests模块requests模块是Python中封装好的一个基于网络请求的模块。 requests模块可以用来模拟浏览器发请求 requests模块的环境安装：pip install requests requests模块的编码流程： 1.指定url 2.发起请求 3.获取响应数据 4.持久化存储 简单爬取搜狗 1234567891011121314151617#解决UA检测url = 'https://www.sogou.com/web'#实现参数动态化wd = input('enter a key:')params = &#123; 'query':wd#指定携带的参数&#125;headers = &#123;#请求头消息 'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36'&#125;#在请求中需要将请求参数对应的字典作用到params这个get方法的参数中response = requests.get(url=url,params=params,headers=headers)response.encoding = 'utf-8' #修改响应数据的编码格式page_text = response.textfileName = wd+'.html'with open(fileName,'w',encoding='utf-8') as fp: fp.write(page_text) UA检测：门户网站通过检测请求载体的身份标识判定改请求是否为爬虫发起的请求 UA伪装：Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36 在请求的页面搜索内容，如果没有对应内容。那么全球的内容应该是动态加载。直接全局搜索对应内容，找到ajax请求。然后分析请求 12345678910111213141516171819#豆瓣爬取样例import requestsurl = 'https://movie.douban.com/j/chart/top_list'start = 0#input('您想从第几部电影开始获取:')limit = 2000#input('您想获取多少电影数据:')headers = &#123; 'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36'&#125;dic = &#123; 'type': '13', 'interval_id': '100:90', 'action': '', 'start': start, 'limit': limit,&#125;response = requests.get(url=url,params=dic,headers=headers)page_text = response.json() #json()返回的是序列化好的实例对象for dic in page_text: print(dic['title']+':'+dic['score']) 数据解析数据解析的作用： 可以帮助我们实现聚焦爬虫 数据解析的实现方式： 正则 bs4 xpath：重点 pyquery：自己拓展，跟jq很像 数据解析的通用原理（聚焦爬虫爬取的数据都被存储在了相关的标签之中and相关标签的属性中） 先定位标签 然后取文本或者取属性 文件头 1234import requestsheaders = &#123; 'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36'&#125; 12345#如何爬取图片url = 'https://pic.qiushibaike.com/system/pictures/12223/122231866/medium/IZ3H2HQN8W52V135.jpg'img_data = requests.get(url,headers=headers).content #byte类型数据with open('./img.jpg','wb') as fp: fp.write(img_data) 12345#直接利用已有方法写到本地#弊端：不能使用UA伪装from urllib import requesturl = 'https://pic.qiushibaike.com/system/pictures/12223/122231866/medium/IZ3H2HQN8W52V135.jpg'request.urlretrieve(url,filename='./qiutu.jpg') 123456789101112131415161718192021#糗图爬取1-3页所有的图片import reimport os#1.使用通用爬虫将前3页对应的页面源码数据进行爬取#通用的url模板(不可变)dirName = './imgLibs'if not os.path.exists(dirName): os.mkdir(dirName)url = 'https://www.qiushibaike.com/pic/page/%d/'for page in range(1,4): new_url = format(url%page) page_text = requests.get(new_url,headers=headers).text #每一个页码对应的页面源码数据 #在通用爬虫的基础上实现聚焦爬虫（每一个页码对应页面源码数据中解析出图片地址） ex = '&lt;div class=\"thumb\"&gt;.*?&lt;img src=\"(.*?)\" alt.*?&lt;/div&gt;' img_src_list = re.findall(ex,page_text,re.S)#re.S忽略回车 for src in img_src_list: src = 'https:'+src img_name = src.split('/')[-1] img_path = dirName+'/'+img_name #./imgLibs/xxxx.jpg request.urlretrieve(src,filename=img_path) print(img_name,'下载成功！！！') bs4解析 bs4解析的原理： 实例化一个BeautifulSoup的对象，需要将即将被解析的页面源码数据加载到该对象中 调用BeautifulSoup对象中的相关方法和属性进行标签定位和数据提取 环境的安装： pip install bs4 pip install lxml BeautifulSoup的实例化： BeautifulSoup(fp,’lxml’):将本地存储的一个html文档中的数据加载到实例化好的BeautifulSoup对象中 BeautifulSoup(page_text,’lxml’):将从互联网上获取的页面源码数据加载到实例化好的BeautifulSoup对象中 定位标签的操作： soup.tagName：定位到第一个出现的tagName标签 属性定位：soup.find(‘tagName’,attrName=’value’) 属性定位:soup.find_all(‘tagName’,attrName=’value’),返回值为列表 选择器定位：soup.select(‘选择器’) 层级选择器：&gt;表示一个层级 空格表示多个层级 取文本 .string:获取直系的文本内容，比如div包p标签再有内容无法获取，而text可以获取 .text:获取所有的文本内容 取属性 tagName[‘attrName’] 12345678910111213141516171819#bs4解析定位样例from bs4 import BeautifulSoupfp = open('./test.html','r',encoding='utf-8')soup = BeautifulSoup(fp,'lxml')soup.divsoup.find('div',class_='song')soup.find('a',id=\"feng\")#id属性就是idsoup.find_all('div',class_=\"song\")soup.select('#feng')#id为feng如果定位class则为.xxxsoup.select('.tang &gt; ul &gt; li')#class为tang的标签下的ul下的lisoup.select('.tang li') #class为tang属性下的li。li和tang可以隔多个标签a_tag = soup.select('#feng')[0]a_tag.textdiv = soup.divdiv.stringdiv = soup.find('div',class_=\"song\")#因为class是关键字，这里就是class_div.string#获取标签的a_tag = soup.select('#feng')[0]a_tag['href'] 123456789101112131415161718#用bs4爬取#爬取三国整篇内容（章节名称+章节内容）http://www.shicimingju.com/book/sanguoyanyi.htmlfp = open('sanguo.txt','w',encoding='utf-8')main_url = 'http://www.shicimingju.com/book/sanguoyanyi.html'page_text = requests.get(main_url,headers=headers).text#解析出章节名称和章节详情页的urlsoup = BeautifulSoup(page_text,'lxml')a_list = soup.select('.book-mulu &gt; ul &gt; li &gt; a') #返回的列表中存储的是一个个a标签for a in a_list: title = a.string detail_url = 'http://www.shicimingju.com'+a['href'] detail_page_text = requests.get(detail_url,headers=headers).text #解析详情页中的章节内容 soup = BeautifulSoup(detail_page_text,'lxml') content = soup.find('div',class_='chapter_content').text fp.write(title+':'+content+'\\n') print(title,'下载成功！')fp.close() xpath解析 xpath解析的实现原理 1.实例化一个etree的对象，然后将即将被解析的页面源码加载到改对象中 2.使用etree对象中的xpath方法结合着不同形式的xpath表达式实现标签定位和数据提取 在xpath里，html会被解析为一个树 环境安装： pip install lxml etree对象的实例化： etree.parse(‘test.html’) etree.HTML(page_text) xpath表达式:xpath方法的返回值一定是一个列表 最左侧的/表示：xpath表达式一定要从根标签逐层进行标签查找和定位 最左侧的//表示：xpath表达式可以从任意位置定位标签 非最左侧的/:表示一个层级 非最左侧的//：表示跨多个层级 属性定位：//tagName[@attrName=”value”] 索引定位：//tagName[index] 索引是从1开始 取文本： /text():直系文本内容 //text():所有的文本内容 取属性： /@attrName 谷歌浏览器提供了复制xpath的功能 123456789101112#xpath使用示范from lxml import etreetree = etree.parse('./test.html')#xpath下都是列表，如果只有一个元素列表就一个元素tree.xpath('/html/head/title')#html标签下的head下的titletree.xpath('//title')#和/html/head/title一样tree.xpath('/html/body//p')tree.xpath('//p')tree.xpath('//div[@class=\"song\"]')#属性定位tree.xpath('//li[7]')#找到li的第七个tree.xpath('//a[@id=\"feng\"]/text()')[0]#这是一个列表，0表示取第一个元素tree.xpath('//div[@class=\"song\"]//text()')tree.xpath('//a[@id=\"feng\"]/@href') 12345678910111213#用xpath爬取糗百中的段子内容和作者名称url = 'https://www.qiushibaike.com/text/'page_text = requests.get(url,headers=headers).text#解析内容tree = etree.HTML(page_text)div_list = tree.xpath('//div[@id=\"content-left\"]/div')for div in div_list: author = div.xpath('./div[1]/a[2]/h2/text()')[0]#实现局部解析#点表示从改div的子标签开始，如果是/表示全局开始 content = div.xpath('./a[1]/div/span//text()') content = ''.join(content) print(author,content) 1234567891011121314151617181920212223#乱码问题示例#http://pic.netbian.com/4kmeinv/中文乱码的处理 dirName = './meinvLibs'if not os.path.exists(dirName): os.mkdir(dirName)url = 'http://pic.netbian.com/4kmeinv/index_%d.html'for page in range(1,11): if page == 1: new_url = 'http://pic.netbian.com/4kmeinv/' else: new_url = format(url%page) page_text = requests.get(new_url,headers=headers).text tree = etree.HTML(page_text) a_list = tree.xpath('//div[@class=\"slist\"]/ul/li/a') for a in a_list: img_src = 'http://pic.netbian.com'+a.xpath('./img/@src')[0] img_name = a.xpath('./b/text()')[0] img_name = img_name.encode('iso-8859-1').decode('gbk')#如果全部页面都编码浪费性能，这里就只编码了name。用iso这样通用的 img_data = requests.get(img_src,headers=headers).content imgPath = dirName+'/'+img_name+'.jpg' with open(imgPath,'wb') as fp: fp.write(img_data) print(img_name,'下载成功！！！') 12345678#用|提高通用性#https://www.aqistudy.cn/historydata/所有城市名称page_text = requests.get('https://www.aqistudy.cn/historydata/',headers=headers).texttree = etree.HTML(page_text)# hot_cities = tree.xpath('//div[@class=\"bottom\"]/ul/li/a/text()')# all_cities = tree.xpath('//div[@class=\"bottom\"]/ul/div[2]/li/a/text()')cities = tree.xpath('//div[@class=\"bottom\"]/ul/div[2]/li/a/text() | //div[@class=\"bottom\"]/ul/li/a/text()') #表示两种都可以，有哪一种就用哪一种。两者都有就用提高xpath的通用性cities","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}]},{"title":"Spring Boot笔记","slug":"Spring-Boot笔记","date":"2019-12-21T06:21:49.000Z","updated":"2021-07-08T07:57:37.509Z","comments":true,"path":"2019/12/21/Spring-Boot笔记/","link":"","permalink":"http://example.com/2019/12/21/Spring-Boot%E7%AC%94%E8%AE%B0/","excerpt":"","text":"微服务 笔记是对SpringBoot的查漏补缺，没有记录详细 pom文件探究12345678910111213&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;!--他的父项目是--&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;relativePath&gt;../../spring-boot-dependencies&lt;/relativePath&gt;&lt;/parent&gt;&lt;!--他来真正管理Spring Boot应用里面的所有依赖版本；--&gt; Spring Boot来管理我们的版本号，我们只要指定springboot的版本号即可 启动器启动器手册 Spring Boot将所有的功能场景都抽取出来，做成一个个的starters（启动器），只需要在项目里面引入这些starter相关场景的所有依赖都会导入进来。要用什么功能就导入什么场景的启动器 自动加载的机制@SpringBootApplication来标注一个主程序类，说明这是一个Spring Boot应用 @SpringBootApplication: Spring Boot应用标注在某个类上说明这个类是SpringBoot的主配置类，SpringBoot就应该运行这个类的main方法来启动SpringBoot应用； 12345678910@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication @SpringBootConfiguration:Spring Boot的配置类； ​ 标注在某个类上，表示这是一个Spring Boot的配置类； ​ @Configuration:配置类上来标注这个注解； ​ 配置类 —– 配置文件；配置类也是容器中的一个组件；@Component @EnableAutoConfiguration：开启自动配置功能； ​ 以前我们需要配置的东西，Spring Boot帮我们自动配置；@EnableAutoConfiguration告诉SpringBoot开启自动配置功能；这样自动配置才能生效； 123@AutoConfigurationPackage@Import(EnableAutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration @AutoConfigurationPackage：自动配置包 ​ @Import(AutoConfigurationPackages.Registrar.class)： ​ Spring的底层注解@Import，给容器中导入一个组件；导入的组件由AutoConfigurationPackages.Registrar.class； 将主配置类（@SpringBootApplication标注的类）的所在包及下面所有子包里面的所有组件扫描到Spring容器； ​ @Import(EnableAutoConfigurationImportSelector.class)； ​ 给容器中导入组件？ ​ EnableAutoConfigurationImportSelector：导入哪些组件的选择器； ​ 将所有需要导入的组件以全类名的方式返回；这些组件就会被添加到容器中； ​ 会给容器中导入非常多的自动配置类（xxxAutoConfiguration）；就是给容器中导入这个场景需要的所有组件，并配置好这些组件； 有了自动配置类，免去了我们手动编写配置注入功能组件等的工作； ​ SpringFactoriesLoader.loadFactoryNames(EnableAutoConfiguration.class,classLoader)； Spring Boot在启动的时候从类路径下的META-INF/spring.factories中获取EnableAutoConfiguration指定的值，将这些值作为自动配置类导入到容器中，自动配置类就生效，帮我们进行自动配置工作；以前我们需要自己配置的东西，自动配置类都帮我们； J2EE的整体整合解决方案和自动配置都在spring-boot-autoconfigure-x.x.x.RELEASE.jar； 配置文件application.yml和application.properties可以放在resource下或/config下 yml语法属性和值大小写敏感 “”双引号不会转义 ‘’单引号会转义 yml多种数据类型 对象、map 1friends: &#123;lastName: zhangsan,age: 18&#125; 123friends: lastName: zhangsan age: 20 List1234pets: - cat - dog - pig 1pets: [cat,dog,pig] 复合写法last-name等同于lastName 123456789101112person: lastName: hello age: 18 boss: false birth: 2017/12/12 maps: &#123;k1: v1,k2: 12&#125; lists: - lisi - zhaoliu dog: name: 小狗 age: 12 pom 123456&lt;!--导入配置文件处理器，配置文件进行绑定就会有提示--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 1234567891011121314151617181920/** * 将配置文件中配置的每一个属性的值，映射到这个组件中 * @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定； * prefix = \"person\"：配置文件中哪个下面的所有属性进行一一映射 * * 只有这个组件是容器中的组件，才能容器提供的@ConfigurationProperties功能； * */@Component@ConfigurationProperties(prefix = \"person\")public class Person &#123; private String lastName; private Integer age; private Boolean boss; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog; properties配置文件乱码在setting内搜索file encodings在内设置为utf-8，后面的打上勾 @Value该注解可以写两种方式${环境变量}和#{EL表达式}。标记在属性上。如#{2*5}值为10 @ConfigurationProperties @Value 功能 批量注入配置文件中的属性 一个个指定 松散绑定（松散语法） 支持，如（lastName=last-name） 不支持 SpEL 不支持 支持 JSR303数据校验 支持 不支持 复杂类型封装 支持 不支持 @Validated，表示要检验 @PropertySource&amp;@ImportResource&amp;@Bean @PropertySource：加载指定的配置文件； 12345678 @PropertySource(value = &#123;\"classpath:person.properties\"&#125;)@Component@ConfigurationProperties(prefix = \"person\")public class Person &#123; private String lastName; private Integer age; private Boolean boss; @ImportResource：导入Spring的配置文件，让配置文件里面的内容生效； Spring Boot里面没有Spring的配置文件，我们自己编写的配置文件，也不能自动识别； 想让Spring的配置文件生效，加载进来；@ImportResource标注在一个配置类上 @ImportResource(locations = {&quot;classpath:beans.xml&quot;}) 建议使用 配置类@Configuration——&gt;Spring配置文件 yml和properties占位符两个都支持占位符 通过以下几个获取随机值 12$&#123;random.value&#125;、$&#123;random.int&#125;、$&#123;random.long&#125;$&#123;random.int(10)&#125;、$&#123;random.int[1024,65536]&#125;、$&#123;random.uuid&#125; 12用：指定默认值person.dog.name&#x3D;$&#123;person.hello:hello&#125;_dog 多配置文件文件名是application-[配置名].properties/yml 在主配置文件中指定spring.profiles.active=配置名 yml中多配置这种方式更简单 1234567891011121314151617181920#指定prod为激活的配置server: port: 8081spring: profiles: active: prod---server: port: 8083spring: profiles: dev---server: port: 8084spring: profiles: prod #指定属于哪个环境 命令行激活方式java -jar spring-boot.jar spring.profiles.active=dev 虚拟机参数激活-Dspring.profiles.active=dev 文件加载位置顺序1234–file:.&#x2F;config&#x2F;–file:.&#x2F;–classpath:&#x2F;config&#x2F;–classpath:&#x2F; 优先级由高到底，高优先级的配置会覆盖低优先级的配置； SpringBoot会从这四个位置全部加载主配置文件；互补配置； 项目打包好以后，我们可以使用命令行参数的形式，启动项目的时候来指定配置文件的新位置；指定配置文件和默认加载的这些配置文件共同起作用形成互补配置； java -jar spring-boot.jar --spring.config.location=G:/application.properties 外部配置加载顺序官网一共17个 告到底，高覆盖低 命令行参数 所有的配置都可以在命令行上进行指定 java -jar spring-boot.jar --server.port=8087 --server.context-path=/abc 多个配置用空格分开； –配置项=值 来自java:comp/env的JNDI属性 Java系统属性（System.getProperties()） 操作系统环境变量 RandomValuePropertySource配置的random.*属性值 由jar包外向jar包内进行寻找； 优先加载带profile同级目录下 jar包外部的application-{profile}.properties或application.yml(带spring.profile)配置文件 jar包内部的application-{profile}.properties或application.yml(带spring.profile)配置文件 再来加载不带profile jar包外部的application.properties或application.yml(不带spring.profile)配置文件 jar包内部的application.properties或application.yml(不带spring.profile)配置文件 @Configuration注解类上的@PropertySource 通过SpringApplication.setDefaultProperties指定的默认属性 自动配置官方手册 1）、SpringBoot启动的时候加载主配置类，开启了自动配置功能 ==@EnableAutoConfiguration== 2）、@EnableAutoConfiguration 作用： 利用EnableAutoConfigurationImportSelector给容器中导入一些组件 可以查看selectImports()方法的内容； List configurations = getCandidateConfigurations(annotationMetadata, attributes);获取候选的配置 SpringFactoriesLoader.loadFactoryNames() 扫描所有jar包类路径下 META-INF/spring.factories 把扫描到的这些文件的内容包装成properties对象 从properties中获取到EnableAutoConfiguration.class类（类名）对应的值，然后把他们添加在容器中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104&#96;&#96;&#96; **将 类路径下 META-INF&#x2F;spring.factories 里面配置的所有EnableAutoConfiguration的值加入到了容器中；**​&#96;&#96;&#96;properties# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration&#x3D;\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\\org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\\org.springframework.boot.autoconfigure.cloud.CloudAutoConfiguration,\\org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\\org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\\org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.ldap.LdapDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.ldap.LdapRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.neo4j.Neo4jRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\\org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\\org.springframework.boot.autoconfigure.elasticsearch.jest.JestAutoConfiguration,\\org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\\org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\\org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\\org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\\org.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\\org.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\\org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration,\\org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\\org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\\org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\\org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\\org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\\org.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\\org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,\\org.springframework.boot.autoconfigure.ldap.embedded.EmbeddedLdapAutoConfiguration,\\org.springframework.boot.autoconfigure.ldap.LdapAutoConfiguration,\\org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\\org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\\org.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\\org.springframework.boot.autoconfigure.mobile.DeviceResolverAutoConfiguration,\\org.springframework.boot.autoconfigure.mobile.DeviceDelegatingViewResolverAutoConfiguration,\\org.springframework.boot.autoconfigure.mobile.SitePreferenceAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\\org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\\org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\\org.springframework.boot.autoconfigure.reactor.ReactorAutoConfiguration,\\org.springframework.boot.autoconfigure.security.SecurityAutoConfiguration,\\org.springframework.boot.autoconfigure.security.SecurityFilterAutoConfiguration,\\org.springframework.boot.autoconfigure.security.FallbackWebSecurityAutoConfiguration,\\org.springframework.boot.autoconfigure.security.oauth2.OAuth2AutoConfiguration,\\org.springframework.boot.autoconfigure.sendgrid.SendGridAutoConfiguration,\\org.springframework.boot.autoconfigure.session.SessionAutoConfiguration,\\org.springframework.boot.autoconfigure.social.SocialWebAutoConfiguration,\\org.springframework.boot.autoconfigure.social.FacebookAutoConfiguration,\\org.springframework.boot.autoconfigure.social.LinkedInAutoConfiguration,\\org.springframework.boot.autoconfigure.social.TwitterAutoConfiguration,\\org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\\org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\\org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration,\\org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration,\\org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration,\\org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration,\\org.springframework.boot.autoconfigure.web.EmbeddedServletContainerAutoConfiguration,\\org.springframework.boot.autoconfigure.web.ErrorMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpEncodingAutoConfiguration,\\org.springframework.boot.autoconfigure.web.HttpMessageConvertersAutoConfiguration,\\org.springframework.boot.autoconfigure.web.MultipartAutoConfiguration,\\org.springframework.boot.autoconfigure.web.ServerPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebClientAutoConfiguration,\\org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.WebSocketAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.WebSocketMessagingAutoConfiguration,\\org.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration 每一个这样的 xxxAutoConfiguration类都是容器中的一个组件，都加入到容器中；用他们来做自动配置； 3）、每一个自动配置类进行自动配置功能； 4）、以HttpEncodingAutoConfiguration（Http编码自动配置）为例解释自动配置原理； 12345678910111213141516171819202122232425262728@Configuration //表示这是一个配置类，以前编写的配置文件一样，也可以给容器中添加组件@EnableConfigurationProperties(HttpEncodingProperties.class) //启动指定类的ConfigurationProperties功能；将配置文件中对应的值和HttpEncodingProperties绑定起来；并把HttpEncodingProperties加入到ioc容器中@ConditionalOnWebApplication //Spring底层@Conditional注解（Spring注解版），根据不同的条件，如果满足指定的条件，整个配置类里面的配置就会生效； 判断当前应用是否是web应用，如果是，当前配置类生效@ConditionalOnClass(CharacterEncodingFilter.class) //判断当前项目有没有这个类CharacterEncodingFilter；SpringMVC中进行乱码解决的过滤器；@ConditionalOnProperty(prefix = \"spring.http.encoding\", value = \"enabled\", matchIfMissing = true) //判断配置文件中是否存在某个配置 spring.http.encoding.enabled；如果不存在，判断也是成立的(matchIfMissing)//即使我们配置文件中不配置spring.http.encoding.enabled=true，也是默认生效的；public class HttpEncodingAutoConfiguration &#123; //他已经和SpringBoot的配置文件映射了 private final HttpEncodingProperties properties; //只有一个有参构造器的情况下，参数的值就会从容器中拿 EnableConfigurationProperties这个注解 public HttpEncodingAutoConfiguration(HttpEncodingProperties properties) &#123; this.properties = properties; &#125; @Bean //给容器中添加一个组件，这个组件的某些值需要从properties中获取 @ConditionalOnMissingBean(CharacterEncodingFilter.class) //判断容器没有这个组件？ public CharacterEncodingFilter characterEncodingFilter() &#123; CharacterEncodingFilter filter = new OrderedCharacterEncodingFilter(); filter.setEncoding(this.properties.getCharset().name()); filter.setForceRequestEncoding(this.properties.shouldForce(Type.REQUEST)); filter.setForceResponseEncoding(this.properties.shouldForce(Type.RESPONSE)); return filter; &#125; 根据当前不同的条件判断，决定这个配置类是否生效？ 一但这个配置类生效；这个配置类就会给容器中添加各种组件；这些组件的属性是从对应的properties类中获取的，这些类里面的每一个属性又是和配置文件绑定的； 5）、所有在配置文件中能配置的属性都是在xxxxProperties类中封装者‘；配置文件能配置什么就可以参照某个功能对应的这个属性类 1234@ConfigurationProperties(prefix = \"spring.http.encoding\") //从配置文件中获取指定的值和bean的属性进行绑定public class HttpEncodingProperties &#123; public static final Charset DEFAULT_CHARSET = Charset.forName(\"UTF-8\"); 精髓： SpringBoot启动会加载大量的自动配置类 我们看我们需要的功能有没有SpringBoot默认写好的自动配置类； 我们再来看这个自动配置类中到底配置了哪些组件；（只要我们要用的组件有，我们就不需要再来配置了） 给容器中自动配置类添加组件的时候，会从properties类中获取某些属性。我们就可以在配置文件中指定这些属性的值； xxxxAutoConfigurartion：自动配置类； 给容器中添加组件 xxxxProperties:封装配置文件中相关属性； 2、细节1、@Conditional派生注解作用：必须是@Conditional指定的条件成立，才给容器中添加组件，配置配里面的所有内容才生效； @Conditional扩展注解 作用（判断是否满足当前指定条件） @ConditionalOnJava 系统的java版本是否符合要求 @ConditionalOnBean 容器中存在指定Bean； @ConditionalOnMissingBean 容器中不存在指定Bean； @ConditionalOnExpression 满足SpEL表达式指定 @ConditionalOnClass 系统中有指定的类 @ConditionalOnMissingClass 系统中没有指定的类 @ConditionalOnSingleCandidate 容器中只有一个指定的Bean，或者这个Bean是首选Bean @ConditionalOnProperty 系统中指定的属性是否有指定的值 @ConditionalOnResource 类路径下是否存在指定资源文件 @ConditionalOnWebApplication 当前是web环境 @ConditionalOnNotWebApplication 当前不是web环境 @ConditionalOnJndi JNDI存在指定项 @conditional的value值是条件判断类，条件判断类中的match方法，匹配返回true，不匹配返回false 自动配置类必须在一定的条件下才能生效； 我们怎么知道哪些自动配置类生效； 我们可以通过在配置文件夹内添加debug=true属性；来让控制台打印自动配置报告，这样我们就可以很方便的知道哪些自动配置类生效； 12345678910111213141516171819202122控制台打印内容=========================AUTO-CONFIGURATION REPORT=========================Positive matches:（自动配置类启用的）----------------- DispatcherServletAutoConfiguration matched: - @ConditionalOnClass found required class 'org.springframework.web.servlet.DispatcherServlet'; @ConditionalOnMissingClass did not find unwanted class (OnClassCondition) - @ConditionalOnWebApplication (required) found StandardServletEnvironment (OnWebApplicationCondition) Negative matches:（没有启动，没有匹配成功的自动配置类）----------------- ActiveMQAutoConfiguration: Did not match: - @ConditionalOnClass did not find required classes 'javax.jms.ConnectionFactory', 'org.apache.activemq.ActiveMQConnectionFactory' (OnClassCondition) AopAutoConfiguration: Did not match: - @ConditionalOnClass did not find required classes 'org.aspectj.lang.annotation.Aspect', 'org.aspectj.lang.reflect.Advice' (OnClassCondition) SpringBoot整合日志官网手册 市面上的日志框架； JUL、JCL、Jboss-logging、logback、log4j、log4j2、slf4j…. 日志门面 （日志的抽象层） 日志实现 JCL（Jakarta Commons Logging） SLF4j（Simple Logging Facade for Java） jboss-logging Log4j JUL（java.util.logging） Log4j2 Logback SpringBoot：底层是Spring框架，Spring框架默认是用JCL；‘ ​ SpringBoot选用 SLF4j和logback； 每一个日志的实现框架都有自己的配置文件。使用slf4j以后，配置文件还是做成日志实现框架自己本身的配置文件； Spring Boot在底层替换掉了别的日志包，用sl4j和logback 如果我们要引入其他的框架，必须要将次框架的默认日志移除 123456789 日志输出格式：%d表示日期时间，%thread表示线程名，%-5level：级别从左显示5个字符宽度%logger&#123;50&#125; 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息，%n是换行符 --&gt; %d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n 日志配置格式 12345678910111213logging.level.com.atguigu=trace#logging.path=# 不指定路径在当前项目下生成springboot.log日志# 可以指定完整的路径；#logging.file=G:/springboot.log# 在当前磁盘的根路径下创建spring文件夹和里面的log文件夹；使用 spring.log 作为默认文件logging.path=/spring/log# 在控制台输出的日志的格式logging.pattern.console=%d&#123;yyyy-MM-dd&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n# 指定文件中日志输出的格式logging.pattern.file=%d&#123;yyyy-MM-dd&#125; === [%thread] === %-5level === %logger&#123;50&#125; ==== %msg%n logging.file logging.path Example Description (none) (none) 只在控制台输出 指定文件名 (none) my.log 输出日志到my.log文件 (none) 指定目录 /var/log 输出到指定目录的 spring.log 文件中 logback.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!--scan：当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。scanPeriod：设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒当scan为true时，此属性生效。默认的时间间隔为1分钟。debug：当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。--&gt;&lt;configuration scan=\"false\" scanPeriod=\"60 seconds\" debug=\"false\"&gt; &lt;!-- 定义日志的根目录 --&gt; &lt;property name=\"LOG_HOME\" value=\"/app/log\" /&gt; &lt;!-- 定义日志文件名称 --&gt; &lt;property name=\"appName\" value=\"atguigu-springboot\"&gt;&lt;/property&gt; &lt;!-- ch.qos.logback.core.ConsoleAppender 表示控制台输出 --&gt; &lt;appender name=\"stdout\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;!-- 日志输出格式： %d表示日期时间， %thread表示线程名， %-5level：级别从左显示5个字符宽度 %logger&#123;50&#125; 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息， %n是换行符 --&gt; &lt;layout class=\"ch.qos.logback.classic.PatternLayout\"&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;!-- 滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件 --&gt; &lt;appender name=\"appLogAppender\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 指定日志文件的名称 --&gt; &lt;file&gt;$&#123;LOG_HOME&#125;/$&#123;appName&#125;.log&lt;/file&gt; &lt;!-- 当发生滚动时，决定 RollingFileAppender 的行为，涉及文件移动和重命名 TimeBasedRollingPolicy： 最常用的滚动策略，它根据时间来制定滚动策略，既负责滚动也负责出发滚动。 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 滚动时产生的文件的存放位置及文件名称 %d&#123;yyyy-MM-dd&#125;：按天进行日志滚动 %i：当文件大小超过maxFileSize时，按照i进行文件滚动 --&gt; &lt;fileNamePattern&gt;$&#123;LOG_HOME&#125;/$&#123;appName&#125;-%d&#123;yyyy-MM-dd&#125;-%i.log&lt;/fileNamePattern&gt; &lt;!-- 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件。假设设置每天滚动， 且maxHistory是365，则只保存最近365天的文件，删除之前的旧文件。注意，删除旧文件是， 那些为了归档而创建的目录也会被删除。 --&gt; &lt;MaxHistory&gt;365&lt;/MaxHistory&gt; &lt;!-- 当日志文件超过maxFileSize指定的大小是，根据上面提到的%i进行日志文件滚动 注意此处配置SizeBasedTriggeringPolicy是无法实现按文件大小进行滚动的，必须配置timeBasedFileNamingAndTriggeringPolicy --&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;!-- 日志输出格式： --&gt; &lt;layout class=\"ch.qos.logback.classic.PatternLayout\"&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [ %thread ] - [ %-5level ] [ %logger&#123;50&#125; : %line ] - %msg%n&lt;/pattern&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;!-- logger主要用于存放日志对象，也可以定义日志类型、级别 name：表示匹配的logger类型前缀，也就是包的前半部分 level：要记录的日志级别，包括 TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR additivity：作用在于children-logger是否使用 rootLogger配置的appender进行输出， false：表示只用当前logger的appender-ref，true： 表示当前logger的appender-ref和rootLogger的appender-ref都有效 --&gt; &lt;!-- hibernate logger --&gt; &lt;logger name=\"com.atguigu\" level=\"debug\" /&gt; &lt;!-- Spring framework logger --&gt; &lt;logger name=\"org.springframework\" level=\"debug\" additivity=\"false\"&gt;&lt;/logger&gt; &lt;!-- root与logger是父子关系，没有特别定义则默认为root，任何一个类只会和一个logger对应， 要么是定义的logger，要么是root，判断的关键在于找到这个logger，然后判断这个logger的appender和level。 --&gt; &lt;root level=\"info\"&gt; &lt;appender-ref ref=\"stdout\" /&gt; &lt;appender-ref ref=\"appLogAppender\" /&gt; &lt;/root&gt;&lt;/configuration&gt; log4.properties 123456789101112131415161718192021222324### set log levels ###log4j.rootLogger = debug , stdout , D , E### 输出到控制台 ###log4j.appender.stdout = org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.Target = System.outlog4j.appender.stdout.layout = org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern = %d&#123;ABSOLUTE&#125; %5p %c&#123; 1 &#125;:%L - %m%n#### 输出到日志文件 ####log4j.appender.D = org.apache.log4j.DailyRollingFileAppender#log4j.appender.D.File = logs/log.log#log4j.appender.D.Append = true#log4j.appender.D.Threshold = DEBUG ## 输出DEBUG级别以上的日志#log4j.appender.D.layout = org.apache.log4j.PatternLayout#log4j.appender.D.layout.ConversionPattern = %-d&#123;yyyy-MM-dd HH:mm:ss&#125; [ %t:%r ] - [ %p ] %m%n##### 保存异常信息到单独文件 ####log4j.appender.D = org.apache.log4j.DailyRollingFileAppender#log4j.appender.D.File = logs/error.log ## 异常日志文件名#log4j.appender.D.Append = true#log4j.appender.D.Threshold = ERROR ## 只输出ERROR级别以上的日志!!!#log4j.appender.D.layout = org.apache.log4j.PatternLayout#log4j.appender.D.layout.ConversionPattern = %-d&#123;yyyy-MM-dd HH:mm:ss&#125; [ %t:%r ] - [ %p ] %m%n 2、指定配置给类路径下放上每个日志框架自己的配置文件即可；SpringBoot就不使用他默认配置的了 Logging System Customization Logback logback-spring.xml, logback-spring.groovy, logback.xml or logback.groovy Log4j2 log4j2-spring.xml or log4j2.xml JDK (Java Util Logging) logging.properties logback.xml：直接就被日志框架识别了； logback-spring.xml：日志框架就不直接加载日志的配置项，由SpringBoot解析日志配置，可以使用SpringBoot的高级Profile功能 1234&lt;springProfile name=\"staging\"&gt; &lt;!-- configuration to be enabled when the \"staging\" profile is active --&gt; 可以指定某段配置只在某个环境下生效&lt;/springProfile&gt; 123456789101112131415161718192021&lt;appender name=\"stdout\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;!-- 日志输出格式： %d表示日期时间， %thread表示线程名， %-5level：级别从左显示5个字符宽度 %logger&#123;50&#125; 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息， %n是换行符 --&gt; &lt;layout class=\"ch.qos.logback.classic.PatternLayout\"&gt; &lt;!--指定dev环境--&gt; &lt;springProfile name=\"dev\"&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; ----&gt; [%thread] ---&gt; %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;!--指定非dev环境--&gt; &lt;springProfile name=\"!dev\"&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; ==== [%thread] ==== %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;/layout&gt;&lt;/appender&gt; 切换日志框架切换到slf4j+log4j 排除掉老的加新的（无意义） 123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;&lt;/dependency&gt; 切换到log4j2 排除掉老的用spring-boot-starter-log4j2代替 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;&lt;/dependency&gt; Web开发所有配置都在WebMvcAuotConfiguration里面 SpringBoot对静态资源的映射规则；123@ConfigurationProperties(prefix = \"spring.resources\", ignoreUnknownFields = false)public class ResourceProperties implements ResourceLoaderAware &#123; //可以设置和静态资源有关的参数，缓存时间等 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364//对应解释在后面@Override//设置webjars的映射路径public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; if (!this.resourceProperties.isAddMappings()) &#123; logger.debug(\"Default resource handling disabled\"); return; &#125; Integer cachePeriod = this.resourceProperties.getCachePeriod(); if (!registry.hasMappingForPattern(\"/webjars/**\")) &#123; customizeResourceHandlerRegistration( registry.addResourceHandler(\"/webjars/**\") .addResourceLocations( \"classpath:/META-INF/resources/webjars/\") .setCachePeriod(cachePeriod)); &#125; String staticPathPattern = this.mvcProperties.getStaticPathPattern(); //静态资源文件夹映射 if (!registry.hasMappingForPattern(staticPathPattern)) &#123; customizeResourceHandlerRegistration( registry.addResourceHandler(staticPathPattern) .addResourceLocations( this.resourceProperties.getStaticLocations()) .setCachePeriod(cachePeriod)); &#125;&#125;//配置欢迎页映射@Beanpublic WelcomePageHandlerMapping welcomePageHandlerMapping( ResourceProperties resourceProperties) &#123; return new WelcomePageHandlerMapping(resourceProperties.getWelcomePage(), this.mvcProperties.getStaticPathPattern());&#125;//配置喜欢的图标@Configuration@ConditionalOnProperty(value = \"spring.mvc.favicon.enabled\", matchIfMissing = true)public static class FaviconConfiguration &#123; private final ResourceProperties resourceProperties; public FaviconConfiguration(ResourceProperties resourceProperties) &#123; this.resourceProperties = resourceProperties; &#125; @Bean public SimpleUrlHandlerMapping faviconHandlerMapping() &#123; SimpleUrlHandlerMapping mapping = new SimpleUrlHandlerMapping(); mapping.setOrder(Ordered.HIGHEST_PRECEDENCE + 1); //所有 **/favicon.ico mapping.setUrlMap(Collections.singletonMap(\"**/favicon.ico\", faviconRequestHandler())); return mapping; &#125; @Bean public ResourceHttpRequestHandler faviconRequestHandler() &#123; ResourceHttpRequestHandler requestHandler = new ResourceHttpRequestHandler(); requestHandler .setLocations(this.resourceProperties.getFaviconLocations()); return requestHandler; &#125;&#125; 1）、所有 /webjars/** ，都去 classpath:/META-INF/resources/webjars/ 找资源； ​ webjars：以jar包的方式引入静态资源； http://www.webjars.org/ localhost:8080/webjars/jquery/3.3.1/jquery.js 123456&lt;!--引入jquery-webjar--&gt;在访问的时候只需要写webjars下面资源的名称即可&lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;jquery&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt;&lt;/dependency&gt; 2）、”/**” 访问当前项目的任何资源，都去（静态资源的文件夹）找映射== 123456如果没人处理请求，都会来下列路径找&quot;classpath:&#x2F;META-INF&#x2F;resources&#x2F;&quot;, &quot;classpath:&#x2F;resources&#x2F;&quot;,&quot;classpath:&#x2F;static&#x2F;&quot;, &quot;classpath:&#x2F;public&#x2F;&quot; &quot;&#x2F;&quot;：当前项目的根路径 localhost:8080/abc === 去静态资源文件夹里面找abc 3）、欢迎页； 静态资源文件夹下的所有index.html页面；被”/**”映射； ​ localhost:8080/ 找index页面 4）、所有的 **/favicon.ico 都是在静态资源文件下找； 也可以自己配置 1spring.resources.static-locations=classpath:/heel/,classpath:/a Thymeleaf12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; 2.1.6&lt;/dependency&gt;&lt;!--SpringBoot的thymeleaf版本太低，切换thymeleaf版本--&gt;&lt;!--加入properties即可--&gt;&lt;properties&gt; &lt;thymeleaf.version&gt;3.0.9.RELEASE&lt;/thymeleaf.version&gt; &lt;!-- 布局功能的支持程序 thymeleaf3主程序 layout2以上版本 --&gt; &lt;!-- thymeleaf2 layout1--&gt; &lt;thymeleaf-layout-dialect.version&gt;2.2.2&lt;/thymeleaf-layout-dialect.version&gt;&lt;/properties&gt; 默认规则都在ThymeleafProperties里 12345678910@ConfigurationProperties(prefix = \"spring.thymeleaf\")public class ThymeleafProperties &#123; private static final Charset DEFAULT_ENCODING = Charset.forName(\"UTF-8\"); private static final MimeType DEFAULT_CONTENT_TYPE = MimeType.valueOf(\"text/html\"); public static final String DEFAULT_PREFIX = \"classpath:/templates/\"; public static final String DEFAULT_SUFFIX = \".html\"; 只要我们把HTML页面放在classpath:/templates/，thymeleaf就能自动渲染； 在h5上的语法提示&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt; 12&lt;!--th:text 将div里面的文本内容设置为 --&gt;&lt;div th:text=\"$&#123;hello&#125;\"&gt;这是显示欢迎信息&lt;/div&gt; 可以通过th:加在任意属性前，做获取 在页面能用到的表达式 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970Simple expressions:（表达式语法） Variable Expressions: $&#123;...&#125;：获取变量值；OGNL； 1）、获取对象的属性、调用方法 #可以调用对象的属性，数组的等等例如：$&#123;person.father.name&#125;、$&#123;person['father']['name']&#125;、$&#123;personsByName['Stephen'].age&#125;等等，具体查官方手册 2）、使用内置的基本对象（本身就有，可以直接用）： #ctx : the context object. #vars: the context variables. #locale : the context locale. #request : (only in Web Contexts) the HttpServletRequest object. #response : (only in Web Contexts) the HttpServletResponse object. #session : (only in Web Contexts) the HttpSession object. #servletContext : (only in Web Contexts) the ServletContext object. $&#123;session.foo&#125; 3）、内置的一些工具对象：#execInfo : information about the template being processed.#messages : methods for obtaining externalized messages inside variables expressions, in the same way as they would be obtained using #&#123;…&#125; syntax.#uris : methods for escaping parts of URLs/URIs#conversions : methods for executing the configured conversion service (if any).#dates : methods for java.util.Date objects: formatting, component extraction, etc.#calendars : analogous to #dates , but for java.util.Calendar objects.#numbers : methods for formatting numeric objects.#strings : methods for String objects: contains, startsWith, prepending/appending, etc.#objects : methods for objects in general.#bools : methods for boolean evaluation.#arrays : methods for arrays.#lists : methods for lists.#sets : methods for sets.#maps : methods for maps.#aggregates : methods for creating aggregates on arrays or collections.#ids : methods for dealing with id attributes that might be repeated (for example, as a result of an iteration). Selection Variable Expressions: *&#123;...&#125;：选择表达式：和$&#123;&#125;在功能上是一样； 补充：配合 th:object=\"$&#123;session.user&#125;： &lt;!--这里的*&#123;属性名&#125;可以直接获取object中的属性--&gt; &lt;div th:object=\"$&#123;session.user&#125;\"&gt; &lt;p&gt;Name: &lt;span th:text=\"*&#123;firstName&#125;\"&gt;Sebastian&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Surname: &lt;span th:text=\"*&#123;lastName&#125;\"&gt;Pepper&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Nationality: &lt;span th:text=\"*&#123;nationality&#125;\"&gt;Saturn&lt;/span&gt;.&lt;/p&gt; &lt;/div&gt; Message Expressions: #&#123;...&#125;：获取国际化内容 Link URL Expressions: @&#123;...&#125;：定义URL； @&#123;/order/process(execId=$&#123;execId&#125;,execType='FAST')&#125; Fragment Expressions: ~&#123;...&#125;：片段引用表达式 &lt;div th:insert=\"~&#123;commons :: main&#125;\"&gt;...&lt;/div&gt; Literals（字面量） Text literals: 'one text' , 'Another one!' ,… Number literals: 0 , 34 , 3.0 , 12.3 ,… Boolean literals: true , false Null literal: null Literal tokens: one , sometext , main ,…Text operations:（文本操作） String concatenation: + Literal substitutions: |The name is $&#123;name&#125;|Arithmetic operations:（数学运算） Binary operators: + , - , * , / , % Minus sign (unary operator): -Boolean operations:（布尔运算） Binary operators: and , or Boolean negation (unary operator): ! , notComparisons and equality:（比较运算） Comparators: &gt; , &lt; , &gt;= , &lt;= ( gt , lt , ge , le ) Equality operators: == , != ( eq , ne )Conditional operators:条件运算（三元运算符） If-then: (if) ? (then) If-then-else: (if) ? (then) : (else) Default: (value) ?: (defaultvalue)Special tokens: No-Operation: _ 页面显示 12345678910111213&lt;!--th:text 将div里面的文本内容设置为 --&gt;&lt;div id=\"div01\" class=\"myDiv\" th:id=\"$&#123;hello&#125;\" th:class=\"$&#123;hello&#125;\" th:text=\"$&#123;hello&#125;\"&gt;这是显示欢迎信息&lt;/div&gt;&lt;hr/&gt;&lt;div th:text=\"$&#123;hello&#125;\"&gt;&lt;/div&gt;&lt;div th:utext=\"$&#123;hello&#125;\"&gt;&lt;/div&gt;&lt;hr/&gt;&lt;!-- th:each每次遍历都会生成当前这个标签： 3个h4 --&gt;&lt;h4 th:text=\"$&#123;user&#125;\" th:each=\"user:$&#123;users&#125;\"&gt;&lt;/h4&gt;&lt;hr/&gt;&lt;h4&gt; &lt;!--[[]]和th:text一致，[()]和th:utext一致--&gt; &lt;span th:each=\"user:$&#123;users&#125;\"&gt; [[$&#123;user&#125;]] &lt;/span&gt;&lt;/h4&gt; SpringMVC配置官网手册 Spring Boot 自动配置好了SpringMVC 以下是SpringBoot对SpringMVC的默认配置:==（WebMvcAutoConfiguration）== Inclusion of ContentNegotiatingViewResolver and BeanNameViewResolver beans. 自动配置了ViewResolver（视图解析器：根据方法的返回值得到视图对象（View），视图对象决定如何渲染（转发？重定向？）） ContentNegotiatingViewResolver：组合所有的视图解析器的； 如何定制：我们可以自己给容器中添加一个视图解析器；自动的将其组合进来； Support for serving static resources, including support for WebJars (see below).静态资源文件夹路径,webjars Static index.html support. 静态首页访问 Custom Favicon support (see below). favicon.ico 自动注册了 of Converter, GenericConverter, Formatter beans. Converter：转换器； public String hello(User user)：类型转换使用Converter Formatter 格式化器； 2017.12.17===Date； 12345@Bean@ConditionalOnProperty(prefix = \"spring.mvc\", name = \"date-format\")//在文件中配置日期格式化的规则，没配则没有public Formatter&lt;Date&gt; dateFormatter() &#123; return new DateFormatter(this.mvcProperties.getDateFormat());//日期格式化组件&#125; ​ 自己添加的格式化器转换器，我们只需要放在容器中即可 Support for HttpMessageConverters (see below). HttpMessageConverter：SpringMVC用来转换Http请求和响应的；User—Json； HttpMessageConverters 是从容器中确定；获取所有的HttpMessageConverter； 自己给容器中添加HttpMessageConverter，只需要将自己的组件注册容器中（@Bean,@Component） Automatic registration of MessageCodesResolver (see below).定义错误代码生成规则 Automatic use of a ConfigurableWebBindingInitializer bean (see below). 我们可以配置一个ConfigurableWebBindingInitializer来替换默认的；（添加到容器）用来初始化WebDataBinder；就是将请求数据封装到JavaBean； org.springframework.boot.autoconfigure.web：在此包下web的所有自动场景； 这串英文就是扩展SpringMVC的内容 If you want to keep Spring Boot MVC features, and you just want to add additional MVC configuration (interceptors, formatters, view controllers etc.) you can add your own @Configuration class of type WebMvcConfigurerAdapter, but without @EnableWebMvc. If you wish to provide custom instances of RequestMappingHandlerMapping, RequestMappingHandlerAdapter or ExceptionHandlerExceptionResolver you can declare a WebMvcRegistrationsAdapter instance providing such components. If you want to take complete control of Spring MVC, you can add your own @Configuration annotated with @EnableWebMvc. 如何修改SpringBoot默认配置如果你添加了同类组件，springBoot会判断是否有同类组件，如果有就不添了。如果同类组件可以共存，那么SpringBoot都会添加 在SpringBoot中会有非常多的xxxConfigurer帮助我们进行扩展配置 在SpringBoot中会有很多的xxxCustomizer帮助我们进行定制配置 扩展SpringMVC编写一个配置类（@Configuration），是WebMvcConfigurerAdapter类型；不能标注@EnableWebMvc 既保留了所有的自动配置，也能用我们扩展的配置； 123456789101112//重写它的方法即可//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController(\"/atguigu\").setViewName(\"success\"); &#125;&#125; WebMvcConfigurationAdapter 在spring boot 2.0被废弃了 原理： ​ 1）、WebMvcAutoConfiguration是SpringMVC的自动配置类 ​ 2）、在做其他自动配置时会导入；@Import(EnableWebMvcConfiguration.class) 123456789101112131415161718@Configurationpublic static class EnableWebMvcConfiguration extends DelegatingWebMvcConfiguration &#123; private final WebMvcConfigurerComposite configurers = new WebMvcConfigurerComposite(); //从容器中获取所有的WebMvcConfigurer @Autowired(required = false) public void setConfigurers(List&lt;WebMvcConfigurer&gt; configurers) &#123; if (!CollectionUtils.isEmpty(configurers)) &#123; this.configurers.addWebMvcConfigurers(configurers); //一个参考实现；将所有的WebMvcConfigurer相关配置都来一起调用； @Override // public void addViewControllers(ViewControllerRegistry registry) &#123; // for (WebMvcConfigurer delegate : this.delegates) &#123; // delegate.addViewControllers(registry); // &#125; &#125; &#125;&#125; ​ 3）、容器中所有的WebMvcConfigurer都会一起起作用； ​ 4）、我们的配置类也会被调用； ​ 效果：SpringMVC的自动配置和我们的扩展配置都会起作用； 全面接管SpringMVC取消SpringBoot的默认配置，完全自己配置 我们需要在配置类中添加@EnableWebMvc即可； 123456789101112//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能@EnableWebMvc@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController(\"/atguigu\").setViewName(\"success\"); &#125;&#125; 原理： 1）@EnableWebMvc的核心 12@Import(DelegatingWebMvcConfiguration.class)//导入DelegatingWebMvcConfigurationpublic @interface EnableWebMvc &#123; 2）、 12@Configurationpublic class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport &#123; 3）、 12345678910@Configuration@ConditionalOnWebApplication@ConditionalOnClass(&#123; Servlet.class, DispatcherServlet.class, WebMvcConfigurerAdapter.class &#125;)//容器中没有这个组件的时候，这个自动配置类才生效@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)@AutoConfigureAfter(&#123; DispatcherServletAutoConfiguration.class, ValidationAutoConfiguration.class &#125;)public class WebMvcAutoConfiguration &#123; 4）、@EnableWebMvc将WebMvcConfigurationSupport组件导入进来后，自动配置类就失效了 5）、导入的WebMvcConfigurationSupport只是SpringMVC最基本的功能； RestfulCRUD默认访问首页1234567891011121314151617181920212223@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController(\"/atguigu\").setViewName(\"success\"); &#125; //所有的WebMvcConfigurerAdapter组件都会一起起作用 @Bean //将组件注册在容器 public WebMvcConfigurerAdapter webMvcConfigurerAdapter()&#123; WebMvcConfigurerAdapter adapter = new WebMvcConfigurerAdapter() &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController(\"/\").setViewName(\"login\"); registry.addViewController(\"/index.html\").setViewName(\"login\"); &#125; &#125;; return adapter; &#125;&#125; 可以通过th:href=&quot;@{/webjars/bootstrap/4.0.0/css/bootstrap.css}&quot;引入webjar下的 国际化在以往springMVC中 编写国际化配置文件； 使用ResourceBundleMessageSource管理国际化资源文件 在页面使用fmt:message取出国际化内容 SpringBoot内 在resource下创建i18n文件夹 创建默认页面名.properties中国的：页面名+zh_CN.properties SpringBoot自动配置好了管理国际化资源文件的组件； 1234567891011121314151617181920212223242526272829//从这里我们得知，我们要在配置文件内写spring.message.basename=i18n.页面名（基础名）@ConfigurationProperties(prefix = \"spring.messages\")public class MessageSourceAutoConfiguration &#123; /** * Comma-separated list of basenames (essentially a fully-qualified classpath * location), each following the ResourceBundle convention with relaxed support for * slash based locations. If it doesn't contain a package qualifier (such as * \"org.mypackage\"), it will be resolved from the classpath root. */ private String basename = \"messages\"; //我们的配置文件可以直接放在类路径下叫messages.properties； @Bean public MessageSource messageSource() &#123; ResourceBundleMessageSource messageSource = new ResourceBundleMessageSource(); if (StringUtils.hasText(this.basename)) &#123; //设置国际化资源文件的基础名（去掉语言国家代码的） messageSource.setBasenames(StringUtils.commaDelimitedListToStringArray( StringUtils.trimAllWhitespace(this.basename))); &#125; if (this.encoding != null) &#123; messageSource.setDefaultEncoding(this.encoding.name()); &#125; messageSource.setFallbackToSystemLocale(this.fallbackToSystemLocale); messageSource.setCacheSeconds(this.cacheSeconds); messageSource.setAlwaysUseMessageFormat(this.alwaysUseMessageFormat); return messageSource; &#125; 去页面获取国际化的值；#{} 原理： ​ 国际化Locale（区域信息对象）；LocaleResolver（获取区域信息对象）； 12345678910111213//默认的就是根据请求头带来的区域信息获取Locale进行国际化@Bean@ConditionalOnMissingBean@ConditionalOnProperty(prefix = \"spring.mvc\", name = \"locale\")public LocaleResolver localeResolver() &#123; if (this.mvcProperties .getLocaleResolver() == WebMvcProperties.LocaleResolver.FIXED) &#123; return new FixedLocaleResolver(this.mvcProperties.getLocale()); &#125; AcceptHeaderLocaleResolver localeResolver = new AcceptHeaderLocaleResolver(); localeResolver.setDefaultLocale(this.mvcProperties.getLocale()); return localeResolver;&#125; 4）、点击链接切换国际化 123456789101112131415161718192021222324/** * 可以在连接上携带区域信息 */public class MyLocaleResolver implements LocaleResolver &#123; @Override public Locale resolveLocale(HttpServletRequest request) &#123; String l = request.getParameter(\"l\"); Locale locale = Locale.getDefault(); if(!StringUtils.isEmpty(l))&#123; //这个l的内容是\"zh_CN\" String[] split = l.split(\"_\"); locale = new Locale(split[0],split[1]); &#125; return locale; &#125; @Override public void setLocale(HttpServletRequest request, HttpServletResponse response, Locale locale) &#123; &#125;&#125; @Bean//将我们的resolver添加到容器 public LocaleResolver localeResolver()&#123; return new MyLocaleResolver(); &#125;&#125; WebMvcConfigurationAdapter 在spring boot 2.0被废弃了，如果遇到使用 WebMvcConfigurationSupport 而静态文件不显示CSS样式的，这是因为替换之后之前的静态资源文件 会被拦截，导致无法可用。解决办法：重写 addResourceHandlers（）方法，加入静态文件路径即可代码如下：@Overrideprotected void addResourceHandlers(ResourceHandlerRegistry registry) {registry.addResourceHandler(“/**”).addResourceLocations(“classpath:/static/“);} 拦截器、获取参数@RequestParam(“username”)：在request中获取username的值，如果没有就报错 12# 禁用缓存spring.thymeleaf.cache=false 页面修改完成以后ctrl+f9：重新编译； 页面显示 12&lt;!--如果msg为空则不显示--&gt;&lt;p style=\"color: red\" th:text=\"$&#123;msg&#125;\" th:if=\"$&#123;not #strings.isEmpty(msg)&#125;\"&gt;&lt;/p&gt; 重定向可以防止表单重复提交”redirect:” 拦截器 写拦截器要继承HandlerInterceptor无需加注解 1234567891011121314151617181920212223//继承WebMvcConfigurerAdapter的配置类，重写方法//所有的WebMvcConfigurerAdapter组件都会一起起作用@Bean //将组件注册在容器public WebMvcConfigurerAdapter webMvcConfigurerAdapter()&#123; WebMvcConfigurerAdapter adapter = new WebMvcConfigurerAdapter() &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController(\"/\").setViewName(\"login\"); registry.addViewController(\"/index.html\").setViewName(\"login\"); registry.addViewController(\"/main.html\").setViewName(\"dashboard\"); &#125; //注册拦截器 @Override public void addInterceptors(InterceptorRegistry registry) &#123; //super.addInterceptors(registry); //静态资源； *.css , *.js //SpringBoot已经做好了静态资源映射 registry.addInterceptor(new LoginHandlerInterceptor()).addPathPatterns(\"/**\") .excludePathPatterns(\"/index.html\",\"/\",\"/user/login\"); &#125; &#125;; return adapter;&#125; RESTFUL如果emp/{xx}。没有xx参数，应该返回所有的 Thymeleaf抽取引入片段12345678910111213141、抽取公共片段&lt;div th:fragment=\"copy\"&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/div&gt;2、引入公共片段 模板名就是页面文件的名字&lt;div th:insert=\"~&#123;footer :: copy&#125;\"&gt;&lt;/div&gt;~&#123;templatename::selector&#125;：模板名::选择器~&#123;templatename::fragmentname&#125;:模板名::片段名3、默认效果：insert的公共片段在div标签中如果使用th:insert等属性进行引入，可以不用写~&#123;&#125;：行内写法可以加上：[[~&#123;&#125;]];[(~&#123;&#125;)]； 三种引入公共片段的th属性： th:insert：将公共片段整个插入到声明引入的元素中 th:replace：将声明引入的元素替换为公共片段 th:include：将被引入的片段的内容包含进这个标签中 123456789101112131415161718192021222324演示&lt;footer th:fragment=\"copy\"&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/footer&gt;引入方式&lt;div th:insert=\"footer :: copy\"&gt;&lt;/div&gt;&lt;div th:replace=\"footer :: copy\"&gt;&lt;/div&gt;&lt;div th:include=\"footer :: copy\"&gt;&lt;/div&gt;效果&lt;div&gt; &lt;footer&gt; &amp;copy; 2011 The Good Thymes Virtual Grocery &lt;/footer&gt;&lt;/div&gt;&lt;footer&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/footer&gt;&lt;div&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/div&gt; 引入时传参 123&lt;!--引入侧边栏;传入参数--&gt;&lt;div th:replace=\"commons/bar::#sidebar(activeUri='emps')\"&gt;&lt;/div&gt;&lt;!--在这里就可以用#&#123;activeUri&#125;来取值--&gt; 页面日期格式化 1#&#123;dates.format(time,'yyyy-MM-dd HH:mm')&#125; 12&lt;!--自定义属性--&gt;&lt;div th:attr=\"属性名=属性值,属性名2=属性值2\"&gt;&lt;/div&gt; 后端配置和注解12#前端传来的日期转化格式spring.mvc.data-format=yyy-MM-dd @PathVariable(‘xxx’)在属性上，xxx即使地址上@GetMapping(“/{xxx}”)的值 在表单内配置name=&quot;_method&quot; value=&quot;方法&quot;来实现delete和put。传递为post 错误处理原理： ​ 可以参照ErrorMvcAutoConfiguration；错误处理的自动配置； 给容器中添加了以下组件 DefaultErrorAttributes： 1234567891011//帮我们在页面共享信息；@Overridepublic Map&lt;String, Object&gt; getErrorAttributes(RequestAttributes requestAttributes, boolean includeStackTrace) &#123; Map&lt;String, Object&gt; errorAttributes = new LinkedHashMap&lt;String, Object&gt;(); errorAttributes.put(\"timestamp\", new Date()); addStatus(errorAttributes, requestAttributes); addErrorDetails(errorAttributes, requestAttributes, includeStackTrace); addPath(errorAttributes, requestAttributes); return errorAttributes;&#125; BasicErrorController：处理默认/error请求 12345678910111213141516171819202122232425@Controller//取出server.error.path的值，如果没有就取出error.path，如果也没有就用 /error@RequestMapping(\"$&#123;server.error.path:$&#123;error.path:/error&#125;&#125;\")public class BasicErrorController extends AbstractErrorController &#123; @RequestMapping(produces = \"text/html\")//产生html类型的数据；浏览器发送的请求来到这个方法处理 public ModelAndView errorHtml(HttpServletRequest request, HttpServletResponse response) &#123; HttpStatus status = getStatus(request); Map&lt;String, Object&gt; model = Collections.unmodifiableMap(getErrorAttributes( request, isIncludeStackTrace(request, MediaType.TEXT_HTML))); response.setStatus(status.value()); //去哪个页面作为错误页面；包含页面地址和页面内容 ModelAndView modelAndView = resolveErrorView(request, response, status, model); return (modelAndView == null ? new ModelAndView(\"error\", model) : modelAndView); &#125; @RequestMapping @ResponseBody //产生json数据，其他客户端来到这个方法处理； public ResponseEntity&lt;Map&lt;String, Object&gt;&gt; error(HttpServletRequest request) &#123; Map&lt;String, Object&gt; body = getErrorAttributes(request, isIncludeStackTrace(request, MediaType.ALL)); HttpStatus status = getStatus(request); return new ResponseEntity&lt;Map&lt;String, Object&gt;&gt;(body, status); &#125; ErrorPageCustomizer： 12@Value(\"$&#123;error.path:/error&#125;\")private String path = \"/error\"; 系统出现错误以后来到error请求进行处理；（web.xml注册的错误页面规则） DefaultErrorViewResolver： 123456789101112131415161718192021222324@Overridepublic ModelAndView resolveErrorView(HttpServletRequest request, HttpStatus status, Map&lt;String, Object&gt; model) &#123; ModelAndView modelAndView = resolve(String.valueOf(status), model); if (modelAndView == null &amp;&amp; SERIES_VIEWS.containsKey(status.series())) &#123; modelAndView = resolve(SERIES_VIEWS.get(status.series()), model); &#125; return modelAndView;&#125;private ModelAndView resolve(String viewName, Map&lt;String, Object&gt; model) &#123; //默认SpringBoot可以去找到一个页面？ error/404 String errorViewName = \"error/\" + viewName; //模板引擎可以解析这个页面地址就用模板引擎解析 TemplateAvailabilityProvider provider = this.templateAvailabilityProviders .getProvider(errorViewName, this.applicationContext); if (provider != null) &#123; //模板引擎可用的情况下返回到errorViewName指定的视图地址 return new ModelAndView(errorViewName, model); &#125; //模板引擎不可用，就在静态资源文件夹下找errorViewName对应的页面 error/404.html return resolveResource(errorViewName, model);&#125; ​ 步骤： ​ 一但系统出现4xx或者5xx之类的错误；ErrorPageCustomizer就会生效（定制错误的响应规则）；就会来到/error请求；就会被BasicErrorController处理； ​ 1）响应页面；去哪个页面是由DefaultErrorViewResolver解析得到的； 1234567891011protected ModelAndView resolveErrorView(HttpServletRequest request, HttpServletResponse response, HttpStatus status, Map&lt;String, Object&gt; model) &#123; //所有的ErrorViewResolver得到ModelAndView for (ErrorViewResolver resolver : this.errorViewResolvers) &#123; ModelAndView modelAndView = resolver.resolveErrorView(request, status, model); if (modelAndView != null) &#123; return modelAndView; &#125; &#125; return null;&#125; 定制错误页面 有模板引擎的情况下；error/状态码;【将错误页面命名为 错误状态码.html 放在模板引擎文件夹里面的 error文件夹下】，发生此状态码的错误就会来到 对应的页面； 我们可以使用4xx和5xx作为错误页面的文件名来匹配这种类型的所有错误，精确优先（优先寻找精确的状态码.html）； ​ 页面能获取的信息； ​ timestamp：时间戳 ​ status：状态码 ​ error：错误提示 ​ exception：异常对象 ​ message：异常消息 ​ errors：JSR303数据校验的错误都在这里 -没有模板引擎（模板引擎找不到这个错误页面），静态资源文件夹下找； 以上都没有错误页面，就是默认来到SpringBoot默认的错误提示页面； 定制错误的json数据； 自定义异常处理&amp;返回定制json数据； 12345678910111213@ControllerAdvicepublic class MyExceptionHandler &#123; @ResponseBody//处理的异常 @ExceptionHandler(UserNotExistException.class) public Map&lt;String,Object&gt; handleException(Exception e)&#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put(\"code\",\"user.notexist\"); map.put(\"message\",e.getMessage()); return map; &#125;&#125;//缺点：没有自适应效果。浏览器和服务器都是JSON数据 转发到/error进行自适应响应效果处理 123456789101112131415@ExceptionHandler(UserNotExistException.class)public String handleException(Exception e, HttpServletRequest request)&#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); //传入我们自己的错误状态码 4xx 5xx，否则就不会进入定制错误页面的解析流程 /** * Integer statusCode = (Integer) request .getAttribute(\"javax.servlet.error.status_code\"); */ //默认状态码是200，所以我们要自己设置状态码。让他能到我们自己定制的错误页面 request.setAttribute(\"javax.servlet.error.status_code\",500); map.put(\"code\",\"user.notexist\"); map.put(\"message\",e.getMessage()); //转发到/error让它帮忙处理自适应， return \"forward:/error\";&#125; 将我们定制的数据携带出去出现错误以后，会来到/error请求，会被BasicErrorController处理，响应出去可以获取的数据是由getErrorAttributes得到的（是AbstractErrorController（ErrorController）规定的方法）； 完全来编写一个ErrorController的实现类【或者是编写AbstractErrorController的子类】，放在容器中； 页面上能用的数据，或者是json返回能用的数据都是通过errorAttributes.getErrorAttributes得到； ​ 容器中DefaultErrorAttributes.getErrorAttributes()；默认进行数据处理的； 自定义ErrorAttributes 1234567891011121314151617//给容器中加入我们自己定义的ErrorAttributes//定制错误信息@Componentpublic class MyErrorAttributes extends DefaultErrorAttributes &#123;//返回的map就是页面和JSON获取的错误信息 @Override public Map&lt;String, Object&gt; getErrorAttributes(RequestAttributes requestAttributes, boolean includeStackTrace) &#123; Map&lt;String, Object&gt; map = super.getErrorAttributes(requestAttributes, includeStackTrace); map.put(\"company\",\"atguigu\"); //我们的异常处理器携带的数据 //ext是自己放入的属性的key，0表示REQUEST域中（详情见RequestAttributes） Map&lt;String,Object&gt; ext = (Map&lt;String, Object&gt;) requestAttributes.getAttribute(\"ext\", 0); map.put(\"ext\",ext); return map; &#125;&#125; 最终的效果：响应是自适应的，可以通过定制ErrorAttributes改变需要返回的内容， Servlet容器配置 通过配置修改容器配置 123456789server.port=8081server.context-path=/crudserver.tomcat.uri-encoding=UTF-8//通用的Servlet容器设置server.xxx//Tomcat的设置server.tomcat.xxx 编写一个EmbeddedServletContainerCustomizer：嵌入式的Servlet容器的定制器；来修改Servlet容器的配置 1234567891011@Bean //一定要将这个定制器加入到容器中public EmbeddedServletContainerCustomizer embeddedServletContainerCustomizer()&#123; return new EmbeddedServletContainerCustomizer() &#123; //定制嵌入式的Servlet容器相关的规则 @Override public void customize(ConfigurableEmbeddedServletContainer container) &#123; container.setPort(8083); &#125; &#125;;&#125; 注册Servlet三大组件【Servlet、Filter、Listener】由于SpringBoot默认是以jar包的方式启动嵌入式的Servlet容器来启动SpringBoot的web应用，没有web.xml文件。 注册三大组件用以下方式 ServletRegistrationBean 1234567//注册三大组件@Beanpublic ServletRegistrationBean myServlet()&#123; //字符串是映射路径 ServletRegistrationBean registrationBean = new ServletRegistrationBean(new MyServlet(),\"/myServlet\"); return registrationBean;&#125; FilterRegistrationBean 12345678@Beanpublic FilterRegistrationBean myFilter()&#123; FilterRegistrationBean registrationBean = new FilterRegistrationBean(); registrationBean.setFilter(new MyFilter()); //拦截路径 registrationBean.setUrlPatterns(Arrays.asList(\"/hello\",\"/myServlet\")); return registrationBean;&#125; ServletListenerRegistrationBean 12345@Beanpublic ServletListenerRegistrationBean myListener()&#123; ServletListenerRegistrationBean&lt;MyListener&gt; registrationBean = new ServletListenerRegistrationBean&lt;&gt;(new MyListener()); return registrationBean;&#125; SpringBoot帮我们自动SpringMVC的时候，自动的注册SpringMVC的前端控制器；DIspatcherServlet； DispatcherServletAutoConfiguration中： 123456789101112131415161718//DispatcherServletAutoConfiguration源代码@Bean(name = DEFAULT_DISPATCHER_SERVLET_REGISTRATION_BEAN_NAME)@ConditionalOnBean(value = DispatcherServlet.class, name = DEFAULT_DISPATCHER_SERVLET_BEAN_NAME)public ServletRegistrationBean dispatcherServletRegistration( DispatcherServlet dispatcherServlet) &#123; ServletRegistrationBean registration = new ServletRegistrationBean( dispatcherServlet, this.serverProperties.getServletMapping()); //默认拦截： / 所有请求；包静态资源，但是不拦截jsp请求； /*会拦截jsp //可以通过server.servletPath来修改SpringMVC前端控制器默认拦截的请求路径 registration.setName(DEFAULT_DISPATCHER_SERVLET_BEAN_NAME); registration.setLoadOnStartup( this.webMvcProperties.getServlet().getLoadOnStartup()); if (this.multipartConfig != null) &#123; registration.setMultipartConfig(this.multipartConfig); &#125; return registration;&#125; 替换为其他嵌入式Servlet容器Jetty（长链接）、Undertow（不支持jsp，性能好） Jetty 1234567891011121314151617&lt;!-- 引入web模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; Undertow 1234567891011121314151617&lt;!-- 引入web模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; 容器自动配置原理EmbeddedServletContainerAutoConfiguration：嵌入式的Servlet容器自动配置？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)@Configuration@ConditionalOnWebApplication@Import(BeanPostProcessorsRegistrar.class)//导入BeanPostProcessorsRegistrar：Spring注解版；给容器中导入一些组件//导入了EmbeddedServletContainerCustomizerBeanPostProcessor：//后置处理器：bean初始化前后（创建完对象，还没属性赋值）执行初始化工作public class EmbeddedServletContainerAutoConfiguration &#123; @Configuration @ConditionalOnClass(&#123; Servlet.class, Tomcat.class &#125;)//判断当前是否引入了Tomcat依赖； @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT)//判断当前容器没有用户自己定义EmbeddedServletContainerFactory：嵌入式的Servlet容器工厂；作用：创建嵌入式的Servlet容器 public static class EmbeddedTomcat &#123; @Bean public TomcatEmbeddedServletContainerFactory tomcatEmbeddedServletContainerFactory() &#123; return new TomcatEmbeddedServletContainerFactory(); &#125; &#125; /** * Nested configuration if Jetty is being used. */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Server.class, Loader.class, WebAppContext.class &#125;) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedJetty &#123; @Bean public JettyEmbeddedServletContainerFactory jettyEmbeddedServletContainerFactory() &#123; return new JettyEmbeddedServletContainerFactory(); &#125; &#125; /** * Nested configuration if Undertow is being used. */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Undertow.class, SslClientAuthMode.class &#125;) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedUndertow &#123; @Bean public UndertowEmbeddedServletContainerFactory undertowEmbeddedServletContainerFactory() &#123; return new UndertowEmbeddedServletContainerFactory(); &#125; &#125; 1）、EmbeddedServletContainerFactory（嵌入式Servlet容器工厂） 1234567public interface EmbeddedServletContainerFactory &#123; //获取嵌入式的Servlet容器 EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers);&#125; 有三个容器创建工厂 2）、EmbeddedServletContainer：（嵌入式的Servlet容器） 3）、以TomcatEmbeddedServletContainerFactory为例 123456789101112131415161718192021222324@Overridepublic EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers) &#123; //创建一个Tomcat Tomcat tomcat = new Tomcat(); //配置Tomcat的基本环境 File baseDir = (this.baseDirectory != null ? this.baseDirectory : createTempDir(\"tomcat\")); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) &#123; tomcat.getService().addConnector(additionalConnector); &#125; prepareContext(tomcat.getHost(), initializers); //将配置好的Tomcat传入进去，返回一个EmbeddedServletContainer；并且启动Tomcat服务器 return getTomcatEmbeddedServletContainer(tomcat);&#125; 4）、我们对嵌入式容器的配置修改是怎么生效？ 1ServerProperties、EmbeddedServletContainerCustomizer EmbeddedServletContainerCustomizer：定制器帮我们修改了Servlet容器的配置？ 怎么修改的原理？ 5）、容器中导入了EmbeddedServletContainerCustomizerBeanPostProcessor 12345678910111213141516171819202122232425262728293031323334353637//初始化之前@Overridepublic Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; //如果当前初始化的是一个ConfigurableEmbeddedServletContainer类型的组件 if (bean instanceof ConfigurableEmbeddedServletContainer) &#123; // postProcessBeforeInitialization((ConfigurableEmbeddedServletContainer) bean); &#125; return bean;&#125;private void postProcessBeforeInitialization( ConfigurableEmbeddedServletContainer bean) &#123; //获取所有的定制器，调用每一个定制器的customize方法来给Servlet容器进行属性赋值； for (EmbeddedServletContainerCustomizer customizer : getCustomizers()) &#123; customizer.customize(bean); &#125;&#125;private Collection&lt;EmbeddedServletContainerCustomizer&gt; getCustomizers() &#123; if (this.customizers == null) &#123; // Look up does not include the parent context this.customizers = new ArrayList&lt;EmbeddedServletContainerCustomizer&gt;( this.beanFactory //从容器中获取所有这葛类型的组件：EmbeddedServletContainerCustomizer //定制Servlet容器，给容器中可以添加一个EmbeddedServletContainerCustomizer类型的组件 .getBeansOfType(EmbeddedServletContainerCustomizer.class, false, false) .values()); Collections.sort(this.customizers, AnnotationAwareOrderComparator.INSTANCE); this.customizers = Collections.unmodifiableList(this.customizers); &#125; return this.customizers;&#125;ServerProperties也是定制器 步骤： 1）、SpringBoot根据导入的依赖情况，给容器中添加相应的EmbeddedServletContainerFactory【TomcatEmbeddedServletContainerFactory】 2）、容器中某个组件要创建对象就会惊动后置处理器；EmbeddedServletContainerCustomizerBeanPostProcessor； 只要是嵌入式的Servlet容器工厂，后置处理器就工作； 3）、后置处理器，从容器中获取所有的EmbeddedServletContainerCustomizer，调用定制器的定制方法 嵌入式Servlet容器启动原理；什么时候创建嵌入式的Servlet容器工厂？什么时候获取嵌入式的Servlet容器并启动Tomcat； 获取嵌入式的Servlet容器工厂： 1）、SpringBoot应用启动运行run方法 2）、refreshContext(context);SpringBoot刷新IOC容器【创建IOC容器对象，并初始化容器，创建容器中的每一个组件】；如果是web应用创建AnnotationConfigEmbeddedWebApplicationContext，否则：AnnotationConfigApplicationContext 3）、refresh(context);刷新刚才创建好的ioc容器； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 4）、 onRefresh(); web的ioc容器重写了onRefresh方法 5）、webioc容器会创建嵌入式的Servlet容器；createEmbeddedServletContainer(); 6）、获取嵌入式的Servlet容器工厂： EmbeddedServletContainerFactory containerFactory = getEmbeddedServletContainerFactory(); ​ 从ioc容器中获取EmbeddedServletContainerFactory 组件；TomcatEmbeddedServletContainerFactory创建对象，后置处理器一看是这个对象，就获取所有的定制器来先定制Servlet容器的相关配置； 7）、使用容器工厂获取嵌入式的Servlet容器：this.embeddedServletContainer = containerFactory .getEmbeddedServletContainer(getSelfInitializer()); 8）、嵌入式的Servlet容器创建对象并启动Servlet容器； 先启动嵌入式的Servlet容器，再将ioc容器中剩下没有创建出的对象获取出来； IOC容器启动创建嵌入式的Servlet容器 使用外置的Servlet容器嵌入式Servlet容器：应用打成可执行的jar ​ 优点：简单、便携； ​ 缺点：默认不支持JSP、优化定制比较复杂（使用定制器【ServerProperties、自定义EmbeddedServletContainerCustomizer】，自己编写嵌入式Servlet容器的创建工厂【EmbeddedServletContainerFactory】）； 外置的Servlet容器：外面安装Tomcat—应用war包的方式打包； 步骤1）、必须创建一个war项目；（利用idea创建好目录结构） 2）、将嵌入式的Tomcat指定为provided； 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 3）、必须编写一个SpringBootServletInitializer的子类，并调用configure方法 123456789public class ServletInitializer extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; //传入SpringBoot应用的主程序 return application.sources(SpringBoot04WebJspApplication.class); &#125;&#125; 4）、启动服务器就可以使用； 原理jar包：执行SpringBoot主类的main方法，启动ioc容器，创建嵌入式的Servlet容器； war包：启动服务器，服务器启动SpringBoot应用【SpringBootServletInitializer】，启动ioc容器； servlet3.0规范的8.2.4章节 共享库 / 运行时插件： 规则： ​ 1）、服务器启动（web应用启动）会创建当前web应用里面每一个jar包里面ServletContainerInitializer实例： ​ 2）、ServletContainerInitializer的实现放在jar包的META-INF/services文件夹下，有一个名为javax.servlet.ServletContainerInitializer的文件，内容就是ServletContainerInitializer的实现类的全类名 ​ 3）、还可以使用@HandlesTypes，在应用启动的时候加载我们感兴趣的类； 流程： 1）、启动Tomcat 2）、org\\springframework\\spring-web\\4.3.14.RELEASE\\spring-web-4.3.14.RELEASE.jar!\\META-INF\\services\\javax.servlet.ServletContainerInitializer： Spring的web模块里面有这个文件：org.springframework.web.SpringServletContainerInitializer 3）、SpringServletContainerInitializer将@HandlesTypes(WebApplicationInitializer.class)标注的所有这个类型的类都传入到onStartup方法的Set&lt;Class&lt;?&gt;&gt;；为这些WebApplicationInitializer类型的类创建实例； 4）、每一个WebApplicationInitializer都调用自己的onStartup； 5）、相当于我们的SpringBootServletInitializer的类会被创建对象，并执行onStartup方法 6）、SpringBootServletInitializer实例执行onStartup的时候会createRootApplicationContext；创建容器 1234567891011121314151617181920212223242526272829303132333435363738protected WebApplicationContext createRootApplicationContext( ServletContext servletContext) &#123; //1、创建SpringApplicationBuilder SpringApplicationBuilder builder = createSpringApplicationBuilder(); StandardServletEnvironment environment = new StandardServletEnvironment(); environment.initPropertySources(servletContext, null); builder.environment(environment); builder.main(getClass()); ApplicationContext parent = getExistingRootWebApplicationContext(servletContext); if (parent != null) &#123; this.logger.info(\"Root context already created (using as parent).\"); servletContext.setAttribute( WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, null); builder.initializers(new ParentContextApplicationContextInitializer(parent)); &#125; builder.initializers( new ServletContextApplicationContextInitializer(servletContext)); builder.contextClass(AnnotationConfigEmbeddedWebApplicationContext.class); //调用configure方法，子类重写了这个方法，将SpringBoot的主程序类传入了进来 builder = configure(builder); //使用builder创建一个Spring应用 SpringApplication application = builder.build(); if (application.getSources().isEmpty() &amp;&amp; AnnotationUtils .findAnnotation(getClass(), Configuration.class) != null) &#123; application.getSources().add(getClass()); &#125; Assert.state(!application.getSources().isEmpty(), \"No SpringApplication sources have been defined. Either override the \" + \"configure method or add an @Configuration annotation\"); // Ensure error pages are registered if (this.registerErrorPageFilter) &#123; application.getSources().add(ErrorPageFilterConfiguration.class); &#125; //启动Spring应用 return run(application);&#125; 7）、Spring的应用就启动并且创建IOC容器 1234567891011121314151617181920212223242526272829303132333435public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); Banner printedBanner = printBanner(environment); context = createApplicationContext(); analyzers = new FailureAnalyzers(context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); //刷新IOC容器 refreshContext(context); afterRefresh(context, applicationArguments); listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; 启动Servlet容器，再启动SpringBoot应用 SpringBoot2上面都是springboot1的笔记 SpringBoot也支持函数式服务。 使用完就结束 SpringBoot2以Spring5为基础。 Spring5引入响应式编程。 123456&lt;!--设置父项目，来真正管理Spring Boot应用里面的所有依赖版本；--&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.4.RELEASE&lt;/version&gt;&lt;/parent&gt; 如果需要不同的的包版本 查看spring-boot-dependencies里面properties规定当前依赖的版本 用的 key。 在当前项目里面重写配置 123&lt;properties&gt; &lt;mysql.version&gt;5.1.43&lt;/mysql.version&gt;&lt;/properties&gt;","categories":[],"tags":[{"name":"后端","slug":"后端","permalink":"http://example.com/tags/%E5%90%8E%E7%AB%AF/"},{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://example.com/tags/spring/"}]},{"title":"SpringSecurity","slug":"SpringSecurity","date":"2019-12-19T05:16:17.000Z","updated":"2021-07-08T07:57:50.940Z","comments":true,"path":"2019/12/19/SpringSecurity/","link":"","permalink":"http://example.com/2019/12/19/SpringSecurity/","excerpt":"","text":"简述SpringSecurity为JavaEE应用提供完整安全解决方案，和全面的安全服务，少量的配置即可构建强大的安全的应用 SpringBoot底层默认整合SpringSecurity作为安全框架 认证：建立主体（principal）的过程 授权：主体（principal）是否被允许执行系统中某个动作的过程 文档样例 基于Java配置整合示例 SpringBoot整合案例 基于XML方式整合示例 SpringMVC集成示例 自定义登录表单示例 支持的身份验证模式 HTTP BASIC身份验证标头 HTTP BASIC authentication headers (an IETF RFC-based standard)参考 HTTP Digest身份验证标头 HTTP Digest authentication headers (an IETF RFC-based standard) HTTP X.509客户端证书交换 HTTP X.509 client certificate exchange (an IETF RFC-based standard) LDAP（一种非常常见的跨平台身份验证方法，特别是在大型环境中） LDAP (a very common approach to cross-platform authentication needs, especially in large environments) 基于表单的身份验证（用于简单的用户界面需求） Form-based authentication (for simple user interface needs) OpenID身份验证 OpenID authentication 基于预先建立的请求标头的身份验证 Authentication based on pre-established request headers (such as Computer Associates Siteminder) Jasig中央认证服务（也称为CAS，是一种流行的开源单点登录系统） Jasig Central Authentication Service (otherwise known as CAS, which is a popular open source single sign-on system) 远程方法调用（RMI）和HttpInvoker（Spring远程协议）的透明身份验证上下文传播 Transparent authentication context propagation for Remote Method Invocation (RMI) and HttpInvoker (a Spring remoting protocol) 自动“记住我”身份验证 Automatic “remember-me” authentication (so you can tick a box to avoid re-authentication for a predetermined period of time) 匿名身份验证（允许每个未经身份验证自动承担特定的安全身份） Anonymous authentication (allowing every unauthenticated call to automatically assume a particular security identity) Runas身份验证（如果一个调用应继续使用不同的安全标识，则非常有用） Run-as authentication (which is useful if one call should proceed with a different security identity) Java身份验证和授权服务（JAAS） Java Authentication and Authorization Service (JAAS) JavaEE容器身份验证（如果需要，您仍然可以使用容器管理身份验证） Java EE container authentication (so you can still use Container Managed Authentication if desired) Java开源单点登录（JOSSO） Java Open Source Single Sign-On (JOSSO) * OpenNMS网络管理平台* OpenNMS Network Management Platform * 您自己的身份验证系统 Your own authentication systems (see below) 其他 Kerberos AppFuse * AndroMDA * Mule ESB * Direct Web Request (DWR) * Grails * Tapestry * JTrac * Jasypt * Roller * Elastic Path * Atlassian Crowd * Jar包模块 jar包 功能 spring-security-core.jar 核心认证、授权功能、支持jdbc-user功能、支持独立的Spring应用 spring-security-remoting.jar 一般不需要，可以使用Spring Remoting功能简化远程客户端交互 spring-security-web.jar web项目使用，基于URL的访问控制（access-control） spring-security-config.jar 必须依赖包，包含解析xml方式和java 注解方式来使用SpringSecurity功能 spring-security-ldap.jar 可选依赖包，LDAP功能支持（轻量目录访问协议） spring-security-acl.jar ACL（Access-Control-List）访问控制列表、细粒度的资源访问控制(RBAC+ACL) spring-security-cas.jar CAS（Central Authentication Service）中央认证服务。开源ApereoCAS整合 spring-security-openid.jar OpenID Web身份验证支持。用于针对外部OpenID服务器对用户进行身份验证（微信,qq，新浪微博等第三方登录） spring-security-test.jar 快速的测试SpringSecurity应用 4种使用方式 一种是全部利用配置文件，将用户、权限、资源(url)硬编码在xml文件中 二种是用户和权限用数据库存储，而资源(url)和权限的对应采用硬编码配置 三种是细分角色和权限，并将用户、角色、权限和资源均采用数据库存储，并且自定义过滤器，代替原有的FilterSecurityInterceptor过滤器， 并分别实现AccessDecisionManager、InvocationSecurityMetadataSourceService和UserDetailsService，并在配置文件中进行相应配置。 四是修改springsecurity的源代码，主要是修改InvocationSecurityMetadataSourceService和UserDetailsService两个类。 nvocationSecurityMetadataSourceService 将配置文件或数据库中存储的资源(url)提取出来加工成为url和权限列表的Map供Security使用 UserDetailsService 提取用户名和权限组成一个完整的(UserDetails)User对象，该对象可以提供用户的详细信息供AuthentationManager进行认证与授权使用 推荐第三种 简单实用依赖的jar包 12345678910111213141516171819202122232425262728293031&lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-config&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 标签库 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-taglibs&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--如果要使用到数据库的记住我要引入以下jar包--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;4.3.20.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.12&lt;/version&gt;&lt;/dependency&gt;&lt;!-- mysql驱动 --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt;&lt;/dependency&gt; 配置security的过滤器 12345678&lt;filter&gt; &lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt;&lt;!--名称固定,不能变--&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 配置类，具体配置权限、角色、页面跳转、密码校验等等 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.core.userdetails.UserDetailsService;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;import org.springframework.security.crypto.password.PasswordEncoder;import org.springframework.security.web.authentication.rememberme.JdbcTokenRepositoryImpl;@Configuration//声明配置类@EnableWebSecurity//声明式配置，启用security机制public class AppWebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Autowired UserDetailsService userDetailsService; @Autowired PasswordEncoder passwordEncoder; @Override protected void configure(HttpSecurity http) throws Exception &#123; //super.configure(http); //取消默认配置 /* http.authorizeRequests() .antMatchers(\"/layui/**\", \"/index.jsp\").permitAll() //设置匹配的资源放行 .anyRequest().authenticated(); //剩余任何资源必须认证 */ http.formLogin().loginPage(\"/index.jsp\")//登录的页面 .loginProcessingUrl(\"/doLogin\")//提交表单的路径 .usernameParameter(\"username\")//指定表单用户名的name .passwordParameter(\"password\")//指定表单密码的name .defaultSuccessUrl(\"/main.html\");//成功后前往的页面 //csrf如果没有验证成功是不会变化的，只有验证成功之后，才会变化 //防止跨站请求伪造，和表单重复提交 http.csrf().disable();//禁止掉csrf验证 //提交注销的路径 注销后前往的页面 如果开启csrf，必须以post方式注销 并且要携带token http.logout().logoutUrl(\"/logout\").logoutSuccessUrl(\"/index.jsp\"); //权限代码必须有一定的顺序，否则会权限错乱 http.authorizeRequests() .antMatchers(\"/xxx/**\", \"/xxx.html\").permitAll()//这些资源允许所有访问 .antMatchers(\"/1/**\").hasRole(\"1级角色\")//这些资源允许1级角色访问 .antMatchers(\"/2/**\").hasRole(\"2级角色\")//这些资源允许2级角色访问 .anyRequest().authenticated();//剩余任何资源必须认证 //定义异常转发的页面 404的不会转到该页面 http.exceptionHandling().accessDeniedPage(\"/exception.jsp\"); //开启记住我，在http请求中有\"remember-me\"参数即可。浏览器会存一个cookie。关闭浏览器再开启也有效。服务器重启会失效 http.rememberMe(); //基于数据库的记住我。 //数据库名为persistent_logins。不需要手动创建数据库，将dataSource给它即可，创建查询插入等工作内部会自动实现 //这样重启服务器也不会失效 JdbcTokenRepositoryImpl jdbcTokenRepository = new JdbcTokenRepositoryImpl(); //jdbcTokenRepository.setDataSource(dataSource); http.rememberMe().tokenRepository(jdbcTokenRepository); &#125; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; //默认认证 //super.configure(auth); /* //自定义认证用户信息 - 基于内存认证方式，写死认证 auth.inMemoryAuthentication().withUser(\"zhangsan\").password(\"123456\").roles(\"学徒\", \"大师\")//角色 .and()//指定账号，密码，权限 .withUser(\"lisi\").password(\"123123\").authorities(\"罗汉拳\", \"武当长拳\"); */ //采用数据库认证方式 //auth.userDetailsService(userDetailsService); //默认密码校验，按照明文进行校验。 //auth.userDetailsService(userDetailsService).passwordEncoder(passwordEncoder); //MD5+盐+随机数。同样的密码每次生成的都不一样。 //可以生成然后在替换掉数据库的密码，也可以用 auth.userDetailsService(userDetailsService).passwordEncoder(new BCryptPasswordEncoder()); &#125;&#125; 12345678910111213141516171819202122232425import org.springframework.beans.factory.annotation.Autowired;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.security.core.authority.AuthorityUtils;import org.springframework.security.core.userdetails.User;import org.springframework.security.core.userdetails.UserDetails;import org.springframework.security.core.userdetails.UserDetailsService;import org.springframework.security.core.userdetails.UsernameNotFoundException;import org.springframework.stereotype.Component;import java.util.Map;//自定义认证@Componentpublic class UserDetailServiceImpl implements UserDetailsService &#123; @Autowired JdbcTemplate jdbcTemplate; @Override//通过查询，将结果包装成User对象，也可以自己实现UserDetails。返回即可 public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; String queryUser = \"SELECT * FROM `t_admin` WHERE loginacct=?\"; //1、查询指定用户的信息 Map&lt;String, Object&gt; map = jdbcTemplate.queryForMap(queryUser, username); //2、将查询到的用户封装到框架使用的UserDetails里面 return new User(map.get(\"loginacct\").toString(), map.get(\"userpswd\").toString(), AuthorityUtils.createAuthorityList(\"ADMIN\", \"ROLE_角色名\", \"USER\"));//这里的权限暂时写死，过后数据库中查。权限直接写名字，如果想在这里写角色的话，要写\"ROLE_角色名\" &#125;&#125; 自定义编码器。了解即可 123456789101112131415161718192021222324import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;import org.springframework.security.crypto.password.PasswordEncoder;import org.springframework.stereotype.Component;@Component//了解即可，框架有写好的编码器public class PasswordEncoderImpl implements PasswordEncoder &#123; @Override//参数原文 public String encode(CharSequence rawPassword) &#123; //自定义加密，返回加密后的字符串 return new String(\"我是加密后的\"); &#125; @Override//参数一：原文 参数二：密文 密文来自数据库 public boolean matches(CharSequence rawPassword, String encodedPassword) &#123; //返回是否相等 return false; &#125; public static void main(String[] args) &#123; BCryptPasswordEncoder encoder = new BCryptPasswordEncoder(); for (int i = 0; i &lt; 10; i++) &#123; System.out.println(encoder.encode(\"123456\")); &#125; &#125;&#125; 详细介绍csrf、默认页面用户name要想使用csrf表单必须传_csrf的token&lt;input name=&quot;_csrf&quot; type=&quot;hidden&quot; value=&quot;755f0b3c-0965-430b-852e-dcf6c77e7edb&quot; /&gt; jsp上使用&lt;input type=&quot;hidden&quot; name=&quot;${_csrf.parameterName}&quot; value=&quot;${_csrf.token}&quot;/&gt; 默认字段名为password和username&#39; jsp提取错误信息${SPRING_SECURITY_LAST_EXCEPTION.message} 用户注销http.logout()可以配置的功能 /logout：退出系统 如果csrf开启，必须post方式的/logout请求，表单中需要增加csrf token logoutUrl()；退出系统需要发送的请求 logoutSuccessUrl()；退出系统成功以后要跳转的页面地址 addLogoutHandler()：自定义注销处理器 deleteCookies()：指定需要删除的cookie invalidateHttpSession()：session失效（DEBUG） 基于角色的访问控制注意点 将.anyRequest().authenticated()错误的设置在前面，后面的设置就不起作用了。 设置所有,“/\\“**都可以访问，其他再进行的设置就不会起作用了 设置匿名访问：.anyRequest().anonymous(); 自定义异常处理器简单使用里有自定义异常页面 12345678910http.exceptionHandling().accessDeniedHandler(new AccessDeniedHandler() &#123; @Override public void handle(HttpServletRequest request, HttpServletResponse response, AccessDeniedException accessDeniedException) throws IOException, ServletException &#123; //设置错误信息 request.setAttribute(\"message\", accessDeniedException.getMessage()); //设置转发路径 request.getRequestDispatcher(\"/WEB-INF/views/unauth.jsp\").forward(request, response); &#125;&#125;); 认证一共有两种方式方式一：重写jdbcAuthentication规则但是不推荐 要求数据库表和SpringSecurity的一模一样，局限太大 要用的时候自己去查 方式二：自定义UserDetailsService检索用户 在简单使用里面有写 细粒度权限控制","categories":[],"tags":[{"name":"后端","slug":"后端","permalink":"http://example.com/tags/%E5%90%8E%E7%AB%AF/"},{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"springsecurity","slug":"springsecurity","permalink":"http://example.com/tags/springsecurity/"}]},{"title":"项目笔记","slug":"项目笔记","date":"2019-12-15T12:26:42.000Z","updated":"2021-07-08T08:52:35.080Z","comments":true,"path":"2019/12/15/项目笔记/","link":"","permalink":"http://example.com/2019/12/15/%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/","excerpt":"","text":"众筹项目负载均衡策略 轮询 加权 随机 最短响应 哈希 ip地址散列、URL散列 通过管理发送方IP和目的地IP地址的散列，将来自同一发送方的分组(或发送至同一目的地的分组)统一转发到相同服务器的算法 系统架构 SANs：静态资源服务器 HA：高可用 软件开发模型瀑布模型按顺序依次实施 计划阶段 可行性研究 需求分析 开发阶段 软件设计 编码 软件测试 维护阶段 运行、维护 其他模型 边做边改 快速原型 敏捷开发 增量 螺旋 演化 喷泉 智能 混合 RAD 原型构建根据需求，创建页面草图 Axure Mockupcreator 数据库设计使用PowerDesigner工具 按住Ctrl+滚轮放缩。 我们一般将一个业务模块放到一个格子内 右侧工具栏，可以创建表等。 创建后双击打开，进行编辑 右侧工具栏，可以创建Reference连接两张表 点击连线，设置外键关联 生成SQL： 右击左侧模块，propertise-&gt;Preview，然后可以复制或保存里面的sql语句 上侧工具栏Database-&gt;Generate Database或者Ctrl+G生成sql语句 建议通过命令行执行SQL文件 source 文件路径，不用加;号 -p为密码，-P为端口号 业务流程设计Rational Rose 打开后直接点取消，因为如果选Java类图加载会比较久 Use Case View；用例图 右击文件夹New-&gt;Use Case Diagram，取名 小人：代表用户 椭圆：代表功能 note：小文本 Logical View：逻辑视图 右击文件夹New-&gt;Class Diagram创建类图 描述类与类之间的关系 右击文件夹New-&gt;Sequence Diagram创建时序图 描述执行流程 调用画实现，返回画虚线 在实现上写，大致请求返回 Component View：组件视图 Mybatis从其他项目包下加载123456&lt;bean class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"configLocation\" value=\"classpath:/mybatis/mybatis-config.xml\"&gt;&lt;/property&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"&gt;&lt;/property&gt; &lt;!--*表示可以从其他包下加载配置，不加*就是当前项目--&gt; &lt;property name=\"mapperLocations\" value=\"classpath*:/mybatis/mapper/*.xml\"&gt;&lt;/property&gt;&lt;/bean&gt; SSM三大框架集成12345678910- config - jdbc.properties- mybatis - mybatis-config.xml- spring - spring-beans.xml - spring-mybatis.xml - spring-tx.xml - springmvc.xml- logback.xml 最后一份是web.xml配置。 jdbc.properties文件 1234datasource.username=rootdatasource.password=000000datasource.url=jdbc:mysql://localhost:3306/atcrowdfunding?useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8datasource.driver=com.mysql.jdbc.Driver mybatis-config.xml 1234567891011121314&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!-- http://www.mybatis.org/mybatis-3/zh/getting-started.html --&gt; &lt;!-- 配置PageHelper插件 ; 或者在spring配置SqlSessionFactoryBean进行配置 &lt;plugins&gt; &lt;plugin interceptor=\"com.github.pagehelper.PageInterceptor\"&gt; &lt;property name=\"reasonable\" value=\"true\" /&gt; &lt;/plugin&gt; &lt;/plugins&gt; --&gt;&lt;/configuration&gt; spring-beans.xml 12345678910111213&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.3.xsd\"&gt; &lt;context:component-scan base-package=\"com.atguigu.atcrowdfunding\"&gt; &lt;context:exclude-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/&gt;&lt;!--Controller增强器,可对controller中被 @RequestMapping注解的方法加一些逻辑处理。最常用的就是异常处理--&gt;&lt;!--这里没用到，可以注释掉--&gt; &lt;context:exclude-filter type=\"annotation\" expression=\"org.springframework.web.bind.annotation.ControllerAdvice\"/&gt; &lt;/context:component-scan&gt;&lt;/beans&gt; spring-mybatis.xml 1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!-- 中间包 --&gt; &lt;bean class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"configLocation\" value=\"classpath:/mybatis/mybatis-config.xml\"&gt;&lt;/property&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"&gt;&lt;/property&gt; &lt;!--*表示可以从其他包下加载配置，不加*就是当前项目--&gt; &lt;property name=\"mapperLocations\" value=\"classpath*:/mybatis/mapper/*.xml\"&gt;&lt;/property&gt; &lt;property name=\"plugins\"&gt; &lt;bean class=\"com.github.pagehelper.PageInterceptor\"&gt; &lt;property name=\"properties\"&gt; &lt;value&gt;&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 映射dao接口，实现dao接口，并放入容器 --&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"com.atguigu.atcrowdfunding.mapper\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; spring-tx.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:mybatis-spring=\"http://mybatis.org/schema/mybatis-spring\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\"http://mybatis.org/schema/mybatis-spring http://mybatis.org/schema/mybatis-spring-1.2.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.3.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.3.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.3.xsd\"&gt;&lt;!--事务配置--&gt; &lt;context:property-placeholder location=\"classpath:/config/jdbc.properties\" /&gt; &lt;!-- 阿里的数据库连接池Druid：获取数据库的操作 --&gt; &lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\"&gt; &lt;property name=\"username\" value=\"$&#123;datasource.username&#125;\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"$&#123;datasource.password&#125;\"&gt;&lt;/property&gt; &lt;property name=\"url\" value=\"$&#123;datasource.url&#125;\"&gt;&lt;/property&gt; &lt;property name=\"driverClassName\" value=\"$&#123;datasource.driver&#125;\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 事务管理器：控制着数据源 --&gt; &lt;bean id=\"tm\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置版的事务切面 --&gt; &lt;aop:config&gt; &lt;!-- *任意返回值 service包下 ..service下的任意包 *任意类 .*任意方法 (..)任意参数 --&gt; &lt;aop:pointcut expression=\"execution(* com.atguigu.atcrowdfunding.service..*.*(..))\" id=\"point\" /&gt; &lt;!-- advice-ref：关联增强事务 pointcut-ref：关联事务的切入点 --&gt; &lt;aop:advisor advice-ref=\"tx\" pointcut-ref=\"point\" /&gt; &lt;/aop:config&gt; &lt;!-- 配置事务增强 --&gt; &lt;tx:advice transaction-manager=\"tm\" id=\"tx\"&gt; &lt;!-- 事务属性 --&gt; &lt;tx:attributes&gt; &lt;!-- 所有 方法都是事务 --&gt; &lt;tx:method name=\"*\" /&gt; &lt;tx:method name=\"get*\" read-only=\"true\" /&gt; &lt;tx:method name=\"find*\" read-only=\"true\" /&gt; &lt;tx:method name=\"list*\" read-only=\"true\" /&gt; &lt;!--增删改 --&gt;&lt;!--超时、回滚--&gt; &lt;tx:method name=\"insert*\" timeout=\"5000\" rollback-for=\"java.lang.Exception\"/&gt; &lt;tx:method name=\"add*\" timeout=\"5000\" /&gt; &lt;tx:method name=\"update*\" timeout=\"5000\" /&gt; &lt;tx:method name=\"delete*\" timeout=\"5000\" /&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt;&lt;/beans&gt; springmvc 1234567891011121314151617181920212223242526&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.3.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.3.xsd\"&gt; &lt;!--把默认扫描@Service,@Controller和@Repository注解关闭--&gt; &lt;context:component-scan base-package=\"com.atguigu.atcrowdfunding.controller\" use-default-filters=\"false\"&gt; &lt;context:include-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/&gt; &lt;context:include-filter type=\"annotation\" expression=\"org.springframework.web.bind.annotation.ControllerAdvice\"/&gt; &lt;/context:component-scan&gt; &lt;!-- springmvc的标配：视图解析器 --&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/jsp/\"&gt;&lt;/property&gt; &lt;property name=\"suffix\" value=\".jsp\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 开启SpringMVC高级模式 --&gt; &lt;mvc:annotation-driven/&gt; &lt;!-- 放行静态资源访问 --&gt; &lt;mvc:default-servlet-handler/&gt;&lt;/beans&gt; logback.xml 12345678910111213&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt; &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;pattern&gt;%-4relative [%thread] %-5level %logger&#123;35&#125; - %msg %n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=\"DEBUG\"&gt; &lt;appender-ref ref=\"STDOUT\" /&gt; &lt;/root&gt;&lt;/configuration&gt; webapp-WEB-INF-web.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd\" version=\"3.1\" metadata-complete=\"true\"&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;!-- 创建Spring IOC容器 --&gt; &lt;!-- needed for ContextLoaderListener --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:/spring/spring-*.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- Bootstraps the root web application context before servlet initialization --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 字符编码过滤器 --&gt; &lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceRequestEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceResponseEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- RESTFul风格，将POST请求转换为PUT或DELETE请求 --&gt; &lt;filter&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.HiddenHttpMethodFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- 核心控制器 --&gt; &lt;!-- The front controller of this Spring Web application, responsible for handling all application requests --&gt; &lt;servlet&gt; &lt;servlet-name&gt;springDispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:/spring/springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;!-- Map all requests to the DispatcherServlet for handling --&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springDispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!-- 欢迎页面 --&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;welcome.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt;&lt;/web-app&gt; MBG逆向工程逆向工程手册 将generatorConfig.xml配置文件放入项目下 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\" \"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\"&gt; &lt;generatorConfiguration&gt; &lt;context id=\"MySQLTables\" targetRuntime=\"MyBatis3\"&gt;&lt;!-- mvn mybatis-generator:generate配置数据库位置 ，配置虚拟机上的mysql ip地址；不采用安全协议连接，否则无法逆向生成--&gt; &lt;jdbcConnection driverClass=\"com.mysql.jdbc.Driver\" connectionURL=\"jdbc:mysql://192.168.137.3:3306/atcrowdfunding?useSSL=false\" userId=\"root\" password=\"root\"&gt; &lt;/jdbcConnection&gt; &lt;javaTypeResolver &gt; &lt;property name=\"forceBigDecimals\" value=\"false\" /&gt; &lt;/javaTypeResolver&gt; &lt;!-- javaBean生成在哪里 --&gt; &lt;javaModelGenerator targetPackage=\"com.atguigu.atcrowdfunding.bean\" targetProject=\"..\\atcrowdfunding-bean\\src\\main\\java\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\" /&gt; &lt;property name=\"trimStrings\" value=\"true\" /&gt; &lt;/javaModelGenerator&gt; &lt;!-- sqlMap sql映射文件（xml mapper文件） --&gt; &lt;sqlMapGenerator targetPackage=\"mybatis.mapper\" targetProject=\"..\\atcrowdfunding-manager-impl\\src\\main\\resources\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\" /&gt; &lt;/sqlMapGenerator&gt; &lt;!-- javaClient：java接口生成的地方 --&gt; &lt;javaClientGenerator type=\"XMLMAPPER\" targetPackage=\"com.atguigu.atcrowdfunding.mapper\" targetProject=\"..\\atcrowdfunding-manager-api\\src\\main\\java\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\" /&gt; &lt;/javaClientGenerator&gt; &lt;table schema=\"\" tableName=\"%\"&gt;&lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 引入mbg的maven插件 12345678910111213141516&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.7&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.42&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 运行 mvn mybatis-generator:generate 如果多个maven工程，需要先全部打包一下 或 1234567891011121314151617181920212223242526import java.io.File;import java.io.IOException;import java.sql.SQLException;import java.util.ArrayList;import java.util.List;import org.mybatis.generator.api.MyBatisGenerator;import org.mybatis.generator.config.Configuration;import org.mybatis.generator.config.xml.ConfigurationParser;import org.mybatis.generator.exception.InvalidConfigurationException;import org.mybatis.generator.exception.XMLParserException;import org.mybatis.generator.internal.DefaultShellCallback;public class TestMBG &#123; public static void main(String[] args) throws IOException, XMLParserException, InvalidConfigurationException, SQLException, InterruptedException &#123; List&lt;String&gt; warnings = new ArrayList&lt;String&gt;(); boolean overwrite = true; File configFile = new File(\"src/test/resources/generatorConfig.xml\"); ConfigurationParser cp = new ConfigurationParser(warnings); Configuration config = cp.parseConfiguration(configFile); DefaultShellCallback callback = new DefaultShellCallback(overwrite); MyBatisGenerator myBatisGenerator = new MyBatisGenerator(config, callback, warnings); myBatisGenerator.generate(null); &#125;&#125; 阿里编程规约命名规约 所有编程相关命名不能以下划线和美元符开头和结尾 不允许直接使用中文，和中文拼音语文混合。 国际通用名称，可以视为英文如taobao、cainiao、hangzhou 类名使用驼峰形式，以下情形例外：(领域模型的相关命名)DO/DTO/VO/DAO等 方法名、参数名、成员变量、局部变量用lowerCamelCase风格 常量命名全部大写，单词以下划线隔开，力求语义表达完整清楚，不要嫌名字长 抽象类名以Abstract或Base开头，异常以Exception结尾，测试类以要测试的类名开头，以Test结尾 类型与中括号紧挨相连来表示数组。 int[] arrayDemo POJO 类中布尔类型变量都不要加 is 前缀，否则部分框架解析会引起序列化错误。 定义为基本数据类型 Boolean isDeleted 的属性，它的方法也是 isDeleted()， RPC 框架在反向解析的时候， “误以为” 对应的属性名称是 deleted，导致属性获取不到，进而抛出异常。 包名统一使用小写，点分隔符之间有且仅有一个自然语义的英语单词。包名统一使用单数形式，但是类名如果有复数含义，类名可以使用复数形式。 各层命名规范 Service/DAO 层方法命名规约 获取单个对象的方法用 get 做前缀。 获取多个对象的方法用 list 做前缀，复数形式结尾如： listObjects。 获取统计值的方法用 count 做前缀。 插入的方法用 save/insert 做前缀。 删除的方法用 remove/delete 做前缀。 修改的方法用 update 做前缀 领域模型命名规约 数据对象： xxxDO， xxx 即为数据表名。 数据传输对象： xxxDTO， xxx 为业务领域相关的名称。 展示对象： xxxVO， xxx 一般为网页名称。 POJO 是 DO/DTO/BO/VO 的统称，禁止命名成 xxxPOJO。 都可以POJP、controller、service、dao都可以叫做JAVABean 不允许任何魔法值(未经定义的常量出现在代码 Long类型数字写大L不能写小l 定义的常量的作用范围必须清楚 日志日志框架 JUL（java.util.logging） JCL（Jakarta Commons Logging） Log4j（Simple Logging Facade for Java） Log4j2 Logback(具体框架，springboot使用) SLF4j jboss-logging 日志门面 日志实现 JCL Log4j SLF4J JUL jboss-logging Log4j2 Logback spring没有JCL是无法运行的，但是我们不使用JCL做日志框架，这时候需要另一个包代替JCL 这里使用SLF4J+Logback 可以单独使用SLF4J，不和任何框架做整合 整合Logback，导入图片上三个包即可 整合log4j，因为log4j比slf4j出现的早。整合较麻烦。需要加一个中间层，导入slf4j-log412.jar。适配器层 剩下都不用 首选第二、第三种 日志框架历史遗留问题解决将不同的框架所集成的日志框架统一到SLF4J springboot（slf4j+logback）: Spring（commons-logging）、Hibernate（jboss-logging）、MyBatis、 SLF4J整合logback：统一commons-logging,log4j,JUL。需要导入三个转化包：jcl-over-slf4j.jar、log4j-over-slf4j.jar、jul-to-slf4j.jar。干掉原来的日志框架 SLF4J整合log4j：比第一种，再加适配层 具体解决通过排除日志包。IDEA可以借助Maven Helper插件 123456&lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;/exclusion&gt;&lt;/exclusions&gt; 12345678910111213141516171819202122232425262728293031323334353637&lt;!--日志版本--&gt;&lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt;&lt;slf4j.version&gt;1.7.6&lt;/slf4j.version&gt;&lt;logback.version&gt;1.2.3&lt;/logback.version&gt;&lt;jcl.over.slf4j&gt;1.7.25&lt;/jcl.over.slf4j&gt;&lt;jul.to.slf4j&gt;1.7.25&lt;/jul.to.slf4j&gt;&lt;!--日志包--&gt;&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt;&lt;!-- 替换commons-logging--&gt; &lt;version&gt;$&#123;jcl.over.slf4j&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jul-to-slf4j&lt;/artifactId&gt;&lt;!-- 替换java.util.logging--&gt; &lt;version&gt;$&#123;jul.to.slf4j&#125;&lt;/version&gt;&lt;/dependency&gt; 日志的使用在根目录下，创建logback.xml 1234567891011121314151617&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt; &lt;!--往控制台输出，叫STDOUT--&gt; &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;!--输出格式--&gt; &lt;!--个格式的第一个字段代表从程序启动开始后经过的毫秒数，第二个字段代表打印出这条日志的线程名字，第三个字段代表日志信息的日志打印级别，第四个字段代表全类名，超过35截取，第五个字段是日志信息，第六个字段仅仅是代表一个换行符。--&gt; &lt;pattern&gt;%-4relative [%thread] %-5level %logger&#123;35&#125; - %msg %n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--设置日志输出级别--&gt; &lt;!--开发阶段DEBUG，生产阶段ERROR--&gt; &lt;!--DEBUG-&gt;INFO-&gt;WARN-&gt;ERROR--&gt; &lt;root level=\"DEBUG\"&gt; &lt;appender-ref ref=\"STDOUT\"/&gt; &lt;/root&gt;&lt;/configuration&gt; 123456789import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class SLF4JTest &#123; public static void main(String[] args) &#123; Logger log = LoggerFactory.getLogger(SLF4JTest.class); log.debug(\"debug消息id=&#123;&#125;，name=&#123;&#125;\",1,\"张翰\"); &#125;&#125; 路径问题 绝对路径 相对路径 后台路径：后台解析的路径 /开头是相对www.xxx.com/项目名/寻找 没有/开头是相对，当前的路径 前台路径：由浏览器发起请求的路径，如引入js、css 以/开头表示从服务器的根(ROOT)进行资源查找 不以/开头，表示从当前应用的根查找 监听器1234567891011121314151617181920212223242526import com.atguigu.atcrowdfunding.util.Const;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import javax.servlet.ServletContext;import javax.servlet.ServletContextEvent;import javax.servlet.ServletContextListener;public class SystemUpInitListener implements ServletContextListener &#123; Logger log = LoggerFactory.getLogger(SystemUpInitListener.class); //初始化 @Override public void contextInitialized(ServletContextEvent servletContextEvent) &#123; ServletContext Context = servletContextEvent.getServletContext(); String contextPath = Context.getContextPath(); //打印路径 log.debug(\"加入应用上下文路径&#123;&#125;\", contextPath); Context.setAttribute(Const.PATH, contextPath); &#125; //销毁方法 @Override public void contextDestroyed(ServletContextEvent servletContextEvent) &#123; log.debug(\"销毁上下文路径\"); &#125;&#125; 加入web.xml 1234&lt;!--先后顺序要放在spring容器之后--&gt;&lt;listener&gt; &lt;listener-class&gt;com.atguigu.atcrowdfunding.listener.SystemUpInitListener&lt;/listener-class&gt;&lt;/listener&gt; controller 拿数据 调业务逻辑 做跳转 MBG生产的Mapper使用1234//找到POJO对应的example类TAdminExample tAdminExample = new TAdminExample();TAdminExample.Criteria criteria = tAdminExample.createCriteria().andLoginacctEqualTo(loginacct);List&lt;TAdmin&gt; list = adminMapper.selectByExample(tAdminExample); 一个Example可以创建多个Criteria，然后通过or或and连接起来 js内的包含包含的页面内有常变得用动态包含 1234&lt;!--动态包含，包含的也会生成一个class--&gt;&lt;jsp:include page=\"/WEB-INF/jsp/common/top.jsp\"&gt;&lt;/jsp:include&gt;&lt;!--静态包含，只生成一个class--&gt;&lt;%@ include file=\"/WEB-INF/jsp/common/css.jsp\" %&gt; session过期session会销毁，所以要判断session是否为null 分页查询引入分页助手 Mybatis配置文件内 123456&lt;!-- 配置PageHelper插件; 或者在spring配置SqlSessionFactoryBean进行配置--&gt;&lt;plugins&gt; &lt;plugin interceptor=\"com.github.pagehelper.PageInterceptor\"&gt; &lt;property name=\"reasonable\" value=\"true\"/&gt;&lt;!--分页合理化--&gt; &lt;/plugin&gt;&lt;/plugins&gt; spring配置文件内 123456789101112&lt;bean class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"configLocation\" value=\"classpath:/mybatis/mybatis-config.xml\"&gt;&lt;/property&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"&gt;&lt;/property&gt; &lt;property name=\"mapperLocations\" value=\"classpath*:/mybatis/mapper/*.xml\"&gt;&lt;/property&gt; &lt;property name=\"plugins\"&gt; &lt;bean class=\"com.github.pagehelper.PageInterceptor\"&gt; &lt;property name=\"properties\"&gt; &lt;value&gt;reasonable=true&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/property&gt;&lt;/bean&gt; 合理化是，当传入的页数过大时。分页助手会把它定位到最后 分页使用 123456789101112131415public void testPage()&#123; PageHelper.startPage(2, 10);//分页指定绑定的是线程，所以可以在controller内指定，在service内使用 //select id, loginacct, userpswd, username, email, createtime from t_admin List&lt;TAdmin&gt; list= adminMapper.selectByExample(null); //5表示，导航条一共5个页数，默认为8 PageInfo&lt;TAdmin&gt; pageInfo = new PageInfo&lt;&gt;( list,5); logger.debug(\"总页码：&#123;&#125;\",pageInfo.getPages()); logger.debug(\"总记录数：&#123;&#125;\",pageInfo.getTotal()); logger.debug(\"当前页：&#123;&#125;\",pageInfo.getPageNum()); logger.debug(\"下一页：&#123;&#125; == &#123;&#125;\",pageInfo.isHasNextPage() , pageInfo.getNextPage()); logger.debug(\"连续分页页码：\"); for (Integer pn : pageInfo.getNavigatepageNums()) &#123; System.out.println(pn); &#125;&#125; 更新1updateByExampleSelective()//有选择性更新 get请求与post请求中文乱码问题的解决办法get 将tomcat的server.xml文件内&lt;Connector connectionTimeout=&quot;20000&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; redirectPort=&quot;8443&quot;/&gt;改为&lt;Connector connectionTimeout=&quot;20000&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; redirectPort=&quot;8443&quot; URIEncoding=&quot;UTF-8&quot;/&gt; post 在项目的web.xml下配置 123456789101112131415161718192021&lt;!-- 字符编码过滤器 --&gt;&lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceRequestEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceResponseEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; Spring代理两种 JDK：代理类以$开头 cglib：代理的类，要求不能是final类 批量删除用where in ( ) 转json启用消息转换器：HttpMessageConverter 如果返回结果为对象（Entity Class,List,Map..）类型：启用这个转换器-&gt;MappingJackson2HttpMessageConverter 将对象序列化为json串，使用Jackson组件转换 如果返回结果为String类型：启用这个转换器-&gt;StringHttpMessageConverter 将字符串原样输出。 zTreejq的插件，生成树 代理主键、自然主键 代理主键：一般是没有业务含义的.只是用于标识一条数据,表示数据的唯一性. 自然主键: 表示业务来维护主键. RBAC权限数据表由简到繁 角色模型的四个级别 0级别： 模型里包括：用户(U)、角色(R)、许可权(P) session代表登录系统产生会话 1级别： 基于级别0，引入角色间的继承关系。 一般继承关系：允许角色间多继承 受限继承关系：要求单继承 2级别： 基于RBAC0模型的基础上，进行了角色的访问控制。添加了责任分离 责任分离包括：静态责任分离、动态责任分离 互斥角色：统一用户只能分配到一组互斥角色集合种最多一个角色。例如：出纳和会计 基数约束：一个角色分配的用户数受限制；一个用户可拥有的角色数受限；一个角色对应的访问权限数也受限，以控制高级全现在系统中的分配 先决条件角色：要想获得较高的权限，要首先拥有低一级的权限。 运行时互斥：运行一个用户具有多个角色，但运行时不可同时激活 3级别 是最全面级的权限管理，它是基于RBAC2的基础上，将RBAC1和RBAC2进行整合了，最全面，也最复杂的 ACL模型用户直接对应权限，不经过角色。 通常用在临时用户 SpringBoot unknown错误2.1.5版本后报错，插件兼容 pom文件内添加 123&lt;properties&gt; &lt;maven-jar-plugin.version&gt;2.6&lt;/maven-jar-plugin.version&gt;&lt;/properties&gt; @ComponentScan(“报名”)指定扫描包，可以不指定 元注解@Document生成javadoc 生成时指定虚拟机参数-encoding UTF-8 -charset UTF-8 @Inherited：继承的子类也能有该直接，接口实现不算 配置、注解整合mybatis要加入在启动类上@MapperScan()注解 在启动类上加@EnableTransactionManagement//启用声明式事务 在方法上加@Transactional即可添加事务，加在类上表示该类上所有方法都有 1234//隔离级别，传播行为，回滚的异常@Transactional(isolation=Isolation.DEFAULT,propagation=Propagation.REQUIRED,rollbackFor=Exception.class)//只读方法@Transactional(readOnly=true) 12345//简单用注解，复杂用xml// @Insert// @Delete// @Update@Select(\"select * from t_admin where id=#&#123;id&#125;\") 1234# 配置德鲁伊数据库连接池spring: datasource: type: com.alibaba.druid.pool.DruidDataSource 12345678910111213141516171819202122232425262728293031323334353637//编程式配置德鲁伊、监控系统@SpringBootConfiguration//官网推荐用这个注解public class AppConfig &#123; @ConfigurationProperties(prefix = \"spring.datasource\") //将数据库连接信息直接封装到数据源对象中 @Bean public DataSource dataSource() throws SQLException &#123; DruidDataSource dataSource = new DruidDataSource(); //等于spring.datasource.filters=stat dataSource.setFilters(\"stat\");//配置监控统计拦截的filters return dataSource; &#125; //配置Druid的监控 //1、配置一个管理后台的Servlet @Bean public ServletRegistrationBean statViewServlet() &#123; ServletRegistrationBean bean = new ServletRegistrationBean(new StatViewServlet(), \"/druid/*\"); Map&lt;String, String&gt; initParams = new HashMap&lt;&gt;(); initParams.put(\"loginUsername\", \"admin\"); initParams.put(\"loginPassword\", \"123456\"); initParams.put(\"allow\", \"\");// 默认就是允许所有访问 initParams.put(\"deny\", \"192.168.15.21\");//拒绝哪个ip访问 bean.setInitParameters(initParams); return bean; &#125; //2、配置一个web监控的filter @Bean public FilterRegistrationBean webStatFilter() &#123; FilterRegistrationBean bean = new FilterRegistrationBean(); bean.setFilter(new WebStatFilter()); Map&lt;String, String&gt; initParams = new HashMap&lt;&gt;(); initParams.put(\"exclusions\", \"*.js,*.css,/druid/*\");//排除过滤 bean.setInitParameters(initParams); bean.setUrlPatterns(Arrays.asList(\"/*\")); return bean; &#125;&#125; 数据库最大连接数默认是100个，实质是101一个，这一个是超级管理员用的 springboot整合web组件@ServletComponentScan开启扫面以下注解 @WebServlet @WebFilter @WebListener 12345678910111213141516import javax.servlet.ServletContextEvent;import javax.servlet.ServletContextListener;import javax.servlet.annotation.WebListener;@WebListenerpublic class HelloListener implements ServletContextListener &#123; @Override public void contextDestroyed(ServletContextEvent arg0) &#123; System.out.println(\"应用销毁了....HelloListener\"); &#125; @Override public void contextInitialized(ServletContextEvent arg0) &#123; System.out.println(\"应用启动了....HelloListener\"); &#125;&#125; 12345678910111213141516171819202122232425import java.io.IOException;import javax.servlet.Filter;import javax.servlet.FilterChain;import javax.servlet.FilterConfig;import javax.servlet.ServletException;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.annotation.WebFilter;@WebFilter(urlPatterns=\"/*\")public class HelloFilter implements Filter &#123; @Override public void destroy() &#123; &#125; @Override public void doFilter(ServletRequest arg0, ServletResponse arg1, FilterChain arg2) throws IOException, ServletException &#123; System.out.println(\"HelloFilter............放行之前\"); arg2.doFilter(arg0, arg1); System.out.println(\"HelloFilter............放行之后\"); &#125; @Override public void init(FilterConfig arg0) throws ServletException &#123; &#125;&#125; 123456789101112131415//基本不用import java.io.IOException;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@WebServlet(urlPatterns=\"/my\")public class MyServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; resp.getWriter().write(\"MyServlet do.......\"); &#125;&#125;","categories":[],"tags":[{"name":"后端","slug":"后端","permalink":"http://example.com/tags/%E5%90%8E%E7%AB%AF/"}]},{"title":"canal笔记","slug":"canal笔记","date":"2019-12-09T02:35:55.000Z","updated":"2021-07-08T07:54:46.463Z","comments":true,"path":"2019/12/09/canal笔记/","link":"","permalink":"http://example.com/2019/12/09/canal%E7%AC%94%E8%AE%B0/","excerpt":"","text":"简介canal是用于监听数据库数据的变化。 原理：伪装成，从数据库。读取数据 环境：MySQL 5.6及以上 下载地址，下载1.1.2.tar.gz 安装配置mysql配置在/etc/my.cnf内的[mysqld]下配置 12345678# mysql的id。id要唯一，与从机不能一样server-id= 1# 写入本地的文件名log-bin=mysql-bin#以什么方式监听binlog_format=row#要监听的库名binlog-do-db=database binlog的三种方式 statement 语句级，binlog会记录每次一执行写操作的语句。 相对row模式节省空间，但是可能产生不一致性，比如update tt set create_date=now() 如果用binlog日志进行恢复，由于执行时间不同可能产生的数据就不同。 优点： 节省空间 缺点： 有可能造成数据不一致。 row 行级， binlog会记录每次操作后每行记录的变化。 优点：保持数据的绝对一致性。因为不管sql是什么，引用了什么函数，他只记录执行后的效果。 缺点：占用较大空间。 mixed statement和row的混合版 在某些情况下譬如： 当函数中包含 UUID() 时； 包含 AUTO_INCREMENT 字段的表被更新时； 执行 INSERT DELAYED 语句时； 用 UDF 时； 会按照 ROW的方式进行处理 优点：节省空间，同时兼顾了一定的一致性。 缺点：还有些极个别情况依旧会造成不一致，另外statement和mixed对于需要对binlog的监控的情况都不方便。 我们只关心数据变化，采用row方式 给canal赋权限，在mysql内执行GRANT ALL PRIVILEGES ON *.* TO canal@&#39;%&#39; IDENTIFIED BY &#39;canal&#39; 这里给的权限很大，具体权限看情况分配 canal配置将下载的canal压缩包解压 记住conf/canal.properties内的配置端口号canal.port = 11111 配置vim conf/example/instance.properties文件 12345678# 不能和mysql的id一致canal.instance.mysql.slaveId=30# 监控的mysql的地址canal.instance.master.address=127.0.0.1:3306# mysql分配的账号密码canal.instance.dbUsername=canalcanal.instance.dbPassword=canalcanal.instance.connectionCharset = UTF-8 客户端获取数据 message:一次canal从日志中抓取的信息，一个message包含多个sql(event) entry: 相当于一个sql命令，一个sql可能会对多行记录造成影响 -type 用于区分是数据变化，还是事务变化 header.tableName 表名 storevalue得到 rowchange entry是序列化的数据，无法直接获取 rowchange ： entry经过反序列化得到的对象，包含了多行记录的变化值 eventtype 数据的变化类型 insert update delete create alter drop rowdatalist RowDatas： 一个rowchange里包含的数据变化集，其中每一个rowdata里面包含了一行的多个字段 afterColumnList beforeColumnList column: 一个RowData里包含了多个column，每个column包含了 name和 value columnName columnValue 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.otter&lt;/groupId&gt; &lt;artifactId&gt;canal.client&lt;/artifactId&gt; &lt;version&gt;1.1.2&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475import com.alibaba.otter.canal.client.CanalConnectorimport com.alibaba.otter.canal.client.CanalConnectorsimport com.alibaba.otter.canal.protocol.CanalEntryimport com.alibaba.otter.canal.protocol.Messageimport com.google.protobuf.ByteStringimport java.net.InetSocketAddressimport java.utilimport java.util.Randomimport com.alibaba.fastjson.JSONObjectimport scala.collection.JavaConversions._/** * @author dianyang * @date 2019/12/9 11:00 */object CanalCli &#123; val rand: Random = new Random def main(args: Array[String]): Unit = &#123; val canalConnector: CanalConnector = CanalConnectors.newSingleConnector(new InetSocketAddress(\"192.168.5.102\", 11111), \"example\", \"\", \"\") //val writer = new FileWriter(\"F:\\\\JAVAIDEA\\\\log-gen\\\\consumer-flink\\\\src\\\\main\\\\resources\\\\order_infor.txt\") while (true) &#123; canalConnector.connect(); canalConnector.subscribe(\"canal.order_info\"); //抓取100条 val message: Message = canalConnector.get(100) if (message.getEntries().size() == 0) &#123; Thread.sleep(5000); &#125; else &#123; for (entry &lt;- message.getEntries) &#123; &#123; //如果数据是行数据 //判断事件类型 只处理 行变化业务 if (entry.getEntryType.equals(CanalEntry.EntryType.ROWDATA)) &#123; //把数据集进行反序列化 val storeValue: ByteString = entry.getStoreValue var rowChange: CanalEntry.RowChange = null; //用的谷歌的序列化工具，目前市面上最快的 rowChange = CanalEntry.RowChange.parseFrom(storeValue); //操作类型为insert，表名为order_info if (rowChange.getEventType.equals(CanalEntry.EventType.INSERT) &amp;&amp; entry.getHeader.getTableName.equals(\"order_info\")) &#123; //获得行集 val rowDatasList: util.List[CanalEntry.RowData] = rowChange.getRowDatasList() for (rowData &lt;- rowDatasList) &#123; val jsonObject = new JSONObject for (column &lt;- rowData.getAfterColumnsList) &#123; val name: String = column.getName jsonObject.put(\"province\", rand.nextInt(55)) if (\"total_amount\".equals(name)) &#123; val amount_value: Double = column.getValue.toDouble jsonObject.put(name, amount_value) &#125; if (\"payment_way\".equals(name)) &#123; jsonObject.put(name, column.getValue) &#125; if (\"create_time\".equals(name)) &#123; jsonObject.put(name, column.getValue) &#125; &#125; //writer.write(jsonObject.toJSONString) //writer.write(\"\\n\") println(jsonObject.toJSONString) &#125; //writer.flush() &#125; //CanalHandler.handle(tableName,eventType,rowDatasList); &#125; &#125; &#125; &#125; &#125; &#125;&#125;","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"}]},{"title":"WordPress笔记","slug":"WordPress笔记","date":"2019-12-08T12:03:28.000Z","updated":"2021-07-08T07:58:14.148Z","comments":true,"path":"2019/12/08/WordPress笔记/","link":"","permalink":"http://example.com/2019/12/08/WordPress%E7%AC%94%E8%AE%B0/","excerpt":"","text":"快速上手简介官网 功能强、搭建快、社区丰富、学习容易、成本低、主题多 环境要求 PHP 5.4以上 MySQL 5.0+ 推荐 PHP7.3以上 MySQL 5.6以上 Nginx或Apache HTTPS(可选) 环境要求会因为WordPress的版本更新而变更具体查看官网 官网打开429就用这个网址","categories":[],"tags":[{"name":"php","slug":"php","permalink":"http://example.com/tags/php/"},{"name":"wordpress","slug":"wordpress","permalink":"http://example.com/tags/wordpress/"}]},{"title":"推荐系统","slug":"推荐系统","date":"2019-12-07T07:49:37.000Z","updated":"2019-12-08T03:38:37.665Z","comments":true,"path":"2019/12/07/推荐系统/","link":"","permalink":"http://example.com/2019/12/07/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/","excerpt":"简述目的 推荐系统是信息过载采用的措施，面对海量的数据，从中快速推荐出符合用户特点的物品。解决一些人的”选择恐惧症”；面向没有明确需求的人","text":"简述目的 推荐系统是信息过载采用的措施，面对海量的数据，从中快速推荐出符合用户特点的物品。解决一些人的”选择恐惧症”；面向没有明确需求的人 解决如何从大量信息中找到自己感兴趣的信息 解决如何让自己生产的信息脱颖而出，收到大众喜爱 让用户更快更好的获取自己需要的内容 让内容更好更快的推送到喜欢它的用户手中 让网站更有效的保留用户资源 分类 实时性分类 离线推荐 实时推荐 推荐原则分类 基于相似度的推荐 基于知识的推荐：规则，经验的总结 基于模型的推荐：通过模型发现规则 根据推荐是否个性化分类 基于统计的推荐 个性化推荐 根据数据源分类 基于人口统计学的推荐：用户信息 基于内容的推荐：物品信息 基于协同过滤的推荐：行为数据 推荐算法简介 基于人口统计学的推荐 通过对用户行为的分析 基于内容推荐 根据电影内容相似度推荐 基于协同过滤推荐 基于近邻的协同过滤 基于用户(User-CF) 基于物品(Item-CF) 基于模型的协同过滤 奇异值分解(SVD) 潜在语义分析(LSA) 支撑向量机(SVM) 根据用户和物品相关联的信息矩阵，在内进行筛选 协同过滤基于内容(CB)主要是利用用户评价过的物品内容特征。而CF方法还可以利用其他用户评分过的物品内容 CF可以解决CB的一些局限性 物品内容不完全或者难以获得时，依然可以通过其他用户的反馈给出推荐 CF基于用户之间对物品的评价质量，避免CB仅依赖内容可能会物品判断的干扰 CF推荐不受内容限制，只要其他类似用户给出了对不同物品的兴趣，CF就可以给用户推荐出内容差异很大的物品 CF更依赖历史数据，如果历史数据少，而且不准，推荐就不准。 基于近邻的协同过滤 基于用户的协同过滤 没有用户基本信息通过用户的行为数据，来推荐相似用户喜欢的物品。 基于物品的协同过滤 根据物品被哪些人喜欢，根据相似度原则，推荐 混合推荐大部分的推荐系统，采用了多种推荐机制和策略，将多个方法混合。从而达到更好的效果。 加权混合 用线性公式，将不同的推荐按权重组合。推荐 具体权重值，需要大量测验 切换混合 有几套推荐系统，在不同的情况下，选择更合适的推荐机制推荐 分区混合 多种推荐机制，讲不通的推荐结果分不同的区显示给用户 分层混合 所有推荐方式，串行。将前一层的推荐做输入，综合多种推荐 推荐系统评测 离线实验 通过体制系统获得用户行为数据，按照一定格式生成标准数据集 将数据集按照一定规则分成训练集和测试集 在训练集上训练用户兴趣模型，在测试集上预测 通过事先定义的离线指标评测算法在测试集上预测的结果 将已经拿到的数据作为训练数据，对应生成测试数据和训练数据。在训练数据上训练出来，找到最优化的模型。用模型预测，得到结果。将测试数据带入，做预测，考察测试结果 用户调查 通过，调查记录，进行分析 在线实验 AB测试 类似切换混合，俩套对比 评测指标 预测准确度 用户满意度 覆盖率 多样性 惊喜度 信任度 实时性 健壮性 商业目标 准确度评测 评分预测 在用户对物品的历史评分中学习，一个兴趣模型，从而预测用户对新物品的评分 评分预测的准确度一般用均方根误差(RMSE)或平均绝对误差(MAE)计算 u：user用户 i：item物品 r：用户u对物品i的评分 r+^：预测评分 Top-N推荐 给用户一个个性化推荐列表，这种推荐叫Top-N推荐 一般由精确率和召回率度量 TP：用户喜欢的，被推荐出来 FN：用户不喜欢，被推荐出来 FP：用户不喜欢，被推荐出来 TN：用户不喜欢，没有被推荐 精确率：被找到的物品里应该被找到的。P=被推荐的正确数/推荐总数 召回率：所有被推荐的占应该被推荐的比例R=被推荐的正确书/应该被推荐的正确数 数学基础 线性代数 微积分 概率和统计 线性代数 矩阵 矩阵的基本概念 矩阵的加法 矩阵的乘法 矩阵的转置 矩阵的运算法则 矩阵的逆","categories":[],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://example.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"},{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"PHP基础笔记","slug":"PHP基础笔记","date":"2019-12-04T02:29:20.000Z","updated":"2021-07-08T07:56:11.055Z","comments":true,"path":"2019/12/04/PHP基础笔记/","link":"","permalink":"http://example.com/2019/12/04/PHP%E5%9F%BA%E7%A1%80%E7%AC%94%E8%AE%B0/","excerpt":"","text":"PHP运行环境目录 1234- wamp - php - apache - mysql 文件名、路径不要出现中文和空格 ApaceApache安装下载地址 创建，解压httpd-……，将Apache24改名为apache放到wamp目录下。 修改wamp\\apache\\conf\\httpd.conf文件将Define SRVROOT &quot;/Apache24&quot;修改为Define SRVROOT &quot;apache的绝对路径&quot; 建议将路径中\\改为/ 安装 管理员打开cmd，用bin\\httpd.exe -k install命令。类似下面信息就是启动正常 1234Installing the &#39;Apache2.4&#39; serviceThe &#39;Apache2.4&#39; service is successfully installed.Testing httpd.conf....Errors reported here must be corrected before the service can be started. 删除服务：httpd.exe -k uninstall 双击打开如下文件并启动服务apche/bin/ApacheMonitor.exe双击打开 点击图标，start。启动 打开网址测试。 Apache目录介绍 目录/文件 bin/ .exe, .dll等主要可执行程序的目录。 ApacheMonitor.exe 监视程序，通常用于apache服务的启停操作。 httpd.exe web服务器的主程序。该程序启动时，才能访问服务器。（通常都是以系统服务的形式启动） conf/ apache的配置文件目录 httpd.conf 是Apache的主配置文件，每次启动都会读取的文件。 conf/extra/ 其他配置文件目录 httpd_vhosts.conf Apache虚拟主机的配置文件 htdocs/** 网站的默认根目录，用于保存网站中的网页文件（html、php等） logs/ 存放apache运行时的有关运行记录 modules/ 存放Apache的可扩展模块文件。 apache主配置文件：httpd.confapache的主配置文件为：wamp/apache/config/httpd.conf 配置文件可以修改以实现某些功能。 配置文件修改后，需要重启apache才生效。 配置文件代码如果出错——则apache重启时会失败。 检测配置文件语法bin\\httpd.exe -t 配置环境变量把apache\\bin配置到path变量里 Apache的启动和停止需要管理员身份 启动：net start apache2.4 停止：net stop apache2.4 PHP安装配置PHP下载 将文件内容解压到wamp/php下 配置php到apache在apache\\conf\\httpd.conf文件内，在&lt;IfModule unixd_module&gt;前配置 ​ LoadModule php7_module php7apache2_4.dll这个文件的完整路径（在php文件夹中） 给apache设定，php文件的后缀为“.php”： 1234#添加PHP模块到本apache中：LoadModule php7_module &quot;G:&#x2F;wamp&#x2F;php&#x2F;php7apache2_4.dll&quot;#添加php文件的后缀AddType Application&#x2F;x-httpd-php .php 在httpd -t检查语法 加载模块报错，我电脑64位下载也是64位的，会报错，换成32位的包就不报错 在apache\\htdocs下创建文件hello.php 如果能正常打开网页并正确显示则配置正确 12345678910111213&lt;!DOCTYPE html&gt;&lt;html xmlns=\"http://www.w3.org/1999/xhtml\"&gt;&lt;link rel=\"icon\" href=\"/favicon.ico\"&gt;&lt;head&gt;&lt;title&gt;Test Page for Apache Installation&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;?php echo '&lt;h1&gt;hello world&lt;/h1&gt;'; echo date(\"Y-m-d H:i:s\");?&gt;&lt;/body&gt;&lt;/html&gt; 以上代码会发现时间不对。因为php默认时间和东八区差了8个小时。 配置PHP时间将php.ini-development改名为php.ini，改文件配置 1234[Date]; Defines the default timezone used by the date functions; http:&#x2F;&#x2F;php.net&#x2F;date.timezonedate.timezone &#x3D; PRC 在apache/conf/httpd.conf文件内，在&lt;IfModule unixd_module&gt;前配置 12#设置php.ini文件路径 形式为：PHPIniDir &quot;php.ini文件所在路径&quot;PHPIniDir &quot;G:&#x2F;wamp&#x2F;php&quot; 重启，刷新页面，检验时间 这里配置只要php.ini的路径不需要文件名，但是我加上也没报错 配置连接mysql本机有mysql 在php.ini内找到extension_dir，将后面改为php/ext的绝对路径 12345; Directory in which the loadable extensions (modules) reside.; http:&#x2F;&#x2F;php.net&#x2F;extension-dir;extension_dir &#x3D; &quot;.&#x2F;&quot;; On windows:extension_dir &#x3D; &quot;G:&#x2F;wamp&#x2F;php&#x2F;ext&quot; 并且将;extension=mysqli前的;去掉 老一点的版本可能为extension=php_mysqli.dll 重启apache，验证代码 1234567if ( mysqli_connect('localhost','root','000000') ) &#123; echo \"成功\";&#125;else&#123; echo \"失败\";&#125; 多站点虚拟主机配置默认的初始站点配置apache/conf/httpd.conf内 站点域名： ServerName localhost 域名是可以设置的！ 站点位置（文件夹位置）： DocumentRoot “${SRVROOT}/htdocs” 站点位置是可以设置的！ ${SRVROOT}就是我们先前定义的绝对路径 站点文件夹的访问权限设置： 使用 … 配置项来配置。 站点默认显示的网页（首页）： DirectoryIndex index.php index.html 网站文件夹访问权限的设置文件夹的访问权限的设置形式如下所示： 12345&lt;Directory “要设置权限的文件夹路径”&gt; Options设置项 AllowOverride设置项 Require权限设置项&lt;/Directory&gt; Options：用于设置一些系统选项，通常window系统中就用Indexes就可以了。 Options Indexes //表示允许列出目录结构（如果没有可显示的网页）在访问文件夹时就展示文件夹内的内容 AllowOverride：用于设置“可覆盖性”，即是否允许在项目文件中覆盖这里的访问权限设置： AllowOverride All //表示可覆盖 AllowOverride None //表示不可覆盖 Require：用于设置可访问权限，常用的有： 允许所有来源的访问：——推荐 Require All granted 拒绝所有来源的访问：——网站需要临时关闭时使用 Require All denied 允许所有但拒绝部分来源的访问： ​ Require all granted ​ Require not ip 192.168.1.102 192.168.1.103 拒绝所有但允许部分来源的访问： ​ Require all denied ​ Require ip 192.168.1.102 192.168.1.103 推荐 12345&lt;Directory “h:/itcast/php60/wamp/www”&gt;Options IndexAllowOverride AllRequire All granted&lt;/Directory&gt; 网站默认网页的设置123&lt;IfModule dir_module&gt; DirectoryIndex index.html&lt;/IfModule&gt; 可以配置多个默认网页DirectoryIndex 网页名1 网页名2 网页名3 .... 配置多站点虚拟主机配置多站点虚拟主机可以分两步： 在apache的主配置文件（httpd.conf），引入多站点的配置文件（虚拟主机配置文件） 在虚拟主机配置文件（httpd-vhosts.conf）中，再挨个网站进行配置（每个网站一段配置） 先在httpd.conf引入虚拟主机配置文件。 12# Virtual hostsInclude conf&#x2F;extra&#x2F;httpd-vhosts.conf 在httpd-vhosts.conf内配置 12345678910111213141516171819202122232425262728#下面，开始“一个一个站点配置”#站点1：（第一个站点，被称为默认站点）&lt;VirtualHost *:80&gt; ServerName www.php69.com DocumentRoot &quot;G:\\wamp&quot; &lt;Directory &quot;G:\\wamp&quot; &gt; #允许列出目录 Options Indexes #允许权限覆盖 AllowOverride All #允许所有访问 Require all granted &lt;&#x2F;Directory&gt; DirectoryIndex abc.php index.php index.html &lt;&#x2F;VirtualHost&gt;#站点2：&lt;VirtualHost *:80&gt; ServerName www.quanzhan7.com DocumentRoot &quot;G:\\wamp&quot; &lt;Directory &quot;G:\\wamp&quot; &gt; Options Indexes AllowOverride All Require all granted &lt;&#x2F;Directory&gt; DirectoryIndex index.php index.html &lt;&#x2F;VirtualHost&gt;#站点3： 大小写没规律，如果错了尝试改大小写 PHP基本语法标记PHP语言，是一种可以嵌入到“html”代码中的后台处理语言（程序） 有以下几种标记形式，只推荐第一种。 php代码写在这里..... 需要到php.ini中进行配置：short_open_tag = On //默认为Off，表示不能用该形式。 纯PHP代码：可以省略标记结尾符。 注释 //：单行注释 /**/：多行注释 变量命名规则定义形式： $变量名 = 具体的数据； 构成：字母、数字、下划线； 开头：字母或下划线； 注意：变量名不要跟系统中的“关键字”（即语法所用单词）重复——关键字不多，也就几十个。 区分大小写 尽量见名知意 12345678&lt;?php$v1 = 1;$v2 = 2;$v3 = $v1 + $v2;echo $v3;echo \"&lt;hr/&gt;\";echo $v1,$v2,$v3;?&gt; 基本操作 赋值：=左边赋给右边 取值： 判断：判断是否有值，isset(v)，true（真，表示有），或者false（假，表示没有）。 删除/销毁：unset(v) 传值$v2 = $v1：复制传值 $v2 = &amp;$v1：引用传值 预定义变量 $_GET[&#39;age&#39;]：获得get方式里的age值 $_POST[&#39;age&#39;]：获得post方式里的age值 $_REQUEST[&#39;age&#39;]：获取get或post里的age值 $_SERVER[&#39;&#39;]：传以下值获取相应信息 PHP_SELF：表示当前请求的网页地址（不含域名部分） SERVER_NAME：表示当前请求的服务器名 SERVER_ADDR：表示当前请求的服务器IP地址 DOCUMENT_ROOT：表示当前请求的网站物理路径（apache设置站点时那个） REMOTE_ADDR：表示当前请求的客户端的IP地址 SCRIPT_NAME：表示当前网页地址 可变变量变量名本身又是一个“变量”的变量。 12345&lt;?php$v1 = 0;$str = \"v1\";echo $$str;//打印0?&gt; 常量不变的量 常量只能存储j简单数据类型 推荐常量名全大写 两种定义形式 define(‘常量名’, 对应的常量值); const 常量名 = 对应的常量值; 两种取值形式 直接使用echo 常量名;：使用常量，前面不带”$”符号，也不能有引号 echo constant(‘常量名’)：此时常量名要用引号引起来。 判断常量defined();：true（表示存在）或false（表示不存在） 预定义常量预定义常量就是PHP语言内部预先定义好的常量，我们可以直接使用。 PHP_VERSION：表示当前php的版本信息 PHP_OS：表示当前php运行所在的系统信息 PHP_INT_MAX：表示当前版本的php中的最大的整数值 M_PI： 表示圆周率π（一个有10多位小数的数） 其他预定义常量在，PHP手册-&gt;附录-&gt;保留字列表-&gt;预定义常量 魔术常量魔术常量也是常量，只是在形式上为常量，而其值其实是“变化”的。 他们也是系统中预先定义好的，也就几个，下面是最常用的 3个： __DIR__：代表当前php网页文件所在的目录 __FILE__：代表当前php网页文件本身的路径 __LINE__：代表当前这个常量所在的行号 数据类型标量类型标量类型也可以理解为“基本类型”，“简单类型”。 标量类型包括如下4种： 字符串类型：String 就是一串字符串，当做一个整体，表示一个连续有确定顺序的字符串。 通常需要使用单引号或双引号来引起来，比如：$name = “张三”; 整数类型：Int， Integer 浮点数： Float， Double 就是数学上的小数。 布尔类型： Bool， Boolean 这种数据类型只有两个数据：true， false 整型integer，int4种表示 12345678//10进制形式：$n1 = 123;//8进制形式：$n1 = 0123; //以0开头//16进制形式：$n1 = 0x12A34; //以0x开头，还可以有A，B，C，D，E，F这个6个“16进制数字” //2进制形式：$n1 = 0b1011011010; //以0b开头 进制转化直接通过系统函数来进行，能完成： 10进制转为2, 8, 16进制： decbin()：将10进制转为2进制 decoct()：将10进制转为8进制 dechex()：将10进制转为16进制 或： 2, 8, 16进制转为10进制： bindec()：将2进制数字字符串转为10进制 octdec()：将8进制数字字符串转为10进制 hexdec()：将16进制数字字符串转为10进制 浮点型floatfloat和double在php一样精度 直接小数点形式：$f1 = 0.1; //或者1.23; 123.0; 科学计数法：$f2 = 1.23e3; //表示1.23 乘以10的3次方 浮点数不要做相等比较（==）：因为浮点数进行相等比较，是“不可靠”的： 布尔型Boolean只有两个数据值： true， false（不区分大小写） false, 0, 0.0, “”, null, ‘0’, 空数组这些都会被当作false 字符串型String可以使用单引号或双引号来表示（引起来）。 字符串.变量：可以拼接变量 双引号字符串中，如果出现“$”符号，则该符号后的连续字符（单词）会被识别为一个变量名。单引号不行 复合类型就是“数组”（Array）和“对象”（Object）两种。 数组类型Array数组，就是将多个“数据”放在一起，排成一个序列，这个序列作为一个整体（里面包括了多个数据） $arr1 = array(‘张三丰’, 18, “男” );和$arr = array(‘name’ =&gt; ‘张三丰’, ‘age’=&gt;18, ‘gender’ =&gt; “男” );也可以$arr = [‘name’ =&gt; ‘张三丰’, ‘age’=&gt;18, ‘gender’ =&gt; “男” ]; 取值：行为为：$数组变量[下标]比如： echo $arr1[0]; print_r( $arr2[‘name’] ); 特殊类型空类型： 有且只有一个数据可以使用，那就是null 空类型NULL只有一个值： null（不区分大小写）。 $v1 = null; //此时，具有变量$v1,但其中的数据是“空的”（没有数据） 空值变量，isset()判断的结果是false（即不存在）。 资源类型后续再说。。。。 类型判断 gettype()：获取一个变量的类型，结果为一个变量类型的名称（字符串） settype()： 设置一个变量的类型 12$v1 &#x3D; 10; &#x2F;&#x2F;此时，$v1中数据是整数类型settype( $v1, ‘string’); &#x2F;&#x2F;此时，$v1是字符串类型，即其中的数据变成了：“10” var_dump()：输出变量的“完整信息”，包括变量类型，长度（如果需要），内容 判断是否为某种类型（类型系列函数）： is_int() / is_integer()：判断是否为整数类型 is_float()：判断是否为浮点类型 is_bool()：判断是否为布尔类型 is_string()：判断是否为字符串类型 is_array()：判断是否为数组类型 is_numeric()：判断是否为“数字”类型（含整数，小数，以及“纯数字字符串”） is_object()： 两个特殊判断： isset()： 判断一个变量中是否有数据，如果有返回true，如果没有(即此时就是null)返回false empty()：判断是否为“空的”。如果确实是“空的”，返回true，否则返回false。 “空的”的意思，比较接近日常生活中的“没有”。 类型转换自动转换我们无需做任何处理，而是，程序会根据运算时运算符所需要的数据类型进行转换。 转换为数字： 12345678910111+”2” //3“1” + “2” //31 + ”2abc” //31 + ”2abc34” //31 + “abc” //11 + “abc2” //11.2 + “2” //3.21.2 + “2.2abc” //3.41.2 + “abc2.2” //1.2“1.2abc” + 2 //3.2“1.2abc” + “2abc” //3.2 字符串当作数字，将字符串开头的数字转化为数值。若无则为0 转换为整数： 123410.8 % 3.6“10.8” % “3.6”“10.8” % “3.6abc”“10.8ab” % “3.6cd” 只保留整数 强制转换：12$v1 &#x3D; (int) “1”; &#x2F;&#x2F;结果，$v1是整数类型的1$v2 &#x3D; (float) “1.23”; &#x2F;&#x2F;结果，$v2是浮点类型的1.23&#96; 运算符分类按参与运算的数据的个数来分类 单目运算符： 只需要一个数据——但必须是变量。 双目运算符： 需要两个数据——可以是变量，也可以直接的数据本身。 三元运算符： 需要3个数据才能运算，也称为三目运算符。只有一个三元运算符。 按功能分类赋值运算符： = 算术运算符： + - * / % 如果不是数字，会自动转换为数字进行 连接运算符： . 就是字符串的连接，能够将前后字符连接起来。 如果不是字符串，会自动转换为字符串。 自赋值运算符： += -= *= = %= .= 自操作运算符： ++ -- 比较运算符： &gt; &gt;= &lt; &lt;= == != === !== 等于（==）和全等于（===）的区别： 通常，等于（==）也会用“模糊相等”或“松散比较”的说法。 两个数据“基本相等”（类型可能会发生自动转换），就算是相等。 全等于（===）就是完全相等： 只有两个数据的数据类型一样，并且其值也一样的时候，才是全等。 不等于： ！= 两个数据不满足“==”这个运算结果，不等于（！=）的结果就是true，比如： if（ 1 != 2 ） //true 不全等于：！== 两个数据不满足“===”这个运算结果，不全等于（！==）的结果就是true，比如： if（ “1” !== 1 ） //true 逻辑运算符： &amp;&amp;(与） ||（或） ！（非） 条件运算符： 数据1 ? 数据2 : 数据3 位运算符： &amp; | ~ 其他： @，是错误抑制符：在一个表达式出现错误的时候，可以将错误“隐藏”（掩盖）起来（不输出）！ @ 运算符只对表达式有效。 通常，该符号，用于在实际运行环境中的一些条件非我们（程序员）所能控制的情形。 如果出现该情形并报错，则我们可以抑制该错误的显示（只是该错误不显示，不是没有错误了）。 ( )，括号，用于提升运算优先级，括号中的先运算。 流程控制三大流程结构 顺序结构 分支结构 循环结构 分支结构if1234567891011121314151617if（ 条件1）&#123;分支1&#125;elseif（条件2）&#123;分支2:；&#125;elseif（ 条件3）&#123;分支3；&#125;。。。。。。else&#123;else分支； //前面没有一个条件满足的时候，就执行本分支&#125; switch123456789101112switch（ 一个变量数据或表达式结果$v1 ）&#123;case 值1： //如果$v1 等于 这个“值1”，就执行本分支分支语句1；break； //表示跳出该分支，也就是跳出switch语句。case 值2： //如果$v1 等于 这个“值2”，就执行本分支分支语句2；break；。。。。。。 //可以更多的分支default：默认分支； //前面都不满足的时候，就执行这里，default分支也可以不写&#125; 进行“相等比较”（==） 循环结构while1234while（条件判断）&#123;。。。。循环体语句；&#125; do while123456do &#123;。。。。循环体语句；&#125;while（条件判断）； for循环语句（重点/难点）12345for（循环变量初始化○1； 循环条件判断○2； 循环变量的改变○3）&#123;。。。。。。。。循环体语句块○4；//这里可以有多条语句//是可以反复执行的部分&#125; 循环的中断 continue中断： 含义：中断当前正在进行的循环体（即后续语句不再执行），继续下一次循环要执行的语句。 语法形式： ​ continue [$n]； //表示是要中断第几层的循环，继续该层循环的下一次。 ​ //其中$n可以省略，如果省略，表示1，就是中断当前层的循环。 break中断： 含义：停止（跳出）当前正在进行的循环（即完全终止循环），去执行该循环之后的语句。 语法形式： ​ break [$n]； //表示是要中断几层循环。 ​ //其中$n可以省略，如果省略，表示1，就是中断当前循环 他们都适用于3种循环。 1234567891011//终端层数while()&#123;//循环1 while()&#123;//循环2 while()&#123;//循环3 break;//中断循环3 break 1;//中断循环3 break 2;//中断循环2 break 3;//中断循环1 &#125; &#125;&#125; 函数定义、调用12345//定义function 函数名（$形参1，$形参2， ...... ）&#123; //形参，就是形式参数，是变&#125;//调用函数名（$实参1，$实参2， ...... ）； //实参就是实际参数，是数据 值传递默认情况下是值传递。 可以使用“&amp;”符号设定为引用传递 形参的默认值1234567function f1($p1, $p2, $p3 = 3, $p4 =true )&#123;//函数体语句块&#125;//则此时调用上述函数，以下形式都可以：f1(1,2);f1(3, 4, 5);f1(6,7,8, 9); 函数返回值return 要返回的数据； return语句也可以不带后面的数据，此时，就只是单纯地结束函数，并不返回数据（也可以说返回null这个空数据） 可变函数函数名和变量一致 123function f1()&#123; ....... &#125;$f = “f1”;$f(); //调用了函数f1，这就是可变函数！！ 匿名函数12$f1 = function (形参...) &#123; ....... &#125; //这是定义匿名函数的形式。$f1(实参); //这就是调用该调用。可见其调用，跟可变函数的写法非常类似。 常用系统函数与函数有关 function_exists(“函数名”)：判断一个函数是否已经存在； func_get_arg( $n )： 在函数内部可用，用于获得第n个实参（n从0开始算起） func_get_args()： 在函数内部可用，用于获得所有实参，结果是一个数组 func_num_args()： 在函数内部可用，用于获得实参的个数 1234567function xxx()&#123; $v1 = func_get_arg(0); //1 echo func_get_arg(2); //5 $a = func_get_args(); //结果是数组：[1, 2, 5]$n = func_num_args(); //3&#125;xxx(1,2, 5); 没有定义形参，传入也可以使用 字符串有关常用函数 输出与格式化：echo , print, printf, print_r, var_dump. 字符串去除与填充：trim, ltrim, rtrim, str_pad 字符串连接与分割：implode, join， explode, str_split 字符串截取：substr, strchr, strrchr, 字符串替换：str_replace, substr_replace 字符串长度与位置： strlen, strpos, strrpos, 字符转换：strtolower, strtoupper, lcfirst, ucfirst, ucwords 特殊字符处理：nl2br, addslashes, htmlspecialchars, htmlspecialchars_decode, 手册-&gt;函数参考-&gt;文本处理-&gt;字符串-&gt;字符串函数 常用数学函数 max： 取得若干个数据中的最大值 min： 取得若干个数据中的最小值 round： 对某个数据进行四舍五入（可以设定保留几位小数） ceil： 对某个数“向上取整”：将一个数据往上找出其小的一个整数（含其本身）。 floor： 对某个数“向下取整”：将一个数据往下找出其大的一个整数（含其本身） 1234$n1 = floor(4.1); //4$n2 = floor(4.9); //4$n3 = floor(4); //4$n4 = floor(-4.1); //-5 abs： 取得某个数据的绝对值 sqrt： 计算某个数的开方值 pow： 对某个数进行“幂运算”（就是获得某个数的若干次方） rand： 获得某两个数之间的随机整数（含该两个数） mt_rand: 获得某两个数之间的随机整数（含该两个数），比rand更快。 $n1 = mt_rand(0, 10); //随机数在0-10之间（含） 常用时间函数 time：获得当前时间（精确到秒），结果其实一个“整数”而已，代表从1970年1月1日0:0:0秒到当前时刻的秒数。 microtime：获得当前时间（可以精确到微秒） mktime：创建一个时间数据，参数为：时、分、秒，月、日、年 $t1 = mktime(10, 8, 5, 7, 12, 2018); date：将一个时间转换为某种字符串形式 idate：取得一个时间的某个单项数据值，比如idate(“Y”)取得年份数 date(“Y-m-d H:i:s”); strtotime：将一个字符串“转换”为时间值； date_default_timezone_set：在代码中设置“时区” date_default_timezone_get：在代码中获取“时区” 函数相关变量的作用域问题简单来说，有3种作用域：局部作用域，全局作用域，超全局作用域； 相对应的，有3种变量： 局部变量， 全局变量， 超全局变量； 局部作用域与局部变量：局部作用域就是函数内部范围的作用域，其中定义的变量就是局部变量（包括形参也是局部变量）。 局部变量只能在其所在的局部作用域中使用（访问）。 局部变量在函数调用结束时，会被自动销毁（可以理解为函数执行结束，该执行空间也被销毁了）。 静态变量：一个特殊的局部变量在函数内部，使用static关键字修饰的变量。 1234function XXX( .... )&#123;static $s1 = 10; //此时，$s1就是静态变量......&#125; 静态局部变量的值不会在函数调用结束时被销毁，而是会一直保留。 局部无法访问全局变量 全局作用域与全局变量：就是函数外部范围的作用域，其中定义的变量就是全局变量。 全局变量只能在其所在的全局作用域中可以直接使用（访问）。 超全局作用域与超全局变量：超全局变量可以在所有范围中使用（访问）。 实际上，只有有限的10来个系统预定义变量是超全局变量，包括：$_GET, $_POST, $_REQUEST等。 所以，系统预定义变量，也被统称为超全局变量。 一个特别的超全局变量：$GLOBALS它也是一个数组，其中存储了我们自己定义的所有全局变量。 每个全局变量的变量名，就是$GLOBALS数组的一个单元。 123456789$v1 = 10; //这一行执行，就有了一个这个：$GLOBALS[‘v1’], 其值为10$v2 = ‘abc’; //这一行执行，就有了一个这个：$GLOBALS[‘v2’], 其值为’abc’$v3 = true; //这一行执行，就有了一个这个：$GLOBALS[‘v3’], 其值为truefunction func1( )&#123;echo $GLOBALS[‘v1’]; //输出10；echo $v1; //报错：变量v1未定义$s1 = $GLOBALS[‘v1’] * 5; //结果为50；$s2 = $v1 * 5; //报错：变量v1未定义&#125; 一个特别的的关键字：global用于在局部作用域中，修饰一个跟全局变量同名的局部变量。 此时该局部变量也可以使用全局变量的值了——实际上他们其实是类似变量引用关系。 其作用类似：$GLOBALS 文件加载文件加载的含义将一个（别的）文件包含到当前文件中，成为当前文件运行过程中的一部分。 include “要载入的文件路径”; //可以是相对路径，或本地物理路径。 载入一个文件的本质是：将被载入的文件“插入”到当前载入代码所在的位置。 可以载入php文件，也可以载入html文件。 通常，一些公共的代码，在多个页面都需要用到的时候，会做成一个独立的文件。 然后在不同的页面需要用到的时候，直接载入进来就可以了。 文件加载的四种方式（重点） include ‘要加载的文件’; include_once ‘要加载的文件’; require ‘要加载的文件’; require_once ‘要加载的文件’; 文件路径，可以是相对路径，也可以是物理路径，或直接文件名 正常情况下，四种方式都一样 获取物理路径（绝对路径）的方式： __DIR__：表示当前文件所在路径，由它可以构建出绝对路径； getcwd()：表示当前正访问的网页路径，由它也可以构建出绝对路径； cwd：其实是current working directory的简写 非相对非绝对路径（其实就是没有给出路径，只给出文件名）：不推荐！ 形式为： include ‘文件名’； 此时，会按如下顺序去寻找该文件： 先在php.ini中include_path项设定的目录中寻找该文件； 如果上一步没有找到，就在当前工作目录（由getcwd()获取）下寻找该文件； 如果上一步没有找到，就在当前载入语句的文件所在目录（由__DIR__获取）下寻找； 如果上一步还是没有找到，就报错了。 四种方式的区别include：每次都载入文件（可能会重复载入），如果载入失败，在报错后继续执行后续语句； include_once：只载入一次（不会重复载入），如果载入失败，在报错后继续执行后续语句； require：每次都载入文件（可能会重复载入），如果载入失败，在报错后终止程序； require_once：只载入一次（不会重复载入），如果载入失败，在报错后终止程序； 一般来说，如果被载入的文件内容，是后续代码运行的必备前提，则应该使用require载入。 如果被载入的文件内容，只需要（或只允许）出现一次，则应该使用”xxxx_once”载入。 错误处理错误分类 语法错误： 程序不能运行，是在运行之前，检查语法的时候，就发现语法出错，结果是提示错误，不运行程序。 运行时错误： 语法检查没错，然后开始运行，在运行中出现了错误，然后报错。 这是开发中最常见的错误。 逻辑错误： 程序能运行，且一直到结束没有报错，但执行得到的结果却是错的。 常见错误代号是指在程序运行时，发生的错误，系统会针对每种错误，给出相应的错误代号，并进行提示（报错）。 另外，程序如果在运行之前检查语法的时候就发现语法错误，也会报错，也有一个错误代号。 常见错误代号： E_NOTICE： 提示性错误，轻微； 错误发生后，后面的程序继续执行。 E_WARNING： 警告性错误，稍微严重； 错误发生后，后面的程序继续执行。 E_ERROR： 严重错误/致命错误； 错误发生后，后面的程序不再执行！ E_PARSE： 语法错误（语法解析错误）； 语法解释错误，是直接就不运行程序。 E_USER_NOTICE： 用户自定义的提示错误 E_USER_WARNING： 用户自定义的警告错误 E_USER_ERROR： 用户自定义的严重错误 E_ALL： 它是一个代表“所有”错误的代号。 这些错误代号，都只是系统预先设定的一些常量，他们的值大约是：1， 2， 4， 8， 16….. 这些错误代号，通常只是用于对错误控制时进行“设置”使用。 他们是一系列的整数，并具有一定的规律：1,2,4,8,16,32,64， 。。。。 可以在php.ini中使用（设置）他们的显示级别，如下所示： 错误触发 程序本身有错，则运行时就会触发错误（并提示）。 程序本身没错，但出现不符合预计的情形（比如数据不符合要求）。 trigger_error(“自定义错误提示内容”, 自定义错误的代号);：触发自定义错误 错误显示可以对错误是否显示做定制 在php.ini中设置 display_errors = On或Off 决定所有的错误显不显示 error_reporting = 错误代号1 | 错误代号2 通过|决定显示哪些错误 在php代码中设置 ini_set(‘display_errors’, 1或0); //1表示显示，0不显示 ini_set(‘error_reporting’, 错误代号1 | 错误代号2 | …..） 错误日志默认不会记录错误日志。我们可以设置错误日志的记录 php.ini中设置 log_errors = On 或 Off 决定是否记录日志 error_log = error.txt; 记录的文件 在php代码中设置 ini_set (‘log_errors’, 1或0) ini_set(“error_log”, ‘error.txt’); 自定义错误处理我们对错误的，是否显示，显示什么，是否记录，记录到哪里做自定义 12345678910111213141516171819202122232425262728293031323334&lt;?php//自定义错误，分2步：//1，声明，我们自己使用自己的函数来处理错误//set_error_handler(\"处理错误的自己的函数名\");//系统自动调用set_error_handler(\"my_error_handler\");//2，定义该函数！function my_error_handler($errCode, $errMsg, $errFile, $errLine)//参数解释：errCode错误代号，errMsg错误信息，errfile错误文件，errline行号//此形参顺序固定，而且是由系统会调用该函数并传入实参数据！&#123; //此函数中，我们就可以去自己显示有关错误信息，和记录信息 $str = \"&lt;p&gt;大事不好了，发生错误了，快来人啊。。。\"; $str .= \"&lt;br&gt;发生时间：\" . date('Y-m-d H:i:s'); $str .= \"&lt;br&gt;错误代号：\" . $errCode; $str .= \"&lt;br&gt;错误信息：\" . $errMsg; $str .= \"&lt;br&gt;错误文件：\" . $errFile; $str .= \"&lt;br&gt;错误行号：\" . $errLine; $str .= \"&lt;/p&gt;\"; echo $str; //也可以在这里继续去“记录错误”——就是错误日志 //FILE_APPEND表示该函数使用“追加模式”来写入数据 file_put_contents(\"./error.html\", $str, FILE_APPEND);&#125;//先给出几个出错的代码：echo \"&lt;br&gt;v1=$v1\"; //未定义的变量include './no-this-file.php'; //载入失败function I1()&#123;&#125;l1(); //调用不存在的函数；echo \"&lt;p&gt;最后的段落&lt;/p&gt;\"; 字符串详解4种不同形式的字符串 单引号字符串 在单引号内只能使用两个转义符：\\\\、\\&#39; 通常推荐使用单引号 双引号字符串 能使用丰富的转义符，\\n、\\r、\\\\、\\t等等 在双引号内的$开头的会被识别为变量。只显示$需要用\\$ heredoc字符串 1234$s1=&lt;&lt;&lt;\"标识符\" ………… ………… 标识符; 多行字符串，结尾行只有标识符;。不能有空格 缩进。 特点与双引号一致 nowdoc字符串 1234$s1=&lt;&lt;&lt;'标识符' ………… ………… 标识符; 特点与单引号一致 用法和heredoc一致 字符长度strlen(字符串)：求该字符串的“字节数”，也就是占据的字节空间大小； 根据编码不同，长度不同 mb_strlen(字符串)：求字符个数 使用该函数前要将php.ini中的extension=mbstring注释打开，老版本为php_mbstring.dll 常用字符串函数字符串输出： echo： 输出一个或多个字符（不是函数，是语言结构）不能输出数组变量 print：输出一个字符串 print_r：输出变量的较为详细的信息 var_dump：输出变量的完整信息 字符串去除与填充： trim：消除一个字符串两端的空白字符或指定字符（空白字符包括：空格，\\n, \\r, \\t等） ltrim：消除一个字符串左边的空白字符或指定字符 rtrim：消除一个字符串右边的空白字符或指定字符 str_pad：将一个字符串使用指定的字符填充到指定的长度 字符串连接与分割： implode：将一个数组的值连接起来组成一个字符串 join：同implode explode： 将一个字符串使用指定的字符分割为一个数组 str_split：将一个字符串按指定的长度分割为一个数组 字符串截取： substr：获取一个字符串中指定位置开始指定长度的子字符串 strstr：获取一个字符串中某个指定字符首次出现的位置起，到最后结尾处的字符 strstr(‘abcd.12.3.txt’, ‘.’); //结果是：”.12.3.txt” strrchr：获取一个字符串中某个指定字符最后一次出现的位置起，到最后结尾处的字符 strrchr(‘abcd.12.3.txt’, ‘.’); //结果是：”.txt” 字符串替换： str_replace：将一个字符串中的指定字符，替换为给定的新字符。 substr_replace：将一个字符串中指定位置开始的指定个数的字符，替换为给定的新字符。 字符串长度与位置： strlen：获取字符串的字节长度。 strpos：获取一个字符串中某个子字符串首次出现的位置。 strpos(‘abcd.12.3.txt’, ‘.’); //结果是：4 strrpos：获取一个字符串中某个子字符串最后一次出现的位置。 strrpos(‘abcd.12.3.txt’, ‘.’); //结果是：9 strrpos(‘abcd.12.3.txt’, ‘cd’); //结果是：2 字符转换： strtolower：将一个字符串转换为小写。 strtoupper：将一个字符串转换为大写。 lcfirst：将一个字符串的首字母转换为小写。 ucfirst：将一个字符串的首字母转换为大写。 ucwords：将一个字符串中的所有单词的首字母转换大写。 特殊字符处理： nl2br：将换行符转换为””标签字符 addslashes： 将一个字符串中的以下几个字符使用反斜杠进行转义：\\ ‘ “ htmlspecialchars：将html中的特殊字符转换为html实体字符，如下所示： （&amp; ‘ “ &lt; &gt; ）分别转换为：（（&amp; &apos; &quot; &lt; &gt; ） htmlspecialchars_decode：将html实体字符，转换回原本的字符。 数组创建、获取创建数组三种形式： $arr1 = array(单元1，单元2，…）； $arr2 = [单元1，单元2，…]； 单元（元素）的形式为： [下标=&gt;]值 $arr3[下标1] = 值1； $arr3[下标2] = 值2； 获取元素$数组名[下标]; 其中，下标可以是整数的，也可以是字符串的（注意有引号） 数组下标每一个没有使用下标的单元，系统给其分配的下标为之前所用过的整数下标的最大值+1 12345$arr1 = array(‘a’, 2=&gt;’b’, ‘c’, ‘x’=&gt;’d’, ‘e’); // 其下标分别为：0, 2, 3, ‘x’, 4$arr2 = array(5=&gt;‘a’, 2=&gt;’b’, ‘c’, ‘x’=&gt;’d’); // 其下标分别为：5, 2, 6, ‘x’$arr3[‘x’] = 5; //这一行，会自动创建一个数组，$arr3[ ] = 6; //此时下标就是0$arr3[] = 3;//下标为1 索引数组：指一个数组的下标是从0开始的连续的整数。 关联数组：指一个数组的下标都是字符串。 多维数组在数组里塞数组 1$arr1 = array(array(1,2),array(2,1),1); 数组遍历1234foreach( $数组名 as [$key =&gt;] $value)&#123;//这里，$key和$value只是变量，它会在遍历数组的过程中，按顺序依次取得数组每个单元的下标和值。echo “&lt;br /&gt;&#123;$key&#125; &gt;&gt;&gt; &#123;$value&#125; “;&#125; 数组内的指针数组内默认维护一个指针，初始状态下指向第一个元素 指针函数： $re = current( $arr1); //取得数组中当前指针所在单元的值； $re = key( $arr1 ); //取得数组中当前指针所在单元的键（下标）； $re = next( $arr1 ); //将数组中的指针往后移动一个位置，并取得新位置上的值； $re = prev( $arr1 ); //将数组中的指针往前移动一个位置，并取得新位置上的值； $re = end( $arr1 ); //将数组中的指针移动到最后一个位置，并取得新位置上的值； $re = reset($arr1); //将数组中的指针移动到最前一个位置，并取得新位置上的值； 1234567891011121314151617181920212223&lt;?php //请用for（即不用foreach）来遍历如下数组，////并按顺序输出其每一个单元的键和值：///提示：count()函数可以求数组的长度$arr1 = array(\"a\", 2=&gt;\"b\", \"c\", \"x\"=&gt;\"d\", \"e\"); $v1 = current($arr1); //\"a\";$k1 = key($arr1); //0next($arr1); //指针往后移动一位$v2 = current($arr1); //'b'$k2 = key($arr1); //2end($arr1); //指针移动到最后一个单元$v3 = current($arr1); //'e'$k3 = key($arr1); //4//先将指针移回第一个：reset($arr1);$len = count($arr1);for($i = 0; $i &lt; $len; $i++)&#123; $key = key($arr1); $value = current($arr1); echo \"&lt;br&gt;$key :::: $value\"; next($arr1); &#125; 数组函数操控数组的函数 max()： 获取一个数组中的最大值 min()： 获取一个数组中的最小值 count()： 获取一个数组的元素个数 in_array()： 判断一个数据是否在指定数组中。 语法形式：$b = in_array( $数组， 数据); //结果true或false range()： 生成某个范围的连续值的数组，比如range(3, 9)会得到数组：array(3, 4, 5, 6, 7, 8, 9, ); array_keys()： 取出一个数组中的所有“键”并放入一个索引数组中。 array_values()： 取出一个数组中的所有“值”并放入一个索引数组中。 array_push()： 将一个或多个数据放入一个数组的“末端”。 array_pop()： 将一个数组的最后一个单元删除，并返回该单元的值。 array_reverse()： 将一个数组的所有单元的顺序进行反转（最前的放最后，最后的放最前） 手册-&gt;函数参考-&gt;变量与类型相关扩展-&gt;数组-&gt;数组函数 PHP连接MySQL基本连接关闭函数 mysqli_connect([host][,username][,password][,dbname][,port]) host：MySQL服务器。可以包含端口号，默认值为“localhost:3306” username：用户名。默认值是服务器进程所有者的用户名； password：密码。 dbname：数据库名称。 port：MySQL服务器的端口号，默认为3306。 如果连接成功，则返回MySQLi连接对象。如果失败，则返回FALSE。 exit()或die() void exit ([ string $string ] ) ：输出 $string 的值，并中止程序的运行。 die()：终止程序 mysqli_connect_error()：返回上一个 MySQL 连接产生的文本错误信息 bool mysqli_close ( mysqli $link ) 传入数据库连接对象 bool mysqli_select_db(mysqli $link, string $database) 选择数据库 bool mysqli_set_charset ( mysqli $link , string $charset ) 设置字符集 SQL语句函数 resource mysqli_query(mysqli $link , string $query )","categories":[],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://example.com/tags/PHP/"},{"name":"后端","slug":"后端","permalink":"http://example.com/tags/%E5%90%8E%E7%AB%AF/"}]},{"title":"实时框架实战","slug":"实时框架实战","date":"2019-11-27T11:29:46.000Z","updated":"2021-07-08T07:59:23.412Z","comments":true,"path":"2019/11/27/实时框架实战/","link":"","permalink":"http://example.com/2019/11/27/%E5%AE%9E%E6%97%B6%E6%A1%86%E6%9E%B6%E5%AE%9E%E6%88%98/","excerpt":"","text":"理论简述框架回顾Hadoop面试面试的时候，问的越来越少，只需要了解shuff、文件的读写、任务的调度即可 以前会让写Top N，现在一般用Spark写。 任务提交流程 Client-&gt;Applications Manager申请启动App Mstr Applications Manager分配Container，告知一个NM启动App Mstr App Mstr向Application Manager注册 App Mstr向RM（Resource Scheduler）申请资源 运行时，NM会和RM一直通讯，提交进度 zookeeper半数机制 投票给Id比他大一的 12345：选3 54321：选5 zk内的节点分俩类四种 永久 有序、无序 暂时 有序、无序 kafka zkoffset是以消费者组存储的：当分区分配好后，一旦有分区数或消费者数增减，会重新分配 如果按照消费者来保存offset，消费者挂了一个，那么它的offset就无效了，在分配后其他的消费者就无法根据之前的位置继续消费。如果按照消费者组的消费。不管消耗多少，只要按照组查询，就能知道消费多少 这里我有点云里雾里，对Kafka还不够熟练的问题 HiveSql语句要多练、Hive的优化很重要（如不要用dis去重，用group by去重） 俩种存储格式：行、列（pa、orc） spark建议使用pa Flumesource先到channle管理器然后到拦截器链然后再回到channle管理器再到channle选择器（必须：如果出问题会报错、回滚，非必须：失败的话不会报错） Sink组：俩种模式，一个是容灾（都发），一个是负载均衡（轮着发） 通过head，指定主题发送。在head里追加k-v（k的名字随意，v的值是发送到的kafka的topic名字）配kafka Sink的时候可以用%的形式取key，它会自动赋值上value值 通过head，指定分区发送，要求在head中追加的k-v，k必须是key，会根据对应的value值决定去哪个分区 事物：只可能造成数据的重复，不会有数据的丢失 flume集群一定是在同一个网域里，基本不会出现网络IO瓶颈。flume是没有分布式的，采用sink组来进行容灾 kafka作用：削峰 有时间了解下kafka的精确一次性消费 Sqoop如何实行批量导入。只能实现关系型数据库和HDFS互相导来导去 DATAX：能支持大量的数据类型的导入导出。阿里的，开源的单节点。 HBASE先横向拆分，再纵向拆分 列族尽量少：ms满了会刷到杀f里，如果有多个列族就有多个store，每个store就有多个ms，满了就刷写会产生大量小文件 小文件合并极其影响性能，一般把自动合并关闭，找空闲点手动合并 大数据的应用大数据平台绝大多数数据来源于日志数据。大多数数据框架用来解决日志数据的采集、清洗、存储和分析，在海量的数据里提取有用的信息 标准的数据仓库分四层。 ods：原始数据 dwd：简单清洗脱敏（清楚敏感数据），维度建模形成宽表 dws：轻度聚合 dm：具体业务 在app内植入sdk。通过sdk采集数据 系统埋点策略pc端：h5 移动端：app分localapp、webapp、hybridapp（主流） 埋点方式：客户端、服务器 用户标识系统： 新设备：用户第一次使用网站，不登陆，分配一个cid，用户登录，cid不变，再分配uid 新设备，用户第一次使用网站，不登陆，分配一个cid，第一次注册，cid不变分配一个uid 老设备，之前的用户访问cid1，uid1，用户退出，cid1,uid1不变，另一用户登录，cid和uid改变 老设备，之前用户为cid1，uid1重新注册cid，uid都改变 多设备用户打通：通过uid实现多屏用户数据打通 实战前置工作通过spark.sql查出DataFrame。通过调用as方法直接转化成具体类的DataSet","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"http://example.com/tags/Spark/"},{"name":"大数据","slug":"大数据","permalink":"http://example.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}]},{"title":"Shell编程","slug":"Shell编程","date":"2019-11-27T03:12:52.000Z","updated":"2021-07-08T07:57:00.598Z","comments":true,"path":"2019/11/27/Shell编程/","link":"","permalink":"http://example.com/2019/11/27/Shell%E7%BC%96%E7%A8%8B/","excerpt":"","text":"简介笔记主要记录Shell编程的高级用法，需要对基础语法有所掌握。 内容会涉及，不限于 变量的高级用法 函数的高级用法 文件查找命令高级用法 文本处理grep、sed、awk 监控脚本的编写 脚本操作MySql获取处理数据 大型脚本工具编写(复杂的文本处理、功能模块函数编写、函数主流程设计)","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"http://example.com/tags/Shell/"}]},{"title":"Flink笔记","slug":"Flink笔记","date":"2019-11-26T07:15:12.000Z","updated":"2021-07-08T07:55:07.988Z","comments":true,"path":"2019/11/26/Flink笔记/","link":"","permalink":"http://example.com/2019/11/26/Flink%E7%AC%94%E8%AE%B0/","excerpt":"","text":"简介介绍Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。 Flink比spark更快，延迟更低 高吞吐，低延迟，准确性高，良好的容错性 有状态：指有些需要保存下来比对的数据 应用场景数据报表、广告投放、实时报警、基站流量调配、实时结算和通知推送、实时监测异常行为 特点事件驱动：程序依赖于事件的发生，来运转。与之相反的Spark流是按照时间来获取流数据 分层API：越顶层越抽象，表达、使用越简洁明了 越底层表达越丰富，越灵活 流与批的世界观在Flink内，所有都是流，离线数据是有界的流，实时数据是无界的流。 Spark内是批，离线数据是一个大批次，而实时数据是由一个一个无限的小批次组成的。 其它特点 支持事件时间、处理时间 精确一次的状态一致性保证 低延迟，每秒处理百万级事件，毫秒级延迟 能与大多数存储系统对接 高可用，动态扩展，24小时运行 Flink和Spark的区别Spark： Spark的流实际是很小的批次，采用RDD模型 批计算，将DAG划分为不同的stage，一个完成后计算下一个 Flink： Flink是数据流和事件序列 流执行模式，一个事件在一个节点处理完成后直接发往下一个节点处理 快速上手wordcount：pom文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-scala_2.11&lt;/artifactId&gt; &lt;version&gt;1.7.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- hehttps://mvnrepository.com/artifact/org.apache.flink/flink-streaming-scala --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-streaming-scala_2.11&lt;/artifactId&gt; &lt;version&gt;1.7.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;!-- 该插件用于将Scala代码编译成class文件 --&gt; &lt;plugin&gt; &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt; &lt;artifactId&gt;scala-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;!-- 声明绑定到maven的compile阶段 --&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;goal&gt;testCompile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 引入Scala框架 批处理123456789101112131415161718//这里要引入org.apache.flink.api.scala下的所有，因为涉及到隐式转化import org.apache.flink.api.scala._/** * @author dianyang * @date 2019/11/29 10:34 */object WordCount &#123; def main(args: Array[String]): Unit = &#123; //创建一个执行环境 val environment: ExecutionEnvironment = ExecutionEnvironment.getExecutionEnvironment //从文件中读取数据 val inputPath: String = \"F:\\\\JAVAIDEA\\\\flink-learn\\\\src\\\\main\\\\resources\\\\hello.txt\" val inputDateSet: DataSet[String] = environment.readTextFile(inputPath) //切分数据 val wordCountDataSet: AggregateDataSet[(String, Int)] = inputDateSet.flatMap(_.split(\" \")).map((_, 1)).groupBy(0).sum(1) wordCountDataSet.print() &#125;&#125; 流处理12345678910111213141516171819//涉及到隐式转化，引入全部import org.apache.flink.streaming.api.scala._/** * @author dianyang * @date 2019/11/29 16:03 */object StreamWordCount &#123; def main(args: Array[String]): Unit = &#123; //创建流处理环境 val environment: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment //接受一个socket文本流 val dataStream: DataStream[String] = environment.socketTextStream(\"localhost\", 7777) val wordCountDataStream: DataStream[(String, Int)] = dataStream.flatMap(_.split(\" \")).filter(_.nonEmpty).map((_, 1)).keyBy(0).sum(1) wordCountDataStream.print() //真正开始执行 environment.execute(\"冲冲冲\") &#125;&#125; Flink部署standalone模式安装解压缩 flink-1.7.0-bin-hadoop27-scala_2.11.tgz 支持的hadoop版本 修改 flink/conf/flink-conf.yaml 文件 将jobmanager.rpc.address: localhost修改为jobmanager.rpc.address: 集群master的ip 12345#flink/conf/flink-conf.yaml文件解析 #可以运行的数量taskmanager.numberOfTaskSlots: 1#实际运行的数量parallelism.default: 1 jobmanager：管理调度 taskmanager：work，执行任务 slot：资源管理最小的单位 修改 /conf/slave文件 分行填入从机的ip地址，一个空格不能多一个不能少 121.1.1.12.3.2.2 bin/start-cluster.sh群起 访问flink的web页面http://Masterip:8081 运行jar包图形界面将打包好的jar包通过页面的Submit new job-&gt;add new提交。 打勾选中，填写参数 Entry class：填要运行的main函数的路径。就是导包的路径 Parallelism：并行度 Program Argumments：参数如--host localhost --port 7777 然后submit。 flink的每个算子都可以设置并行度 停止任务：右上角有Cancel按钮 命令行下启动 1bin/flink run -c 入口类 -p 并行度 jar包地址 --host localhost --port 7777 查看 1bin/flink list –all查看所有，包括已取消的 停止 1bin/shell 用list查看到的运行的一串编号 yarn模式 启动hadoop集群 启动yarn-session 1./yarn-session.sh -n 2 -s 2 -jm 1024 -tm 1024 -nm test -d -n(–container)：TaskManager的数量。 -s(–slots)： 每个TaskManager的slot数量，默认一个slot一个core，默认每个taskmanager的slot的个数为1，有时可以多一些taskmanager，做冗余。 -jm：JobManager的内存（单位MB)。 -tm：每个taskmanager的内存（单位MB)。 -nm：yarn 的appName(现在yarn的ui上的名字)。 -d：后台执行。 执行 1./flink run -m yarn-cluster -c 入口类全路径 jar包 --input 输入路径 --output 输出路径 去yarn控制台查看任务状态 K8S也是一种重要的基于docker的部署方式。知道即可 Flink运行组件和原理组件 重点：JobManager和TaskManager JobManager 控制一个应用程序执行的主进程。就是说，每个应用程序都对应一个JobManager JboManager会先接收要执行的应用程序。程序包括：作业图(JobGraph)、逻辑数据流图(logical dataflow graph)和打包了所有的类、库和其他资源的jar包 JobManager会将JobGraph转化为物理层面的数据流图(执行图”ExecutionGraph”)，包含了所有可以并发执行的任务 JobManager会向ResourceManager请求执行任务的资源，也就是TaskManager上的slot。一旦有足够的资源，就会方法到真正运行它们的TaskManager上。运行时，JobManager会负责所有需要中央协调的操作，如检查点(checkpoints)的保存记录 TaskManager Flink中的工作进程。通常有多个TaskManager。每个都有一定量的slots。slots的数量限制了TaskManager能执行的任务数 启动之后，TaskManager会像resourceManager注册slots，收到resourceManager的指令，TaskManager会将slots供给给JobManager调用。JobManager就可以向slots分配任务执行 一个TaskeManager可以和其它运行同一应用程序的TaskManager交换数据 ResourveManager 主要负责TaskManager和slot 不同的环境和资源管理工具有不同的资源管理器。如：yarn、mesos、k8s，standlaone部署 当JM申请slot时，RM会将空闲的TM分配给JM。如果slot不够，会向资源提供平台发起会话，来启动TM进程的容器 Dispatcher 可以跨作业运行，为应用提交提供了REST接口 当一个应用被提交执行，分发器就会启动并将应用移交给一个JM Dispatcher也会启动Web UI，来展示和监控作业执行的信息 Dispatcher在架构中不是必需的，取决于应用提交方式 提交流程 yarn模式 这里的RM是yarn的RM 调度原理 Flink Program：我们写的代码通过转化，提交 TaskManager和Slots Flink中每个TaskManager都是一个JVM进程，它会在独立的线程上执行一个或多个subtask 为了控制一个TaskManager能接收多少task，TaskManager通过taskslot来进行控制（一个TaskManager至少一个slot） slot是在配置文件中提前定义好。或者是在创建yarnsession是指定。 一般按照每个TaskManager这个机器的性能，它所含有的资源来配置slots slots中主要隔离的就是内存，cpu不做隔离 一般内存是够用的，为了防止cpu复用，往往可以按照cpu数来划分 默认情况下，Flink允许子任务共享slot，即使它们是不同任务的子任务。这样的结果是，一个slot可以保存作业的整个管道 Task Slot是静态概念，是指TaskManager具有并发执行能力 可以通过修改共享组不共享，默认是一个共享组 这样不仅能防止资源倾斜，Flink只用计算最大任务的并行度即可，无需计算总和 可以通过修改配置文件，运行时-p参数，代码内设置子任务并行度，代码内设置环境并行度来修改并行度 数据流与执行图流程 所有Flink程序都是由三部分组成，Source、Transformation和Sink Source负责读取数据源，Transformation利用各种算子进行处理加工，Sink负责输出 程序与数据流 运行时，Flink上运行的程序会被映射成”逻辑数据流”(dataflows)，它包含三部分 每个dataflow以一个或多个sources开始，以一个或多个sinks结束。dataflow类似于任意的有向无环图(DAG) 在大部分情况下，程序中的转换运算(transformations)和dataflow中的算子(operator)是一一对应的 执行图(ExecutionGraph) Flink中的执行图分为四层：StreamGraph-&gt;JobGraph-&gt;ExecutionGraph-&gt;物理执行图 StreamGraph：是根据用户通过Stream API编写代码生成的最初的图。用来表示程序的拓扑结构。 JobGraph：StreamGraph经过优化生成的JobGraph，提交给JobManager的数据结构。主要的优化为，将多个符合条件的节点chain在一起作为一个节点 ExecutionGraph：JobManager根据JobGraph生成ExecutionGraph。ExecutionGraph是JobGraph的并行化版本，是调度层最核心的数据结构 物理执行图：JobManager根据ExecutionGraph对Job进行调度后，在各个TaskManager上部署Task后形成的，并不是一个具体的数据结构 在客户端提交的时候就生成了JobGraph。 ExecutionGraph传给TaskManager就可以执行了 并行度（ Parallelism） 一个特定算子的子任务(subtask)的个数被称之为其并行度(parallelism)。一般情况下，一个stream的并行度，可以认为就是其所有算子中最大的并行度 Flink里的并行非常的灵活 这张图就体现了灵活的并行度 太多的并行可能会影响效率，这时候就要通过修改共享组来减少并行，提高效率 一个程序中不同的算子可能有不同的并行度。所以算子之间传输数据的形式可以是one-to-one(forwarding)的模式也可以是redistributing的模式，具体取决于算子种类 One-to-One：strem维护着分区以及元素顺序（比如source和map之间）。意味着map算子的子任务看到的元素的个数以及顺序根source算子的子任务生产的元素的个数、顺序相同。map、fliter、flatMap等算子都是改模式的对于酸洗。对应spark的窄依赖 Redistributing：stream的分区会发生改变。每一个算子的子任务一句所选择的transformation发送数据到不同的目标任务。例如，keyBy基于hashCode重分区、而broadcast和rebalance会随机重新分区，这些算子都会引起redistribute过程，而redistribute过程就类似于Spark中的shuffle。对应spark的宽依赖 任务链(Operator Chains) Flink采用了一种称为任务链的优化技术，可以在特定条件下减少本地通信的开销。为了满足任务链的要求，必须将俩个或多个算子设为相同的并行度，并通过本地转发（local forward）的方式进行连接 相同并行度的one-to-one操作，Flink这样相连的算子链接在一起形成一个task，原来的算子称为里面的subtask 并行度相同、并且是one-to-one操作，俩个条件缺一不可 ![](Flink笔记/Operator Chains.png) 在一些情况下我们并不希望很多的任务合并operator chain。有时候更希望它打散运行，让他有更好的并行度。 我们可以在代码内手动控制 env.disableOperatorChaining()：在环境变量使用，是全部打散 .disableChaining()：在算子后使用，后面全部打散 .startNewChain()：开启一个新operatorChain。后面还会链接 Flink流处理APIEnvironmentExecutionEnvironment.getExecutionEnvironment：根据查询运行的方式决定返回什么样的运行环境，是最常用的一种创建执行环境的方式。 StreamExecutionEnvironment.createLocalEnvironment(1)：返回本地执行环境，需要在调用时指定默认的并行度。 ExecutionEnvironment.createRemoteEnvironment(&quot;jobmanager-hostname&quot;, 6123,&quot;C://jar//flink//wordcount.jar&quot;)：返回集群执行环境，将Jar提交到远程服务器。需要在调用时指定JobManager的IP和端口号，并指定要在集群中运行的Jar包。 Source简单source(用的少)有界流 1234567891011121314151617181920212223242526import org.apache.flink.streaming.api.scala._// 定义传感器数据样例类case class SensorReading(id: String, timestamp: Long, temperature: Double)object SourceTest &#123; def main(args: Array[String]): Unit = &#123; val env = StreamExecutionEnvironment.getExecutionEnvironment env.setParallelism(1) // 1. 从集合中读取数据 val stream1 = env.fromCollection(List( SensorReading(\"sensor_1\", 1547718199, 35.80018327300259), SensorReading(\"sensor_6\", 1547718201, 15.402984393403084), SensorReading(\"sensor_7\", 1547718202, 6.720945201171228), SensorReading(\"sensor_10\", 1547718205, 38.101067604893444) )) //可以读取不同类型的元素，没有设置并行度时候默认为cpu核数 //env.fromElements(1,2.1,\"sad\").print //读取文本文件 //env.readTextFile(\"路径\") //在输出前会加上'stream1&gt; '并发情况下，会变成'stream1:1&gt; '的形式，&gt;前的数字为并发任务编号 stream1.print(\"stream1\").setParallelism(1) env.execute(\"source api test\") &#125;&#125; Kafka Sourcepom 123456&lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;!--kafka的版本是0.11，scala的版本为2.11--&gt; &lt;artifactId&gt;flink-connector-kafka-0.11_2.11&lt;/artifactId&gt; &lt;version&gt;1.7.2&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324import java.util.Propertiesimport org.apache.flink.api.common.serialization.SimpleStringSchemaimport org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer011import org.apache.flink.streaming.api.scala._object SourceTest &#123; def main(args: Array[String]): Unit = &#123; val env = StreamExecutionEnvironment.getExecutionEnvironment env.setParallelism(1) // 从kafka中读取数据 // 创建kafka相关的配置 val properties = new Properties() properties.setProperty(\"bootstrap.servers\", \"localhost:9092\") properties.setProperty(\"group.id\", \"consumer-group\") properties.setProperty(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\") properties.setProperty(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\") properties.setProperty(\"auto.offset.reset\", \"latest\") //第一个参数：topic，第二个参数：值的反序列化工具，第三个参数：配置参数 val stream = env.addSource(new FlinkKafkaConsumer011[String](\"sensor\", new SimpleStringSchema(), properties)) stream.print(\"stream\").setParallelism(1) //bin/kafka-console-producer.sh --broker-list localhost:9092 --topic sensor启动kafka生产者 env.execute(\"source api test\") &#125;&#125; 容灾机制：如果kafka已经发送了数据，我们就回复接收。如果在数据转化时数据丢失就无法回滚，所以Spark选择在数据接收转化后再回复。 Flink是有状态的流处理，可以把kafka的偏移量作为状态保存。如果数据丢失，Flink会自动修改偏移量 自定义Source测试环境中，可能需要自己自定义Source来生成测试数据，但是生产环境中很少 12345678910111213141516171819202122232425262728293031323334353637383940import org.apache.flink.api.common.serialization.SimpleStringSchemaimport org.apache.flink.streaming.api.functions.source.SourceFunctionimport org.apache.flink.streaming.api.scala._import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer011import scala.util.Random//样例类case class SensorReading( id: String, timestamp: Long, temperature: Double )//基础SourceFunctionclass SensorSource() extends SourceFunction[SensorReading]&#123; // 定义一个flag：表示数据源是否还在正常运行 var running: Boolean = true override def cancel(): Unit = running = false override def run(ctx: SourceFunction.SourceContext[SensorReading]): Unit = &#123; // 创建一个随机数发生器 val rand = new Random() // 随机初始换生成10个传感器的温度数据，之后在它基础随机波动生成流数据 var curTemp = 1.to(10).map( i =&gt; ( \"sensor_\" + i, 60 + rand.nextGaussian() * 20 ) ) // 无限循环生成流数据，除非被cancel while(running)&#123; // 更新温度值 curTemp = curTemp.map( t =&gt; (t._1, t._2 + rand.nextGaussian()) ) // 获取当前的时间戳 val curTime = System.currentTimeMillis() // 包装成SensorReading，输出 curTemp.foreach( t =&gt; ctx.collect( SensorReading(t._1, curTime, t._2) ) ) // 间隔100ms Thread.sleep(100) &#125; &#125;&#125; Transform基本转化算子 map：val streamMap = stream.map { x =&gt; x * 2 } flatmap：传数组进入会打散。val streamFlatMap = stream.flatMap{ x =&gt; x.split(&quot; &quot;)} filter：过滤，返回bool类型 val streamFilter = stream.filter{x =&gt; x == 1} 分组转化算子(键控流) KeyBy：从dataStream=&gt;KeyedStream：流还是单个流，内部做了分区。每个分区有相同的key，内部以hash实现 123456789//传入int，Int为传入元素的键值位置 返回//T为dataStream的泛型//JavaTuple就是KeyedStream[T, K]的Kdef keyBy(fields: Int*):KeyedStream[T, JavaTuple]//传入函数//T为dataStream的泛型//K为函数返回值的类型 def keyBy[K: TypeInformation](fun: T =&gt; K): KeyedStream[T, K] 滚动聚合算子(Rolling Aggregation)dataStream没有这些算子。这些算子针能对keyedStream的每一支流做聚合。会返回DataStream。 sum()：可以传位置参数，也可以传属性名 min() max() minBy() maxBy() 如果数据很简单，需要直接使用聚合算子，可以先造一个无用的key，然后keyby转化再用聚合算子 Reduce KeyedStream=&gt;DataStream 一个分组数据流的聚合操作，合并当前的元素和上次聚合的结果，产生一个新的值，返回的流中包含每一次聚合的结果，而不是只返回最后一次聚合的最终结果。 Reduce：传入一个需要俩个参数的函数，第一个参数为之前聚合的值，第二个为新传入的值 多流转化算子 split和 Select Split：将strean转化为SplitStream，SplitStream里面有俩个组。但是无法对里面的流进行操作。必须用select摘取出来，才能操作。 123456789//分流，根据温度是否大于30度划分val splitStream = dataStream .split(sensorData =&gt; &#123;//seq是TraversableOnce的实现类，返回一个戳标记一下 if (sensorData.temperature &gt; 30) Seq(\"high\") else Seq(\"low\") &#125;)//用select选出来val highTempStream = splitStream.select(\"high\")val lowTempStream = splitStream.select(\"low\")val allTempStream = splitStream.select(\"high\", \"low\") Connect 两个流被放在了一个同一个流中，内部依然保持各自的数据和形式不发生任何变化，两个流相互独立。 CoMap 123456val warningStream = highTempStream.map(sensorData =&gt; (sensorData.id, sensorData.temperature))val connectedStreams = warningStream.connect(lowTempStream)val coMapStream: DataStream[Product] = connectedStreams.map( warningData =&gt; (warningData._1, warningData._2, \"high temperature warning\"), lowData =&gt; (lowData.id, \"healthy\")) Union val unionStream = highTempStream.union(lowTempStream) 两个以上的DataStream进行union 产生一个包含所有DataStream元素的新DataStream。DataStream可以跟它自己做union操作，在新的DataStream中，你将看到每一个元素都出现两次。 Union之前两个流的类型必须是一样，Connect可以不一样，在之后的coMap中再去调整成为一样的Connect只能操作两个流，Union可以操作多个 支持的数据类型 基础数据类型：所有的Java和Scala基础数据类型如Int、Doublt… Java和Scala元组(Tuples) Scala样例类 Java的简单对象(POJOs) 其他(Arrays，list，maps，enums等等) 实现UDF函数可以实现更细粒度的控制流 函数类写一个类继承函数对象。重写内部方法。然后传实例化该类的对象。 12345678910111213141516//使用dataStream.filter( new MyFilter() ).print()//定义类class MyFilter() extends FilterFunction[SensorReading]&#123; override def filter(value: SensorReading): Boolean = &#123; value.id.startsWith(\"sensor_1\") &#125;&#125;class MyMapper() extends RichMapFunction[SensorReading, String]&#123; override def map(value: SensorReading): String = &#123; \"flink\" &#125; override def open(parameters: Configuration): Unit = super.open(parameters)&#125; 函数类，可以在new的时候，传额外参数 匿名函数传入函数，即是我们一般用的 富函数“富函数”是Flink提供的函数类接口。它可以获取运行环境上下文，有生命周期方法，能实现更复杂的功能。每个函数都有对应的接口。 123456789101112131415//第一个泛型是输入，第二个泛型是输出class MyFlatMap extends RichFlatMapFunction[Int, String] &#123; //做初始化内容等等 override def open(parameters: Configuration): Unit = &#123; &#125; //具体工作 override def flatMap(in: Int, collector: Collector[String]): Unit = &#123; collector.collect(\"sad\") &#125; //关闭工作 override def close(): Unit = &#123; &#125;&#125; SinkFlink中没有类似Spark中的行动算子。所有的对外输出操作都由Sink来做。最后都通过类似下面的方式完成stream.addSink(new XXSink(xxx))。我们常用的print方法返回的也是Sink 官方提供了一部分的框架的sink。除此之外的，需要自定义 Kafka Cassandra Amazon Kinesis Streams Elasticsearch Hadoop FileSystem RabbitMQ Apache NIFI Twitter Streaming Api Bahir提供支持的 ActiveMQ Flume Redis Akka Netty Kafkapom 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-kafka-0.11_2.11&lt;/artifactId&gt; &lt;version&gt;1.7.2&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142import java.util.Propertiesimport com.atguigu.apitest.SensorReadingimport org.apache.flink.api.common.serialization.SimpleStringSchemaimport org.apache.flink.streaming.api.scala._import org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer011.Semanticimport org.apache.flink.streaming.connectors.kafka.&#123;FlinkKafkaConsumer011, FlinkKafkaProducer011&#125;object KafkaSinkTest &#123; def main(args: Array[String]): Unit = &#123; val env = StreamExecutionEnvironment.getExecutionEnvironment env.setParallelism(1) // source 文件读取 // val inputStream = env.readTextFile(\"D:\\\\Projects\\\\BigData\\\\FlinkTutorial\\\\src\\\\main\\\\resources\\\\sensor.txt\") val properties = new Properties() properties.setProperty(\"bootstrap.servers\", \"localhost:9092\") properties.setProperty(\"group.id\", \"consumer-group\") properties.setProperty(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\") properties.setProperty(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\") properties.setProperty(\"auto.offset.reset\", \"latest\") //kafka读取 val inputStream = env.addSource(new FlinkKafkaConsumer011[String](\"sensor\", new SimpleStringSchema(), properties)) // Transform操作 val dataStream = inputStream .map( data =&gt; &#123; val dataArray = data.split(\",\") SensorReading( dataArray(0).trim, dataArray(1).trim.toLong, dataArray(2).trim.toDouble ).toString // 转成String方便序列化输出 &#125; ) /*new FlinkKafkaProducer011[(String)](\"localhost\", \"topic\", new SimpleStringSchema())*/ // sink dataStream.addSink( new FlinkKafkaProducer011[String]( \"sinkTest\", new SimpleStringSchema(), properties) ) dataStream.print() env.execute(\"kafka sink test\") &#125;&#125; 后面会讲端到端状态一致性。 redispom 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.bahir&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-redis_2.11&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import org.apache.flink.streaming.api.scala._import org.apache.flink.streaming.connectors.redis.RedisSinkimport org.apache.flink.streaming.connectors.redis.common.config.FlinkJedisPoolConfigimport org.apache.flink.streaming.connectors.redis.common.mapper.&#123;RedisCommand, RedisCommandDescription, RedisMapper&#125;object RedisSinkTest &#123; def main(args: Array[String]): Unit = &#123; val env = StreamExecutionEnvironment.getExecutionEnvironment env.setParallelism(1) // source val inputStream = env.readTextFile(\"F:\\\\JAVAIDEA\\\\flink-learn\\\\src\\\\main\\\\resources\\\\sensor.txt\") // transform val dataStream = inputStream .map( data =&gt; &#123; val dataArray = data.split(\",\") SensorReading( dataArray(0).trim, dataArray(1).trim.toLong, dataArray(2).trim.toDouble ) &#125; ) val conf = new FlinkJedisPoolConfig.Builder() .setHost(\"localhost\") .setPort(6379) .build() // sink dataStream.addSink( new RedisSink(conf, new MyRedisMapper()) ) env.execute(\"redis sink test\") &#125;&#125;class MyRedisMapper() extends RedisMapper[SensorReading]&#123; // 定义保存数据到redis的命令 override def getCommandDescription: RedisCommandDescription = &#123; // 把传感器id和温度值保存成哈希表 HSET key field value new RedisCommandDescription( RedisCommand.HSET, \"sensor_temperature\" ) &#125; // 定义保存到redis的value override def getValueFromData(t: SensorReading): String = t.temperature.toString // 定义保存到redis的key override def getKeyFromData(t: SensorReading): String = t.id&#125; ES1234567891011&lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-elasticsearch6_2.11&lt;/artifactId&gt; &lt;version&gt;1.7.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.3&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import org.apache.flink.api.common.functions.RuntimeContextimport org.apache.flink.streaming.api.scala._import org.apache.flink.streaming.connectors.elasticsearch.&#123;ElasticsearchSinkFunction, RequestIndexer&#125;import org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSinkimport org.apache.http.HttpHostimport org.elasticsearch.client.Requestsimport java.utilobject EsSinkTest &#123; def main(args: Array[String]): Unit = &#123; val env = StreamExecutionEnvironment.getExecutionEnvironment env.setParallelism(1) // source val inputStream = env.readTextFile(\"D:\\\\Projects\\\\BigData\\\\FlinkTutorial\\\\src\\\\main\\\\resources\\\\sensor.txt\") // transform val dataStream = inputStream .map( data =&gt; &#123; val dataArray = data.split(\",\") SensorReading( dataArray(0).trim, dataArray(1).trim.toLong, dataArray(2).trim.toDouble ) &#125; ) val httpHosts = new util.ArrayList[HttpHost]() httpHosts.add(new HttpHost(\"localhost\", 9200)) // 创建一个esSink 的builder val esSinkBuilder = new ElasticsearchSink.Builder[SensorReading]( httpHosts, new ElasticsearchSinkFunction[SensorReading] &#123; override def process(element: SensorReading, ctx: RuntimeContext, indexer: RequestIndexer): Unit = &#123; println(\"saving data: \" + element) // 包装成一个Map或者JsonObject val json = new util.HashMap[String, String]() json.put(\"sensor_id\", element.id) json.put(\"temperature\", element.temperature.toString) json.put(\"ts\", element.timestamp.toString) // 创建index request，准备发送数据 val indexRequest = Requests.indexRequest() .index(\"sensor\") .`type`(\"readingdata\") .source(json) // 利用index发送请求，写入数据 indexer.add(indexRequest) println(\"data saved.\") &#125; &#125; ) // sink dataStream.addSink( esSinkBuilder.build() ) env.execute(\"es sink test\") &#125;&#125; JDBC12345&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.44&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import java.sql.&#123;Connection, DriverManager, PreparedStatement&#125;import org.apache.flink.configuration.Configurationimport org.apache.flink.streaming.api.functions.sink.&#123;RichSinkFunction, SinkFunction&#125;import org.apache.flink.streaming.api.scala._object JdbcSinkTest &#123; def main(args: Array[String]): Unit = &#123; val env = StreamExecutionEnvironment.getExecutionEnvironment env.setParallelism(1) // source val inputStream = env.readTextFile(\"D:\\\\Projects\\\\BigData\\\\FlinkTutorial\\\\src\\\\main\\\\resources\\\\sensor.txt\") // transform val dataStream = inputStream .map( data =&gt; &#123; val dataArray = data.split(\",\") SensorReading(dataArray(0).trim, dataArray(1).trim.toLong, dataArray(2).trim.toDouble) &#125; ) // sink dataStream.addSink(new MyJdbcSink()) env.execute(\"jdbc sink test\") &#125;&#125;class MyJdbcSink() extends RichSinkFunction[SensorReading] &#123; // 定义sql连接、预编译器 var conn: Connection = _ var insertStmt: PreparedStatement = _ var updateStmt: PreparedStatement = _ // 初始化，创建连接和预编译语句 override def open(parameters: Configuration): Unit = &#123; super.open(parameters) conn = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/test\", \"root\", \"123456\") insertStmt = conn.prepareStatement(\"INSERT INTO temperatures (sensor, temp) VALUES (?,?)\") updateStmt = conn.prepareStatement(\"UPDATE temperatures SET temp = ? WHERE sensor = ?\") &#125; // 调用连接，执行sql override def invoke(value: SensorReading, context: SinkFunction.Context[_]): Unit = &#123; // 执行更新语句 updateStmt.setDouble(1, value.temperature) updateStmt.setString(2, value.id) updateStmt.execute() // 如果update没有查到数据，那么执行插入语句 if (updateStmt.getUpdateCount == 0) &#123; insertStmt.setString(1, value.id) insertStmt.setDouble(2, value.temperature) insertStmt.execute() &#125; &#125; // 关闭时做清理工作 override def close(): Unit = &#123; insertStmt.close() updateStmt.close() conn.close() &#125;&#125; Window API简述概念窗口API。流是无界的，窗口时有界的。哦那个窗口截取流。获得有界流。 窗口就是将无限流切割为有限流的一种方式，它会将流数据分发到有限大小的桶(bucket)当中 类型 时间窗口 滚动时间窗口 滑动时间窗口 会话窗口 计数窗口 滚动计数窗口 滑动计数窗口 滚动窗口：依据窗口长度对数据进行切分。没有重叠，前后对齐 滑动窗口：长度固定，有重叠部分 会话窗口：由一系列事件组合一个指定时间长度的timeout间隙组成，类似于web应用的session，也就是一段时间没有接收到新数据就会生成新的窗口。 会话窗口，就是数据流如果超过一段时间，就会隔断 API窗口分配器——window()方法 window方法只能用于keyedStream。 Flink提供了简捷的timewindow和countwindow方法，用于定义时间窗口和计数窗口 窗口分配器 window方法接收一个WindowAssigner WindowAssigner负责将每条输入的数据分发到window中 Flink提供了通用的WindowAssigner 滚动窗口 滑动窗口 会话窗口 全局窗口：所有数据放一个窗口 全局窗口一般是自定义的时候使用。 创建窗口 滚动时间窗口：.timeWindow(Time.seconds(15)) 滑动时间窗口：.timeWindow(Time.seconds(15),Time.seconds(5)) 会话窗口：window(EventTimeSessionWindows.withGap(Time.minutes(10))) 滚动计数窗口：countWindow(5) 滑动计数窗口：.countWindow(10,2) 窗口函数窗口函数定义了对窗口内的数据做的操作 增量聚合函数 每条数据到来就进行计算，保持一个简单的状态 ReduceFunction,AggregateFunction(聚合函数) 增量就是，在窗口内像流一样，来一条收一条 全窗口函数 先把窗口所有数据收集起来，等到计算的时候会遍历所有数据。能做的事情相较于增量聚合更多 ProcessWindowFunction：会回到dataStream 其他可选API .trigger()——触发器：定义window什么时候关闭，触发计算并输出结果 .evitor()——移除器：定义移除某些数据的逻辑，可选移除时间 .allowedLatenss()——允许处理迟到的数据：窗口关闭后，延迟的数据。默认不允许 .sideOutputLateData()——将迟到的数据放入侧输出流： .getSideOutput()——获得侧输出流 时间语义和watermark时间语义 Event Time：事件创建的时间 Ingestion Time：数据进入Flink的事件 Processing Time：执行操作算子的本地系统事件，与机器相关 在代码中设置Event TIme在代码中，对执行环境调用.setStreamTimeCharacteristic方法，设置流时间特性，具体的时间需要从数据中提取时间戳，Flink无法自动提取 123val env = StreamExecutionEnvironment.getExecutionEnvironment//从调用时刻开始给env创建的每个stream追加时间特征env.setStreamTimeCharacteristic(TimeCharacteristic.EvenTime) 水位线(watermark)时一直衡量Event Time进展的机制，可以设置延迟触发。 watermark用来处理乱序时间，一般解和window实现。 数据流中watermark用于表示timestamp小雨water mark的数据都已经到达。 所以window的执行由watermark触发 watermark用来让程序自己平衡延迟和结果准确性 特点 watermark是一条特殊的数据记录。 watermark必须单调递增，来确保任务的事件时间时钟在向前推进 watermark与数据的时间戳相关 每个时间窗口，内部都有事件时间的时钟。由watermark推进时钟 一个分区对应一个分区watermark task的watermark以最小的分区watermark为准 向下游广播已接受的有序的数据 watermark的引入指定数据源中的时间戳和延时 12345678910dataStream.assignTimestampsAndWatermarks(//数据流的泛型 new BoundedOutOfOrdernessTimestampExtractor[String] //延迟时间 (Time.milliseconds(1000)) &#123; override def extractTimestamp(t: String): Long = &#123; //指定数据流的时间戳 t.toInt*100 &#125; &#125;) 只指定时间戳dataStream.assignAscendingTimestamps(_.timestamp*1000) 也可以自定义类传入dataStream.assignTimestampsAndWatermarks(new MyAssigner()) Flink提供了俩种类型，这俩种都继承TimestampAssigner AssignerWithPeriodicWatermarks 周期性生产watermark；系统会周期性将watermark插入流中（Processing Time） 默认周期200mm，可以使用ExecutionConfig.setAutoWatermarkInterval()进行设置 升序和前面乱序的处理BoundedOutOfOrderness，都是基于周期性watermark的 AssignerWithPunctuatedWatermarks 没有时间周期。可以打断生成 watermark设定watermark由应用程序开发人员生成 延迟设久了，收到结果的速度就很慢，解决办法就是在水位线到达之前输出近似值 watermark设短了，看你会收到错误结果，就要设置延迟处理 123456789101112131415//周期性生成class PeriodicAssigner extends AssignerWithPeriodicWatermarks[SensorReading] &#123; val bound: Long = 60 * 1000 var maxTs: Long = Long.MinValue //周个周期会获取这个方法 override def getCurrentWatermark: Watermark = &#123; //当前最大时间戳减去延迟 new Watermark(maxTs - bound) &#125; //抽取时间戳 override def extractTimestamp(t: SensorReading, l: Long): Long = &#123; maxTs = maxTs.max(t.timestamp) t.timestamp &#125;&#125; 12345678910111213141516//断点class PunctuatedAssigner extends AssignerWithPunctuatedWatermarks[SensorReading]&#123; val bound:Long=60*1000 override def checkAndGetNextWatermark(t: SensorReading, l: Long): Watermark = &#123; //可以通过指定条件触发watermanrk if(t.id==\"sensor_1\")&#123; new Watermark(l-bound) &#125;else&#123; null &#125; &#125; override def extractTimestamp(t: SensorReading, l: Long): Long = &#123; t.timestamp &#125;&#125; 没设置时间戳默认为Processing Time 12345678910111213141516171819202122232425//Processing Time//周期10秒，选出10秒内最小的object Test &#123; def main(args: Array[String]): Unit = &#123; val env = StreamExecutionEnvironment.getExecutionEnvironment env.setParallelism(1) // 设置事件时间 val inputStream = env.socketTextStream(\"192.168.5.102\", 7777) val dataStream: DataStream[SensorReading] = inputStream.map(data =&gt; &#123; val dataArray = data.split(\",\") //case class SensorReading( id: String, timestamp: Long, temperature: Double ) SensorReading(dataArray(0).trim, dataArray(1).trim.toLong, dataArray(2).trim.toDouble) &#125; ) //dataStream.map(data =&gt; (data.id, data.timestamp)).print val minTimeStream: DataStream[(String, Long)] = dataStream.map(data =&gt; (data.id, data.timestamp)) .keyBy(_._1).timeWindow(Time.seconds(10)) .reduce((data1, data2) =&gt; (data1._1, math.min(data2._2, data1._2))) minTimeStream.print() env.execute(\"window api test\") &#125;&#125; timeWindow(Time.seconds(10), Time.seconds(3))意思是滑动窗口15秒大，每3秒滑动一次 窗口：包含开始没包含结束 12345678910111213141516171819202122232425262728293031323334//Event time//滑动窗口大小10，每4秒滑动一次object Test &#123; def main(args: Array[String]): Unit = &#123; val env = StreamExecutionEnvironment.getExecutionEnvironment env.setParallelism(1) // 设置事件时间 env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime) //设置周期性时间 env.getConfig.setAutoWatermarkInterval(300) // 设置事件时间 val inputStream = env.socketTextStream(\"192.168.5.102\", 7777) val valueStream: DataStream[SensorReading] = inputStream.map(data =&gt; &#123; val dataArray = data.split(\",\") //case class SensorReading( id: String, timestamp: Long, temperature: Double ) SensorReading(dataArray(0).trim, dataArray(1).trim.toLong, dataArray(2).trim.toDouble) &#125; ) val dataStream: DataStream[SensorReading] = valueStream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor[SensorReading](Time.seconds(1)) &#123; override def extractTimestamp(t: SensorReading): Long = t.timestamp * 1000L &#125;) //dataStream.map(data =&gt; (data.id, data.timestamp)).print val minTimeStream: DataStream[(String, Long)] = dataStream.map(data =&gt; (data.id, data.timestamp)) .keyBy(_._1).timeWindow(Time.seconds(10), Time.seconds(4)) .reduce((data1, data2) =&gt; (data1._1, math.min(data2._2, data1._2))) minTimeStream.print() env.execute(\"window api test\") &#125;&#125; .timeWindow(SlidingEventTimeWindows.of(Time.seconds(15),Time.seconds(5),Time.hours(-8)))可以通过该方法指定时间偏移量（时差） ProcessFunction API(底层)先前的转化算子无法访问事件的时间戳信息和水位线信息。 ProcessFunction API可以访问时间戳、watermark以及注册定时事件。还能输出特定一些事件。 共8个ProcessFunction： ProcessFunction KeyedProcessFunction CoProcessFunction ProcessJoinFunction BroadcastProcessFunction KeyedBroadcastProcessFunction ProcessWindowFunction ProcessAllWindowFunction 所有ProcessFunction都基础了RichFunction接口，所以都有open，close，getRuntimeContext()等方法 KeyedProcessFunction(重点)用来操作KeyedStream。KeyedProcessFunction会处理流中的每个元素，输出0以上的元素。 KeyedProcessFunction&lt;K, I, O&gt;的俩个方法 processElement(I value, Context ctx, Collector&lt;O&gt; out)：处理每个数据都会调用该方法，I为输入数据，out为输出，ctx为上下文 onTimer(long timestamp, OnTimerContext ctx, Collector&lt;O&gt; out)：回调函数。定时器触发时的操作。timestamp为定时器所设定的触发时间戳。out为输出。ctx为上下文 1234567891011121314151617181920212223242526272829303132333435//实现温度连续上升一秒后报警//泛型为key，输入，输出class TempIncreAlert() extends KeyedProcessFunction[String, SensorReading, String]&#123; // 定义一个状态，用来保存上一个数据的温度值 lazy val lastTemp: ValueState[Double] = getRuntimeContext.getState( new ValueStateDescriptor[Double](\"lastTemp\", classOf[Double]) ) // 定义一个状态，用来保存定时器的时间戳 lazy val currentTimer: ValueState[Long] = getRuntimeContext.getState( new ValueStateDescriptor[Long](\"currentTimer\", classOf[Long]) ) override def processElement(value: SensorReading, ctx: KeyedProcessFunction[String, SensorReading, String]#Context, out: Collector[String]): Unit = &#123; // 先取出上一个温度值 val preTemp = lastTemp.value() // 更新温度值 lastTemp.update( value.temperature ) val curTimerTs = currentTimer.value() if( value.temperature &lt; preTemp || preTemp == 0.0 )&#123; // 如果温度下降，或是第一条数据，删除定时器并清空状态 ctx.timerService().deleteProcessingTimeTimer( curTimerTs ) currentTimer.clear() &#125; else if ( value.temperature &gt; preTemp &amp;&amp; curTimerTs == 0 )&#123; // 温度上升且没有设过定时器，则注册定时器，定时器为onTimer内的内容 val timerTs = ctx.timerService().currentProcessingTime() + 5000L ctx.timerService().registerProcessingTimeTimer( timerTs ) currentTimer.update( timerTs ) &#125; &#125; override def onTimer(timestamp: Long, ctx: KeyedProcessFunction[String, SensorReading, String]#OnTimerContext, out: Collector[String]): Unit = &#123; // 输出报警信息 out.collect( ctx.getCurrentKey + \" 温度连续上升\" ) currentTimer.clear() &#125;&#125; TimerService和定时器context和OnTimerContext所有的TimerService对象有这些方法 currentProcessingTime();：返回当前处理时间 currentWatermark();：返回当前watermark的时间戳 registerProcessingTimeTimer(long time);：注册当前key的Processing Time定时器，当到达时间时，触发timer registerEventTimeTimer(long time);：注册当前key的event time定时器。当水位线大于等于定时器注册时间时，会触发 deleteProcessingTimeTimer(long time);：删除之前处理eventime的定时器，如果没有对应定时器则不执行 deleteEventTimeTimer(long time);：删除之前处理Processing Time的定时器，如果没有对应定时器则不执行 Emitting toSide Outputs(侧输出)split其实已经被弃用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546//冰点报警，如果小于32F，输出报警信息到侧输出流，import org.apache.flink.streaming.api.TimeCharacteristicimport org.apache.flink.streaming.api.functions.ProcessFunctionimport org.apache.flink.streaming.api.functions.timestamps.BoundedOutOfOrdernessTimestampExtractorimport org.apache.flink.streaming.api.scala._import org.apache.flink.streaming.api.windowing.time.Timeimport org.apache.flink.util.Collectorobject SideOutputTest &#123; def main(args: Array[String]): Unit = &#123; val env = StreamExecutionEnvironment.getExecutionEnvironment env.setParallelism(1) env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime) val stream = env.socketTextStream(\"localhost\", 7777) val dataStream = stream.map(data =&gt; &#123; val dataArray = data.split(\",\") SensorReading(dataArray(0).trim, dataArray(1).trim.toLong, dataArray(2).trim.toDouble) &#125;) .assignTimestampsAndWatermarks( new BoundedOutOfOrdernessTimestampExtractor[SensorReading]( Time.seconds(1) ) &#123; override def extractTimestamp(element: SensorReading): Long = element.timestamp * 1000 &#125; ) val processedStream = dataStream .process( new FreezingAlert() ) processedStream.print(\"processed data\") //获取对应的侧输出流，打印 processedStream.getSideOutput( new OutputTag[String](\"freezing alert\") ).print(\"alert data\") env.execute(\"side output test\") &#125;&#125;//泛型：输入，主输出class FreezingAlert() extends ProcessFunction[SensorReading, SensorReading]&#123;// lazy val alertOutput: OutputTag[String] = new OutputTag[String]( \"freezing alert\" ) override def processElement(value: SensorReading, ctx: ProcessFunction[SensorReading, SensorReading]#Context, out: Collector[SensorReading]): Unit = &#123; if( value.temperature &lt; 32.0 )&#123;//定义侧输出流 ctx.output( new OutputTag[String]( \"freezing alert\" ), \"freezing alert for \" + value.id ) &#125; out.collect( value ) &#125;&#125; CoProcessFunction俩个流，连接在一起。需要提供俩个处理方法，分别对流进行处理 状态管理状态：其实就是数据，在处理数据的时候。可能需要依赖，之前的数据中的属性。所有需要保存下来，这就是状态。可以认为是一个本地变量 Flink会统一管理状态。如状态的一致性、故障处理和高效存储 Flink中的状态Flink中的状态与特定算子相关联 状态使用前要预先注册 共有俩种类型的状态： 算子状态 算子状态的作用范围限定为算子任务。一个任务一个状态 键控状态 根据数据定义的key，状态的维护，对应key维护和访问，不同的key有不同的状态。 算子状态同一并行子任务认为一个状态，同一并行任务的所有数据可以访问到相同的状态。 状态在同一任务是共享，对不同任务是隔离的包括同一算子不同子任务 算子状态数据结构 列表状态 状态为一组数据的列表 联合列表状态 与列表状态区别为，在发生故障时，或者从保持点启动程序时如何恢复 列表会根据并行度的调整，重新调整分配。联合列表会将每个状态广播到对应算子 广播状态 一个算子多个子任务的任务状态相同，使用广播状态 实际应用中这些状态用的都不多,用的更多的是none keyed state.没有用键控制的状态.更常见是用keyby后的状态 键控状态一个key会维护自己的状态,不同key访问自己对应的状态. 每条数据,会自动将状态的访问范围限定为当前的key 键控状态数据结构 值状态 将状态表示为单个的值 列表状态 一组数据的列表 映射状态 状态表示为k-v的类型 聚合状态(Reducing state &amp; Aggregating State) 状态表示为用于聚合创作的列表,每个数据进入,都会被操作 Reducing:内部相当于reduce操作,输出和输入类型同样,不可变 Aggregating:一般的操作.数据类型可不一样 不同数据类型的操作时不同的.具体查看对应文档 简单使用123456//声明一个键控状态.传入相应的名称和类lazy val lastTemp: ValueState[Double] = getRuntimeContext.getState( new ValueStateDescriptor[Double](\"lastTemp\", classOf[Double]) )//更新数据lastTemp.update( timerTs )//获取值val lastTemp = lastTemp.value() 状态后端 管理状态的可插入的组件叫状态后端。是用来管理状态的存储、维护和访问。 主要负责：本地的状态管理、以及将检查点状态写入远程存储 有效的状态访问对于数据的低延迟至关重要，因此每个并行任务都会在本地维护其状态。 选择一个状态后端 MemoryStateBackend 内存级的状态后端，会将键控状态作为对象在内存中管理。将它们存储到TaskManager的JVM堆上，而checkpoint存储在JobManager内存中 快速、低延迟、不稳定。生产环境一般不会使用 FsStateBackend 将checkpoint存到远程的持久化文件系统上，本地状态和MemoryStateBackend一样。 本地拥有内存级的访问。高容错性。 远程存储checkpoint，对性能影响不大 RocksDBStateBackend 将状态序列化存储到本地RocksDB上 状态过大，可能导致oom。就使用该状态后端 使用RocksDBStateBackend需要引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-statebackend-rocksdb_2.11&lt;/artifactId&gt; &lt;version&gt;1.7.2&lt;/version&gt;&lt;/dependency&gt; 1234//使用状态管理env.setStateBackend(new RocksDBStateBackend(\"路径\"))//开启checkpoint，传入存储间隔时间env.enableCheckpointing(1) 状态编程在代码中管理状态 12345678910111213141516171819202122//传入一个阈值，当温度差超过阈值则输出报警。把new出的对象传入flatMapclass TempChangeAlert(threshold: Double) extends RichFlatMapFunction[SensorReading, (String, Double, Double)] &#123; private var lastTempState: ValueState[Double] = _ override def open(parameters: Configuration): Unit = &#123; // 初始化的时候声明state变量 lastTempState = getRuntimeContext.getState(new ValueStateDescriptor[Double](\"lastTemp\", classOf[Double])) &#125; override def flatMap(value: SensorReading, out: Collector[(String, Double, Double)]): Unit = &#123; // 获取上次的温度值 val lastTemp = lastTempState.value() // 用当前的温度值和上次的求差，如果大于阈值，输出报警信息 val diff = (value. -temperature lastTemp).abs if (diff &gt; threshold) &#123; out.collect((value.id, lastTemp, value.temperature)) &#125; lastTempState.update(value.temperature) &#125;&#125; flatMapWithState方法。reduce这类方法没有withState，是因为这类方法本身是有状态的 1234567891011121314//用flatMapWithState实现需求。val processedStream3 = dataStream.keyBy(_.id)//第一个泛型为输出，第二个为状态 .flatMapWithState[(String, Double, Double), Double]&#123; // 如果没有状态的话，也就是没有数据来过，那么就将当前数据温度值存入状态 case ( input: SensorReading, None ) =&gt; ( List.empty, Some(input.temperature) ) // 如果有状态，就应该与上次的温度值比较差值，如果大于阈值就输出报警 case ( input: SensorReading, lastTemp: Some[Double] ) =&gt; val diff = ( input.temperature - lastTemp.get ).abs if( diff &gt; 10.0 )&#123;//返回一个TraversableOnce[R]的输出数据集。 ( List((input.id, lastTemp.get, input.temperature)), Some(input.temperature) ) &#125; else ( List.empty, Some(input.temperature) ) &#125; 容错机制一致性检查点 有状态流应用的检查点，就是所有任务在某个时间点的快照备份。这个时间点，应该是所有任务都恰好处理完一个相同的输入数据的时候 Flink故障恢复机制的核心，就是检查点 让数据流动流动到刚好处理完某一个数据的时候，这时候保存快照 会保存的数据的偏移量 检查点恢复 在执行流应用程序期间，Flink会定期保存状态的一致性检查点 如果发生故障，Flink将会使用最近的检查点来一致恢复应用程序的状态，并重新启动处理流程（重启处理流程，可以由我们在代码中或配置文件中配置） 这种检查点机制，保证了应用程序状态“精确一次”的一致性。所有算子都会保存检查点并恢复所有状态，这样所有的输入流会被重置到检查点完成时 精确一次就是数据保证不丢失，只处理一次。这里的精确一次是内部的精确一次。无法保证外部精确一次。 检查点实现算法和分界线 简单的实现 暂停所有应用，保存状态到检查点，再重新恢复 性能损耗过大 Flink的实现 改进基于Chandy-Lamport算法的分布式快照 将检查点的保存和数据处理分离开，不暂停整个应用。只短暂暂停对应的应用 检查点分界线 Flink的检查点算法通过分界线，将一条流上数据按照不同的检查点分开 分界线是一种特殊数据形式 分界线之前到来的数据导致的状态更改，都会保存到当前分界线所属的检查点中。分界线后的数据更改，会保存到之后的检查点 检查点流程 该图共分为：输入、根据奇偶重排，分别计算奇数和偶数和、输出 有俩个流并行运作 JobManager向每个source任务发送带有新检查点ID的消息，通过这种方式，启动检查点 收到检查点，任务会停止然后数据源会将它们的状态写入检查点，并会发出检查点barrier， 在存入检查点之后，会返回通知给source任务，source任务会向JobManager确认检查点完成 barrier会向下游传递，sum任务会等待所有输入分区的barrier到达，比如黄色检查点到达后，黄色的数据再来就会被存入缓存。还未到达的检查点的分区数据会继续处理 所有输入分区的barrier都到达后，任务就将状态保存到转台后端的检查点。然后将barrier向下发送 发送后，任务继续正常处理 Sink任务向JobManager确认状态保存到checkpoint完毕。 当所有任务都确认成功保存，检查点建立完毕 保存点原理和算法几乎和检查点一样。用法不同 Flink不会自动创建保持点，需要用户指定触发创建。 保持点，除了故障恢复外，可用于：手动备份，更新升级应用程序，版本迁移，测试，展厅和重启应用，也可以升级Flink版本，暂停不重要Flink程序释放资源等等 检查点配置12345678910111213141516171819//检查点间隔env.enableCheckpointing(60000)//默认EXACTLY_ONCE，可以改成至少一次env.getCheckpointConfig.setCheckpointingMode(CheckpointingMode.AT_LEAST_ONCE)//超时时间，超过就丢弃checkpointenv.getCheckpointConfig.setCheckpointTimeout(100000)//checkpoint失败，是否整个任务失败，默认是true。env.getCheckpointConfig.setFailOnCheckpointingErrors(false)//最大同时的checkpoint的数量，默认为1env.getCheckpointConfig.setMaxConcurrentCheckpoints(1)//俩次checkpoint最小时间间隔，如果设置了间隔，最大同时数就只能为1env.getCheckpointConfig.setMinPauseBetweenCheckpoints(100)//开启checkpoint外部持久化。如果不设置，job失败后checkpoint会清理掉checkpoint的持久化。// DELETE_ON_CANCELLATION:手动取消就不要存,RETAIN_ON_CANCELLATION：即使手动取消也要存env.getCheckpointConfig.enableExternalizedCheckpoints(ExternalizedCheckpointCleanup.DELETE_ON_CANCELLATION)//重启策略，//fixedDelayRestart：尝试次数、尝试间隔时间// failureRateRestart：失败率最大尝试次数在失败尝试时间内、失败尝试时间、尝试间隔env.setRestartStrategy(RestartStrategies.failureRateRestart(3, org.apache.flink.api.common.time.Time.seconds(300), org.apache.flink.api.common.time.Time.seconds(10))) 状态一致性无论是断电、短路、宕机等等，最后结果都要准确 一条数据不应该丢失，也不能重复计算 遇到故障可以恢复，恢复后重新计算结果也是正确 状态一致性的类别 AT-MOST-ONCE（最多一次） 当任务故障时，啥事都不干，既不恢复丢失的状态，也不重播丢失的数据。 AT-LEAST-ONCE（至少一次） 所有事件都得到处理，可能会被处理多次 EXACTLY-ONCE（精确一次） 恰好处理一次，保证不丢失 一致性检查点是Flink数据一致性的的保证 端到端状态一致性在生产环境中，需要保证数据源、流处理器和输出到持久化系统的数据一致性。 整个端到端的数据一致性取决于所有组件最弱的一个组件 端到端exactly-once 内部保证—checkpoint source端—可重设数据的读取位置 sink端—从故障恢复时，数据不会重复写入外部系统 幂等写入 事物写入 幂等写入(Idempotent Writes)幂等操作，就是一个操作执行多次和执行一次的结果是一致的 幂等写入无法做到，真正意义上的精确一次 事务写入所有做错必须同时成功或者同时失败 实现思想：构建的事物对应着checkpoint，等到checkpoint完成的时候，才将结果写入sink 实现方式 预写日志 两阶段提交 预写日志(WAL) 把结果数据先当初状态保持，在收到checkpoint完成通知后，一次性写入sink DataStream API提供了模板类：GenericWriteAheadSink来实现这种事务性sink 可能会出现最后一次性写入，出现故障。再重写可能会导致数据重复 两阶段提交(2pc) 对于每个checkpoint，sink任务都会启动事物，然后将数据添加到事务中 然后将数据写到外部sink系统，但不提交，只是”预提交” 等他收到checkpoint完成通知时，才正式提交事务，真正写入 实现了exactly-one，但是需要一个提供事务支持的外部sink系统。Flink提供了TwoPhaseCommitSinkFunction接口 2pc对外部sink系统的要求 外部sink系统必须提供事务支持，或sink任务必须能够模拟外部系统上的事务 在checkpoint间隔间内，必须能够开启一个事务接收数据写入 在收到checkpoint完成通知之前，事务必须是”等待提交”的出台。如果超时，未提交数据会丢失 sink任务能在进程失败后恢复事务 提交事务必须是幂等操作 Flink+Kafka端到端状态一致性 source：kafka consumer作为source，可以将偏移量保留，如果后续任务出故障，恢复可以由连接器重置偏移量，重新消费 transform：checkpoint机制 sink：kafka producer作为sink，采用两阶段提交sink，实现一个TwoPhaseCommitSinkFunction 提交步骤 第一条数据来了就开启了kafka的一个事务，正常写入kafka分区日志，但标记未提交 jobmanager触发checkpoint操作，barrier从source开始向下传递，遇到barrier的算子将状态存入状态后端，并通知jobmanager sink连接器收到barrier，保存当前状态，存入checkpoint，通知jobmanager，并开启下一段事务 jobmanager收到所有任务的通知，发出确认信息，表示checkpoint完成 sink任务收到jobmanager的确认信息，表示checkpoint完成 kafka关闭事务，已提交的数据可以正常消费 flink的sink超时时间默认为1小时 kafka的事件默认超时时间15分钟 Table APITable API是流处理和批处理通用的关系型API，Table API可以基于流输入或者批输入来运行而不需要进行任何修改。Table API是SQL语言的超集并专门为Apache Flink设计的，Table API是Scala 和Java语言集成式的API。与常规SQL语言中将查询指定为字符串不同，Table API查询是以Java或Scala中的语言嵌入样式来定义的，具有IDE支持如:自动完成和语法检测。 快速使用pom 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-table_2.11&lt;/artifactId&gt; &lt;version&gt;1.7.2&lt;/version&gt;&lt;/dependency&gt; 样例 1234567891011121314151617181920def main(args: Array[String]): Unit = &#123; def main(args: Array[String]): Unit = &#123; val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment val myKafkaConsumer: FlinkKafkaConsumer011[String] = MyKafkaUtil.getConsumer(\"ECOMMERCE\") val dstream: DataStream[String] = env.addSource(myKafkaConsumer) val tableEnv: StreamTableEnvironment = TableEnvironment.getTableEnvironment(env) val startupLogDstream: DataStream[StartupLog] = dstream.map&#123; jsonString =&gt;JSON.parseObject(jsonString,classOf[StartupLog]) &#125; //从dataStream读取一张表 val startupLogTable: Table = tableEnv.fromDataStream(startupLogDstream) val table: Table = startupLogTable.select(\"mid,ch\").filter(\"ch ='appstore'\") //dataStream转化为流 val midchDataStream: DataStream[(String, String)] = table.toAppendStream[(String,String)] midchDataStream.print() env.execute() &#125; 动态表如果流中的数据类型是case classk可以总结根据case class的结构生成table tableEnv.fromDataStream(ecommerceLogDstream) 或者根据字段顺序单独命名tableEnv.fromDataStream(ecommerceLogDstream,&#39;mid&#39;,&#39;name&#39;,……) 动态表可以转化为流 table.toAppendStream[(String,String)] 传入的字段名为单引号，Append模式只能用insert 12345678910111213141516171819202122232425262728293031323334353637383940414243//每10秒中渠道为appstore的个数def main(args: Array[String]): Unit = &#123; //sparkcontext val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment //时间特性改为eventTime env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime) val myKafkaConsumer: FlinkKafkaConsumer011[String] = MyKafkaUtil.getConsumer(\"GMALL_STARTUP\") val dstream: DataStream[String] = env.addSource(myKafkaConsumer) val startupLogDstream: DataStream[StartupLog] = dstream.map&#123; jsonString =&gt;JSON.parseObject(jsonString,classOf[StartupLog]) &#125; //告知watermark 和 eventTime如何提取 val startupLogWithEventTimeDStream: DataStream[StartupLog] = startupLogDstream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor[StartupLog](Time.seconds(0L)) &#123; override def extractTimestamp(element: StartupLog): Long = &#123; element.ts &#125; &#125;).setParallelism(1) //SparkSession val tableEnv: StreamTableEnvironment = TableEnvironment.getTableEnvironment(env) //把数据流转化成Table //时间使用eventtime要用.rowtime //如果为Processing Time，就要自己指定字段.proctime val startupTable: Table = tableEnv.fromDataStream(startupLogWithEventTimeDStream , 'mid,'uid,'appid,'area,'os,'ch,'logType,'vs,'logDate,'logHour,'logHourMinute,'ts.rowtime) //通过table api 进行操作 // 每10秒 统计一次各个渠道的个数 table api 解决 //1 groupby 2 要用 window 3 用eventtime来确定开窗时间 val resultTable: Table = startupTable.window(Tumble over 10000.millis on 'ts as 'tt).groupBy('ch,'tt ).select( 'ch, 'ch.count) //把Table转化成数据流 //val appstoreDStream: DataStream[(String, String, Long)] = appstoreTable.toAppendStream[(String,String,Long)] val resultDstream: DataStream[(Boolean, (String, Long))] = resultSQLTable.toRetractStream[(String,Long)] resultDstream.filter(_._1).print() env.execute()&#125; 其他1234567//窗口函数，preAggregator做聚合运算。windowFunction做结果输出//传入的俩个函数，可以继承自定义def aggregate[ACC: TypeInformation, V: TypeInformation, R: TypeInformation]( //IN：输入，OUT：输出，ACC累加器(中间的聚合状态) preAggregator: AggregateFunction[IN, ACC, OUT], //IN：输入(这里的输入一般是聚合函数的输出)，OUT：输出，KEY：key的类型*(具体按照keyby返回的类型)，W：当前window类型 windowFunction: WindowFunction[IN, OUT, KEY, W &lt;: Window]): DataStream[R]","categories":[],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://example.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Flink","slug":"Flink","permalink":"http://example.com/tags/Flink/"}]},{"title":"ElasticSearch笔记","slug":"ElasticSearch笔记","date":"2019-11-10T06:27:38.000Z","updated":"2021-07-08T07:54:58.777Z","comments":true,"path":"2019/11/10/ElasticSearch笔记/","link":"","permalink":"http://example.com/2019/11/10/ElasticSearch%E7%AC%94%E8%AE%B0/","excerpt":"","text":"es简介Elasticsearch是一个基于Apache Lucene(TM)的开源搜索引擎 github 概述特点 分布式的实时文件存储，每个字段都被索引并可被搜索 分布式的实时分析搜索引擎–做不规则查询 可以扩展到上百台服务器，处理PB级结构化或非结构化数据 用处全文检索（全部字段）、模糊查询（搜索）、数据分析（提供分析语法，例如聚合） 同类比较Solr、ElasticSearch、Hermes（腾讯）（实时检索分析） Solr、ES：侧重搜索与全文检索。数据规模从几百万到千万不等，数据量过亿的集群特别少 Hermes：侧重数据分析。数据规模从几亿到万亿不等。最小的表也是千万级别。 Solr、ES区别： Solr 利用 Zookeeper 进行分布式管理，而 Elasticsearch 自身带有分布式协调管理功能; Solr 支持更多格式的数据，而 Elasticsearch 仅支持json文件格式； Solr 官方提供的功能更多，而 Elasticsearch 本身更注重于核心功能，高级功能多有第三方插件提供； Solr 在传统的搜索应用中表现好于 Elasticsearch，但在处理实时搜索应用时效率明显低于 Elasticsearch—–附近的人 es、ki安装准备环境安装Centos7、建议内存2G以上、安装java1.8环境 Centos6需要改动的配置较多 正式安装 拷贝并解压 elasticsearch-6.6.0.tar.gz kibana-6.6.0-linux-x86_64.tar.gz 修改配置文件 vim /bigdata/elasticsearch-6.6.0/config/elasticsearch.yml 集群名称，同一集群名称必须相同 单个节点名称 ，同一集群中的节点，节点名必须不同 网络部分 改为当前的ip地址 ，端口号保持默认9200就行 把bootstrap自检程序关掉 自发现配置：新节点向集群报到的主机名 修改Linux配置 vi /etc/security/limits.conf 添加内容： 1234* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 65536 注意：“*” 不要省略掉 vi /etc/security/limits.d/90-nproc.conf （CentOS7.x 不用改） 修改如下内容： * soft nproc 1024 #修改为 * soft nproc 4096 1234- vim &#x2F;etc&#x2F;sysctl.conf文件最后添加一行（CentOS7.x 不用改） - vm.max_map_count=262144 123456789101112131415161718192021222324252627282930313233343536373839- 修改虚拟机内存，防止es跑不动 ![](ElasticSearch笔记&#x2F;esinstall6.png)#### 配置ki- 进入kibana根目录的config下- vim kibana.yml ![](ElasticSearch笔记&#x2F;kibanainstall.png)&gt; 这里我的elasticsearch.url是没有的，改成这个启动会报错。将elasticsearch.url改成elasticsearch.host即可#### 群起脚本&#96;&#96;&#96;shell#!&#x2F;bin&#x2F;bash es_home&#x3D;es的根目录kibana_home&#x3D;kib的根目录case $1 in &quot;start&quot;) &#123; for i in 集群的ip do ssh $i &quot;source &#x2F;etc&#x2F;profile;$&#123;es_home&#125;&#x2F;bin&#x2F;elasticsearch &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 &amp;&quot; done nohup $&#123;kibana_home&#125;&#x2F;bin&#x2F;kibana &gt;kibana.log 2&gt;&amp;1 &amp;&#125;;;&quot;stop&quot;) &#123; ps -ef|grep $&#123;kibana_home&#125; |grep -v grep|awk &#39;&#123;print $2&#125;&#39;|xargs kill for i in 集群的ip do ssh $i &quot;ps -ef|grep $es_home |grep -v grep|awk &#39;&#123;print \\$2&#125;&#39;|xargs kill&quot; &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 done &#125;;;esac 验证curl http://hadoop1:9200/_cat/nodes?v出现对应机器的ip即可 访问IP地址: Elasticsearch数据存储方式Elasticsearch存储方式 面向文档 Elasticsearch是面向文档(document oriented)的，这意味着它可以存储整个对象或文档(document)。然而它不仅仅是存储，还会索引(index)每个文档的内容使之可以被搜索。在Elasticsearch中，你可以对文档（而非成行成列的数据）进行索引、搜索、排序、过滤。这种理解数据的方式与以往完全不同，这也是Elasticsearch能够执行复杂的全文搜索的原因之一。 JSON ELasticsearch使用Javascript对象符号(JavaScript Object Notation)，也就是JSON，作为文档序列化格式。JSON现在已经被大多语言所支持，而且已经成为NoSQL领域的标准格式。它简洁、简单且容易阅读。 Elasticsearch存储结构 6.x一个index只有一个type 索引创建索引库settings和index是固定的 number_of_shards：分片数 number_of_replicas：副本数 123456789put /索引库名称&#123; \"settings\":&#123; \"index\":&#123; \"number_of_shards\":1, \"number_of_replicas\":0 &#125; &#125;&#125; 相当于一张表 创建映射文档–Row记录 字段–Columns列 post http://localhost:9200/索引库名称/类型名称/_mapping 类型在6.0开始逐渐弱化，索引指定类型名称的时候，可以取一个没有意义的名字 创建映射 12345678910111213141516POST 索引库名/类型名称/_mapping&#123; \"properties\": &#123; \"name\": &#123; \"type\": \"text\" &#125;, \"description\": &#123; \"type\": \"text\" &#125;, \"studymodel\": &#123; \"type\": \"keyword\" &#125; &#125;&#125;# 查看GET 索引库名/类型名称/[Id值] 创建文档123456POST 索引库名/类型名称/[Id值]&#123; \"字段名\": \"值\", \"字段名\": \"值\", ……&#125; 如果不指定Id值，会随机生成Id。修改既是覆盖 搜索文档12345678910111213141516#根据ID查询GET 索引库名/类型名称/[Id值]#结果&#123; \"_index\" : \"索引库名\", \"_type\" : \"类型名称\", \"_id\" : \"Id值\", \"_version\" : 1, \"_seq_no\" : 1, \"_primary_term\" : 1, \"found\" : true, \"_source\" : &#123; 内容键值对 &#125;&#125; 通过搜索接口搜索12345#查询所有GET 索引库名/类型名称/_search #查询name中包括xxx关键字的的记录，中文会报错GET 索引库名/类型名称/_search?q=name:xxx 删除文档DELETE /{index}/{type}/{id}：根据id删除 POST /{index}/{type}/_delete_by_query：通过搜索删除 IK分词器在添加文档时会进行分词，索引中存放的就是一个一个的词（term），当你去搜索时就是拿关键字去匹配词，最终找到词关联的文档。测试当前索引库使用的分词器： 1234POST _analyze&#123; \"text\":\"测试分词器，后边是测试内容：spring cloud实战\"&#125; 发现是按照一个字一个字分词 下载安装下载IK分词器，在releases下载和es版本相同的ik分词器。解压将整个文件夹放入plugins文件夹下。文件夹名可以随意。重启es 测试ik分词器 12345POST _analyze&#123; \"text\":\"测试分词器，后边是测试内容：spring cloud实战\", \"analyzer\":\"ik_max_word\"&#125; 俩种分词器ik分词器有两种分词模式：ik_max_word和ik_smart模式。 ik_max_word会将文本做最细粒度的拆分，比如会将“中华人民共和国人民大会堂”拆分为“中华人民共和国、中华人民、中华、华人、人民共和国、人民、共和国、大会堂、大会、会堂等词语。 ik_smart会做最粗粒度的拆分，比如会将“中华人民共和国人民大会堂”拆分为中华人民共和国、人民大会堂。 添加分词Ik分词器中有一些特殊词 是无法分词的，这就需要到elasticsearch-6.6.0/plugins/analysis-ik/config/IKAnalyzer.cfg.xml配置文件中指定要添加的词汇表 123456789101112&lt;!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\"&gt;&lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置自己的扩展字典 --&gt; &lt;entry key=\"ext_dict\"&gt;my.dic&lt;/entry&gt; &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt; &lt;entry key=\"ext_stopwords\"&gt;&lt;/entry&gt; &lt;!--用户可以在这里配置远程扩展字典 --&gt; &lt;!-- &lt;entry key=\"remote_ext_dict\"&gt;words_location&lt;/entry&gt; --&gt; &lt;!--用户可以在这里配置远程扩展停止词字典--&gt; &lt;!-- &lt;entry key=\"remote_ext_stopwords\"&gt;words_location&lt;/entry&gt; --&gt;&lt;/properties&gt; 然后在平级目录下创建my.dic 12xxxxx 保存格式为UTF-8 映射12345678910111213141516#查看所有映射GET _mapping#创建映射POST 索引库名/类型名称/_mapping&#123; \"properties\": &#123; \"字段名\": &#123; \"type\": \"类型\" &#125;, …… &#125;&#125;#删除DELETE 索引库名 无则添加，有则更新。不允许已添加字段名的类型 常用映射类型 text：可以指定分词器和搜索时使用的分词器 123456789\"name\": &#123; \"type\": \"text\", \"analyzer\":\"ik_max_word\", \"search_analyzer\":\"ik_smart\", #是否建立索引 \"index\":false, #是否在source之外存储，每个文档索引后会在 ES中保存一份原始文档，存放在\"_source\"中，一般情况下不需要设置 store为true，因为在_source中已经有一份原始文档了。 \"stoure\": true&#125; date类型：format设置样式 1234\"timestamp\": &#123; \"type\": \"date\", \"format\": \"yyyy‐MM‐dd HH:mm:ss||yyyy‐MM‐dd\"&#125; 数值类型：尽量选择范围小的类型，提高搜索效率 .对于浮点数尽量用比例因子 1234\"price\": &#123; \"type\": \"scaled_float\", \"scaling_factor\": 100&#125; 客户端维护索引多种客户端 TransportClient：计划8.0删除 RestClient：推荐使用包含俩种客户端 Java Low Level REST Client和 Java High Level REST Client。 两种客户端官方更推荐使用 Java High Level REST Client pom文件 12345678910&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch‐rest‐high‐level‐client&lt;/artifactId&gt; &lt;version&gt;6.2.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;6.2.1&lt;/version&gt;&lt;/dependency&gt; 123456//默认已经注入@AutowiredRestHighLevelClient client;@AutowiredRestClient restClient; 删除 索引库 123456789101112public void testDeleteIndex() throws IOException &#123; //删除索引对象 DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(\"xc_course\"); //操作索引的客户端 IndicesClient indices = client.indices(); //执行删除索引 DeleteIndexResponse delete = indices.delete(deleteIndexRequest); //得到响应 boolean acknowledged = delete.isAcknowledged(); System.out.println(acknowledged);&#125; 创建索引库 12345678910111213141516171819202122232425262728293031323334public void testCreateIndex() throws IOException &#123; //创建索引对象 CreateIndexRequest createIndexRequest = new CreateIndexRequest(\"xc_course\"); //设置参数 createIndexRequest.settings(Settings.builder().put(\"number_of_shards\", \"1\").put(\"number_of_replicas\", \"0\")); //指定映射 createIndexRequest.mapping(\"doc\", \" &#123;\\n\" + \" \\t\\\"properties\\\": &#123;\\n\" + \" \\\"studymodel\\\":&#123;\\n\" + \" \\\"type\\\":\\\"keyword\\\"\\n\" + \" &#125;,\\n\" + \" \\\"name\\\":&#123;\\n\" + \" \\\"type\\\":\\\"keyword\\\"\\n\" + \" &#125;,\\n\" + \" \\\"description\\\": &#123;\\n\" + \" \\\"type\\\": \\\"text\\\",\\n\" + \" \\\"analyzer\\\":\\\"ik_max_word\\\",\\n\" + \" \\\"search_analyzer\\\":\\\"ik_smart\\\"\\n\" + \" &#125;,\\n\" + \" \\\"pic\\\":&#123;\\n\" + \" \\\"type\\\":\\\"text\\\",\\n\" + \" \\\"index\\\":false\\n\" + \" &#125;\\n\" + \" \\t&#125;\\n\" + \"&#125;\", XContentType.JSON); //操作索引的客户端 IndicesClient indices = client.indices(); //执行创建索引库 CreateIndexResponse createIndexResponse = indices.create(createIndexRequest); //得到响应 boolean acknowledged = createIndexResponse.isAcknowledged(); System.out.println(acknowledged);&#125; 添加文档 123456789101112131415161718192021//添加文档@Testpublic void testAddDoc() throws IOException &#123; //准备json数据 Map&lt;String, Object&gt; jsonMap = new HashMap&lt;&gt;(); jsonMap.put(\"name\", \"spring cloud实战\"); jsonMap.put(\"description\", \"本课程主要从四个章节进行讲解： 1.微服务架构入门 2.spring cloud基础入门 3.实战Spring Boot 4.注册中心eureka。\"); jsonMap.put(\"studymodel\", \"201001\"); SimpleDateFormat dateFormat =new SimpleDateFormat(\"yyyy‐MM‐dd HH:mm:ss\"); jsonMap.put(\"timestamp\", dateFormat.format(new Date())); jsonMap.put(\"price\", 5.6f); //索引请求对象 IndexRequest indexRequest = new IndexRequest(\"xc_course\",\"doc\"); //指定索引文档内容 indexRequest.source(jsonMap); //索引响应对象 IndexResponse indexResponse = client.index(indexRequest); //获取响应结果 DocWriteResponse.Result result = indexResponse.getResult(); System.out.println(result);&#125; 查询文档 1234567891011@Testpublic void getDoc() throws IOException &#123; GetRequest getRequest = new GetRequest( \"xc_course\", \"doc\", \"4028e581617f945f01617f9dabc40000\"); GetResponse getResponse = client.get(getRequest); boolean exists = getResponse.isExists(); Map&lt;String, Object&gt; sourceAsMap = getResponse.getSourceAsMap(); System.out.println(sourceAsMap);&#125; 更新文档 1234567891011//更新文档@Testpublic void updateDoc() throws IOException &#123; UpdateRequest updateRequest = new UpdateRequest(\"xc_course\", \"doc\",\"4028e581617f945f01617f9dabc40000\"); Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); map.put(\"name\", \"spring cloud实战\"); updateRequest.doc(map); UpdateResponse update = client.update(updateRequest); RestStatus status = update.status(); System.out.println(status);&#125; 删除文档 12345678910111213//根据id删除文档@Testpublic void testDelDoc() throws IOException &#123; //删除文档id String id = \"eqP_amQBKsGOdwJ4fHiC\"; //删除索引请求对象 DeleteRequest deleteRequest = new DeleteRequest(\"xc_course\",\"doc\",id); //响应对象 DeleteResponse deleteResponse = client.delete(deleteRequest); //获取响应结果 DocWriteResponse.Result result = deleteResponse.getResult(); System.out.println(result);&#125; 搜索环境准备12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667PUT /xc_course&#123; \"settings\":&#123; \"index\":&#123; \"number_of_shards\":1, \"number_of_replicas\":0 &#125; &#125;&#125;POST xc_course/doc/_mapping&#123; \"properties\": &#123; \"description\": &#123; \"type\": \"text\", \"analyzer\": \"ik_max_word\", \"search_analyzer\": \"ik_smart\" &#125;, \"name\": &#123; \"type\": \"text\", \"analyzer\": \"ik_max_word\", \"search_analyzer\": \"ik_smart\" &#125;, \"pic\":&#123; \"type\":\"text\", \"index\":false &#125;, \"price\": &#123; \"type\": \"float\" &#125;, \"studymodel\": &#123; \"type\": \"keyword\" &#125;, \"timestamp\": &#123; \"type\": \"date\", \"format\": \"yyyy‐MM‐dd HH:mm:ss||yyyy‐MM‐dd||epoch_millis\" &#125; &#125;&#125;PUT /xc_course/doc/1&#123; \"name\": \"Bootstrap开发\", \"description\": \"Bootstrap是由Twitter推出的一个前台页面开发框架，是一个非常流行的开发框架，此框架集成了多种页面效果。此开发框架包含了大量的CSS、JS程序代码，可以帮助开发者（尤其是不擅长页面开发的程序人员）轻松的实现一个不受浏览器限制的精美界面效果。\", \"studymodel\": \"201002\", \"price\":38.6, \"timestamp\":\"2018‐04‐25 19:11:35\", \"pic\":\"group1/M00/00/00/wKhlQFs6RCeAY0pHAAJx5ZjNDEM428.jpg\"&#125; PUT xc_course/doc/2&#123; \"name\": \"java编程基础\", \"description\": \"java语言是世界第一编程语言，在软件开发领域使用人数最多。\", \"studymodel\": \"201001\", \"price\":68.6, \"timestamp\":\"2018‐03‐25 19:11:35\", \"pic\":\"group1/M00/00/00/wKhlQFs6RCeAY0pHAAJx5ZjNDEM428.jpg\"&#125; PUT xc_course/doc/3&#123; \"name\": \"spring开发基础\", \"description\": \"spring 在java领域非常流行，java程序员都在用。\", \"studymodel\": \"201001\", \"price\":88.6, \"timestamp\":\"2018‐02‐24 19:11:35\", \"pic\":\"group1/M00/00/00/wKhlQFs6RCeAY0pHAAJx5ZjNDEM428.jpg\"&#125; DSL搜索ES提出的基于JSON的搜索方式 查询所有文档1234567POST xc_course/doc/_search&#123; \"query\": &#123; \"match_all\": &#123;&#125; &#125;, \"_source\" : [\"name\",\"studymodel\",\"description\"]&#125; 查询结果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&#123; \"took\" : 5, \"timed_out\" : false, \"_shards\" : &#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &#125;, \"hits\" : &#123; \"total\" : 3, \"max_score\" : 1.0, \"hits\" : [ &#123; \"_index\" : \"xc_course\", \"_type\" : \"doc\", \"_id\" : \"1\", \"_score\" : 1.0, \"_source\" : &#123; \"studymodel\" : \"201002\", \"name\" : \"Bootstrap开发\", \"description\" : \"Bootstrap是由Twitter推出的一个前台页面开发框架，是一个非常流行的开发框架，此框架集成了多种页面效果。此开发框架包含了大量的CSS、JS程序代码，可以帮助开发者（尤其是不擅长页面开发的程序人员）轻松的实现一个不受浏览器限制的精美界面效果。\" &#125; &#125;, &#123; \"_index\" : \"xc_course\", \"_type\" : \"doc\", \"_id\" : \"2\", \"_score\" : 1.0, \"_source\" : &#123; \"studymodel\" : \"201001\", \"name\" : \"java编程基础\", \"description\" : \"java语言是世界第一编程语言，在软件开发领域使用人数最多。\" &#125; &#125;, &#123; \"_index\" : \"xc_course\", \"_type\" : \"doc\", \"_id\" : \"3\", \"_score\" : 1.0, \"_source\" : &#123; \"studymodel\" : \"201001\", \"name\" : \"spring开发基础\", \"description\" : \"spring 在java领域非常流行，java程序员都在用。\" &#125; &#125; ] &#125;&#125; took：本次操作花费的时间，单位为毫秒。 timed_out：请求是否超时 _shards：说明本次操作共搜索了哪些分片 hits：搜索命中的记录 hits.total ： 符合条件的文档总数 hits.hits ：匹配度较高的前N个文档 hits.max_score：文档匹配得分，这里为最高分 _score：每个文档都有一个匹配度得分，按照降序排列。 _source：显示了文档的原始内容。 JAVA API123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@SpringBootTest@RunWith(SpringRunner.class)public class TestSearch &#123; @Autowired RestHighLevelClient client; @Autowired RestClient restClient; //搜索全部记录 @Test public void testSearchAll() throws IOException, ParseException &#123; //搜索请求对象 SearchRequest searchRequest = new SearchRequest(\"xc_course\"); //指定类型 searchRequest.types(\"doc\"); //搜索源构建对象 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); //搜索方式 //matchAllQuery搜索全部 searchSourceBuilder.query(QueryBuilders.matchAllQuery()); //设置源字段过虑,第一个参数结果集包括哪些字段，第二个参数表示结果集不包括哪些字段 searchSourceBuilder.fetchSource(new String[]&#123;\"name\",\"studymodel\",\"price\",\"timestamp\"&#125;,new String[]&#123;&#125;); //向搜索请求对象中设置搜索源 searchRequest.source(searchSourceBuilder); //执行搜索,向ES发起http请求 SearchResponse searchResponse = client.search(searchRequest); //搜索结果 SearchHits hits = searchResponse.getHits(); //匹配到的总记录数 long totalHits = hits.getTotalHits(); //得到匹配度高的文档 SearchHit[] searchHits = hits.getHits(); //日期格式化对象 SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); for(SearchHit hit:searchHits)&#123; //文档的主键 String id = hit.getId(); //源文档内容 Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap(); String name = (String) sourceAsMap.get(\"name\"); //由于前边设置了源文档字段过虑，这时description是取不到的 String description = (String) sourceAsMap.get(\"description\"); //学习模式 String studymodel = (String) sourceAsMap.get(\"studymodel\"); //价格 Double price = (Double) sourceAsMap.get(\"price\"); //日期 Date timestamp = dateFormat.parse((String) sourceAsMap.get(\"timestamp\")); System.out.println(name); System.out.println(studymodel); System.out.println(description); &#125; &#125;&#125; 分页查询12345678POST xc_course/doc/_search&#123; \"from\" : 0, \"size\" : 1, \"query\": &#123; \"match_all\": &#123;&#125; &#125;, \"_source\" : [\"name\",\"studymodel\"]&#125; from：起始位置 size：条目数 JAVA API12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//分页查询@Testpublic void testSearchPage() throws IOException, ParseException &#123; //搜索请求对象 SearchRequest searchRequest = new SearchRequest(\"xc_course\"); //指定类型 searchRequest.types(\"doc\"); //搜索源构建对象 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); //设置分页参数 //页码 int page = 1; //每页记录数 int size = 1; //计算出记录起始下标 int from = (page-1)*size; searchSourceBuilder.from(from);//起始记录下标，从0开始 searchSourceBuilder.size(size);//每页显示的记录数 //搜索方式 //matchAllQuery搜索全部 searchSourceBuilder.query(QueryBuilders.matchAllQuery()); //设置源字段过虑,第一个参数结果集包括哪些字段，第二个参数表示结果集不包括哪些字段 searchSourceBuilder.fetchSource(new String[]&#123;\"name\",\"studymodel\",\"price\",\"timestamp\"&#125;,new String[]&#123;&#125;); //向搜索请求对象中设置搜索源 searchRequest.source(searchSourceBuilder); //执行搜索,向ES发起http请求 SearchResponse searchResponse = client.search(searchRequest); //搜索结果 SearchHits hits = searchResponse.getHits(); //匹配到的总记录数 long totalHits = hits.getTotalHits(); //得到匹配度高的文档 SearchHit[] searchHits = hits.getHits(); //日期格式化对象 SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); for(SearchHit hit:searchHits)&#123; //文档的主键 String id = hit.getId(); //源文档内容 Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap(); String name = (String) sourceAsMap.get(\"name\"); //由于前边设置了源文档字段过虑，这时description是取不到的 String description = (String) sourceAsMap.get(\"description\"); //学习模式 String studymodel = (String) sourceAsMap.get(\"studymodel\"); //价格 Double price = (Double) sourceAsMap.get(\"price\"); //日期 Date timestamp = dateFormat.parse((String) sourceAsMap.get(\"timestamp\")); System.out.println(name); System.out.println(studymodel); System.out.println(description); &#125;&#125; 分页查询时，total数是匹配到的数，而不是查询结果数 Term QueryTerm Query为精确查询，在搜索时会整体匹配关键字，不再将关键字分词。 123456789POST xc_course/doc/_search&#123; \"query\": &#123; \"term\" : &#123; \"name\": \"spring\" &#125; &#125;, \"_source\" : [\"name\",\"studymodel\"]&#125; 这里是整体搜索，如果es分词了spring开发，为spring、开发。你搜索spring能匹配到，但是搜索spring开发就无法匹配到 JAVA API123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//TermQuery@Testpublic void testTermQuery() throws IOException, ParseException &#123; //搜索请求对象 SearchRequest searchRequest = new SearchRequest(\"xc_course\"); //指定类型 searchRequest.types(\"doc\"); //搜索源构建对象 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); //设置分页参数 //页码 int page = 1; //每页记录数 int size = 1; //计算出记录起始下标 int from = (page-1)*size; searchSourceBuilder.from(from);//起始记录下标，从0开始 searchSourceBuilder.size(size);//每页显示的记录数 //搜索方式 //termQuery searchSourceBuilder.query(QueryBuilders.termQuery(\"name\",\"spring\")); //设置源字段过虑,第一个参数结果集包括哪些字段，第二个参数表示结果集不包括哪些字段 searchSourceBuilder.fetchSource(new String[]&#123;\"name\",\"studymodel\",\"price\",\"timestamp\"&#125;,new String[]&#123;&#125;); //向搜索请求对象中设置搜索源 searchRequest.source(searchSourceBuilder); //执行搜索,向ES发起http请求 SearchResponse searchResponse = client.search(searchRequest); //搜索结果 SearchHits hits = searchResponse.getHits(); //匹配到的总记录数 long totalHits = hits.getTotalHits(); //得到匹配度高的文档 SearchHit[] searchHits = hits.getHits(); //日期格式化对象 SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); for(SearchHit hit:searchHits)&#123; //文档的主键 String id = hit.getId(); //源文档内容 Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap(); String name = (String) sourceAsMap.get(\"name\"); //由于前边设置了源文档字段过虑，这时description是取不到的 String description = (String) sourceAsMap.get(\"description\"); //学习模式 String studymodel = (String) sourceAsMap.get(\"studymodel\"); //价格 Double price = (Double) sourceAsMap.get(\"price\"); //日期 Date timestamp = dateFormat.parse((String) sourceAsMap.get(\"timestamp\")); System.out.println(name); System.out.println(studymodel); System.out.println(description); &#125;&#125; 根据id精确匹配123456789POST xc_course/doc/_search&#123; \"query\": &#123; \"ids\" : &#123; \"type\" : \"doc\", \"values\" : [\"3\", \"4\", \"100\"] &#125; &#125;&#125; JAVA API1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//根据id查询@Testpublic void testTermQueryByIds() throws IOException, ParseException &#123; //搜索请求对象 SearchRequest searchRequest = new SearchRequest(\"xc_course\"); //指定类型 searchRequest.types(\"doc\"); //搜索源构建对象 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); //搜索方式 //根据id查询 //定义id String[] ids = new String[]&#123;\"1\",\"2\"&#125;; searchSourceBuilder.query(QueryBuilders.termsQuery(\"_id\",ids)); //设置源字段过虑,第一个参数结果集包括哪些字段，第二个参数表示结果集不包括哪些字段 searchSourceBuilder.fetchSource(new String[]&#123;\"name\",\"studymodel\",\"price\",\"timestamp\"&#125;,new String[]&#123;&#125;); //向搜索请求对象中设置搜索源 searchRequest.source(searchSourceBuilder); //执行搜索,向ES发起http请求 SearchResponse searchResponse = client.search(searchRequest); //搜索结果 SearchHits hits = searchResponse.getHits(); //匹配到的总记录数 long totalHits = hits.getTotalHits(); //得到匹配度高的文档 SearchHit[] searchHits = hits.getHits(); //日期格式化对象 SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); for(SearchHit hit:searchHits)&#123; //文档的主键 String id = hit.getId(); //源文档内容 Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap(); String name = (String) sourceAsMap.get(\"name\"); //由于前边设置了源文档字段过虑，这时description是取不到的 String description = (String) sourceAsMap.get(\"description\"); //学习模式 String studymodel = (String) sourceAsMap.get(\"studymodel\"); //价格 Double price = (Double) sourceAsMap.get(\"price\"); //日期 Date timestamp = dateFormat.parse((String) sourceAsMap.get(\"timestamp\")); System.out.println(name); System.out.println(studymodel); System.out.println(description); &#125;&#125; QueryBuilders.termsQuery(“_id”,ids);还有termQuery方法，如果用这个方法会查不到 match Querymatch Query即全文检索，它的搜索方式是先将搜索字符串分词，再使用各各词条从索引中搜索。match query与Term query区别是match query在搜索前先将搜索关键字分词，再拿各各词语去索引中搜索。 1234567891011121314151617181920212223POST xc_course/doc/_search&#123; \"query\": &#123; \"match\" : &#123; \"description\" : &#123; \"query\" : \"spring开发\", \"operator\" : \"or\" &#125; &#125; &#125;&#125;POST xc_course/doc/_search&#123; \"query\": &#123; \"match\" : &#123; \"description\" : &#123; \"query\" : \"spring开发框架\", \"minimum_should_match\": \"80%\" &#125; &#125; &#125;&#125; query：这里会将spring和开发分开匹配 operator：or是分词后匹配一个即可。and是分词后都匹配 minimum_should_match：百分之80的词匹配即可。然后向上取整。如3个词 3*0.8=2.4向上取整2 JAVA API1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//MatchQuery@Testpublic void testMatchQuery() throws IOException, ParseException &#123; //搜索请求对象 SearchRequest searchRequest = new SearchRequest(\"xc_course\"); //指定类型 searchRequest.types(\"doc\"); //搜索源构建对象 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); //搜索方式 //MatchQuery searchSourceBuilder.query(QueryBuilders.matchQuery(\"description\",\"spring开发框架\") .minimumShouldMatch(\"80%\")); //设置源字段过虑,第一个参数结果集包括哪些字段，第二个参数表示结果集不包括哪些字段 searchSourceBuilder.fetchSource(new String[]&#123;\"name\",\"studymodel\",\"price\",\"timestamp\"&#125;,new String[]&#123;&#125;); //向搜索请求对象中设置搜索源 searchRequest.source(searchSourceBuilder); //执行搜索,向ES发起http请求 SearchResponse searchResponse = client.search(searchRequest); //搜索结果 SearchHits hits = searchResponse.getHits(); //匹配到的总记录数 long totalHits = hits.getTotalHits(); //得到匹配度高的文档 SearchHit[] searchHits = hits.getHits(); //日期格式化对象 SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); for(SearchHit hit:searchHits)&#123; //文档的主键 String id = hit.getId(); //源文档内容 Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap(); String name = (String) sourceAsMap.get(\"name\"); //由于前边设置了源文档字段过虑，这时description是取不到的 String description = (String) sourceAsMap.get(\"description\"); //学习模式 String studymodel = (String) sourceAsMap.get(\"studymodel\"); //价格 Double price = (Double) sourceAsMap.get(\"price\"); //日期 Date timestamp = dateFormat.parse((String) sourceAsMap.get(\"timestamp\")); System.out.println(name); System.out.println(studymodel); System.out.println(description); &#125;&#125; 12345//匹配关键字MatchQueryBuilder matchQueryBuilder = QueryBuilders.matchQuery(\"description\", \"前台页面开发框架 架构\").minimumShouldMatch(\"80%\");//设置匹配占比searchSourceBuilder.query(matchQueryBuilder); multi Query上边学习的termQuery和matchQuery一次只能匹配一个Field，本节学习multiQuery，一次可以匹配多个字段。 12345678910POST xc_course/doc/_search&#123; \"query\": &#123; \"multi_match\" : &#123; \"query\" : \"spring css\", \"minimum_should_match\": \"50%\", \"fields\": [ \"name\", \"description\" ] &#125; &#125;&#125; 提升boost 123456789101112131415161718192021POST xc_course/doc/_search&#123; \"query\": &#123; \"multi_match\" : &#123; \"query\" : \"spring框架\", \"minimum_should_match\": \"50%\", \"fields\": [ \"name\", \"description\" ] &#125; &#125;&#125;#将name的权重加大POST xc_course/doc/_search&#123; \"query\": &#123; \"multi_match\" : &#123; \"query\" : \"spring框架\", \"minimum_should_match\": \"50%\", \"fields\": [ \"name^10\", \"description\" ] &#125; &#125;&#125; JAVA API123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//MultiMatchQuery@Testpublic void testMultiMatchQuery() throws IOException, ParseException &#123; //搜索请求对象 SearchRequest searchRequest = new SearchRequest(\"xc_course\"); //指定类型 searchRequest.types(\"doc\"); //搜索源构建对象 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); //搜索方式 //MultiMatchQuery searchSourceBuilder.query(QueryBuilders.multiMatchQuery(\"spring css\",\"name\",\"description\") .minimumShouldMatch(\"50%\") .field(\"name\",10)); //设置源字段过虑,第一个参数结果集包括哪些字段，第二个参数表示结果集不包括哪些字段 searchSourceBuilder.fetchSource(new String[]&#123;\"name\",\"studymodel\",\"price\",\"timestamp\"&#125;,new String[]&#123;&#125;); //向搜索请求对象中设置搜索源 searchRequest.source(searchSourceBuilder); //执行搜索,向ES发起http请求 SearchResponse searchResponse = client.search(searchRequest); //搜索结果 SearchHits hits = searchResponse.getHits(); //匹配到的总记录数 long totalHits = hits.getTotalHits(); //得到匹配度高的文档 SearchHit[] searchHits = hits.getHits(); //日期格式化对象 SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); for(SearchHit hit:searchHits)&#123; //文档的主键 String id = hit.getId(); //源文档内容 Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap(); String name = (String) sourceAsMap.get(\"name\"); //由于前边设置了源文档字段过虑，这时description是取不到的 String description = (String) sourceAsMap.get(\"description\"); //学习模式 String studymodel = (String) sourceAsMap.get(\"studymodel\"); //价格 Double price = (Double) sourceAsMap.get(\"price\"); //日期 Date timestamp = dateFormat.parse((String) sourceAsMap.get(\"timestamp\")); System.out.println(name); System.out.println(studymodel); System.out.println(description); &#125;&#125; Bool Query布尔查询对应于Lucene的BooleanQuery查询，实现将多个查询组合起来 1234567891011121314151617181920212223POST xc_course/doc/_search&#123; \"_source\" : [ \"name\", \"studymodel\", \"description\"], \"from\" : 0, \"size\" : 1, \"query\": &#123; \"bool\" : &#123; \"must\":[ &#123; \"multi_match\" : &#123; \"query\" : \"spring框架\", \"minimum_should_match\": \"50%\", \"fields\": [ \"name^10\", \"description\" ] &#125; &#125; , &#123; \"term\":&#123; \"studymodel\" : \"201001\" &#125; &#125; ] &#125; &#125;&#125; must：表示必须，多个查询条件必须都满足。（通常使用must） should：表示或者，多个查询条件只要有一个满足即可。 must_not：表示非。 不满足也行 JAVA API123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//BoolQuery@Testpublic void testBoolQuery() throws IOException, ParseException &#123; //搜索请求对象 SearchRequest searchRequest = new SearchRequest(\"xc_course\"); //指定类型 searchRequest.types(\"doc\"); //搜索源构建对象 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); //boolQuery搜索方式 //先定义一个MultiMatchQuery MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(\"spring css\", \"name\", \"description\") .minimumShouldMatch(\"50%\") .field(\"name\", 10); //再定义一个termQuery TermQueryBuilder termQueryBuilder = QueryBuilders.termQuery(\"studymodel\", \"201001\"); //定义一个boolQuery BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery(); boolQueryBuilder.must(multiMatchQueryBuilder); boolQueryBuilder.must(termQueryBuilder); searchSourceBuilder.query(boolQueryBuilder); //设置源字段过虑,第一个参数结果集包括哪些字段，第二个参数表示结果集不包括哪些字段 searchSourceBuilder.fetchSource(new String[]&#123;\"name\",\"studymodel\",\"price\",\"timestamp\"&#125;,new String[]&#123;&#125;); //向搜索请求对象中设置搜索源 searchRequest.source(searchSourceBuilder); //执行搜索,向ES发起http请求 SearchResponse searchResponse = client.search(searchRequest); //搜索结果 SearchHits hits = searchResponse.getHits(); //匹配到的总记录数 long totalHits = hits.getTotalHits(); //得到匹配度高的文档 SearchHit[] searchHits = hits.getHits(); //日期格式化对象 SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); for(SearchHit hit:searchHits)&#123; //文档的主键 String id = hit.getId(); //源文档内容 Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap(); String name = (String) sourceAsMap.get(\"name\"); //由于前边设置了源文档字段过虑，这时description是取不到的 String description = (String) sourceAsMap.get(\"description\"); //学习模式 String studymodel = (String) sourceAsMap.get(\"studymodel\"); //价格 Double price = (Double) sourceAsMap.get(\"price\"); //日期 Date timestamp = dateFormat.parse((String) sourceAsMap.get(\"timestamp\")); System.out.println(name); System.out.println(studymodel); System.out.println(description); &#125;&#125; 过虑器过虑是针对搜索的结果进行过虑，过虑器主要判断的是文档是否匹配，不去计算和判断文档的匹配度得分，所以过虑器性能比查询要高，且方便缓存，推荐尽量使用过虑器去实现查询或者过虑器和查询共同使用。 1234567891011121314151617181920POST xc_course/doc/_search&#123; \"_source\" : [ \"name\", \"studymodel\", \"description\",\"price\"], \"query\": &#123; \"bool\" : &#123; \"must\":[ &#123; \"multi_match\" : &#123; \"query\" : \"spring框架\", \"minimum_should_match\": \"50%\", \"fields\": [ \"name^10\", \"description\" ] &#125; &#125; ], \"filter\": [ &#123; \"term\": &#123; \"studymodel\": \"201001\" &#125;&#125;, &#123; \"range\": &#123; \"price\": &#123; \"gte\": 60 ,\"lte\" : 100&#125;&#125;&#125; ] &#125; &#125;&#125; range：范围过虑，保留大于等于60 并且小于等于100的记录。 term：项匹配过虑，保留studymodel等于”201001”的记录。 range和term一次只能对一个Field设置范围过虑。 JAVA API12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//filter@Testpublic void testFilter() throws IOException, ParseException &#123; //搜索请求对象 SearchRequest searchRequest = new SearchRequest(\"xc_course\"); //指定类型 searchRequest.types(\"doc\"); //搜索源构建对象 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); //boolQuery搜索方式 //先定义一个MultiMatchQuery MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(\"spring css\", \"name\", \"description\") .minimumShouldMatch(\"50%\") .field(\"name\", 10); //定义一个boolQuery BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery(); boolQueryBuilder.must(multiMatchQueryBuilder); //定义过虑器 boolQueryBuilder.filter(QueryBuilders.termQuery(\"studymodel\",\"201001\")); boolQueryBuilder.filter(QueryBuilders.rangeQuery(\"price\").gte(90).lte(100)); searchSourceBuilder.query(boolQueryBuilder); //设置源字段过虑,第一个参数结果集包括哪些字段，第二个参数表示结果集不包括哪些字段 searchSourceBuilder.fetchSource(new String[]&#123;\"name\",\"studymodel\",\"price\",\"timestamp\"&#125;,new String[]&#123;&#125;); //向搜索请求对象中设置搜索源 searchRequest.source(searchSourceBuilder); //执行搜索,向ES发起http请求 SearchResponse searchResponse = client.search(searchRequest); //搜索结果 SearchHits hits = searchResponse.getHits(); //匹配到的总记录数 long totalHits = hits.getTotalHits(); //得到匹配度高的文档 SearchHit[] searchHits = hits.getHits(); //日期格式化对象 SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); for(SearchHit hit:searchHits)&#123; //文档的主键 String id = hit.getId(); //源文档内容 Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap(); String name = (String) sourceAsMap.get(\"name\"); //由于前边设置了源文档字段过虑，这时description是取不到的 String description = (String) sourceAsMap.get(\"description\"); //学习模式 String studymodel = (String) sourceAsMap.get(\"studymodel\"); //价格 Double price = (Double) sourceAsMap.get(\"price\"); //日期 Date timestamp = dateFormat.parse((String) sourceAsMap.get(\"timestamp\")); System.out.println(name); System.out.println(studymodel); System.out.println(description); &#125;&#125; 排序可以在字段上添加一个或多个排序，支持在keyword、date、float等类型上添加，text类型的字段上不允许添加排序。 12345678910111213141516171819POST xc_course/doc/_search&#123; \"_source\" : [ \"name\", \"studymodel\", \"description\",\"price\"], \"query\": &#123; \"bool\" : &#123; \"filter\": [ &#123; \"range\": &#123; \"price\": &#123; \"gte\": 0 ,\"lte\" : 100&#125;&#125;&#125; ] &#125; &#125;, \"sort\" : [ &#123; \"studymodel\" : \"desc\" &#125;, &#123; \"price\" : \"asc\" &#125; ]&#125; 过虑0–10元价格范围的文档，并且对结果进行排序，先按studymodel降序，再按价格升序 JAVA API123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//Sort@Testpublic void testSort() throws IOException, ParseException &#123; //搜索请求对象 SearchRequest searchRequest = new SearchRequest(\"xc_course\"); //指定类型 searchRequest.types(\"doc\"); //搜索源构建对象 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); //boolQuery搜索方式 //定义一个boolQuery BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery(); //定义过虑器 boolQueryBuilder.filter(QueryBuilders.rangeQuery(\"price\").gte(0).lte(100)); searchSourceBuilder.query(boolQueryBuilder); //添加排序 searchSourceBuilder.sort(\"studymodel\", SortOrder.DESC); searchSourceBuilder.sort(\"price\", SortOrder.ASC); //设置源字段过虑,第一个参数结果集包括哪些字段，第二个参数表示结果集不包括哪些字段 searchSourceBuilder.fetchSource(new String[]&#123;\"name\",\"studymodel\",\"price\",\"timestamp\"&#125;,new String[]&#123;&#125;); //向搜索请求对象中设置搜索源 searchRequest.source(searchSourceBuilder); //执行搜索,向ES发起http请求 SearchResponse searchResponse = client.search(searchRequest); //搜索结果 SearchHits hits = searchResponse.getHits(); //匹配到的总记录数 long totalHits = hits.getTotalHits(); //得到匹配度高的文档 SearchHit[] searchHits = hits.getHits(); //日期格式化对象 SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); for(SearchHit hit:searchHits)&#123; //文档的主键 String id = hit.getId(); //源文档内容 Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap(); String name = (String) sourceAsMap.get(\"name\"); //由于前边设置了源文档字段过虑，这时description是取不到的 String description = (String) sourceAsMap.get(\"description\"); //学习模式 String studymodel = (String) sourceAsMap.get(\"studymodel\"); //价格 Double price = (Double) sourceAsMap.get(\"price\"); //日期 Date timestamp = dateFormat.parse((String) sourceAsMap.get(\"timestamp\")); System.out.println(name); System.out.println(studymodel); System.out.println(description); &#125;&#125; 高亮给匹配到的地方添加指定标签 123456789101112131415161718192021222324252627282930313233POST xc_course/doc/_search&#123; \"_source\" : [ \"name\", \"studymodel\", \"description\",\"price\"], \"query\": &#123; \"bool\" : &#123; \"must\":[ &#123; \"multi_match\" : &#123; \"query\" : \"开发框架\", \"minimum_should_match\": \"50%\", \"fields\": [ \"name^10\", \"description\" ], \"type\":\"best_fields\" &#125; &#125; ], \"filter\": [ &#123; \"range\": &#123; \"price\": &#123; \"gte\": 0 ,\"lte\" : 100&#125;&#125;&#125; ] &#125; &#125;, \"sort\" : [ &#123; \"price\" : \"asc\" &#125; ], \"highlight\": &#123; \"pre_tags\": [\"&lt;tag1&gt;\"], \"post_tags\": [\"&lt;/tag2&gt;\"], \"fields\": &#123; \"name\": &#123;&#125;, \"description\":&#123;&#125; &#125; &#125;&#125; pre_tags JAVA API12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576//Highlight@Testpublic void testHighlight() throws IOException, ParseException &#123; //搜索请求对象 SearchRequest searchRequest = new SearchRequest(\"xc_course\"); //指定类型 searchRequest.types(\"doc\"); //搜索源构建对象 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); //boolQuery搜索方式 //先定义一个MultiMatchQuery MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(\"开发框架\", \"name\", \"description\") .minimumShouldMatch(\"50%\") .field(\"name\", 10); //定义一个boolQuery BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery(); boolQueryBuilder.must(multiMatchQueryBuilder); //定义过虑器 boolQueryBuilder.filter(QueryBuilders.rangeQuery(\"price\").gte(0).lte(100)); searchSourceBuilder.query(boolQueryBuilder); //设置源字段过虑,第一个参数结果集包括哪些字段，第二个参数表示结果集不包括哪些字段 searchSourceBuilder.fetchSource(new String[]&#123;\"name\", \"studymodel\", \"price\", \"timestamp\"&#125;, new String[]&#123;&#125;); //设置高亮 HighlightBuilder highlightBuilder = new HighlightBuilder(); highlightBuilder.preTags(\"&lt;tag&gt;\"); highlightBuilder.postTags(\"&lt;/tag&gt;\"); highlightBuilder.fields().add(new HighlightBuilder.Field(\"name\")); //再添加一个高亮字段 //highlightBuilder.fields().add(new HighlightBuilder.Field(\"description\")); searchSourceBuilder.highlighter(highlightBuilder); //向搜索请求对象中设置搜索源 searchRequest.source(searchSourceBuilder); //执行搜索,向ES发起http请求 SearchResponse searchResponse = client.search(searchRequest); //搜索结果 SearchHits hits = searchResponse.getHits(); //匹配到的总记录数 long totalHits = hits.getTotalHits(); //得到匹配度高的文档 SearchHit[] searchHits = hits.getHits(); //日期格式化对象 SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); for (SearchHit hit : searchHits) &#123; //文档的主键 String id = hit.getId(); //源文档内容 Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap(); //源文档的name字段内容 String name = (String) sourceAsMap.get(\"name\"); //取出高亮字段 Map&lt;String, HighlightField&gt; highlightFields = hit.getHighlightFields(); if (highlightFields != null) &#123; //取出name高亮字段 HighlightField nameHighlightField = highlightFields.get(\"name\"); if (nameHighlightField != null) &#123; Text[] fragments = nameHighlightField.getFragments(); StringBuffer stringBuffer = new StringBuffer(); for (Text text : fragments) &#123; stringBuffer.append(text); &#125; name = stringBuffer.toString(); &#125; &#125; //由于前边设置了源文档字段过虑，这时description是取不到的 String description = (String) sourceAsMap.get(\"description\"); //学习模式 String studymodel = (String) sourceAsMap.get(\"studymodel\"); //价格 Double price = (Double) sourceAsMap.get(\"price\"); //日期 Date timestamp = dateFormat.parse((String) sourceAsMap.get(\"timestamp\")); System.out.println(name); System.out.println(studymodel); System.out.println(description); &#125;&#125; aggs聚合环境改变了。下列代码不复用上述环境 1234567891011# 按照total_amount求平均值POST order_infor/_doc/_search&#123; \"aggs\":&#123; \"Name\":&#123; \"avg\":&#123; \"field\":\"total_amount\" &#125; &#125; &#125;&#125; 1234567891011121314151617#AAA中包含BBB的，根据name分类降序聚合出前10位GET …/_search&#123; \"query\": &#123; \"match\" : &#123; \"AAA\": \"BBB\" &#125; &#125;, \"aggs\":&#123; \"Name\":&#123; \"terms\":&#123; \"field\":\"name\", \"size\": 10 &#125; &#125; &#125;&#125; 在聚合的时候test字段可能会报错，这时要设置字段属性 PUT 索引库名/_mapping/类型名{ “properties”: { “参数名”: { “type”: “text”, “fielddata”: true } }} 如果设置报错，可以删除索引库，再创建，在创建映射的时候，在字段的属性内加入”fielddata”: true 123456789101112131415161718#聚合内部还可以再聚合GET 索引名/_search&#123; \"aggs\":&#123; \"name1\":&#123; \"terms\":&#123; \"field\": \"field1\" &#125; &#125;, \"aggs\":&#123; \"name2\":&#123; \"terms\":&#123; \"field\": \"field2\" &#125; &#125; &#125; &#125;&#125;","categories":[],"tags":[{"name":"nosql","slug":"nosql","permalink":"http://example.com/tags/nosql/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://example.com/tags/elasticsearch/"}]},{"title":"nginx笔记","slug":"nginx笔记","date":"2019-11-09T03:13:49.000Z","updated":"2021-07-08T07:56:00.571Z","comments":true,"path":"2019/11/09/nginx笔记/","link":"","permalink":"http://example.com/2019/11/09/nginx%E7%AC%94%E8%AE%B0/","excerpt":"","text":"介绍基本概念nginx是什么高性能的HTTP和反向代理web服务器，内存小，并发强。 反向代理正向代理：VPN 反向代理：将请求发至代理服务器，代理服务器转发到目标服务器 负载均衡多台服务器，将负载分发到不同服务器 常用：轮询，权重 动静分离将静态资源（js、css、html等）和动态资源（jsp、servlet等）分开 可以由nginx直接获取静态资源 nginx安装、常用命令和配置文件在Linux中安装nginx 在nginx官网下载 .tar.gz 安装相关依赖sudo yum -y install openssl openssl-devel pcre pcre-devel zlib zlib-devel gcc gcc-c++ 使用命令解压 执行./configure --prefix=/安装目录/nginx 执行make &amp;&amp; make install 1234567查看开放的端口号firewall-cmd --list-all设置开放的端口号firewall-cmd --add-service=http –permanentfirewall-cmd --add-port=80/tcp --permanent重启防火墙firewall-cmd –reload nginx常用命令在sbin目录下使用 sbin/nginx -v：查看端口号 sbin/nginx -s stop：关闭 sbin/nginx：启动 sbin/nginx -s reload：重新加载配置文件 ps -ef|grep nginx：查看端口号 nginx配置文件conf/nginx.conf 全局块：配置服务器整体运行的配置指令比如 worker_processes 1;处理并发数的配置 events 块：影响 Nginx 服务器与用户的网络连接比如 worker_connections 1024; 支持的最大连接数为 1024 http 块还包含两部分：http 全局块 server 块 nginx配置实例反向代理例1实现效果：使用 nginx 反向代理，访问 www.123.com 直接跳转到 127.0.0.1:8080 通过修改本地 host（C:\\Windows\\System32\\drivers\\etc） 文件，将 www.123.com 映射到 127.0.0.1 nginx.conf 配置文件增加配置 将访问192.168.17.129的请求转发到127.0.0.1:8080 例2实现效果：访问http://127.0.0.1:9001/edu/ 直接跳转到 127.0.0.1:8081访问 http://127.0.0.1:9001/vod/ 直接跳转到 127.0.0.1:8082 location 指令说明123location [ &#x3D; | ~ | ~*| ^~ ] uri&#123;&#125; = ：用于不含正则表达式的 uri 前，要求请求字符串与 uri 严格匹配，如果匹配成功，就停止继续向下搜索并立即处理该请求。 ~：用于表示 uri 包含正则表达式，并且区分大小写。 ~*：用于表示 uri 包含正则表达式，并且不区分大小写。 ^~：用于不含正则表达式的 uri 前，要求 Nginx 服务器找到标识 uri 和请求字符串匹配度最高的 location 后，立即使用此 location 处理请求，而不再使用 location块中的正则 uri 和请求字符串做匹配。 如果 uri 包含正则表达式，则必须要有 ~ 或者 ~* 标识。 负载均衡实现效果：浏览器地址栏输入地址，负载均衡效果，平均 8080和 8081 端口中 proxy_pass后写的是服务名 四种负载均衡策略 轮询（默认） weight 指定weight的值就行了 ip_hash：每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 的问题。 在upstream中加一行ip_hash即可 fair（第三方） ：按后端服务器的响应时间来分配请求，响应时间短的优先分配。 在upstream中加一行fair即可 动静结合高可用集群","categories":[],"tags":[{"name":"后端","slug":"后端","permalink":"http://example.com/tags/%E5%90%8E%E7%AB%AF/"},{"name":"服务器","slug":"服务器","permalink":"http://example.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]},{"title":"Vue笔记","slug":"Vue笔记","date":"2019-11-08T13:42:14.000Z","updated":"2021-07-08T07:58:04.417Z","comments":true,"path":"2019/11/08/Vue笔记/","link":"","permalink":"http://example.com/2019/11/08/Vue%E7%AC%94%E8%AE%B0/","excerpt":"","text":"引入的方式 CDN引入： 1234&lt;!--开发环境下推荐--&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;!--生产环境下推荐--&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.6.0\"&gt;&lt;/script&gt; NPM：npm install vue 直接下载：开发版本、生产版本 初体验Vue的创建new 一个Vue对象。 el传入管理标签的id data内传入数据 data内的数据时响应式的，修改时页面会响应式变化 123456789101112131415&lt;!--html5--&gt;&lt;body&gt;&lt;div id=\"app\"&gt; &#123;&#123;message&#125;&#125;&lt;/div&gt;&lt;/body&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; new Vue(&#123; el: '#app', data:&#123; message:\"欧里给\" &#125; &#125;)&lt;/script&gt; v-forv-for=”变量 in 数组”：用mustache+变量获取数据 v-for=”(变量,index) in 数组”：index为索引 123456789101112131415161718&lt;!--html5--&gt;&lt;body&gt;&lt;div id=\"app\"&gt; &#123;&#123;message&#125;&#125; &lt;li v-for=\"item in movies\"&gt;&#123;&#123;item&#125;&#125;&lt;/li&gt; &lt;li v-for=\"(item,index) in movies\"&gt;&#123;&#123;item&#125;&#125;&lt;/li&gt;&lt;/div&gt;&lt;/body&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; new Vue(&#123; el: '#app', data:&#123; message:\"欧里给\", movies:[\"齐天大圣\",\"上下为难\",\"强人所难\",\"左右为难\"] &#125; &#125;)&lt;/script&gt; v-on@click和v-on:click等价，是语法糖 在methods内写方法 1234567891011121314151617181920212223242526&lt;!--html5--&gt;&lt;body&gt;&lt;div id=\"app\"&gt; &lt;h2&gt;当前计数：&#123;&#123;counter&#125;&#125;&lt;/h2&gt; &lt;!--这里的()省略了--&gt; &lt;button v-on:click=\"add\"&gt;+&lt;/button&gt; &lt;button v-on:click=\"counter--\"&gt;-&lt;/button&gt; &lt;button @click=\"counter--\"&gt;-&lt;/button&gt;&lt;/div&gt;&lt;/body&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; new Vue(&#123; el: '#app', data: &#123; counter: 0 &#125;, methods: &#123; add: function () &#123; //这里不能直接使用变量名，否则会从全局找该变量 //this表示当前对象 this.counter++ &#125; &#125; &#125;)&lt;/script&gt; MVVMMVVM：Model View ViewModel Model：模型相当于数据（js部分） View：视图dom部分 ViewModel：连接视图与模型进行通讯。 options选项options文档 el: [string | HTMLElement]：决定之后Vue实例会管理哪一个DOM。 data: [Object | Function]：Vue实例对应的数据对象。 methods: [[key: string]: Function ] ：定义属于Vue的一些方法，可以在其他地方调用，也可以在指令中使用。 vue的生命周期 Vue基础mustache语法1234567891011121314151617&lt;!--html5--&gt;&lt;body&gt;&lt;div id=\"app\"&gt; &lt;!--mustache语法中，可以写表达式--&gt; &lt;h2&gt;&#123;&#123;fn+' '+ln&#125;&#125;&lt;/h2&gt;&lt;/div&gt;&lt;/body&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; new Vue(&#123; el: '#app', data: &#123; fn: '1', ln: '2' &#125; &#125;)&lt;/script&gt; v-once1234&lt;div id=\"app\"&gt; &lt;h2&gt;&#123;&#123;message&#125;&#125;&lt;/h2&gt; &lt;h2 v-once&gt;&#123;&#123;message&#125;&#125;&lt;/h2&gt;&lt;/div&gt; 修改message之后，v-once并不会改变。只渲染一次 v-html123456789101112&lt;div id=\"app\"&gt; &lt;h2&gt;&#123;&#123;message&#125;&#125;&lt;/h2&gt; &lt;h2 v-html=\"message\"&gt;&lt;/h2&gt;&lt;/div&gt;&lt;script&gt; new Vue(&#123; el: '#app', data: &#123; message: \"&lt;a&gt;mydata&lt;/a&gt;\" &#125; &#125;)&lt;/script&gt; v-html：会解析html样式 v-textv-text不会解析，和mushtache类似。如果标签内有内容，会覆盖。用的比较少 v-pre123456789101112&lt;div id=\"app\"&gt; &lt;h2&gt;&#123;&#123;message&#125;&#125;&lt;/h2&gt; &lt;h2 v-pre&gt;&#123;&#123;message&#125;&#125;&lt;/h2&gt;&lt;/div&gt;&lt;script&gt; new Vue(&#123; el: '#app', data: &#123; message: \"&lt;a&gt;mydata&lt;/a&gt;\" &#125; &#125;)&lt;/script&gt; 不做任何解析 v-cloak123456789101112131415161718192021222324252627&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;style&gt; [v-cloak]&#123; display: none; &#125; &lt;/style&gt;&lt;/head&gt;&lt;!--html5--&gt;&lt;body&gt;&lt;div id=\"app\" v-cloak&gt; &lt;!--mustache语法中，可以写表达式--&gt; &lt;h2&gt;&#123;&#123;message&#125;&#125;&lt;/h2&gt;&lt;/div&gt;&lt;/body&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; setTimeout(function () &#123; new Vue(&#123; el: '#app', data: &#123; message: 'hello' &#125; &#125;) &#125;, 1000)&lt;/script&gt; 很少用，防止Vue的创建延迟 v-bind属性当中不能使用mustache语法 用v-bind 动态绑定属性 :属性为v-bind语法糖 12345678910111213141516&lt;!--html5--&gt;&lt;body&gt;&lt;div id=\"app\" v-cloak&gt; &lt;img v-bind:src=\"imgurl\" alt=\"\"/&gt; &lt;img :src=\"imgurl\" alt=\"\"/&gt;&lt;/div&gt;&lt;/body&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; new Vue(&#123; el: '#app', data: &#123; imgurl: 'https://i0.hdslb.com/bfs/sycp/creative_img/201911/593427a98170b6015ab84c6057d19af4.jpg@880w_440h.jpg' &#125; &#125;)&lt;/script&gt; v-bind动态绑定class属性可以通过修改bool值，来决定是否加入对象样式 这里还可以写class属性，:class并不会覆盖，而会合并 :class内也可以写methods中的方法 :class中也可以放数组，以,分隔 只是用的很少。如果元素加了&#39;&#39;就是字符串，如果没加就是变量 1234567891011121314151617181920212223242526272829303132333435363738&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;style&gt; .act &#123; color: red; &#125; .bla &#123; color: yellow; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=\"app\" v-cloak&gt; &lt;h2 class=\"act\"&gt;hello&lt;/h2&gt; &lt;h2 :class=\"active\"&gt;hello&lt;/h2&gt; &lt;!--&lt;h2 :class=\"&#123;类名1: bool,类名2: bool&#125;\"&gt;&lt;/h2&gt;--&gt; &lt;h2 :class=\"&#123;act: isact , bla: isbla&#125;\"&gt;hello&lt;/h2&gt; &lt;h2 :class=\"getclasses()\"&gt;hello&lt;/h2&gt; &lt;h2 :class=\"['act']\"&gt;hello&lt;/h2&gt;&lt;/div&gt;&lt;/body&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; new Vue(&#123; el: '#app', data: &#123; active: \"act\", isbla: true, isact: false &#125;, methods:&#123; getclasses:function () &#123; return &#123;act: this.isact , bla: this.isbla&#125; &#125; &#125; &#125;)&lt;/script&gt; v-bind动态绑定style属性123456789101112131415161718192021222324&lt;body&gt;&lt;div id=\"app\"&gt; &lt;!--font-size和fontSize是一样的，这里可以用驼峰命名法--&gt; &lt;!--这里不加''会当作变量--&gt; &lt;h2 :style=\"&#123;fontSize:'50px'&#125;\"&gt;&#123;&#123;message&#125;&#125;&lt;/h2&gt; &lt;h2 :style=\"&#123;fontSize:finalSize&#125;\"&gt;&#123;&#123;message&#125;&#125;&lt;/h2&gt; &lt;!--这里可以放表达式--&gt; &lt;h2 :style=\"&#123;fontSize:finalSizeNum+'px'&#125;\"&gt;&#123;&#123;message&#125;&#125;&lt;/h2&gt; &lt;h2 :style=\"[bg1,bg2]\"&gt;&#123;&#123;message&#125;&#125;&lt;/h2&gt;&lt;/div&gt;&lt;/body&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; new Vue(&#123; el: '#app', data: &#123; message: '大家好', finalSize: '100px', finalSizeNum: 150, bg1: &#123;fontSize: '100px'&#125;, bg2: &#123;backgroundColor: 'red'&#125; &#125; &#125;)&lt;/script&gt; 计算属性 computed123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;body&gt;&lt;div id=\"app\"&gt; &lt;!--本质就是属性，我们只是实现了它的get方法。不需要加小括号--&gt; &lt;h2&gt;&#123;&#123;fullName&#125;&#125;&lt;/h2&gt; &lt;h2&gt;总价格：&#123;&#123;totalPrice&#125;&#125;&lt;/h2&gt;&lt;/div&gt;&lt;/body&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; new Vue(&#123; el: '#app', data: &#123; firstName: '大家好', lastName: '笨比', books: [ &#123;id: 110, name: 'Unix编程艺术', price: 119&#125;, &#123;id: 110, name: '代码大全', price: 76&#125;, &#123;id: 110, name: '深入理解计算机原理', price: 87&#125;, &#123;id: 110, name: '现代操作系统', price: 65&#125; ] &#125;, //计算属性，只被调用一次，就会缓存，而methods不会 computed: &#123; //这里起名字一般不加动词 fullName: function () &#123; return this.firstName + ' ' + this.lastName &#125;, totalPrice: function () &#123; //let是有块级作用域 let result = 0; for (let i = 0; i &lt; this.books.length; i++) &#123; result += this.books[i].price &#125; //es6语法 // for(let i in this.books)&#123; // 这里的i相当于上面的i // &#125; // for(let i of this.books)&#123; // 这里的i相当于book[i] // &#125; return result &#125; &#125; &#125;)&lt;/script&gt; 计算属性的setter和getter12345678910111213141516171819202122232425262728293031&lt;body&gt;&lt;div id=\"app\"&gt; &lt;h2&gt;&#123;&#123;fullName&#125;&#125;&lt;/h2&gt;&lt;/div&gt;&lt;/body&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; new Vue(&#123; el: '#app', data: &#123; firstName: '大家好', lastName: '笨比' &#125;, computed: &#123; //简写 // fullName: function () &#123; // return this.firstName + ' ' + this.lastName // &#125; //计算属性一般是没有set方法，只读属性，没有set方法也可以 //set方法可以用fullName=值来使用，参数一定要传值 fullName: &#123; set: function (newValue) &#123; this.firstName = newValue &#125;, get: function () &#123; return this.firstName + ' ' + this.lastName &#125; &#125; &#125; &#125;)&lt;/script&gt; 计算属性和methods对比123456789101112131415161718192021222324252627282930313233&lt;body&gt;&lt;div id=\"app\"&gt; &lt;h2&gt;&#123;&#123;getFullName()&#125;&#125;&lt;/h2&gt; &lt;h2&gt;&#123;&#123;getFullName()&#125;&#125;&lt;/h2&gt; &lt;h2&gt;&#123;&#123;fullName&#125;&#125;&lt;/h2&gt; &lt;h2&gt;&#123;&#123;fullName&#125;&#125;&lt;/h2&gt;&lt;/div&gt;&lt;/body&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; new Vue(&#123; el: '#app', data: &#123; firstName: '大家好', lastName: '笨比' &#125;, methods: &#123; //不会缓存 getFullName: function () &#123; alert('methods') return this.firstName + ' ' + this.lastName &#125; &#125;, computed: &#123; //当firstName和lastName的值改变和初始化的时候，该方法才会被调用 //否则会缓存该值 fullName: function () &#123; alert('computed') return this.firstName + ' ' + this.lastName &#125; &#125; &#125;)&lt;/script&gt; ES6补充let/varvar为js语言设计上的错误，但是因为要向后兼容，无法被修复和移除 var没有块级作用域，这里用闭包可用解决问题（函数是一个作用域） let有块级作用域 constconst修饰的标识符为常量，不可再被赋值。优先使用const。 const修饰的对象不能被修改，但是可用更改对象内的属性 对象字面量增强写法属性字面量增强写法1234567891011121314// const obj = new Object()//字面量写法// const obj=&#123;// // &#125;//增强写法const name = 'name' const age = 19 const height = 1.88 const obj=&#123; name, age, height &#125; 方法增强写法12345678910//ES5const obj = &#123; run: function () &#123; &#125;&#125;//ES6const obj = &#123; run() &#123; &#125;&#125; Vue详解v-onv-on传参问题1234567891011121314151617181920212223242526272829303132&lt;body&gt;&lt;div id=\"app\"&gt; &lt;button @click=\"btn1Click()\"&gt;按钮1&lt;/button&gt; &lt;!--没有参数可以省略--&gt; &lt;button @click=\"btn1Click\"&gt;按钮2&lt;/button&gt; &lt;button @click=\"btn2Click(123)\"&gt;按钮3&lt;/button&gt; &lt;!--如果函数需要参数，未传，形参为undefined--&gt; &lt;button @click=\"btn2Click()\"&gt;按钮4&lt;/button&gt; &lt;!--如果没有括号，vue会传递event事件作为对象传入方法--&gt; &lt;button @click=\"btn2Click\"&gt;按钮4&lt;/button&gt;&lt;!--如果有多个参数，用$event来传事件对象--&gt; &lt;button @click=\"btn3Click('123',$event)\"&gt;按钮4&lt;/button&gt;&lt;/div&gt;&lt;/body&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; new Vue(&#123; el: '#app', methods: &#123; btn1Click() &#123; alert('btn1') &#125;, btn2Click(value) &#123; alert(value) &#125;, btn3Click(value, event) &#123; alert(value) alert(event) &#125; &#125; &#125;)&lt;/script&gt; v-on修饰符1234567891011121314151617181920212223242526272829303132333435363738394041&lt;body&gt;&lt;div @click=\"divClick\" id=\"app\"&gt; &lt;button @click=\"btnClick\"&gt;按钮1&lt;/button&gt; &lt;!--使用.stop阻止divClick触发--&gt; &lt;button @click.stop=\"btnClick\"&gt;按钮1&lt;/button&gt; &lt;br/&gt; &lt;form action=\"action\"&gt; &lt;!--使用.prevent阻止原本事件的触发--&gt; &lt;input type=\"submit\" value=\"提交\" @click.prevent=\"submitClick\"&gt;&lt;/input&gt; &lt;/form&gt; &lt;!--监听某个键帽弹起--&gt; &lt;input type=\"text\" @keyup=\"keyUp\"/&gt; &lt;!--监听回车谈起--&gt; &lt;input type=\"text\" @keyup.enter=\"keyUp\"/&gt; &lt;!--只有第一次有效，用的较少--&gt; &lt;button @click.once=\"doOnce\"&gt;点一次&lt;/button&gt;&lt;/div&gt;&lt;/body&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; new Vue(&#123; el: '#app', methods: &#123; btnClick() &#123; alert('btn') &#125;, divClick() &#123; alert('div') &#125;, submitClick() &#123; alert('submit') &#125;, keyUp() &#123; alert('1') &#125;, doOnce() &#123; alert('once') &#125; &#125; &#125;)&lt;/script&gt; v-if v-else123456789101112131415161718&lt;body&gt;&lt;div id=\"app\"&gt; &lt;h2 v-if=\"isShow\"&gt;&#123;&#123;message1&#125;&#125;&lt;/h2&gt; &lt;h1 v-else&gt;&#123;&#123;message2&#125;&#125;&lt;/h1&gt;&lt;/div&gt;&lt;/body&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; new Vue(&#123; el: '#app', data: &#123; message1: \"v-if=true\", message2: \"v-if=false\", isShow: true &#125;, methods: &#123;&#125; &#125;)&lt;/script&gt; v-else-if12345678910111213141516171819&lt;body&gt;&lt;div id=\"app\"&gt; &lt;!--如果逻辑复杂，不建议，用else-if。应该使用计算属性--&gt; &lt;h2 v-if=\"score&gt;=90\"&gt;优秀&lt;/h2&gt; &lt;h2 v-else-if=\"score&gt;=80\"&gt;良好&lt;/h2&gt; &lt;h2 v-else-if=\"score&gt;=60\"&gt;及格&lt;/h2&gt; &lt;h2 v-else&gt;不及格&lt;/h2&gt;&lt;/div&gt;&lt;/body&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: '#app', data: &#123; score: 80 &#125;, methods: &#123;&#125; &#125;)&lt;/script&gt; 小案例在vue渲染到页面之前，为了性能优化会在中间渲染virtual dom。如果页面上出现可复用的组件，会进行复用。可能会导致遗留属性。这时用key来标识不可复用的代码块。 123456789101112131415161718192021&lt;body&gt;&lt;div id=\"app\"&gt; &lt;span v-if=\"isUser\"&gt; &lt;label for=\"username\"&gt;用户账号&lt;/label&gt; &lt;input type=\"text\" id=\"username\" placeholder=\"用户账号\" key=\"username\"&gt; &lt;/span&gt; &lt;span v-else&gt; &lt;label for=\"email\"&gt;用户邮箱&lt;/label&gt; &lt;input type=\"text\" id=\"email\" placeholder=\"用户邮箱\" key=\"email\"&gt; &lt;/span&gt; &lt;button @click=\"isUser = !isUser\"&gt;切换类型&lt;/button&gt;&lt;/div&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: '#app', data: &#123; isUser: true &#125; &#125;)&lt;/script&gt; v-show、v-if当需要在显示与隐藏之间切片很频繁时，使用v-show 当只有一次切换时，通过使用v-if 1234567891011121314151617&lt;body&gt;&lt;div id=\"app\"&gt; &lt;!--当条件为false时，该元素，不会存在。如果条件改为true会重新创建--&gt; &lt;h2 v-if=\"isShow\" id=\"if\"&gt;&#123;&#123;message&#125;&#125;&lt;/h2&gt; &lt;!--当条件为false时，v-show会给该元素添加display:none的样式--&gt; &lt;h2 v-show=\"isShow\" if=\"show\"&gt;&#123;&#123;message&#125;&#125;&lt;/h2&gt;&lt;/div&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: '#app', data: &#123; isShow: true &#125; &#125;)&lt;/script&gt;&lt;/body&gt; v-for12345678910111213141516171819202122232425262728293031323334353637383940&lt;body&gt;&lt;div id=\"app\"&gt; &lt;!--数组遍历--&gt; &lt;ul&gt; &lt;li v-for=\"item in names\"&gt;&#123;&#123;item&#125;&#125;&lt;/li&gt; &lt;/ul&gt; &lt;!--有索引遍历--&gt; &lt;ul&gt; &lt;li v-for=\"(item,index) in names\"&gt; &#123;&#123;index+1&#125;&#125;.&#123;&#123;item&#125;&#125; &lt;/li&gt; &lt;/ul&gt; &lt;!--便利对象获取道德是value--&gt; &lt;ul&gt; &lt;li v-for=\"item in info\"&gt;&#123;&#123;item&#125;&#125;&lt;/li&gt; &lt;/ul&gt; &lt;!--遍历对象 获取k-v 格式(v,k)--&gt; &lt;ul&gt; &lt;li v-for=\"(v,k) in info\"&gt;&#123;&#123;k&#125;&#125;-&#123;&#123;v&#125;&#125;&lt;/li&gt; &lt;/ul&gt; &lt;!--遍历对象 获取k-v,index 格式(v,k)--&gt; &lt;ul&gt; &lt;li v-for=\"(v,k,index) in info\"&gt;&#123;&#123;k&#125;&#125;-&#123;&#123;v&#125;&#125;-&#123;&#123;index&#125;&#125;&lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: '#app', data: &#123; names: ['xiaoming', 'xiaohong', 'xiaolv', 'xiaolan'], info: &#123; name: 'why', age: 18, height: 1.88 &#125; &#125; &#125;)&lt;/script&gt;&lt;/body&gt; key属性当插入元素的时候，vue会将相应位置上的值改掉，然后依次更改后面的值。性能很低 使用key来一一对应元素，这样vue就是创建插入，效率更高，key的值和item必须一一对应，如果使用index的话，插入元素index会改变。保证key的唯一性 key的作用主要是为了高效的更新虚拟DOM。（diff算法） &lt;ul&gt; &lt;li v-for=&quot;item in names&quot; :key=&quot;item&quot;&gt;&lt;/li&gt;&lt;/ul&gt; 数组中响应式的方法响应式的 push()：添加一个或者多个 pop()：删除最后一个 shift()：删除第一个 unshift(v)：在数组最前面添加v（可以为数组） splice(n,m,v)：从n开始删除m个元素（如果不传删完），在n插入v sort() reverse() Vue.set(this.list,0,’v’)：用vue的修改list的0号值改为v 非响应式 数组[n]=v JS高阶函数补充filter：过滤函数 map：遍历 reduce(function(preValue,currentValue),0)：函数和初始值 v-model双向绑定 原理 v-bind绑定一个value属性 v-on指令给当前元素绑定input事件 123456789101112131415&lt;div id=\"app\"&gt; &lt;!--用input监听事件，模仿v-model--&gt; &lt;!--&lt;input type=\"text\" @input=\"message=$event.target.value\"&gt;--&gt; &lt;input type=\"text\" v-model=\"message\"&gt; &lt;h2&gt;&#123;&#123;message&#125;&#125;&lt;/h2&gt;&lt;/div&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: '#app', data: &#123; message: \"大家好\" &#125; &#125;)&lt;/script&gt; radio12345678910111213141516171819&lt;div id=\"app\"&gt; &lt;label for=\"male\"&gt; &lt;input type=\"radio\" id=\"male\" value=\"男\" v-model=\"sex\"&gt;男 &lt;/label&gt; &lt;label for=\"female\"&gt; &lt;input type=\"radio\" id=\"female\" value=\"女\" v-model=\"sex\"&gt;女 &lt;/label&gt; &lt;h2&gt;您选择的性别是: &#123;&#123;sex&#125;&#125;&lt;/h2&gt;&lt;/div&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊', sex: '女' &#125; &#125;)&lt;/script&gt; checkbox12345678910111213141516171819202122232425&lt;div id=\"app\"&gt; &lt;!--1.checkbox单选框--&gt; &lt;!--&lt;label for=\"agree\"&gt;--&gt; &lt;!--&lt;input type=\"checkbox\" id=\"agree\" v-model=\"isAgree\"&gt;同意协议--&gt; &lt;!--&lt;/label&gt;--&gt; &lt;!--&lt;h2&gt;您选择的是: &#123;&#123;isAgree&#125;&#125;&lt;/h2&gt;--&gt; &lt;!--&lt;button :disabled=\"!isAgree\"&gt;下一步&lt;/button&gt;--&gt; &lt;!--2.checkbox多选框--&gt; &lt;input type=\"checkbox\" value=\"篮球\" v-model=\"hobbies\"&gt;篮球 &lt;input type=\"checkbox\" value=\"足球\" v-model=\"hobbies\"&gt;足球 &lt;input type=\"checkbox\" value=\"乒乓球\" v-model=\"hobbies\"&gt;乒乓球 &lt;input type=\"checkbox\" value=\"羽毛球\" v-model=\"hobbies\"&gt;羽毛球 &lt;h2&gt;您的爱好是: &#123;&#123;hobbies&#125;&#125;&lt;/h2&gt;&lt;/div&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊', isAgree: false, // 单选框 hobbies: [] // 多选框, &#125; &#125;)&lt;/script&gt; select1234567891011121314151617181920212223242526272829&lt;div id=\"app\"&gt; &lt;!--1.选择一个--&gt; &lt;select name=\"abc\" v-model=\"fruit\"&gt; &lt;option value=\"苹果\"&gt;苹果&lt;/option&gt; &lt;option value=\"香蕉\"&gt;香蕉&lt;/option&gt; &lt;option value=\"榴莲\"&gt;榴莲&lt;/option&gt; &lt;option value=\"葡萄\"&gt;葡萄&lt;/option&gt; &lt;/select&gt; &lt;h2&gt;您选择的水果是: &#123;&#123;fruit&#125;&#125;&lt;/h2&gt; &lt;!--2.选择多个--&gt; &lt;select name=\"abc\" v-model=\"fruits\" multiple&gt; &lt;option value=\"苹果\"&gt;苹果&lt;/option&gt; &lt;option value=\"香蕉\"&gt;香蕉&lt;/option&gt; &lt;option value=\"榴莲\"&gt;榴莲&lt;/option&gt; &lt;option value=\"葡萄\"&gt;葡萄&lt;/option&gt; &lt;/select&gt; &lt;h2&gt;您选择的水果是: &#123;&#123;fruits&#125;&#125;&lt;/h2&gt;&lt;/div&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊', fruit: '香蕉', fruits: [] &#125; &#125;)&lt;/script&gt; 值绑定就是值动态获取v-bind 1234567891011121314151617&lt;div id=\"app\"&gt; &lt;h2&gt;您的爱好是: &#123;&#123;hobbies&#125;&#125;&lt;/h2&gt; &lt;label v-for=\"item in originHobbies\" :for=\"item\"&gt; &lt;input type=\"checkbox\" :value=\"item\" :id=\"item\" v-model=\"hobbies\"&gt;&#123;&#123;item&#125;&#125; &lt;/label&gt;&lt;/div&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊', hobbies: [], // 多选框, originHobbies: ['篮球', '足球', '乒乓球', '羽毛球', '台球', '高尔夫球'] &#125; &#125;)&lt;/script&gt; 修饰符 lazy修饰符：plazy修饰符可以让数据在失去焦点或者回车时才会更新； nnumber修饰符：可以让在输入框中输入的内容自动转成数字类型；只能输入数字 ntrim修饰符：可以过滤内容左右两边的空格 12345678910111213141516171819202122&lt;div id=\"app\"&gt; &lt;!--1.修饰符: lazy--&gt; &lt;input type=\"text\" v-model.lazy=\"message\"&gt; &lt;h2&gt;&#123;&#123;message&#125;&#125;&lt;/h2&gt; &lt;!--2.修饰符: number--&gt; &lt;input type=\"number\" v-model.number=\"age\"&gt; &lt;h2&gt;&#123;&#123;age&#125;&#125;-&#123;&#123;typeof age&#125;&#125;&lt;/h2&gt; &lt;!--3.修饰符: trim--&gt; &lt;input type=\"text\" v-model.trim=\"name\"&gt; &lt;h2&gt;您输入的名字:&#123;&#123;name&#125;&#125;&lt;/h2&gt;&lt;/div&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊', age: 0, name: '' &#125; &#125;)&lt;/script&gt; 组件化开发将页面拆分为小的功能模块。每个模块独立完成自己的功能 组件注册三步骤 创建组件构造器：Vue.extend() 注册组件：Vue.component() 使用组件：在Vue实例范围之内使用 基本使用过程1234567891011121314151617181920212223242526272829303132&lt;div id=\"app\"&gt; &lt;!--3.使用组件--&gt; &lt;my-cpn&gt;&lt;/my-cpn&gt; &lt;my-cpn&gt;&lt;/my-cpn&gt; &lt;div&gt; &lt;div&gt; &lt;my-cpn&gt;&lt;/my-cpn&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;!--外界用不到--&gt;&lt;my-cpn&gt;&lt;/my-cpn&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; // 1.创建组件构造器对象 const cpnC = Vue.extend(&#123; template: ` &lt;div&gt; &lt;h2&gt;我是标题&lt;/h2&gt; &lt;p&gt;我是内容, 哈哈哈哈&lt;/p&gt; &lt;p&gt;我是内容, 呵呵呵呵&lt;/p&gt; &lt;/div&gt;` &#125;) // 2.注册组件 第一个参数是指定的名字 Vue.component('my-cpn', cpnC) const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊' &#125; &#125;)&lt;/script&gt; 全部组件和局部组件123456789101112131415161718192021222324252627282930313233343536&lt;div id=\"app\"&gt; &lt;cpn&gt;&lt;/cpn&gt; &lt;cpn&gt;&lt;/cpn&gt; &lt;cpn&gt;&lt;/cpn&gt;&lt;/div&gt;&lt;div id=\"app2\"&gt; &lt;cpn&gt;&lt;/cpn&gt;&lt;/div&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; // 1.创建组件构造器 const cpnC = Vue.extend(&#123; template: ` &lt;div&gt; &lt;h2&gt;我是标题&lt;/h2&gt; &lt;p&gt;我是内容,哈哈哈哈啊&lt;/p&gt; &lt;/div&gt; ` &#125;) // 2.注册组件(全局组件, 意味着可以在多个Vue的实例下面使用) // Vue.component('cpn', cpnC) const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊' &#125;, //注册局部组件 components: &#123; // cpn使用组件时的标签名 cpn: cpnC &#125; &#125;) const app2 = new Vue(&#123; el: '#app2' &#125;)&lt;/script&gt; 父组件子组件12345678910111213141516171819202122232425262728293031323334353637383940&lt;div id=\"app\"&gt; &lt;cpn2&gt;&lt;/cpn2&gt;&lt;/div&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; // 1.创建第一个组件构造器(子组件) const cpnC1 = Vue.extend(&#123; template: ` &lt;div&gt; &lt;h2&gt;我是标题1&lt;/h2&gt; &lt;p&gt;我是内容, 哈哈哈哈&lt;/p&gt; &lt;/div&gt; ` &#125;) // 2.创建第二个组件构造器(父组件) const cpnC2 = Vue.extend(&#123; template: ` &lt;div&gt; &lt;h2&gt;我是标题2&lt;/h2&gt; &lt;p&gt;我是内容, 呵呵呵呵&lt;/p&gt; &lt;cpn1&gt;&lt;/cpn1&gt; &lt;/div&gt; `, components: &#123; //注册组件 cpn1: cpnC1 &#125; &#125;) // root组件 //cpn2下注册了cpn1，这里没有注册不能使用cpn1 const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊' &#125;, components: &#123; cpn2: cpnC2 &#125; &#125;)&lt;/script&gt; 组件注册语法糖1234567891011121314151617181920212223242526272829303132333435&lt;div id=\"app\"&gt; &lt;cpn1&gt;&lt;/cpn1&gt; &lt;cpn2&gt;&lt;/cpn2&gt;&lt;/div&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; // 1.全局组件注册的语法糖 //创建注册组件 //内部会去调用extend() Vue.component('cpn1', &#123; template: ` &lt;div&gt; &lt;h2&gt;我是标题1&lt;/h2&gt; &lt;p&gt;我是内容, 哈哈哈哈&lt;/p&gt; &lt;/div&gt; ` &#125;) // 2.注册局部组件的语法糖 const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊' &#125;, components: &#123; 'cpn2': &#123; template: ` &lt;div&gt; &lt;h2&gt;我是标题2&lt;/h2&gt; &lt;p&gt;我是内容, 呵呵呵&lt;/p&gt; &lt;/div&gt; ` &#125; &#125; &#125;)&lt;/script&gt; 组件模板的简单抽离写法模板内必须由div包裹，不然会报错 1234567891011121314151617181920212223242526272829303132&lt;div id=\"app\"&gt; &lt;cpn&gt;&lt;/cpn&gt; &lt;cpn&gt;&lt;/cpn&gt; &lt;cpn&gt;&lt;/cpn&gt;&lt;/div&gt;&lt;!--1.script标签, 注意:类型必须是text/x-template--&gt;&lt;!--&lt;script type=\"text/x-template\" id=\"cpn\"&gt; &lt;div&gt; &lt;h2&gt;我是标题&lt;/h2&gt; &lt;p&gt;我是内容,哈哈哈&lt;/p&gt; &lt;/div&gt;&lt;/script&gt;--&gt;&lt;!--2.template标签--&gt;&lt;template id=\"cpn\"&gt; &lt;div&gt; &lt;h2&gt;我是标题&lt;/h2&gt; &lt;p&gt;我是内容,呵呵呵&lt;/p&gt; &lt;/div&gt;&lt;/template&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; // 1.注册一个全局组件 Vue.component('cpn', &#123; template: '#cpn' &#125;) const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊' &#125; &#125;)&lt;/script&gt; 组件中data访问1234567891011121314151617181920212223242526272829&lt;div id=\"app\"&gt; &lt;cpn&gt;&lt;/cpn&gt;&lt;/div&gt;&lt;template id=\"cpn\"&gt; &lt;div&gt; &lt;h2&gt;&#123;&#123;title&#125;&#125;&lt;/h2&gt; &lt;p&gt;我是内容,呵呵呵&lt;/p&gt; &lt;/div&gt;&lt;/template&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; Vue.component('cpn', &#123; template: '#cpn', //data必须是一个函数，返回一个对象 data() &#123; return &#123; title: 'abc' &#125; &#125; &#125;) const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊' //这里的title cpn中式访问不到的 // title: '我是标题' &#125; &#125;)&lt;/script&gt; 为什么data必须为函数因为组件是复用的。各个组件的data必须是不同的对象，否则会造成数据修改的同步 data: {}是一个对象而data(){return {}}是每次调用都会产生新对象。 父子组件的通信父传子props 123456789101112131415161718192021222324252627282930313233&lt;div id=\"app\"&gt; &lt;!--如果没有用v-bind那么就是按照写的字符串传递--&gt; &lt;cpn :cmessage=\"message\" :cmovies=\"movies\"&gt;&lt;/cpn&gt;&lt;/div&gt;&lt;template id=\"cpn\"&gt; &lt;div&gt; &lt;ul&gt; &lt;li v-for=\"item in cmovies\"&gt;&#123;&#123;item&#125;&#125;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;&#123;&#123;cmessage&#125;&#125;&lt;/h2&gt; &lt;/div&gt;&lt;/template&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; // 父传子: props const cpn = &#123; template: '#cpn', props: ['cmovies', 'cmessage'], data() &#123; return &#123;&#125; &#125; &#125; const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊', movies: ['海王', '海贼王', '海尔兄弟'] &#125;, components: &#123; cpn &#125; &#125;)&lt;/script&gt; props：对象的写法 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;div id=\"app\"&gt; &lt;cpn&gt;&lt;/cpn&gt;&lt;/div&gt;&lt;template id=\"cpn\"&gt; &lt;p&gt;&#123;&#123;cmessage&#125;&#125;&lt;/p&gt;&lt;/template&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const cpn = &#123; template: '#cpn', props: &#123; // 1.指定类型，类型限制 // cmovies: Array, // cmessage: String, // 2.提供一些默认值 // required:true 必传值 cmessage: &#123; type: String, default: 'aaaaaaaa' //, required: true &#125;, // 类型是对象或者数组时, 默认值必须是一个函数 cmovies: &#123; type: Array, default() &#123; return [] &#125; &#125; &#125;, data() &#123; return &#123;&#125; &#125; &#125; const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊', movies: ['海王', '海贼王', '海尔兄弟'] &#125;, components: &#123; cpn &#125; &#125;)&lt;/script&gt; props驼峰标识@后也不能写驼峰 后面使用脚手架是可以的 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;div id=\"app\"&gt;&lt;!--v-bind不接受驼峰写法，要用的时候必须加个'-' --&gt; &lt;cpn :c-info=\"info\" :child-my-message=\"message\" v-bind:class&gt;&lt;/cpn&gt;&lt;/div&gt;&lt;template id=\"cpn\"&gt; &lt;div&gt; &lt;h2&gt;&#123;&#123;cInfo&#125;&#125;&lt;/h2&gt; &lt;h2&gt;&#123;&#123;childMyMessage&#125;&#125;&lt;/h2&gt; &lt;/div&gt;&lt;/template&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const cpn = &#123; template: '#cpn', props: &#123; cInfo: &#123; type: Object, default() &#123; return &#123;&#125; &#125; &#125;, childMyMessage: &#123; type: String, default: '' &#125; &#125; &#125; const app = new Vue(&#123; el: '#app', data: &#123; info: &#123; name: 'why', age: 18, height: 1.88 &#125;, message: 'aaaaaa' &#125;, components: &#123; cpn &#125; &#125;)&lt;/script&gt; 子传父events：自定义事件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;!--父组件模板--&gt;&lt;div id=\"app\"&gt; &lt;cpn @item-click=\"cpnClick\"&gt;&lt;/cpn&gt;&lt;/div&gt;&lt;!--子组件模板--&gt;&lt;template id=\"cpn\"&gt; &lt;div&gt; &lt;button v-for=\"item in categories\" @click=\"btnClick(item)\"&gt; &#123;&#123;item.name&#125;&#125; &lt;/button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; // 1.子组件 const cpn = &#123; template: '#cpn', data() &#123; return &#123; categories: [ &#123;id: 'aaa', name: '热门推荐'&#125;, &#123;id: 'bbb', name: '手机数码'&#125;, &#123;id: 'ccc', name: '家用家电'&#125;, &#123;id: 'ddd', name: '电脑办公'&#125;, ] &#125; &#125;, methods: &#123; btnClick(item) &#123; // 发射事件: 自定义事件 向父组件传消息 this.$emit('item-click', item) &#125; &#125; &#125; // 2.父组件 const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊' &#125;, components: &#123; cpn &#125;, methods: &#123; cpnClick(item) &#123; console.log('cpnClick', item); &#125; &#125; &#125;)&lt;/script&gt; 脚手架可以驼峰原理.vue文件内组件对象是没有template。会被渲染成render函数。最终没有组件对象只有render函数 不懂就算了 双向绑定注意事项不要通过子组件中绑定数据修改父组件的数据。会造成逻辑混乱 Vue也会报错 小样例上为下的十分之一，联动修改 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;div id=\"app\"&gt; &lt;!--@num3change是用来监听子组件传递的num3change事件,触发父组件的num1change事件--&gt; &lt;cpn :number1=\"num1\" :number2=\"num2\" @num3change=\"num1change\" @num4change=\"num2change\"/&gt;&lt;/div&gt;&lt;template id=\"cpn\"&gt; &lt;div&gt; &lt;h2&gt;props:&#123;&#123;number1&#125;&#125;&lt;/h2&gt; &lt;h2&gt;data:&#123;&#123;dnumber1&#125;&#125;&lt;/h2&gt; &lt;!--&lt;input type=\"text\" v-model=\"dnumber1\"&gt;--&gt; &lt;input type=\"text\" :value=\"dnumber1\" @input=\"num1Input\"&gt; &lt;h2&gt;props:&#123;&#123;number2&#125;&#125;&lt;/h2&gt; &lt;h2&gt;data:&#123;&#123;dnumber2&#125;&#125;&lt;/h2&gt; &lt;!--&lt;input type=\"text\" v-model=\"dnumber2\"&gt;--&gt; &lt;input type=\"text\" :value=\"dnumber2\" @input=\"num2Input\"&gt; &lt;/div&gt;&lt;/template&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: '#app', data: &#123; num1: 1, num2: 0 &#125;, methods: &#123; num1change(value) &#123; this.num1 = parseFloat(value) &#125;, num2change(value) &#123; this.num2 = parseFloat(value) &#125; &#125;, components: &#123; cpn: &#123; template: '#cpn', props: &#123; number1: Number, number2: Number &#125;, data() &#123; return &#123; dnumber1: this.number1, dnumber2: this.number2 &#125; &#125;, methods: &#123; num1Input(event) &#123; // 1.将input中的value赋值到dnumber中 this.dnumber1 = event.target.value; // 2.为了让父组件可以修改值, 发出一个事件 this.$emit('num3change', this.dnumber1) // 3.同时修饰dnumber2的值 this.dnumber2 = this.dnumber1 * 100; this.$emit('num4change', this.dnumber2); &#125;, num2Input(event) &#123; this.dnumber2 = event.target.value; this.$emit('num3change', this.dnumber2) // 同时修饰dnumber2的值 this.dnumber1 = this.dnumber2 / 100; this.$emit('num4change', this.dnumber1); &#125; &#125; &#125; &#125; &#125;)&lt;/script&gt; 使用watch实现 watch后面会将，用来监控属性 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;div id=\"app\"&gt; &lt;cpn :number1=\"num1\" :number2=\"num2\" @num1change=\"num1change\" @num2change=\"num2change\"/&gt;&lt;/div&gt;&lt;template id=\"cpn\"&gt; &lt;div&gt; &lt;h2&gt;props:&#123;&#123;number1&#125;&#125;&lt;/h2&gt; &lt;h2&gt;data:&#123;&#123;dnumber1&#125;&#125;&lt;/h2&gt; &lt;input type=\"text\" v-model=\"dnumber1\"&gt; &lt;h2&gt;props:&#123;&#123;number2&#125;&#125;&lt;/h2&gt; &lt;h2&gt;data:&#123;&#123;dnumber2&#125;&#125;&lt;/h2&gt; &lt;input type=\"text\" v-model=\"dnumber2\"&gt; &lt;/div&gt;&lt;/template&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: '#app', data: &#123; num1: 1, num2: 0 &#125;, methods: &#123; num1change(value) &#123; this.num1 = parseFloat(value) &#125;, num2change(value) &#123; this.num2 = parseFloat(value) &#125; &#125;, components: &#123; cpn: &#123; template: '#cpn', props: &#123; number1: Number, number2: Number, name: '' &#125;, data() &#123; return &#123; dnumber1: this.number1, dnumber2: this.number2 &#125; &#125;, watch: &#123; dnumber1(newValue) &#123; this.dnumber2 = newValue * 100; this.$emit('num1change', newValue); &#125;, dnumber2(newValue) &#123; this.number1 = newValue / 100; this.$emit('num2change', newValue); &#125; &#125; &#125; &#125; &#125;)&lt;/script&gt; 引用对象访问父访问子1234567891011121314151617181920212223242526272829303132333435363738394041&lt;div id=\"app\"&gt; &lt;cpn&gt;&lt;/cpn&gt; &lt;!--标识子组件的引用--&gt; &lt;cpn ref=\"aaa\"&gt;&lt;/cpn&gt; &lt;button @click=\"btnClick\"&gt;按钮&lt;/button&gt;&lt;/div&gt;&lt;template id=\"cpn\"&gt; &lt;div&gt;我是子组件&lt;/div&gt;&lt;/template&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊' &#125;, methods: &#123; btnClick() &#123; // 1.$children 获取到子组件的集合，是使用的子组件数目。用的少 // this.$children // 2.$refs =&gt; 对象类型, 默认是一个空的对象 ref='bbb'。通过子组件的ref获取到子组件对象 //this.$refs.aaa &#125; &#125;, components: &#123; cpn: &#123; template: '#cpn', data() &#123; return &#123; name: '我是子组件的name' &#125; &#125;, methods: &#123; showMessage() &#123; console.log('showMessage'); &#125; &#125; &#125;, &#125; &#125;)&lt;/script&gt; 子访问父1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;div id=\"app\"&gt; &lt;cpn&gt;&lt;/cpn&gt;&lt;/div&gt;&lt;template id=\"cpn\"&gt; &lt;div&gt; &lt;h2&gt;我是cpn组件&lt;/h2&gt; &lt;ccpn&gt;&lt;/ccpn&gt; &lt;/div&gt;&lt;/template&gt;&lt;template id=\"ccpn\"&gt; &lt;div&gt; &lt;h2&gt;我是子组件&lt;/h2&gt; &lt;button @click=\"btnClick\"&gt;按钮&lt;/button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊' &#125;, components: &#123; cpn: &#123; template: '#cpn', data() &#123; return &#123; name: '我是cpn组件的name' &#125; &#125;, components: &#123; ccpn: &#123; template: '#ccpn', methods: &#123; btnClick() &#123; // 1.访问父组件$parent，获取到父组件对象 // this.$parent // 2.访问根组件$root，获取到根组件对象 this.$root &#125; &#125; &#125; &#125; &#125; &#125; &#125;)&lt;/script&gt; slot插槽在模板中挖一个插槽用来存放不同的地方 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;!--1.插槽的基本使用 在模板中定义&lt;slot&gt;&lt;/slot&gt;即可2.插槽的默认值 &lt;slot&gt;button&lt;/slot&gt; 如果有传入默认值会被替换3.如果有多个值, 同时放入到组件进行替换时, 一起作为替换元素--&gt;&lt;div id=\"app\"&gt; &lt;cpn&gt;&lt;/cpn&gt; &lt;cpn&gt;&lt;span&gt;哈哈哈&lt;/span&gt;&lt;/cpn&gt; &lt;cpn&gt;&lt;i&gt;呵呵呵&lt;/i&gt;&lt;/cpn&gt; &lt;cpn&gt; &lt;i&gt;呵呵呵&lt;/i&gt; &lt;div&gt;我是div元素&lt;/div&gt; &lt;p&gt;我是p元素&lt;/p&gt; &lt;/cpn&gt; &lt;cpn&gt;&lt;/cpn&gt; &lt;cpn&gt;&lt;/cpn&gt; &lt;cpn&gt;&lt;/cpn&gt; &lt;cpn&gt;&lt;/cpn&gt;&lt;/div&gt;&lt;template id=\"cpn\"&gt; &lt;div&gt; &lt;h2&gt;我是组件&lt;/h2&gt; &lt;p&gt;我是组件, 哈哈哈&lt;/p&gt; &lt;slot&gt;&lt;button&gt;按钮&lt;/button&gt;&lt;/slot&gt; &lt;!--&lt;button&gt;按钮&lt;/button&gt;--&gt; &lt;/div&gt;&lt;/template&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊' &#125;, components: &#123; cpn: &#123; template: '#cpn' &#125; &#125; &#125;)&lt;/script&gt; 多slot插槽12345678910111213141516171819202122232425262728&lt;div id=\"app\"&gt; &lt;!--如果需要替换有name的slot的。需要指定slot属性。如果没指定就是替换没name的--&gt; &lt;cpn&gt;&lt;span slot=\"center\"&gt;标题&lt;/span&gt;&lt;/cpn&gt; &lt;cpn&gt; &lt;button slot=\"left\"&gt;返回&lt;/button&gt; &lt;/cpn&gt;&lt;/div&gt;&lt;template id=\"cpn\"&gt; &lt;div&gt; &lt;slot name=\"left\"&gt;&lt;span&gt;左边&lt;/span&gt;&lt;/slot&gt; &lt;slot name=\"center\"&gt;&lt;span&gt;中间&lt;/span&gt;&lt;/slot&gt; &lt;slot name=\"right\"&gt;&lt;span&gt;右边&lt;/span&gt;&lt;/slot&gt; &lt;/div&gt;&lt;/template&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊' &#125;, components: &#123; cpn: &#123; template: '#cpn' &#125; &#125; &#125;)&lt;/script&gt; 编译作用域Vue实例的作用域 12345678910111213141516171819202122232425262728293031&lt;div id=\"app\"&gt; &lt;!--这里用的是父组件的作用域--&gt; &lt;cpn v-show=\"isShow\"&gt;&lt;/cpn&gt;&lt;/div&gt;&lt;template id=\"cpn\"&gt; &lt;div&gt; &lt;h2&gt;我是子组件&lt;/h2&gt; &lt;!--这里用的是子组件的isShow--&gt; &lt;button v-show=\"isShow\"&gt;按钮&lt;/button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊', isShow: true &#125;, components: &#123; cpn: &#123; template: '#cpn', data() &#123; return &#123; isShow: false &#125; &#125; &#125;, &#125; &#125;)&lt;/script&gt; 插槽作用域使用1234567891011121314151617181920212223242526272829303132333435363738&lt;div id=\"app\"&gt; &lt;cpn&gt;&lt;/cpn&gt; &lt;cpn&gt; &lt;!--目的是获取子组件中的pLanguages vue2.5.x以上可以用div--&gt; &lt;template slot-scope=\"slot\"&gt; &lt;span&gt;&#123;&#123;slot.data.join(' - ')&#125;&#125;&lt;/span&gt; &lt;/template&gt; &lt;/cpn&gt;&lt;/div&gt;&lt;template id=\"cpn\"&gt; &lt;div&gt; &lt;slot :data=\"pLanguages\"&gt; &lt;ul&gt; &lt;li v-for=\"item in pLanguages\"&gt;&#123;&#123;item&#125;&#125;&lt;/li&gt; &lt;/ul&gt; &lt;/slot&gt; &lt;/div&gt;&lt;/template&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; const app = new Vue(&#123; el: '#app', data: &#123; message: '你好啊' &#125;, components: &#123; cpn: &#123; template: '#cpn', data() &#123; return &#123; pLanguages: ['JavaScript', 'C++', 'Java', 'C#', 'Python', 'Go', 'Swift'] &#125; &#125; &#125; &#125; &#125;)&lt;/script&gt; Webpack简述Webpack是一个js应用的模块和打包工具。 模块化随着ajax异步请求出现，前端代码越来越多。而代码的编写方式对js文件的依赖顺序几乎是强制性的。为了更方便的维护代码。就出现了模块化。 解决方案匿名函数的解决方案 利用函数的作用域来解决重名问题 (function(){var flag = true})() 但是这样别人就无法使用到内部的属性、方法等 使用模块作为出口 在函数内部定义一个对象。给对象添加需要暴露给外部的属性、方法。任何将对象返回。 然而这样打包会比较繁琐，就诞生了很多的规范和实现方案 常见的解决方案：CommonJS、AMD、CMD，也有ES6的Modules CommonJs 导出： 导入： ES6 export指令用于导出变量。导出函数和类同理 两种写法 export default 一个模块只能有一个default。导入的时候名字是自己取的 import 在HTML代码中引入两个js文件type需要设置为module import指令用于导入模块中的内容，比如main.js的代码 通过*可以导入模块中所有的export变量 打包webpack可以帮助我们进行模块化，并且处理模块间的各种复杂关系。 可以将webpack中的各种资源模块进行打包合并成一个或多个包(Bundle)。 打包的过程中，还可以对资源进行处理，比如压缩图片，将scss转成css，将ES6语法转成ES5语法，将TypeScript转成JavaScript等等操作。 webpack安装n安装webpack首先需要安装Node.js，Node.js自带了软件包管理工具npm 查看node版本node -v 全局安装webpacknpm install webpack@3.6.0 -g这里安装的是3.6.0 开发时，项目使用的webpack版本和全局webpack版本不一致需要修改： 局部安装先cd 目录然后npm install webpack@3.6.0 --save-dev webpack初步使用创建俩个文件夹，src和dist。src用来存放源代码。dist用来存放编译好的文件 将要测试的代码使用webpack src/xx.js dist/xx.js然后在网页中引入dist下刚编译好的js文件即可。不需要自己处理依赖和模块 每次运行都需要敲这么长的命令，比较繁琐。可以在项目根目录下创建webpack.config.js在内键入 12345678910111213//require是依赖一个包const path = require('path')//__dirname是一个上下文的环境变量。//拼接dist。组成输出路径module.exports = &#123; entry: './src/main.js', output: &#123; path: path.resolve(__dirname, 'dist'), filename: 'bundle.js', //给路径添加默认前缀 publicPath: 'dist/' &#125;,&#125; 然后使用npm init初始化项目，会在根目录生成package.json和package-lok.json两个文件 因为webpack版本问题，我们可能要安装局部webpacknpm install webpack@3.6.0 --save-dev指定版本号安装。然后会自动在package.json生成webpack的版本号 webpack命令默认使用的是全局的webpack。局部webpack需要使用node_modules\\.bin\\webpack来执行本地webpack命令。但是过于繁琐。就可以在package.json中自定义命令脚本 package.json中的命令在执行的时候会先去node_modules/.bin下寻找 在scripts下添加一条&quot;build&quot;: &quot;webpack&quot;，即可使用npm run build命令使用局部webpack Loaderwebpack主要用来打包js代码，当css图片或者ts转为es5代码时候，webpack是不支持的，这时候就要使用loader来扩展webpack。 Loader中文手册 例：转化css样式先安装css-loadernpm install css-loader --save-dev再安装style-loadernpm install style-loader --save-dev 需要在使用的js文件内引入css样式require(&#39;xxx.css&#39;)在html内引入js文件即可 然后在webpack.config.js配置loader 1234567891011121314151617181920module.exports = &#123; entry: './src/main.js', output: &#123; path: path.resolve(__dirname, 'dist'), filename: 'bundle.js' &#125;,//新增配置 rules: [ &#123; //正则表达式 test: /\\.css$/, //style-loader扶着解析样式添加到dom //css-loader只负责将css文件进行加载 //多个loader时，是从右向左读取，所以css-loader要在后面 use: [ &#123; loader: \"style-loader\" &#125;, &#123; loader: \"css-loader\" &#125; ] &#125; ]&#125; 例：转化less文件先安装less-loader和lessnpm install --save-dev less-loader less 需要在使用的js文件内引入css样式require(&#39;xxx.less&#39;)在html内引入js文件即可 然后在webpack.config.js配置loader，在rules集合下，添加一个对象 123456789&#123; test: /\\.less$/, use: [&#123; loader: \"style-loader\" // creates style nodes from JS strings &#125;, &#123; loader: \"css-loader\" // translates CSS into CommonJS &#125;, &#123; loader: \"less-loader\" // compiles Less to CSS&#125; 例：转化图片文件图片引入需要安装url-loader：npm install --save-dev url-loader 然后在webpack.config.js配置loader，在rules集合下，添加一个对象 123456789101112131415&#123; test: /\\.(png|jpg|gif|jpeg)$/, use: [ &#123; loader: 'url-loader', options: &#123; // 当加载的图片, 小于limit时, 会将图片编译成base64字符串形式. // 当加载的图片, 大于limit时, 需要使用file-loader模块进行加载. limit: 13000, //img文件夹下原文件名.哈希值的8位.原扩展名。[]是获取变量 name: 'img/[name].[hash:8].[ext]' &#125;, &#125; ]&#125; 如果图片大于limit的值需要安装file-loader。不需要配置 例：ES6转ES5语法先安装npm install --save-dev babel-loader@7 babel-core babel-preset-es2015 然后配置webpack.config.js文件 12345678910&#123; test: /\\.js$/, exclude: /(node_modules|bower_components)/, use: &#123; loader: 'babel-loader', options: &#123; presets: ['es2015'] &#125; &#125;&#125; webpack引入vue.js安装npm install vue --save 然后import Vue from &#39;vue&#39;在js中引用。然后webpack运行。会出现报错 解决方案：Vue不同版本构建是以为Vue默认是runtime-only模式。我们需要改成runtime-compiler模式。 runtime-only模式不允许有template。其中被vue 管理的div也算。 在module.exports下添加属性 123456789101112131415const path = require('path')module.exports = &#123; entry: './src/main.js', output: &#123; path: path.resolve(__dirname, 'dist'), filename: 'bundle.js' &#125;, resolve: &#123; // alias: 别名 alias: &#123; 'vue$': 'vue/dist/vue.esm.js' &#125; &#125;&#125; el和template的关系1234567891011121314&lt;div id=\"app\"&gt;&lt;/div&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;script&gt; //同时有el和template时template会覆盖el //&lt;div id=\"app\"&gt;&lt;/div&gt;会被替换为template的内容 const app = new Vue(&#123; el: '#app', template: '&lt;div&gt;&lt;h2&gt;&#123;&#123;message&#125;&#125;&lt;/h2&gt;&lt;/div&gt;', data: &#123; message: '你好啊' &#125; &#125;)&lt;/script&gt; Vue组件化开发引入安装npm install vue-loader vue-template-compiler --save-dev 修改webpack.config.js的配置文件 这里使用webpack可能会遇到错误 原因是从14版本的vue-loader需要安装别的插件。将package.json的vue-loader修改为&quot;vue-loader&quot;: &quot;^13.0.0&quot; ^13.0.0的意思是，如果没有13.0.0版本会在13-14版本中找一个版本 这样就可以使用.vue文件 引入vue文件需要写全名 template标签：模板 style标签：css样式 script标签：写导出的组件对象 12345678910111213141516171819202122232425262728293031323334&lt;template&gt; &lt;div&gt; &lt;h2 class&#x3D;&quot;title&quot;&gt;&#123;&#123;message&#125;&#125;&lt;&#x2F;h2&gt; &lt;button @click&#x3D;&quot;btnClick&quot;&gt;按钮&lt;&#x2F;button&gt; &lt;h2&gt;&#123;&#123;name&#125;&#125;&lt;&#x2F;h2&gt; &lt;Cpn&#x2F;&gt; &lt;&#x2F;div&gt;&lt;&#x2F;template&gt;&lt;script&gt; import Cpn from &#39;.&#x2F;Cpn.vue&#39; export default &#123; name: &quot;App&quot;, components: &#123; Cpn &#125;, data() &#123; return &#123; message: &#39;Hello Webpack&#39;, name: &#39;coderwhy&#39; &#125; &#125;, methods: &#123; btnClick() &#123; &#125; &#125; &#125;&lt;&#x2F;script&gt;&lt;style scoped&gt; .title &#123; color: green; &#125;&lt;&#x2F;style&gt; 如果需要配置不用后缀名引入需要在webpack.config.js文件内resolve添加属性 resolve: { // alias: 别名 extensions: [&#39;.js&#39;, &#39;.css&#39;, &#39;.vue&#39;], alias: { &#39;vue$&#39;: &#39;vue/dist/vue.esm.js&#39; } } plugin版权声明在生成的文件中添加版权声明 在webpack.config.js文件内添加 1234const webpack = require('webpack')module.exports = &#123; plugins: [new webpack.BannerPlugin('版权归dian所有')]&#125; html打包打包html代码到dist目录下 安装插件npm install html-webpack-plugin --save-dev 在webpack.config.js文件内添加 12345678const HtmlWebpackPlugin = require('html-webpack-plugin')module.exports = &#123; plugins: [ //指定要打包的html new HtmlWebpackPlugin(&#123; template: 'index.html' &#125;)]&#125; 压缩js代码将代码压缩。这里会删掉版权声明的注释 安装npm install uglifyjs-webpack-plugin@1.1.1 --save-dev 在webpack.config.js文件内添加 本地服务器基于nnode.js搭建，内部使用express框架，可以实现我们想要的让浏览器自动刷新显示我们修改后的结果。是内存上修改，速度极快。只有确认编译才会写到内存 安装npm install --save-dev webpack-dev-server@2.9.1 在webpack.config.js文件内添加 还可以配置以下属性 pcontentBase：为哪一个文件夹提供本地服务，默认是根文件夹，我们这里要填写./dist pport：端口号 默认是8080 inline：页面实时刷新 phistoryApiFallback：在SPA页面中，依赖HTML5的history模式 在package.json文件下,scripts对象下添加&quot;dev&quot;: &quot;webpack-dev-server --open&quot; –open是自动打开网页 开发和发布配置分离先创建一个base.condif.js放基础配置。 npm install webpack-merge --save-dev 使用包合并baseConfig导出 123456789const webpackMerge = require('webpack-merge')const baseConfig = require('./base.config')module.exports = webpackMerge(baseConfig, &#123; devServer: &#123; contentBase: './dist', inline: true &#125;&#125;) 然后指定配置文件的位置webpack --config ./xx/xx.js。记得修改package.json中scripts的指令 Vue Cli脚手架Vue Cli脚手架可以帮助我们快速搭建项目环境 安装需要Node环境。要求8.9以上或者更高的版本 设置淘宝镜像npm install -g cnpm --registry=https://registry.npm.taobao.org。然后就可以用cnpm install xxx 安装webpacknpm install webpack -g 安装脚手架npm install -g @vue/cli 拉取vue-cli 2.x的脚手架npm install @vue/cli-init 创建项目Vue CLI2初始化项目 vue init webpack my-project Vue CLI3初始化项目 vue create my-project 如果遇到问题尝试使用管理员身份安装，再不行。删除C:\\Users\\User\\AppData\\Roaming\\npm-cache目录。再不行，删除目录再重新安装 详解Vue CLI2详解 项目名称，直接回车即是创建时指定的默认的文件夹名称 项目描述 作者：默认读取git信息，可修改 Vue build：选择运行+编译还是只运行。一般选只运行。这里暂时先选运行+编译 是否安装vue-路由：还没学到暂时选no Es-Lint：js代码限制。自动检查代码规范，如果不规范编译会报错。 选择规范：标准规范或爱彼迎规范或配置自己的标准 单元测试：中国比较少，先选no e2e：end to end 端到端测试。一般由测试人员。先选no 用npm还是yarn管理 了解vuecli-cli2的目录结构 查看package.json文件下的命令 123456\"scripts\": &#123; \"dev\": \"webpack-dev-server --inline --progress --config build/webpack.dev.conf.js\", \"start\": \"npm run dev\", \"lint\": \"eslint --ext .js,.vue src\", \"build\": \"node build/build.js\" &#125; build：用node运行buildjs node可以直接执行代码。node是c++写的，基于V8引擎 build/build.js 12345678910111213141516171819202122232425262728//先删除之前的dist文件夹rm(path.join(config.build.assetsRoot, config.build.assetsSubDirectory), err =&gt; &#123; if (err) throw err //获取webpack.prod.conf.js配置 //然后执行webpack webpack(webpackConfig, (err, stats) =&gt; &#123; spinner.stop() if (err) throw err process.stdout.write(stats.toString(&#123; colors: true, modules: false, children: false, // If you are using ts-loader, setting this to true will make TypeScript errors show up during build. chunks: false, chunkModules: false &#125;) + '\\n\\n') if (stats.hasErrors()) &#123; console.log(chalk.red(' Build failed with errors.\\n')) process.exit(1) &#125; console.log(chalk.cyan(' Build complete.\\n')) console.log(chalk.yellow( ' Tip: built files are meant to be served over an HTTP server.\\n' + ' Opening index.html over file:// won\\'t work.\\n' )) &#125;)&#125;) dev：webpack-dev-server --inline --progress --config build/webpack.dev.conf.js搭建本地服务器俩项配置，指定配置文件 config 配置文件index.js为主要配置。dec.env.js为开发配置。prod.env.js为生产配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980'use strict'// Template version: 1.3.1// see http://vuejs-templates.github.io/webpack for documentation.const path = require('path')module.exports = &#123; dev: &#123; // Paths assetsSubDirectory: 'static', assetsPublicPath: '/', proxyTable: &#123;&#125;, // Various Dev Server settings //主机 host: 'localhost', // can be overwritten by process.env.HOST //端口号 port: 8080, // can be overwritten by process.env.PORT, if port is in use, a free one will be determined //是否自动打卡浏览器 autoOpenBrowser: false, errorOverlay: true, notifyOnErrors: true, poll: false, // https://webpack.js.org/configuration/dev-server/#devserver-watchoptions- // Use Eslint Loader? // If true, your code will be linted during bundling and // linting errors and warnings will be shown in the console. //改为false可以取消代码检查 useEslint: true, // If true, eslint errors and warnings will also be shown in the error overlay // in the browser. showEslintErrorsInOverlay: false, /** * Source Maps */ // https://webpack.js.org/configuration/devtool/#development devtool: 'cheap-module-eval-source-map', // If you have problems debugging vue-files in devtools, // set this to false - it *may* help // https://vue-loader.vuejs.org/en/options.html#cachebusting cacheBusting: true, cssSourceMap: true &#125;, build: &#123; // Template for index.html index: path.resolve(__dirname, '../dist/index.html'), // Paths assetsRoot: path.resolve(__dirname, '../dist'), assetsSubDirectory: 'static', assetsPublicPath: '/', /** * Source Maps */ productionSourceMap: true, // https://webpack.js.org/configuration/devtool/#production devtool: '#source-map', // Gzip off by default as many popular static hosts such as // Surge or Netlify already gzip all static assets for you. // Before setting to `true`, make sure to: // npm install --save-dev compression-webpack-plugin productionGzip: false, productionGzipExtensions: ['js', 'css'], // Run the build command with an extra argument to // View the bundle analyzer report after build finishes: // `npm run build --report` // Set to `true` or `false` to always turn it on or off bundleAnalyzerReport: process.env.npm_config_report &#125;&#125; static 静态资源，会原封不动的放到dist文件夹下。src的资源会经过处理.getkeep是git的文件 .babelrc 配置ES6转ES5&quot;browsers&quot;: [&quot;&gt; 1%&quot;, &quot;last 2 versions&quot;, &quot;not ie &lt;= 8&quot;]适配市场份额大于百分之一最后两个版本，ie版本小于8的就不考虑了 .editorconfig 配置项目的规范。如编码类型，缩进 换行 在追后新加一行 清除空格等等 .eslinitignore 一些文件或文件夹下的文件的代码不规范 忽略检查 .gitignore 配置一些文件不传到git仓库 package.json 配置要安装的依赖的大概的版本 package-lock.json 配置要安装的依赖的真实版本 Runtime-Compiler和Runtime-only的区别区别只再main.js里面 runtime-compiler 12345new Vue(&#123; el: '#app', components: &#123; App &#125;, template: '&lt;App/&gt;'&#125;) Runtime-only 12345new Vue(&#123; el: '#app', //箭头函数 render: h =&gt; h(App)&#125;) 本质： 1234567891011121314151617//在runtime-compiler下也可以使用render函数new Vue(&#123; el: '#app', render: function (createElement) &#123; // 1.普通用法: createElement('标签', &#123;标签的属性&#125;, ['']) // return createElement('h2', // &#123;class: 'box'&#125;, // ['Hello World', createElement('button', ['按钮'])]) // 2.传入组件对象: return createElement(App) &#125;&#125;)// runtime-compiler(v1)// template -&gt; ast -&gt; render -&gt; vdom -&gt; UI// runtime-only(v2)(1.性能更高 2.下面的代码量更少)// render -&gt; vdom -&gt; UI 在vue中的template是由vue-template-compiler解析，而它是运行时依赖。在vue对象内是没有template的。vue内只有render。 Vue CLI3详解vue cli3 不是vue3。 nvue-cli 3 与 2 版本有很大区别 vue-cli 3 是基于 webpack 4 打造，vue-cli 2 还是 webapck 3 vue-cli 3 的设计原则是“0配置”，移除的配置文件根目录下的，build和config等目录。配置隐藏了起来 vue-cli 3 提供了 vue ui 命令，提供了可视化配置，更加人性化 移除了static文件夹，新增了public文件夹，并且index.html移动到public中 vue create 项目名 Please pick a preset：默认 和手动选择（空格选择和取消），目前只选择babel linter就是代码检测 pwa先进的app，多很多功能（了解）。 Where do you prefer placing config for Babel, PostCSS, ESLint, etc.：这些配置是单独的配置文件 还是放在package.json后 目前选单独的配置文件 Save this as a preset for future projects?：是否保存到未来的项目中。那么以后创建第一步会有第三个选项就是 按yes 后取的名 目前选y Save preset as：给你保存的配置取名 Pick the package manager to use when installing dependencies：选择包个管理工具 用npm 如果想删除自己的默认配置在C:\\Users\\User\\.vuerc内删除 rc：在linux中一般与终端有关的都叫rc（run command） vcs：version control system （版本控制git） 了解vuecli-cli3的目录结构参照vli3的配置笔记阅读 许多配置依赖都隐藏在@vue/cli-service里所以cli3中很多配置看起来没有cl2多 命令：npm run serve：”vue-cli-service serve” “build”: “vue-cli-service build”。使用了vue-cli-service依赖启动 main.js代码阅读 12345678import Vue from 'vue'import App from './App.vue'//在编译时候的提示信息。在构建的时候一般需要。开发的时候一般设置为falseVue.config.productionTip = false//在传el属性的时候 vue内部其实使用的还是mount。俩种写法是一样的new Vue(&#123; render: h =&gt; h(App),&#125;).$mount('#app') cli3配置详解确定依赖vue版本号，在vue项目的dist下的vue.js中注释部分会写。 在命令行输入vue ui。如何导入项目，就通过图形化界面可以查看和修改增加配置 其实依赖都隐藏到node_modules\\@vue\\cli-service\\webpack.config.js所引入的lib下的Service.js 如果需要自己配置，在项目根目录下创建vue.config.js文件。在内写自己的配置。项目会自动将自己的配置和默认配置合并 123module.exports = &#123;&#125; 箭头函数和this1234567const a = () =&gt; &#123;&#125;const b = h =&gt; &#123;&#125;const c = (a, b) =&gt; &#123;&#125;const d = () =&gt; alert(1)//会自动返回 不用写return//如果没有返回值，会返回undefinedconst e = (a, b) =&gt; a + b 箭头函数的this问题 箭头函数是没有this的。箭头函数中的this是在定义函数的时候绑定的。可以理解为会向最近的外层找this 而普通函数的this是在调用该函数的时候才会有的。谁调用它。谁就是this。这里的setTimeout是由dom调用所以this就是window 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/*setTimeout(function () &#123; console.log(this);//window&#125;, 1000)setTimeout(() =&gt; &#123; console.log(this);//window&#125;, 1000)*/// 问题: 箭头函数中的this是如何查找的了?// 答案: 向外层作用域中, 一层层查找this, 直到有this的定义.// const obj = &#123;// aaa() &#123;// //是由dom调用// setTimeout(function () &#123;// console.log(this); // window// &#125;)// setTimeout(() =&gt; &#123;// console.log(this); // obj对象// &#125;)// &#125;// &#125;// obj.aaa()const obj = &#123; aaa() &#123; setTimeout(function () &#123; setTimeout(function () &#123; console.log(this); // window &#125;) setTimeout(() =&gt; &#123; console.log(this); // window &#125;) &#125;) setTimeout(() =&gt; &#123; setTimeout(function () &#123; console.log(this); // window &#125;) setTimeout(() =&gt; &#123; console.log(this); // obj &#125;) &#125;) &#125;&#125;obj.aaa() Vue router路由：就是通过互联的网络把信息从来源传输到目的地 前端路由、后端路由后端：在后端会有controller来对应url映射 前端：SPA，单页面。改变URL，而页面不会整体刷新。仅仅改变内部组件 改变url，却不发起请求的方式URL的hash1location.hash = '/bar' history12345678910//history可以看作是一个栈。pushState相当于压栈。URL上显示的是栈顶元素history.pushState(&#123;&#125;,'','/bar')//替换栈顶元素history.replaceState(&#123;&#125;,'','')//go(-1)是跳到前一个。go(2)是跳到当前的后面第二个history.go(-1)//等价于go(1)history.forward()//等价于go(-1)history.back() 认识vue-routerAngular、React、Vue都有路由实现 vue-router官网 安装vue-router：npm install vue-router --save 脚手架安装是有默认路由的，这里是从0开始。 在根目录下创建router文件夹。不再router下创建index.js文件 在index.js文件内导入路由对象，调用Vue.use(VueRouter) 创建路由实例，并且传入路由映射配置 在Vue实例中挂载创建的路由实例 1234567891011121314151617//router/index.js// 配置路由相关的信息import VueRouter from 'vue-router'import Vue from 'vue'// 1.通过Vue.use(插件), 安装插件Vue.use(VueRouter)// 2.创建VueRouter对象const routes = []const router = new VueRouter(&#123; // 配置路由和组件之间的应用关系 routes&#125;)// 3.将router对象传入到Vue实例export default router 123456789101112//main.jsimport Vue from 'vue'import App from './App'//会自动 去找文件夹下的index文件import router from './router'Vue.config.productionTip = falsenew Vue(&#123; el: '#app', //在Vue实例中挂载创建的路由实例 router, render: h =&gt; h(App)&#125;) 使用vue-router 创建路由组件 配置路由映射: 组件和路径映射关系 使用路由: 通过&lt;router-link&gt;和&lt;router-view&gt; 12345678910111213141516171819202122//router/index.jsimport VueRouter from 'vue-router'import Vue from 'vue'import Home from '../components/Home'import About from '../components/About'Vue.use(VueRouter)const routes = [ &#123; path: '/home', component: Home &#125;, &#123; path: '/about', component: About &#125;]const router = new VueRouter(&#123; // 配置路由和组件之间的应用关系 routes&#125;)// 3.将router对象传入到Vue实例export default router router-link是自动注册的组件，全局组件。本质是a router-view是显示组件的位置 12345678&lt;template&gt; &lt;div id=\"app\"&gt; &lt;h2&gt;我是APP组件&lt;/h2&gt; &lt;router-link to=\"/home\" &gt;首页&lt;/router-link&gt; &lt;router-link to=\"/about\" &gt;关于&lt;/router-link&gt; &lt;router-view&gt;&lt;/router-view&gt; &lt;/div&gt;&lt;/template&gt; 配置history模式vue-router默认是hash模式 这样跳转页面URL会有#比较不美观 在VueRouter下加一个mode属性即可 123const router = new VueRouter(&#123; mode: 'history'&#125;) 配置默认路由希望用户进入的就是首页 在routes下配置默认路径 1234567const routes = [ &#123; path: '',//'/'也是可以的 // redirect重定向 redirect: '/home' &#125;] router-link属性配置 tag: tag可以指定&lt;router-link&gt;之后渲染成什么组件, 比如下面的代码会被渲染成一个&lt;button&gt;元素, 而不是&lt;a&gt; &lt;router-link to=&#39;/home&#39; tag=&#39;button&#39;&gt; replace: replace不会留下history记录, 所以指定replace的情况下, 后退键返回不能返回到上一个页面中。相当于将pushState改成了replaceState active-class: 当&lt;router-link&gt;对应的路由匹配成功时, 会自动给当前元素设置一个router-link-active的class属性, 该属性可以通过增加active-class属性来指定class 也可以在router实例对象下新增一个属性 123const router = new VueRouter(&#123; linkActiveClass: 'active'&#125;) 通过代码跳转路由 12345678910//在vue对象中定义methods: &#123; homeClick() &#123; // 通过代码的方式修改路由 vue-router // push =&gt; pushState // this.$router.push('/home') this.$router.replace('/home') console.log('homeClick'); &#125;&#125; vue-router进阶动态路由我们希望URL有时能够使双层路径 在定义路由映射的时候加上:变量名 123456const routes = [ &#123; path: '/user/:u_id', component: Home &#125;] 通过$route获取被选中的路由 123456&#x2F;&#x2F;在页面中使用mustache语法获取&lt;p&gt;&#123;&#123;$route.params.u_id&#125;&#125;&lt;&#x2F;p&gt;&#x2F;&#x2F;或者通过计算属性f()&#123; return this.$route.params.u_id&#125; 在模板中可以用v-bind绑定to属性 1&lt;router-link :to=\"'user'+属性名\"&gt; &lt;/router-link&gt; 懒加载vue打包后，将css和js分开。并且将js分成三个文件main…、vendor…、app… app…：写的是开发的代码 vendor…：写的是第三方依赖的代码 main…：是做底层支撑的代码 懒加载会根据路由分割文件。需要用到某个路由时再去请求文件。 懒加载有三种方式，推荐第三种，前俩种要认识： const Home = resolve =&gt; { require.ensure([&#39;../components/Home.vue&#39;], () =&gt; { resolve(require(&#39;../components/Home.vue&#39;)) })}; 用得极少const About = resolve =&gt; require([&#39;../components/About.vue&#39;], resolve); const Home = () =&gt; import(&#39;../components/Home.vue&#39;) 嵌套路由希望一级路由下有二级路由 绑定不同的组件 12345678910111213141516171819202122232425const routes = [ &#123; //在一级路由下。继续有二级路由现实的router-view path: '/home', component: Home, meta: &#123; title: '首页' &#125;, //配置二级路由和默认的二级路由 children: [ &#123; path: '', redirect: 'news' &#125;, &#123; path: 'news', component: HomeNews &#125;, &#123; path: 'message', component: HomeMessage &#125; ] &#125;] 参数传递params的类型：在动态路由里讲过 query的类型： 在路径后用参数传递如localhost:8080/path?key=value 在对象中使用$route.query对象获取 123456&lt;!--在to属性内用v-bind添加对象属性。在query内添加query参数--&gt;&lt;router-link :to=\"&#123;path: '/profile', query: &#123;name: 'why', age: 18, height: 1.88&#125;&#125;\"&gt;档案&lt;/router-link&gt;&lt;!--获取参数--&gt;&#123;&#123;$route.query.name&#125;&#125;&#123;&#123;$route.query.age&#125;&#125;&#123;&#123;$route.query.height&#125;&#125; 通过方法传递参数 12345678910111213//使用$router.push方法传递参数methods:&#123; profileClick() &#123; this.$router.push(&#123; path: '/profile', query: &#123; name: 'kobe', age: 19, height: 1.87 &#125; &#125;) &#125;&#125; router和route详解$router为VueRouter的实例，本质就是我们写的router。 $route是活跃的组件。 所有的组件都继承自Vue类的原型。而route和router都会被混入Vue原型。所以所有的组件都能使用router和route 在Vue内部，Vue会注册View和Link的全局组件 Object.defineProperty(obj, &#39;age&#39;, 18)在阅读源码时遇到的。这句话的意思是往obj对象内添加一个age属性值为18 全局导航守卫手册 需求，当更换路由的时候，改变页面标题。 可以通过生命周期函数，在组件被创建的时候，改变标题。但是比较繁琐 生命周期函数 123456789created()&#123;//组件被创建的时候调用 &#125;,mounted()&#123;//在组件被挂载到dom时被调用 &#125;,updated()&#123;//界面更新时候调用 &#125; 这里就用到导航守卫 给路由属性加上title和使用前置守卫 12345678910111213141516171819//router/index.js//给对应的路由加上meta原属性，在原属性下加titleconst routes = [ &#123; path: '/home', component: Home, meta: &#123; title: '首页' &#125; &#125;]// 前置守卫(guard)//传递一个有三个参数的函数//一定要执行next()不然vue的使用会失效如果next中传入false就表明中断。也可以以字符串形式传入要跳转的路由router.beforeEach((to, from, next) =&gt; &#123; // 从from跳转到to。改变title document.title = to.matched[0].meta.title next()&#125;) meta：元数据（描述数据的数据） 123// 后置钩子(hook)router.afterEach((to, from) =&gt; &#123;&#125;) 前置守卫和后置钩子都被称为全局守卫，只要发生路由跳转就会回调这两个函数 这里还有路由独享受委，和组件内的守卫，原理一样，具体查看官方文档 keep-alive因为每次跳转路由，组件都会重新创建。这里就要使用keep-alive保存信息 keep-alive使用，只需要将&lt;keep-alive&gt;标签包裹住router-view即可。可提高效率 12345678910// 这两个函数, 只有该组件被保持了状态使用了keep-alive时, 才是有效的。//当前页面被显示时候执行activated() &#123; this.$router.push(this.path); console.log('activated');&#125;,//当前页面不被显示时候执行deactivated() &#123; console.log('deactivated');&#125; keep-alive属性keep-alive有俩个属性，include和exclude分别 include：字符串或正则表达，只有匹配的组件会被缓存 exclude：字符串或正则表达式，任何匹配的组件都不会被缓存 可用字符串分割 小项目tabbar手记 在vue文件中的&lt;style&gt;内引入css文件@import &quot;相对路径&quot; 一般手机app底部选项组件的高度为49px 插槽替换的时候，&lt;slot&gt;会被整个替换掉，上面的属性也会无法起作用，所以属性要写在新加一个div，然后包裹slot 在项目里，由底部按钮控制路由一般会在src目录下创建一个新文件夹views或pages，再在该文件夹下创建对应组建的目录，然后与之相关的组件都放在对应的目录下。如home组件和它的子组件都放在home文件夹下 components文件夹下只放公共的组件 路径起别名在webpack.base.conf.js文件内。resolve.alias属性添加别名。默认有&#39;@&#39;:resolve(&#39;src&#39;) 自己一般添加assets:resolve(&#39;@/assets&#39;)等类似的 脚手架3中在定义别名时可以使用已经定义的，脚手架2不行 import是可以直接使用别名 但是dom内无法直接使用别名，需要在别名前添加~符号 PromisePromise是ES6中的一种重要 好用的特性。一种异步编程的解决方案 当网络请求十分复杂的时候，可能会出现回调地狱（在ajax请求的回调函数内还要执行ajax请求，嵌套多层ajax请求） 12345678910111213141516171819202122232425262728293031//实现停留一秒后打印Hello World，然后再停一秒打印Hello Vuejs，再停一秒打印Hello Python// 参数 -&gt; 函数(resolve, reject)// resolve, reject本身它们又是函数// 链式编程new Promise((resolve, reject) =&gt; &#123; // 第一次网络请求的代码 setTimeout(() =&gt; &#123; resolve() &#125;, 1000)&#125;).then(() =&gt; &#123; // 第一次拿到结果的处理代码 console.log('Hello World'); return new Promise((resolve, reject) =&gt; &#123; // 第二次网络请求的代码 setTimeout(() =&gt; &#123; resolve() &#125;, 1000) &#125;)&#125;).then(() =&gt; &#123; // 第二次处理的代码 console.log('Hello Vuejs'); return new Promise((resolve, reject) =&gt; &#123; // 第三次网络请求的代码 setTimeout(() =&gt; &#123; resolve() &#125;) &#125;)&#125;).then(() =&gt; &#123; // 第三处理的代码 console.log('Hello Python');&#125;) 12345678910111213141516171819202122232425262728//resolve对应then方法，reject对应catch方法，可以简写到then内new Promise((resolve, reject) =&gt; &#123; setTimeout(() =&gt; &#123; // resolve('Hello Vuejs') reject('error message') &#125;, 1000)&#125;).then(data =&gt; &#123; console.log(data);&#125;, err =&gt; &#123; console.log(err);&#125;)// 一般情况下是有异步操作时,使用Promise对这个异步操作进行封装// new -&gt; 构造函数(1.保存了一些状态信息 2.执行传入的函数)// 在执行传入的回调函数时, 会传入两个参数, resolve, reject.本身又是函数new Promise((resolve, reject) =&gt; &#123; setTimeout(() =&gt; &#123; // 成功的时候调用resolve // resolve('Hello World') // 失败的时候调用reject reject('error message') &#125;, 1000)&#125;).then((data) =&gt; &#123; // 1.处理代码 console.log(data);&#125;).catch((err) =&gt; &#123; console.log(err);&#125;) 简写12345678return new Promise((resolve, reject) =&gt; &#123; // resolve(res + '111') reject('err')&#125;)// new Promise(resolve =&gt; resolve(结果))简写return Promise.resolve(res + '111')//简写return Promise.resolve(res + '111')return res + '111' promise.all网络请求中，如果一个需求需要俩个网络请求才能继续。用通常的方法比较繁琐，因为我们不知道俩个请求完成的顺序。 这时就需要用promise.all方法 12345678910111213141516171819202122232425262728293031//传入一个可迭代的对象Promise.all([ // new Promise((resolve, reject) =&gt; &#123; // $.ajax(&#123; // url: 'url1', // success: function (data) &#123; // resolve(data) // &#125; // &#125;) // &#125;), // new Promise((resolve, reject) =&gt; &#123; // $.ajax(&#123; // url: 'url2', // success: function (data) &#123; // resolve(data) // &#125; // &#125;) // &#125;) new Promise((resolve, reject) =&gt; &#123; setTimeout(() =&gt; &#123; resolve(&#123;name: 'why', age: 18&#125;) &#125;, 2000) &#125;), new Promise((resolve, reject) =&gt; &#123; setTimeout(() =&gt; &#123; resolve(&#123;name: 'kobe', age: 19&#125;) &#125;, 1000) &#125;)//results会有以上结果的值，按函数的顺序一致]).then(results =&gt; &#123; console.log(results);&#125;) VuexVuex是Vue.js的状态管理的工具。 Vuex可以理解为一个保存多个组件共享变量的对象。可以通过Vuex获取和改变（响应式） Vuex一般只存放多个页面都需要共享的变量 初步使用先安装vuexnpm install vuex --save 在src下创建文件夹store，在该文件夹下创建index.js 1234567891011121314151617181920212223242526272829import Vue from 'vue'import Vuex from 'vuex'// 1.安装插件Vue.use(Vuex)// 2.创建对象const store = new Vuex.Store(&#123; //这些都是固有属性 //state写状态 state:&#123; &#125;,//方法 mutations:&#123; &#125;, actions:&#123; &#125;, getters:&#123; &#125;, modules:&#123; &#125;&#125;)// 3.导出store独享export default store 在main.js里挂载 123new Vue(&#123; store&#125;) 在别的页面可以通过 可以通过&lt;button @click=&quot;$store.state.counter++&quot;/&gt; 但是Vue官方不建议这种直接修改的方式。 官方建议通过Actions-&gt;Mutations来修改state，而不是直接修改State。 因为在调试的时候，Devtools只能监控通过Mutations内的，并做记录。也可以vue直接通过mustations来修改state，但是如果mustations内有异步操作的话，会导致Devtools监控不到。这里在actions里做异步操作。将同步操作放到Mutations内 devtools、mutations在chrom安装开发者工具。在扩展商店，安装。重启浏览器。F12内有Vue界面即可 在mutations方法内，添加自己想用的方法 12345678910const store = new Vuex.Store(&#123; state:&#123; counter: 100 &#125;,//方法 mutations:&#123;//里面方法，默认传入state increment(state)&#123; state.counter++ &#125; &#125;&#125;) 在vue对象内添加对应调用mutations的方法 12345methods:&#123; addition()&#123;//不是直接调用，二十通过commit提交 this.$store.commit('increment') &#125;&#125; 详解vuex-state单一状态树将所有共享信息统一放在一个store内。不推荐多个store getters类似于计算属性 12345678910111213getter: &#123;//默认传入state属性 ageSum(state)&#123; &#125;,//俩个参数，第二个就是getters，可以直接使用定义的 ageSum2(state,getters)&#123; getters.ageSum &#125;,//可以返回一个带参数的函数，这样就可以调用的 ageSum3(state)&#123; return function(age)&#123; return … &#125; &#125;&#125; 页面使用 mutation带参1234//将state的counter加上countincrementCount(state,count)&#123; state.counter+=count&#125; 使用$store.commit(&#39;incrementCount&#39;,count)，第二个填要传的参数 参数被称为是mutation的载荷(Payload) this.$store.commit({type: &#39;incrementCount&#39;,count})如果提交的是一个对象的话，那么mutation中拿到的是Payload对象 vuex响应式原理所有响应式的数据，必须初始化。 初始化的属性都会被加入响应式系统当中，响应式系统会监听属性的变化，当属性发生变化，会通知所有界面刷新属性 vuex无法监听新增/删除的属性，但是可以通过Vue.set(对象,属性名,值)/vue.delete(对象,属性名)方法使其响应式增加 Mutation常量因为Mutation的方法名称，我们可能需要经常使用，每次手写容易出错，所以就采用定义常量的方法，来规避错误。 在store新建文件mutation-type.js在里面定义常量export const XXX=&#39;XXX&#39;将方法名称替代成[XXX]，在方法使用时this.$store.commit(XXX,参数) actions使用当有异步操作修改state时候，就需要actions来完成异步。一般在对应的mutation的方法名称前加一个a来做actions对应的方法。 在内完成异步操作当要修改state的值的时候，通过context.commit(&#39;方法名&#39;)调用mutation的方法，用this.$store.dispatch(&#39;方法名&#39;)来调用 1234567actions: &#123;//context是store对象 aXXX(context)&#123; setTimeout(() =&gt; &#123; context.commit('XXX') &#125;,1000) &#125;&#125; actions回调12345678910111213141516//定义方法返回PromiseaXXX(context,payload)&#123; return new Promise((resolve,reject)=&gt;&#123; setTimeout(()=&gt;&#123; context.commit('xxx') resolve &#125;,1000) &#125;)&#125;//调用this.$store .dispatch('aUpdateInfo', '我是携带的信息') .then(res =&gt; &#123; console.log('里面完成了提交'); console.log(res); &#125;) modules详解随着项目越来越大，state中属性越来越多。但是要求单一state，这时要借助modules分模块。 modules内还能定义mutations、state、getters、actions 12345678910111213const moudleA = &#123; state: &#123; name : \"XXX\" &#125;, mutations: &#123;&#125;, actions: &#123;&#125;, getters: &#123;&#125;&#125;const store = new Vuex.Store(&#123; modules: &#123; a: moduleA &#125;&#125;) 在modules定义的state，解析的时候会被放入state内，使用的时候要用$store.state.模块名.属性名，不需要在模块名后加state 在modules内定义的mutation，使用时和外部的mutation一样。mutation和外部不能重名！ modules内的getters，也是和外部getter一样调用。如果还传入getter，是本modules的getter。getters还能传入第三个参数rootState就是根的state modules内的actions。actions里方法的context指的是本模块的mutation。这里的context可以通过.rootGetters和.rootState等方法拿到根的属性 对象的解构数组也可以解构 123//可以这样获取对象内的属性const obj=&#123;name:'lisi',age:18,heigh:175&#125;const &#123;name,age,heigh&#125;=obj 传参的时候也是可以使用的 文件夹目录组织 将store内的所有属性都抽离出来一个单独的文件，通过导入导出，来添加属性。modules内的在store下新建文件夹下进行创建。一般State不会抽离。 网络模块封装axios不直接使用网络请求框架是防止，框架出现漏洞，和更换框架更简易 跨域问题使用jsonp axios支持 在浏览器中发送XMLHttpRequests请求 在node.js中发送http请求 支持Promise API 拦截请求和响应 转换请求和响应数据 安装使用安装：npm install axios --save。 导入import axios from &#39;axios&#39; 使用axios({url:&#39;httpbin.org&#39;}) axios返回的是一个Promise 可以直接通过.then进行回调 httpbin.org可以进行网络测试 12345678axios(&#123;//params是要传递的参数，框架内部会自动拼接 url:'http//host:port/path', params:&#123; 参数名: 值 &#125;&#125;).then(res=&gt;&#123; &#125;) 发送并发请求123axios.all([axios(),axios()]) .then(res =&gt;&#123;&#125;) 这里返回的res默认是一个数组 1234axios.all([axios(),axios()]) .then(axios.spread((res1,res2)=&gt;&#123; &#125;)) 可以通过axios.spread将数组打散传入 axios全局配置通过设置，更axios的默认配置 axios.defaults.headers.post[‘Content-Type’] = ‘application/x-www-form-urlencoded’; axios常见配置 请求地址 url: ‘/user’, 请求类型 method: ‘get’, 请根路径 baseURL: ‘http://www.mt.com/api&#39;, 请求前的数据处理 transformRequest:[function(data){}], 请求后的数据处理 transformResponse: [function(data){}], 自定义的请求头 headers:{‘x-Requested-With’:’XMLHttpRequest’}, URL查询对象（get传递数据的方式） params:{ id: 12 }, 查询对象序列化函数 paramsSerializer: function(params){ } request body（post传递数据的方式） data: { key: ‘aa’}, 超时设置s timeout: 1000, 跨域是否带Token withCredentials: false, 自定义请求处理 adapter: function(resolve, reject, config){}, 身份验证信息 auth: { uname: ‘’, pwd: ‘12’}, 响应的数据格式 json / blob /document /arraybuffer / text / stream responseType: ‘json’, 封装axios不要在项目中直接引用第三方框架 1234567891011import axios from 'axios'export function request(config) &#123; // 1.创建axios的实例，设置自己的默认配置 const instance = axios.create(&#123; baseURL: 'http://0.0.0.0', timeout: 5000 &#125;) //return Promise return instance(config)&#125; axios拦截器123456789101112131415161718192021222324252627282930import axios from 'axios'export function request(config) &#123; // 1.创建axios的实例 const instance = axios.create(&#123; baseURL: 'http://0.0.0.0:8000', timeout: 5000 &#125;) // 2.axios的拦截器 // 2.1.请求拦截的作用 instance.interceptors.request.use(config =&gt; &#123; // console.log(config); // 1.比如config中的一些信息不符合服务器的要求 // 2.比如每次发送网络请求时, 都希望在界面中显示一个请求的图标 // 3.某些网络请求(比如登录(token)), 必须携带一些特殊的信息 return config &#125;, err =&gt; &#123; // console.log(err); &#125;) // 2.2.响应拦截 //res里会有响应码，响应数据等，响应数据一般在data属性里 instance.interceptors.response.use(res =&gt; &#123; // console.log(res); return res.data &#125;, err =&gt; &#123; console.log(err); &#125;) // 3.发送真正的网络请求 return instance(config)&#125; 项目","categories":[],"tags":[{"name":"前端","slug":"前端","permalink":"http://example.com/tags/%E5%89%8D%E7%AB%AF/"},{"name":"Vue","slug":"Vue","permalink":"http://example.com/tags/Vue/"}]},{"title":"SparkSQL","slug":"SparkSQL","date":"2019-11-02T01:05:26.000Z","updated":"2021-07-08T07:57:19.181Z","comments":true,"path":"2019/11/02/SparkSQL/","link":"","permalink":"http://example.com/2019/11/02/SparkSQL/","excerpt":"","text":"简介Spark SQL是Spark用来处理结构化数据的一个模块，它提供了2个编程抽象：DataFrame和DataSet，并且作为分布式SQL查询引擎的作用。 将Spark SQL转换成RDD，然后提交到集群执行，执行效率非常快！ 特点 易整合 统一的数据访问方式 兼容Hive 标准的数据连接 DataFrameDataFrame也是一个分布式数据容器。然而DataFrame更像传统数据库的二维表格，除了数据以外，还记录数据的结构信息 可以把它当做数据库中的一张表来对待，DataFrame也是懒执行的。性能上比RDD要高， 优化的执行计划：查询计划通过Spark catalyst optimiser进行优化。 DataSetDataframe是Dataset的特列，DataFrame=Dataset[Row] ，所以可以通过as方法将Dataframe转换为Dataset。DataSet是强类型的。比如可以有Dataset[Car]，Dataset[Person].DataFrame只是知道字段，但是不知道字段的类型。 在执行这些操作的时候是没办法在编译的时候检查是否类型失败的，比如你可以对一个String进行减法操作，在执行的时候才报错，而DataSet不仅仅知道字段，而且知道字段类型，所以有更严格的错误检查。就跟JSON对象和类对象之间的类比。 SparkSQL编程SparkSession新的起始点在老的版本中，SparkSQL提供两种SQL查询起始点：一个叫SQLContext，用于Spark自己提供的SQL查询；一个叫HiveContext，用于连接Hive的查询。 SparkSession是Spark最新的SQL查询起始点，实质上是SQLContext和HiveContext的组合，所以在SQLContext和HiveContext上可用的API在SparkSession上同样是可以使用的。SparkSession内部封装了sparkContext，所以计算实际上是由sparkContext完成的。 DataFrame创建使用SQL风格1234567891011//读取json，展示val df = spark.read.json(\"/opt/module/spark/examples/src/main/resources/peopledf.show/*SQL风格语法*///创建临时表df.createOrReplaceTempView(\"people\")//sql查询val sqlDF = spark.sql(\"SELECT * FROM people\")sqlDF.show//临时表是Session范围内的，Session退出后，表就失效了。如果想应用范围内有效，可以使用全局表。注意使用全局表时需要全路径访问，如：global_temp.peopledf.createGlobalTempView(\"people\") 临时表是Session范围内的，Session退出后，表就失效了。 DSL风格语法(次要)123456spark.readdf.printSchemadf.select(\"name\").show()//查看”name”列数据以及”age+1”数据，要用转换符df.select($\"name\", $\"age\" + 1).show()df.groupBy(\"age\").count().show() 导入的是对象的包 DateFrame、RDD和DataSet相互转化123456789101112131415161718192021222324252627282930313233343536373839404142//导入隐式转换并创建一个RDD//spark不是包名，而是sparkSession对象的名称import spark.implicits._//RDD转换为DateFrame//Shell//1val peopleRDD = sc.textFile(\"examples/src/main/resources/people.txt\")peopleRDD.map&#123;x=&gt;val para = x.split(\",\");(para(0),para(1).trim.toInt)&#125;.toDF(\"name\",\"age\")//2case class People(name:String, age:Int)peopleRDD.map&#123; x =&gt; val para = x.split(\",\");People(para(0),para(1).trim.toInt)&#125;.toDF//DateFrame转换为RDD//直接.rdd即可//DataSet创建case class Person(name: String, age: Long)val caseClassDS = Seq(Person(\"Andy\", 32)).toDS()//RDD转换为DataSetval peopleRDD = sc.textFile(\"examples/src/main/resources/people.txt\")case class Person(name: String, age: Long)peopleRDD.map(line =&gt; &#123;val para = line.split(\",\");Person(para(0),para(1).trim.toInt)&#125;).toDS()//DataSet转换为RDDval DS = Seq(Person(\"Andy\", 32)).toDS()DS.rdd//DataFrame转换为DataSetval df = spark.read.json(\"examples/src/main/resources/people.json\")case class Person(name: String, age: Long)df.as[Person]//DataSet转换为DataFramecase class Person(name: String, age: Long)val ds = Seq(Person(\"Andy\", 32)).toDS()val df = ds.toDF//DataSet转DataFrameimport spark.implicits._val testDF = testDS.toDF// DataFrame转DataSetimport spark.implicits._case class Coltest(col1:String,col2:Int)extends Serializable //定义字段名和类型val testDS = testDF.as[Coltest] 三者的共性 RDD、DataFrame、Dataset全都是spark平台下的分布式弹性数据集，为处理超大型数据提供便利 三者都有惰性机制，在进行创建、转换，如map方法时，不会立即执行，只有在遇到Action如foreach时，三者才会开始遍历运算。 三者都会根据spark的内存情况自动缓存运算，这样即使数据量很大，也不用担心会内存溢出。 三者都有partition的概念 三者有许多共同的函数，如filter，排序等 在对DataFrame和Dataset进行操作许多操作都需要这个包进行支持import spark.implicits._ DataFrame和Dataset均可使用模式匹配获取各个字段的值和类型 三者的区别 RDD: RDD一般和spark mlib(机器学习)同时使用 RDD不支持sparkSQL操作 DataFrame: 与和不同，每一行的类型固定为，每一列的值没法直接访问，只有通过解析才能获取各个字段的值 DataFrame与Dataset一般不与spark mlib同时使用 DataFrame与Dataset均支持sparksql的操作，比如select，groupby之类，还能注册临时表/视窗，进行sql语句操作 DataFrame与Dataset支持一些特别方便的保存方式，比如保存成csv，可以带上表头，这样每一列的字段名一目了然 123456//保存val saveoptions = Map(\"header\" -&gt; \"true\", \"delimiter\" -&gt; \"\\t\", \"path\" -&gt; \"hdfs://hadoop102:9000/test\")datawDF.write.format(\"com.atguigu.spark.csv\").mode(SaveMode.Overwrite).options(saveoptions).save()//读取val options = Map(\"header\" -&gt; \"true\", \"delimiter\" -&gt; \"\\t\", \"path\" -&gt; \"hdfs://hadoop102:9000/test\")val datarDF= spark.read.options(options).format(\"com.atguigu.spark.csv\").load() Dataset: Dataset和DataFrame拥有完全相同的成员函数，区别只是每一行的数据类型不同。 DataFrame也可以叫Dataset[Row],每一行的类型是Row，不解析，每一行究竟有哪些字段，各个字段又是什么类型都无从得知，只能用上面提到的getAS方法或者共性中的第七条提到的模式匹配拿出特定字段。而Dataset中，每一行是什么类型是不一定的，在自定义了case class之后可以很自由的获得每一行的信息 IDEA创建SparkSQL程序pom文件 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-sql_2.11&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122import org.apache.spark.sql.SparkSessionimport org.apache.spark.&#123;SparkConf, SparkContext&#125;import org.slf4j.LoggerFactoryobject HelloWorld &#123; def main(args: Array[String]) &#123; //创建SparkConf()并设置App名称 val spark = SparkSession .builder() .appName(\"Spark SQL basic example\") .config(\"spark.some.config.option\", \"some-value\") .getOrCreate() // For implicit conversions like converting RDDs to DataFrames import spark.implicits._ val df = spark.read.json(\"data/people.json\") // Displays the content of the DataFrame to stdout df.show() df.filter($\"age\" &gt; 21).show() df.createOrReplaceTempView(\"persons\") spark.sql(\"SELECT * FROM persons where age &gt; 21\").show() spark.stop() &#125;&#125; 用户自定义函数spark.udf.register(&quot;addName&quot;, (x:String)=&gt;&quot;Name:&quot;+x)","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"http://example.com/tags/Spark/"},{"name":"大数据","slug":"大数据","permalink":"http://example.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"}]},{"title":"SparkCore","slug":"SparkCore","date":"2019-10-30T07:38:34.000Z","updated":"2021-07-08T07:57:10.647Z","comments":true,"path":"2019/10/30/SparkCore/","link":"","permalink":"http://example.com/2019/10/30/SparkCore/","excerpt":"","text":"RDD概述 只有在collect的时候才会真正开始运行，前面都只是封装逻辑 什么是RDDRDD（Resilient DistributedDataset）叫做分布式数据集，是Spark中最基本的数据抽象。代码中是一个抽象类，它代表一个不可变、可分区、里面的元素可并行计算的集合。 分布式是指数据来源为分布式，可能来自多个文件 RDD的属性 一组分区（Partition），即数据集的基本组成单位; 一个计算每个分区的函数; RDD之间的依赖关系;（装饰者模式，血缘） 一个Partitioner，即RDD的分片函数; 一个列表，存储存取每个Partition的优先位置（数据存储的位置）（preferred location）。（移动数据不如移动计算） 首选位置是一个seq，表示优先同一个进程，其次同一个机器，再其次同一个机架 RDD特点RDD表示只读的分区的数据集，对RDD进行改动，只能通过RDD的转换操作，由一个RDD得到一个新的RDD，新的RDD包含了从其他RDD衍生所必需的信息。RDDs之间存在依赖，RDD的执行是按照血缘关系延时计算的。如果血缘关系较长，可以通过持久化RDD来切断血缘关系。 分区RDD逻辑上是分区的，每个分区的数据是抽象存在的，计算的时候会通过一个compute函数得到每个分区的数据。如果RDD是通过已有的文件系统构建，则compute函数是读取指定文件系统中的数据，如果RDD是通过其他RDD转换而来，则compute函数是执行转换逻辑将其他RDD的数据进行转换。 就是可以并行计算 只读RDD是只读的，要想改变RDD中的数据，只能在现有的RDD基础上创建新的RDD。 由一个RDD转换到另一个RDD，可以通过丰富的操作算子实现，不再像MapReduce那样只能写map和reduce了 算子从认知心理学角度，解决问题其实是将问题的初始化状态，通过一系列的操作（算子）对问题的状态进行转化，然后达成完成（解决）状态。 Spark中的所有的RDD方法都称之为算子，但是分为2大类：转化算子&amp;行动算子 创建RDD创建RDD方式分为3种：从集合中创建；从外部存储创建；从其他RDD创建 从集合中创建从集合中创建RDD，Spark主要提供了两种函数：parallelize和makeRDD 12val rdd = sc.parallelize(Array(1,2,3,4,5,6,7,8))val rdd1 = sc.makeRDD(Array(1,2,3,4,5,6,7,8)) 从外部存储创建包括本地的文件系统，还有所有Hadoop支持的数据集，比如HDFS、Cassandra、HBase等 1val rdd2= sc.textFile(\"hdfs://hadoop102:9000/RELEASE\") textFile&amp;makeRDD区别1234567//分区数，如果没指定就是getmin(可用Cpu核数,2)//读取文件时，传递的分区参数为最小分区数，但是不一定是这个分区数，取决于Hadoop读取文件时分片规则sc.textFile(\"in\",2)//4，先看有没有默认值，如果没有getmax(可用的Cpu核数,2)//Local模式的时候，没有配置就是local[*]就是本机最大内核数//多余的数放最后一个分区，老师是这么说的，但是我验证是平均随机的sc.makeRDD(List(1,2,3)) RDD的转换（面试开发重点）Value类型map(func)：一个一个进行执行。 mapPartitions(func)：一个分区一个分区的执行。效率优于map 一个func是一个算子。因为map细化，所有发送执行的次数高，效率就低。mapPartitions只需要发给相应分区就行了。交互次数小，如果分区大但是可能爆内存（oom）。 mapPartitionsWithIndex(func)：类似于mapPartitions，传值要传(Int, Interator[T]) =&gt; Iterator[U] flatMap(func)：类似于map，不会扁平化(如果是RDD[List[Int]]不会扁平化为Int传入)，但是是输入一个元素，返回一个序列（0至多个元素）。但是存入还是单个元素的存。最后是一个一个的个体 glom()：将每一个分区转成一个数组，返回。 groupBy(func)：分组，按照传入函数的返回值进行分组。将相同的key对应的值放入一个迭代器。分组后的数据形成了对偶元组（K-V），K表示分组的key，v表示分组的数据集合 sample(withReplacement,fraction, seed)：随机抽样。数量为fraction（false：0-1，true：可以大于1就会重复了）的数据，withReplacement表示是抽出的数据是否放回，true为有放回的抽样，false为无放回的抽样，seed用于指定随机数生成器种子。 distinct([numTasks]))：对源RDD进行去重后返回一个新的RDD（数据打乱重组）。默认情况下，只有8个并行任务来操作，但是可以传入一个可选的numTasks参数改变它。 rdd一个分区的数据打乱重组到其他不同分区的操作，称之为shuffle。 俩个分区合并一起，不叫shuffle shuffle需要写，影响性能 coalesce(numPartitions)：减少分区数（合并分区）。默认shuffle是false，可以改为true。重新洗牌。无shuffle容易引起数据倾斜。 repartition(numPartitions)：根据分区数，重新通过网络随机洗牌所有数据。实际上是调用的coalesce sortBy(func,[ascending],[numTasks])：使用func先对数据进行处理，按照处理后的数据比较结果排序，默认为正序。ascending: Boolean = false逆序 双Value类型交互union(otherDataset)：对源RDD和参数RDD求并集后返回一个新的RDD。RDD1.union(RDD2) subtract (otherDataset)：去除两个RDD中相同的元素，不同的RDD将保留下来 intersection(otherDataset)：求交集后返回一个新的RDD cartesian(otherDataset)：笛卡尔积（少用） zip(otherDataset)：将两个RDD组合成Key/Value形式的RDD,这里默认两个RDD的partition数量以及元素数量都相同，否则会抛出异常。 Key-Value类型partitionBy：对pairRDD进行分区操作，如果原有的partionRDD和现有的partionRDD是一致的话就不进行分区， 否则就会产生shuffle过程。传一个org.apache.spark.Partitioner.也可以自己继承实现。只要k-v的RDD才可以，这里用到了隐式转换 1234567891011class MyPartitioner(partitions: Int) extends Partitioner &#123; //分区数 override def numPartitions: Int = &#123; partitions &#125; //返回去哪个分区 override def getPartition(key: Any): Int = &#123; 1 &#125;&#125; groupByKey：分组更具key，但只生成一个sequence。 reduceByKey(func,[numTasks])：根据分组Key，将俩个Value传入，返回一个Value。第二个指定任务数（并行数） 在shuffle之前有combine（预聚合）操作。写的量会低一些 aggregateByKey(zeroValue:U,[partitioner: Partitioner]) (seqOp: (U, V) =&gt; U,combOp: (U, U) =&gt; U) ：zeroValue给每个key一个初始值（第一次用），seqOp：分区内函数，combOp：分区间函数。 取出每个分区相同key对应值的最大值，然后相同key相加 rdd.aggregateByKey(0)(math.max(_,_),_+_) foldByKey(zeroValue: V)(func: (V, V) =&gt; V): RDD[(K, V)]：可以理解为，与aggregateByKey差不多。分区内和分区间用相同的函数。和aggregateByKey底层用的相同的函数 combineByKey[C](createCombiner: V =&gt; C, mergeValue: (C, V) =&gt; C, mergeCombiners: (C, C) =&gt; C)createCombiner :分区内每种key调用一次，mergeValue：分区内将createCombiner()结果与相同的key对应的值做合并，mergeCombiners：分区间相同的key做聚合 combineByKey如果不加参数的类型可能会报错，aggregateByKey中不会，因为可以通过运行时反射获得 sortByKey([ascending],[numTasks])：在一个(K,V)的RDD上调用，K必须实现Ordered接口，返回一个按照key进行排序的(K,V)的RDD mapValues(f: V =&gt; U)：只对V进行操作 join(otherDataset,[numTasks])：：在类型为(K,V)和(K,W)的RDD上调用，返回一个(K,(V,W))的RDD。性能低 cogroup(otherDataset,[numTasks]) 行动算子（Action）reduce(func)：聚集RDD中的所有元素，先聚合分区内数据，再聚合分区间数据。函数接受俩个值，返回一个 collect()：以数组的形式返回数据集的所有元素。 count()：返回RDD中元素的个数 first()：返回RDD中的第一个元素 take(n)：返回一个由RDD的前n个元素组成的数组 takeOrdered(n)：返回该RDD排序后的前n个元素组成的数组 aggregate(zeroValue: U)(seqOp: (U, T) ⇒ U, combOp: (U, U) ⇒ U)：ggregate函数将每个分区里面的元素通过seqOp和初始值进行聚合，然后用combine函数将每个分区的结果和初始值(zeroValue)进行combine操作。这个函数最终返回的类型不需要和RDD中元素类型一致。 这里分区内加初始值，分区间也会加初始值。但是之前的aggregateByKey只会在分区内加初始值 fold(num)(func)：折叠操作，aggregate的简化操作，seqop和combop一样。 saveAsTextFile(path)：将数据集的元素以textfile的形式保存到HDFS文件系统或者其他支持的文件系统，对于每个元素，Spark将会调用toString方法，将它装换为文件中的文本 saveAsSequenceFile(path)：将数据集中的元素以Hadoop sequencefile的格式保存到指定的目录下，可以使HDFS或者其他Hadoop支持的文件系统。 saveAsObjectFile(path)：用于将RDD中的元素序列化成对象，存储到文件中。 countByKey()：针对(K,V)类型的RDD，返回一个(K,Int)的map，表示每一个key对应的元素个数。 foreach(func)：在数据集的每一个元素上，运行函数func进行更新。 123456789101112//Executor中执行rdd.foreach( i=&gt;&#123; println(i*2) &#125;)//Drvier中执行rdd.collect.foreach( i=&gt;&#123; println(i*2) &#125;) Driver和Executor的关系只有算子是在Executor种执行的，如果算子中用到了Driver中的资源，则该资源必须被序列化，否则会报错。 RDD中的函数传递在实际开发中我们往往需要自己定义一些对于RDD的操作，那么此时需要主要的是，初始化工作是在Driver端进行的，而实际运行程序是在Executor端进行的，这就涉及到了跨进程通信，是需要序列化的。 使类继承scala.Serializable即可 如果Executor执行的代码段，用到的是局部变量，而不是对象属性就不用实例化i 123456789101112131415161718192021222324252627282930313233343536373839404142object SeriTest &#123; def main(args: Array[String]): Unit = &#123; //1.初始化配置信息及SparkContext val sparkConf: SparkConf = new SparkConf().setAppName(\"WordCount\").setMaster(\"local[*]\") val sc = new SparkContext(sparkConf)//2.创建一个RDD val rdd: RDD[String] = sc.parallelize(Array(\"hadoop\", \"spark\", \"hive\", \"atguigu\"))//3.创建一个Search对象 val search = new Search(\"h\")//4.运用第一个过滤函数并打印结果 val match1: RDD[String] = search.getMatche1(rdd) match1.collect().foreach(println) &#125;&#125;class Search(s:String)&#123;//过滤出包含字符串的数据 def isMatch(s: String): Boolean = &#123; s.contains(query) &#125;//过滤出包含字符串的RDD def getMatch1 (rdd: RDD[String]): RDD[String] = &#123; rdd.filter(isMatch) &#125; //过滤出包含字符串的RDD def getMatche2(rdd: RDD[String]): RDD[String] = &#123; rdd.filter(x =&gt; x.contains(query)) &#125;//过滤出包含字符串的RDD，这样就不会报错 def getMatche2(rdd: RDD[String]): RDD[String] = &#123; val query_ : String = this.query//将类变量赋值给局部变量 rdd.filter(x =&gt; x.contains(query_)) &#125;&#125; RDD依赖关系将创建RDD的一系列Lineage（血统）记录下来，以便恢复丢失的分区。RDD的Lineage会记录RDD的元数据信息和转换行为，当该RDD的部分分区数据丢失时，它可以根据这些信息来重新运算和恢复丢失的数据分区。 RDD和它依赖的父RDD（s）的关系有两种不同的类型，即窄依赖（narrow dependency）和宽依赖（wide dependency）。 窄依赖窄依赖指的是每一个父RDD的Partition最多被子RDD的一个Partition使用,窄依赖我们形象的比喻为独生子女 宽依赖宽依赖指的是多个子RDD的Partition会依赖同一个父RDD的Partition，会引起shuffle,总结：宽依赖我们形象的比喻为超生 DAGDAG(Directed Acyclic Graph)叫做有向无环图。 根据RDD之间的依赖关系的不同将DAG划分成不同的Stage，对于窄依赖，partition的转换处理在Stage中完成计算。对于宽依赖，由于有Shuffle的存在，只能在parent RDD处理完成后，才能开始接下来的计算，因此宽依赖是划分Stage的依据。 任务划分（面试重点） Application：初始化一个SparkContext即生成一个Application Job：一个（行动）Action算子就会生成一个Job Stage：根据RDD之间的依赖关系的不同将Job划分成不同的Stage，遇到一个宽依赖则划分一个Stage。 Task：Stage是一个TaskSet，将Stage划分的结果发送到不同的Executor执行即为一个Task。 Application-&gt;Job-&gt;Stage-&gt; Task每一层都是1对n的关系。 RDD缓存RDD通过persist方法或cache方法可以将前面的计算结果缓存，默认情况下 persist() 会把数据以序列化的形式缓存在 JVM 的堆空间中。 这两个方法在触发后面的action时才会缓存。 123456789101112131415161718object StorageLevel &#123; //不存 val NONE = new StorageLevel(false, false, false, false) val DISK_ONLY = new StorageLevel(true, false, false, false) //磁盘俩分 val DISK_ONLY_2 = new StorageLevel(true, false, false, false, 2) val MEMORY_ONLY = new StorageLevel(false, true, false, true) val MEMORY_ONLY_2 = new StorageLevel(false, true, false, true, 2) val MEMORY_ONLY_SER = new StorageLevel(false, true, false, false) //内存 序列化 俩分 val MEMORY_ONLY_SER_2 = new StorageLevel(false, true, false, false, 2) val MEMORY_AND_DISK = new StorageLevel(true, true, false, true) val MEMORY_AND_DISK_2 = new StorageLevel(true, true, false, true, 2) val MEMORY_AND_DISK_SER = new StorageLevel(true, true, false, false) val MEMORY_AND_DISK_SER_2 = new StorageLevel(true, true, false, false, 2) //堆外内存 val OFF_HEAP = new StorageLevel(true, true, true, false, 1)&#125; RDD CheckPointpark中对于数据的保存除了持久化操作之外，还提供了一种检查点的机制，检查点（本质是通过将RDD写入Disk做检查点）是为了通过lineage做容错的辅助，lineage过长会造成容错成本过高，这样就不如在中间阶段做检查点容错，如果之后有节点出现问题而丢失分区，从做检查点的RDD开始重做Lineage，就会减少开销。检查点通过将数据写入到HDFS文件系统实现了RDD的检查点功能。 为当前RDD设置检查点。该函数将会创建一个二进制的文件，并存储到checkpoint目录中，该目录是用SparkContext.setCheckpointDir()设置的。在checkpoint的过程中，该RDD的所有依赖于父RDD中的信息将全部被移除。对RDD进行checkpoint操作并不会马上被执行，必须执行Action操作才能触发。 键值对RDD数据分区器Spark目前支持Hash分区和Range分区，用户也可以自定义分区，Hash分区为当前的默认分区，Spark中分区器直接决定了RDD中分区的个数、RDD中每条数据经过Shuffle过程属于哪个分区和Reduce的个数 只有Key-Value类型的RDD才有分区器的，非Key-Value类型的RDD分区器的值是None 每个RDD的分区ID范围：0~numPartitions-1，决定这个值是属于那个分区的。 Hash分区ashPartitioner分区的原理：对于给定的key，计算其hashCode，并除以分区的个数取余，如果余数小于0，则用余数+分区的个数（否则加0），最后返回的值就是这个key所属的分区ID。 弊端：可能导致每个分区中数据量的不均匀，极端情况下会导致某些分区拥有RDD的全部数据。 Ranger分区RangePartitioner作用：将一定范围内的数映射到某一个分区内，尽量保证每个分区中数据量的均匀，而且分区与分区之间是有序的，一个分区中的元素肯定都是比另一个分区内的元素小或者大，但是分区内的元素是不能保证顺序的。简单的说就是将一定范围内的数映射到某一个分区内。 实现 先重整个RDD中抽取出样本数据，将样本数据排序，计算出每个分区的最大key值，形成一个Array[KEY]类型的数组变量rangeBounds； 判断keyrangeBoundskey 自定义分区要继承org.apache.spark.Partitioner 类并实现numPartitions: Int:返回创建出来的分区数。getPartition(key: Any): Int:返回给定键的分区编号(0到numPartitions-1)。 数据读取与保存文件格式分为：Text文件、Json文件、Csv文件、Sequence文件以及Object文件 文件系统分为：本地文件系统、HDFS、HBASE以及数据库 Text文件数据读取:textFile(String) 数据保存:saveAsTextFile(String) Json文件JSON文件中每一行就是一个JSON记录。可以通过将JSON文件当做文本文件来读取，然后利用相关的JSON库对每一条数据进行JSON解析。 使用RDD读取JSON文件处理很复杂，同时SparkSQL集成了很好的处理JSON文件的方式，所以应用中多是采用SparkSQL处理JSON文件。 导入解析json所需的包 import scala.util.parsing.json.JSON 上传json文件到HDFS $ hadoop fs -put ./examples/src/main/resources/people.json / 读取文件 val json = sc.textFile(&quot;/people.json&quot;) 解析json数据 val result = json.map(JSON.parseFull) 打印 result.collect 累加器123456789101112131415161718192021object Spark_ShareData &#123; def main(args: Array[String]): Unit = &#123; val sparkConf = new SparkConf().setMaster(\"local[*]\").setAppName(\"WordCount\") val sc: SparkContext = new SparkContext(sparkConf) val dataRDD: RDD[Int] = sc.makeRDD(List(1, 2, 3, 4, 5), 2) val i: Int = dataRDD.reduce(_ + _) println(\"i=\" + i) //i=15 var sum: Int = 0; dataRDD.foreach(i =&gt; sum += i) println(\"sum=\" + sum) //sum=0 //累加器 val accumulator: LongAccumulator = sc.longAccumulator dataRDD.foreach &#123; j =&gt; &#123; accumulator.add(j) &#125; &#125; println(\"accumulator=\" + accumulator) //accumulator=LongAccumulator(id: 144, name: None, value: 15) sc.stop() &#125;&#125; sum为0原理图： 使用累加器共享变量（只写变量。可读汇总的时候读） 自定义累加器","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"http://example.com/tags/Spark/"},{"name":"大数据","slug":"大数据","permalink":"http://example.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}]},{"title":"C++","slug":"c++","date":"2019-10-30T07:38:34.000Z","updated":"2021-07-08T09:01:36.952Z","comments":true,"path":"2019/10/30/c++/","link":"","permalink":"http://example.com/2019/10/30/c++/","excerpt":"","text":"C++一、C补充我学过C，这部分为自己一些遗忘知识点的补充 0~255的内存编号是系统占用，不可访问 *在定义是表示为指针，在使用时表解指针 野指针：指向一个非法的内存空间。 没有开过空间，就指向他 const修饰指针 1234567891011121314//常量指针//指针的指向可以修改，但指针指向的值不可以改。就是a不能改const int *p = &amp;a;*p = 20;//错误，这样不允许p = &amp;b;//正确//指针常量//指针的指向不可以修改，但指针指向的值可以改。int * const p = &amp;a;*p = 20;//正确p = &amp;b;//错误，这样不允许//都不能改const int * const p = &amp;a; 将函数的形参指针 加上const 可以避免误操作 动态分配数组大小 头文件&lt;stdlib.h&gt; malloc(m)：开辟m字节长度的空间 sizeod(x)：计算x的长度 free(p)：释放p指针所指的空间 1指针变量=(类型*)malloc(sizeof(类型)*大小); 二、内存模型C++执行时，内存大致分为4个区域： 代码区：存放函数体的二进制代码，由操作系统进行管理的 全局区：存放全局变量和静态变量以及常量 栈区：由编译器自动分配释放, 存放函数的参数值,局部变量等 堆区：由程序员分配和释放,若程序员不释放,程序结束时由操作系统回收 分区意义：不同区域存放的数据，赋予不同的生命周期, 给我们更大的灵活编程 程序运行前 代码区： 存放 CPU 执行的机器指令(二进制指令)。特点： 共享：对于频繁被执行的程序，只需要在内存中有一份代码即可 只读：防止程序意外地修改了它的指令 全局区：存放全局变量和静态变量 还存放常量区, 字符串常量和其他常量 常量：包括const修饰的全局的 全局变量：只要没写在函数体内，都叫全局变量。 该区域的数据在程序结束后由操作系统释放. 程序运行后 栈区：由编译器自动分配释放, 存放函数的参数值,局部变量等 因此不要返回局部变量的地址，栈区开辟的数据由编译器自动释放。 若使用指针返回，第一次使用，编译器会保留数据。 堆区：由程序员分配释放,若程序员不释放,程序结束时由操作系统回收 在C++中主要利用new在堆区开辟内存 指针 本质也是局部变量，存放在栈上，指针保存的数据存放在堆区。 new运算符 new返回指针。 12345678int* a = new int(10);//利用delete释放堆区数据delete p;int* arr = new int[10];//释放数组 delete 后加 []delete[] arr; 三、引用数据类型 &amp;别名 = 原名引用一旦初始化，就不可以更改，只能进行赋值操作 别名和原名指向的是同一块内存。 引用做函数形参 引用传递，也可以通过形参修改实参。 12345678910111213//地址传递void swap0(int* a, int* b) &#123; int temp = *a; *a = *b; *b = temp;&#125;//引用传递，传实参的时候和值传递是一样的void swap1(int&amp; a, int&amp; b) &#123; int temp = a; a = b; b = temp;&#125; 引用做函数返回值 123456789101112131415161718192021222324//返回局部变量引用，最好不要这么做，因为栈区的内存会被自动释放掉，但第一次使用编译器会保留int&amp; test01() &#123; int a = 10; //局部变量 return a;&#125;//返回静态变量引用int&amp; test02() &#123; static int a = 20; return a;&#125;int main() &#123; //如果函数做左值，那么必须返回引用 int&amp; ref2 = test02(); cout &lt;&lt; \"ref2 = \" &lt;&lt; ref2 &lt;&lt; endl; cout &lt;&lt; \"ref2 = \" &lt;&lt; ref2 &lt;&lt; endl; //做左值相当于将返回a赋值1000，别的使用到该引用的地方都会改为1000 test02() = 1000; cout &lt;&lt; \"ref2 = \" &lt;&lt; ref2 &lt;&lt; endl; cout &lt;&lt; \"ref2 = \" &lt;&lt; ref2 &lt;&lt; endl; system(\"pause\"); return 0;&#125; 引用本质上就是一个指针常量 在初始化的时候，本质就是数据类型* const 别名 = &amp;原名，当使用时候内部会自动解指针转化为*别名 = xx 常量引用 常用于修饰形参，防止误操作。 int&amp; ref = 10;是不合法的，引用需要指向一个合法的内存空间。当加入const为const int&amp; ref = 10;时，编译器优化代码为int temp = 10; const int&amp; ref = temp;，使用一个临时空间，来指向它。不可修改 123void showValue(const int&amp; v) &#123; cout &lt;&lt; v &lt;&lt; endl;&#125; 四、函数高级函数的默认参数 和Python规则相似，但声明和实现中只能有一个 有默认参数。 函数的占位参数 占位参数也可以有默认参数 1234//函数占位参数 void func(int a, int) &#123; cout &lt;&lt; \"this is func\" &lt;&lt; endl;&#125; 函数的重载 和Java类似，const修饰和无const是不同类型。 当类似void func(const int&amp; a)和void func(int a)虽然编译能通过，但调用时会出现二义性，报错。 默认参数往往会导致二义性。 123456789101112131415161718#include&lt;iostream&gt;using namespace std;void func(int&amp; a)&#123; cout &lt;&lt; \"func (int &amp;a) 调用 \" &lt;&lt; endl;&#125;void func(const int&amp; a)&#123; cout &lt;&lt; \"func (const int &amp;a) 调用 \" &lt;&lt; endl;&#125;int main() &#123; int a = 10; func(a); //调用无const func(10);//调用有const return 0;&#125; 五、类和对象 公共权限 public 都可以访问 保护权限 protected 类内可以访问 类外不可以访问 子类可以访问 私有权限 private 类内可以访问 类外不可以访问 子类不可以访问 struct默认权限是public class默认权限是private 对象的初始化和清理 编译器提供了俩种函数来完成初始化和清理 构造函数：用于创建对象时为属性赋值，由编译器自动调用，无需手动调用 语法：类名(){} 用法和Java类似 析构函数：用于对象销毁前系统自动调用，执行清理工作 语法： ~类名(){} 如果不写构造和析构函数，编译器会提供空的构造和析构函数。 构造函数的分类、调用 按参数分为：有参构造和无参构造 按类型分为：普通构造和拷贝构造 12345678910class Person &#123;public: //拷贝构造函数 Person(const Person&amp; p) &#123; age = p.age; cout &lt;&lt; \"拷贝构造函数!\" &lt;&lt; endl; &#125;public: int age;&#125;; 三种调用方式： 括号法：类型 变量名(参数);调用无参构造函数不能加括号，如果加了，编译器会认为这是一个函数声明 显示法：类型 变量名 = 类型(参数); 隐式转换法：类型 变量名 = 参数;编译器会转化为类型 变量名 = 类型(参数); 类型(参数);就是匿名对象，在当前行结束后，匿名对象很快就会被回收 不要利用拷贝构造函数 初始化匿名对象，编译器会认为对象重复声明。 拷贝函数的调用 C++中拷贝构造函数 调用的时机通常有三种情况 使用一个已经创建完毕的对象来初始化一个新对象 值传递的方式给函数参数传值 以值方式返回局部对象：返回的时候会重新构造一个新的对象。 构造函数调用规则 默认情况下，c++编译器至少给一个类添加4个函数 默认构造函数(无参，函数体为空)：当提供有参构造器时，就不再默认提供无参构造器。 默认析构函数(无参，函数体为空) 默认拷贝构造函数，对属性进行值拷贝：浅拷贝 赋值运算符operator=，对属性进行值拷贝 构造函数调用规则如下： 如果用户定义有参构造函数，c++不在提供默认无参构造，但是会提供默认拷贝构造 如果用户定义拷贝构造函数，c++不会再提供其他构造函数 如果不写拷贝构造，编译器会自动添加拷贝构造，并且做浅拷贝操作 拷贝 浅拷贝：简单的赋值拷贝操作。浅拷贝中的指针，只会简单的将指针的地址复制一份。 深拷贝：在堆区重新申请空间，进行拷贝操作 总结：如果属性有在堆区开辟的，一定要自己提供拷贝构造函数，防止浅拷贝带来的问题 浅拷贝往往会导致，堆区重复释放。 初始化列表 给类中的属性进行初始化操作 语法：构造函数()：属性1(值1),属性2（值2）... {} 1234//可以传入初始化Person(int a, int b, int c) :m_A(a), m_B(b), m_C(c) &#123;&#125;//可以写死初始化Person() :m_A(1), m_B(2), m_C(3) &#123;&#125; 类对象作为类成员 构造时：先调用对象成员的构造，再调用本类构造 析构时：与构造相反 静态成员 静态成员也拥有访问权限。 静态成员变量 所有对象共享同一份数据 在编译阶段分配内存 类内声明，类外初始化 静态成员函数 所有对象共享同一个函数 静态成员函数只能访问静态成员变量 大致与Java类似，但通过类名调用静态方法时，语法类名::方法名() C++对象模型和this指针 在C++中，类内的成员变量和成员函数分开存储，只有非静态成员变量才属于类的对象上，占空间。空对象占1个字节，非空是成员变量所占空间总和。 this指针：本质是指针常量，作用和Java中类似，但使用方式不同。调用属性时语法this-&gt;属性名 在成员方法返回该对象时候，例子 123456Person&amp; PersonAddPerson(Person p)&#123; 方法体; //返回对象本身 return *this;&#125; 在空指针调用成员方法，是可以调用的，只有使用到成员属性才会报错。 1234567891011121314151617181920212223242526//空指针访问成员函数class Person &#123;public: void ShowClassName() &#123; cout &lt;&lt; \"我是Person类!\" &lt;&lt; endl; &#125; void ShowPerson() &#123; if (this == NULL) &#123; return; &#125; //mAge相当于this-&gt;mAge cout &lt;&lt; mAge &lt;&lt; endl; &#125;public: int mAge;&#125;;int main() &#123; Person * p = NULL; p-&gt;ShowClassName(); //空指针，可以调用成员函数 p-&gt;ShowPerson(); //但是如果成员函数中用到了this指针，就不可以了 return 0;&#125; 修饰成员函数 常函数： 成员函数后加const我们称为这个函数为常函数 常函数内不可以修改成员属性 成员属性声明时加关键字mutable后，在常函数中依然可以修改 常函数只能调用常函数 常对象： 声明对象前加const称该对象为常对象 常对象只能调用常函数 成员属性声明时加关键字mutable后，在常函数中也可以修改 常函数，相当于将this改为了const 类型 * const 变量名 12345678910111213141516171819202122232425262728class Person &#123;public: Person() &#123; m_A = 0; m_B = 0; &#125; void ShowPerson() const &#123; //const修饰成员函数，表示指针指向的内存空间的数据不能修改，除了mutable修饰的变量 this-&gt;m_B = 100; &#125; void MyFunc() const &#123; //mA = 10000; &#125;public: int m_A; mutable int m_B; //可修改 可变的&#125;;int main() &#123; const Person person; //常量对象 return 0;&#125; 友元 友元可以使得一些类外的函数或类访问私有属性。关键字friend 友元的三种实现 全局函数做友元：在类内声明friend 返回值 方法名(形参);该方法是友元 类做友元：在类内声明friend class 类名该类是友元 成员函数做友元：在类内声明friend class 类名::方法名(形参)该类的成员函数是友元 构造方法和成员方法是可以在类内先声明，然后在类外进行定义的 12345678910111213141516171819202122232425262728293031323334353637383940414243//全局函数做友元class Building&#123; //告诉编译器 goodGay全局函数 是 Building类的好朋友，可以访问类中的私有内容 friend void goodGay(Building * building);public: Building() &#123; this-&gt;m_SittingRoom = \"客厅\"; this-&gt;m_BedRoom = \"卧室\"; &#125;public: string m_SittingRoom; //客厅private: string m_BedRoom; //卧室&#125;;void goodGay(Building * building)&#123; cout &lt;&lt; \"好基友正在访问： \" &lt;&lt; building-&gt;m_SittingRoom &lt;&lt; endl; cout &lt;&lt; \"好基友正在访问： \" &lt;&lt; building-&gt;m_BedRoom &lt;&lt; endl;&#125;void test01()&#123; Building b; goodGay(&amp;b);&#125;int main()&#123; test01(); system(\"pause\"); return 0;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859//类做友元class Building;class goodGay&#123;public: goodGay(); void visit();private: Building *building;&#125;;class Building&#123; //告诉编译器 goodGay类是Building类的好朋友，可以访问到Building类中私有内容 friend class goodGay;public: Building();public: string m_SittingRoom; //客厅private: string m_BedRoom;//卧室&#125;;Building::Building()&#123; this-&gt;m_SittingRoom = \"客厅\"; this-&gt;m_BedRoom = \"卧室\";&#125;goodGay::goodGay()&#123; building = new Building;&#125;void goodGay::visit()&#123; cout &lt;&lt; \"好基友正在访问\" &lt;&lt; building-&gt;m_SittingRoom &lt;&lt; endl; cout &lt;&lt; \"好基友正在访问\" &lt;&lt; building-&gt;m_BedRoom &lt;&lt; endl;&#125;void test01()&#123; goodGay gg; gg.visit();&#125;int main()&#123; test01(); system(\"pause\"); return 0;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566//成员函数做友元class Building;class goodGay&#123;public: goodGay(); void visit(); //只让visit函数作为Building的好朋友，可以发访问Building中私有内容 void visit2(); private: Building *building;&#125;;class Building&#123; //告诉编译器 goodGay类中的visit成员函数 是Building好朋友，可以访问私有内容 friend void goodGay::visit();public: Building();public: string m_SittingRoom; //客厅private: string m_BedRoom;//卧室&#125;;Building::Building()&#123; this-&gt;m_SittingRoom = \"客厅\"; this-&gt;m_BedRoom = \"卧室\";&#125;goodGay::goodGay()&#123; building = new Building;&#125;void goodGay::visit()&#123; cout &lt;&lt; \"好基友正在访问\" &lt;&lt; building-&gt;m_SittingRoom &lt;&lt; endl; cout &lt;&lt; \"好基友正在访问\" &lt;&lt; building-&gt;m_BedRoom &lt;&lt; endl;&#125;void goodGay::visit2()&#123; cout &lt;&lt; \"好基友正在访问\" &lt;&lt; building-&gt;m_SittingRoom &lt;&lt; endl; //cout &lt;&lt; \"好基友正在访问\" &lt;&lt; building-&gt;m_BedRoom &lt;&lt; endl;&#125;void test01()&#123; goodGay gg; gg.visit();&#125;int main()&#123; test01(); system(\"pause\"); return 0;&#125; 运算符重载 ”+“重载：operator+可以通过重载实现，相同类型和不同类型之间的加减 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253lass Person &#123;public: Person() &#123;&#125;; Person(int a, int b) &#123; this-&gt;m_A = a; this-&gt;m_B = b; &#125; //成员函数实现 + 号运算符重载 Person operator+(const Person&amp; p) &#123; Person temp; temp.m_A = this-&gt;m_A + p.m_A; temp.m_B = this-&gt;m_B + p.m_B; return temp; &#125;public: int m_A; int m_B;&#125;;//全局函数实现 + 号运算符重载//Person operator+(const Person&amp; p1, const Person&amp; p2) &#123;// Person temp(0, 0);// temp.m_A = p1.m_A + p2.m_A;// temp.m_B = p1.m_B + p2.m_B;// return temp;//&#125;//运算符重载 可以发生函数重载，这样就可以执行person+int的类型Person operator+(const Person&amp; p2, int val) &#123; Person temp; temp.m_A = p2.m_A + val; temp.m_B = p2.m_B + val; return temp;&#125;int main() &#123; Person p1(10, 10); Person p2(20, 20); //成员函数方式 Person p3 = p2 + p1; //相当于 p2.operaor+(p1) cout &lt;&lt; \"mA:\" &lt;&lt; p3.m_A &lt;&lt; \" mB:\" &lt;&lt; p3.m_B &lt;&lt; endl; Person p4 = p3 + 10; //相当于 operator+(p3,10) cout &lt;&lt; \"mA:\" &lt;&lt; p4.m_A &lt;&lt; \" mB:\" &lt;&lt; p4.m_B &lt;&lt; endl; return 0;&#125; 左移运算符重载 成员函数实现的左移运算符重载不是我们想要的，所以往往使用全局函数进行，左移运算符重载。再利用友元，来访问私有属性。 12345678910111213141516171819202122232425262728293031323334353637class Person &#123; friend ostream&amp; operator&lt;&lt;(ostream&amp; out, Person&amp; p);public: Person(int a, int b) &#123; this-&gt;m_A = a; this-&gt;m_B = b; &#125; //成员函数 实现不了 p &lt;&lt; cout 不是我们想要的效果 //void operator&lt;&lt;(Person&amp; p)&#123; //&#125;private: int m_A; int m_B;&#125;;//全局函数实现左移重载//ostream对象只能有一个ostream&amp; operator&lt;&lt;(ostream&amp; out, Person&amp; p) &#123; out &lt;&lt; \"a:\" &lt;&lt; p.m_A &lt;&lt; \" b:\" &lt;&lt; p.m_B; return out;&#125;int main() &#123; Person p1(10, 20); cout &lt;&lt; p1 &lt;&lt; \"hello world\" &lt;&lt; endl; //链式编程 system(\"pause\"); return 0;&#125; 递增运算符重载 前置递增：返回引用，对同一个对象操作 后置递增：返回值。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class MyInteger &#123; friend ostream&amp; operator&lt;&lt;(ostream&amp; out, MyInteger myint);public: MyInteger() &#123; m_Num = 0; &#125; //前置++ MyInteger&amp; operator++() &#123; //先++ m_Num++; //再返回 return *this; &#125; //后置++ MyInteger operator++(int) &#123; //先返回 MyInteger temp = *this; //记录当前本身的值，然后让本身的值加1，但是返回的是以前的值，达到先返回后++； m_Num++; return temp; &#125;private: int m_Num;&#125;;ostream&amp; operator&lt;&lt;(ostream&amp; out, MyInteger myint) &#123; out &lt;&lt; myint.m_Num; return out;&#125;//前置++ 先++ 再返回void test01() &#123; MyInteger myInt; cout &lt;&lt; ++myInt &lt;&lt; endl; cout &lt;&lt; myInt &lt;&lt; endl;&#125;//后置++ 先返回 再++void test02() &#123; MyInteger myInt; cout &lt;&lt; myInt++ &lt;&lt; endl; cout &lt;&lt; myInt &lt;&lt; endl;&#125;int main() &#123; test01(); //test02(); system(\"pause\"); return 0;&#125; 赋值运算符 编译器默认提供一个浅拷贝的赋值运算方法。但往往我们需要深拷贝就需要重载赋值运算符. 注意点： 如果当前被赋值的对象，已经占用空间，应该先释放，再给它分配空间 返回引用，使得可以连等 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273class Person&#123;public: Person(int age) &#123; //将年龄数据开辟到堆区 m_Age = new int(age); &#125; //重载赋值运算符 Person&amp; operator=(Person &amp;p) &#123; if (m_Age != NULL) &#123; delete m_Age; m_Age = NULL; &#125; //编译器提供的代码是浅拷贝 //m_Age = p.m_Age; //提供深拷贝 解决浅拷贝的问题 m_Age = new int(*p.m_Age); //返回自身 return *this; &#125; ~Person() &#123; if (m_Age != NULL) &#123; delete m_Age; m_Age = NULL; &#125; &#125; //年龄的指针 int *m_Age;&#125;;int main() &#123;Person p1(18); Person p2(20); Person p3(30); p3 = p2 = p1; //赋值操作 cout &lt;&lt; \"p1的年龄为：\" &lt;&lt; *p1.m_Age &lt;&lt; endl; cout &lt;&lt; \"p2的年龄为：\" &lt;&lt; *p2.m_Age &lt;&lt; endl; cout &lt;&lt; \"p3的年龄为：\" &lt;&lt; *p3.m_Age &lt;&lt; endl; Person p1(18); Person p2(20); Person p3(30); p3 = p2 = p1; //赋值操作 cout &lt;&lt; \"p1的年龄为：\" &lt;&lt; *p1.m_Age &lt;&lt; endl; cout &lt;&lt; \"p2的年龄为：\" &lt;&lt; *p2.m_Age &lt;&lt; endl; cout &lt;&lt; \"p3的年龄为：\" &lt;&lt; *p3.m_Age &lt;&lt; endl; return 0;&#125; 关系运算符重载 用于两个自定义类型进行对比操作 返回值为bool 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class Person&#123;public: Person(string name, int age) &#123; this-&gt;m_Name = name; this-&gt;m_Age = age; &#125;; bool operator==(Person &amp; p) &#123; if (this-&gt;m_Name == p.m_Name &amp;&amp; this-&gt;m_Age == p.m_Age) &#123; return true; &#125; else &#123; return false; &#125; &#125; bool operator!=(Person &amp; p) &#123; if (this-&gt;m_Name == p.m_Name &amp;&amp; this-&gt;m_Age == p.m_Age) &#123; return false; &#125; else &#123; return true; &#125; &#125; string m_Name; int m_Age;&#125;;int main() &#123; Person a(\"孙悟空\", 18); Person b(\"孙悟空\", 18); if (a == b) &#123; cout &lt;&lt; \"a和b相等\" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; \"a和b不相等\" &lt;&lt; endl; &#125; if (a != b) &#123; cout &lt;&lt; \"a和b不相等\" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; \"a和b相等\" &lt;&lt; endl; &#125; return 0;&#125; 函数调用运算符重载 函数调用运算符 () 也可以重载 由于重载后使用的方式非常像函数的调用，因此称为仿函数 仿函数没有固定写法，非常灵活 123456789101112131415161718192021222324252627282930313233class MyPrint&#123;public: void operator()(string text) &#123; cout &lt;&lt; text &lt;&lt; endl; &#125;&#125;;class MyAdd&#123;public: int operator()(int v1, int v2) &#123; return v1 + v2; &#125;&#125;;int main() &#123; //重载的（）操作符 也称为仿函数 MyPrint myFunc; myFunc(\"hello world\"); MyAdd add; int ret = add(10, 10); cout &lt;&lt; \"ret = \" &lt;&lt; ret &lt;&lt; endl; //匿名对象调用 cout &lt;&lt; \"MyAdd()(100,100) = \" &lt;&lt; MyAdd()(100, 100) &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"}]},{"title":"Spark","slug":"Spark基础","date":"2019-10-29T09:36:49.000Z","updated":"2021-07-08T07:57:26.130Z","comments":true,"path":"2019/10/29/Spark基础/","link":"","permalink":"http://example.com/2019/10/29/Spark%E5%9F%BA%E7%A1%80/","excerpt":"","text":"Spark简介起源Hadoop1.x的缺陷： mr式基于数据集的计算，所以面向数据 基本运算规则从存储介质中获取（采集）数据，然后进行计算，最后将结果存储到介质中，所以主要应用于一次性计算不适合于数据挖掘和机器学习和图形挖掘计算这样的迭代计算 MR基于文件存储介质的操作，性能非常慢 MR和Hadoop紧密耦合，无法动态替换 改进 由RM调度资源，AMApplicationMaster调度任务。提供了一个Driver来于Task关联。RM于NM关联。AM起到Driver和RM中间人。降低耦合。Contoiner来协调NM和Task 历史13年6月份发布 Spark基于Hadoop1.x结构思想，采用自己的方式来改善Hadoop1.x中的问题 基于内存，并且基于Scala语法开发，所以天生适合迭代式计算 Yran支持Spark计算 Executor：计算 Worker：资源 RM，NM可以替代这俩个 定义Spark是一种基于内存的快速、通用、可扩展的大数据分析引擎 Spark的内置模块 Spark Core：实现了Spark的基本功能，包含任务调度、内存管理、错误恢复、与存储系统交互等模块。Spark Core中还包含了对弹性分布式数据集(Resilient Distributed DataSet，简称RDD)的API定义。 Spark SQL：是Spark用来操作结构化数据的程序包。通过Spark SQL，我们可以使用 SQL或者Apache Hive版本的SQL方言(HQL)来查询数据。Spark SQL支持多种数据源，比如Hive表、Parquet以及JSON等。 Spark Streaming：是Spark提供的对实时数据进行流式计算的组件。提供了用来操作数据流的API，并且与Spark Core中的 RDD API高度对应。 Spark MLlib：提供常见的机器学习(ML)功能的程序库。包括分类、回归、聚类、协同过滤等，还提供了模型评估、数据 导入等额外的支持功能。 集群管理器：Spark 设计为可以高效地在一个计算节点到数千个计算节点之间伸缩计 算。为了实现这样的要求，同时获得最大灵活性，Spark支持在各种集群管理器(Cluster Manager)上运行，包括Hadoop YARN、Apache Mesos，以及Spark自带的一个简易调度 器，叫作独立调度器。 特点 快：基于内存，效率高。Spark实现了高效的DAG执行引擎。可以通过内存处理数据流，结果也存于内存 通用：Spark提供了统一的解决方案，可以用于批处理、交互式查询、实时流处理、机器学习、图计算。都可以无缝使用 易用：支持Java、Python、Scala的API。还支持80多种算法。而且支持交互式的Python和Scala的Shell 兼容性：可以使用Hadoop的Yarn和Apache Mesos作为他的资源管理和调度器。可以处理所以Hadoop支持的数据，HDFS和HBase等。 Spark运用Spark安装地址官网地址 文档查看地址 下载地址 重要角色 Driver（驱动器）:Spark的驱动器是执行开发程序中的main方法的进程。它负责开发人员编写的用来创建SparkContext、创建RDD，以及进行RDD的转化操作和行动操作代码的执行。如果你是用spark shell，那么当你启动Spark shell的时候，系统后台自启了一个Spark驱动器程序，就是在Spark shell中预加载的一个叫作 sc的SparkContext对象。如果驱动器程序终止，那么Spark应用也就结束了。主要负责： 把用户程序转为作业（JOB） 跟踪Executor的运行状况 为执行器节点调度任务 UI展示应用运行状况 也就是支持自定义系统开发 Executor（执行器）:Spark Executor是一个工作进程，负责在 Spark 作业中运行任务，任务间相互独立。Spark 应用启动时，Executor节点被同时启动，并且始终伴随着整个 Spark 应用的生命周期而存在。如果有Executor节点发生了故障或崩溃，Spark 应用也可以继续执行，会将出错节点上的任务调度到其他Executor节点上继续运行。主要负责： 负责运行组成 Spark 应用的任务，并将结果返回给驱动器进程； 通过自身的块管理器（Block Manager）为用户程序中要求缓存的RDD提供内存式存储。RDD是直接缓存在Executor进程内的，因此任务可以在运行时充分利用缓存数据加速运算。 可以有多个来执行不同任务 Local模式简述Local模式就是运行在一台计算机的模式，就是用来在本机上联手和测试。可以通过以下方式设置Master local：所有计算在一个线程中，没有并行计算 local[K]：K是指定几个线程来运算。通常Cpu有几个Core，就指定几个线程。 local[*]：帮你按照Cpu最多Cores来设置线程数 安装使用上传并解压spark安装包[ sorfware]$ tar -zxvf spark-2.1.1-bin-hadoop2.7.tgz -C /opt/module/ [ module]$ mv spark-2.1.1-bin-hadoop2.7 spark 测试样例 spark]$ bin/spark-submit --class org.apache.spark.examples.SparkPi --executor-memory 1G --total-executor-cores 2 ./examples/jars/spark-examples_2.11-2.1.1.jar 100 基本语法12345678bin/spark-submit \\--class &lt;main-class&gt;--master &lt;master-url&gt; \\--deploy-mode &lt;deploy-mode&gt; \\--conf &lt;key&gt;=&lt;value&gt; \\... # other options&lt;application-jar&gt; \\[application-arguments] 参数说明： –master 指定Master的地址，默认为Local –class: 你的应用的启动类 (如 org.apache.spark.examples.SparkPi) –deploy-mode: 是否发布你的驱动到worker节点(cluster) 或者作为一个本地客户端 (client) (default: client)* –conf: 任意的Spark配置属性， 格式key=value. 如果值包含空格，可以加引号“key=value” application-jar: 打包好的应用jar,包含依赖. 这个URL在集群中全局可见。 比如hdfs:// 共享存储系统， 如果是 file:// path， 那么所有的节点的path都包含同样的jar application-arguments: 传给main()方法的参数 –executor-memory 1G 指定每个executor可用内存为1G –total-executor-cores 2 指定每个executor使用的cup核数为2个 –开头的参数，可以调换位置 启动spark-shell12345678910111213141516171819[atguigu@hadoop102 spark]$ bin/spark-shellUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.propertiesSetting default log level to \"WARN\".To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).18/09/29 08:50:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable18/09/29 08:50:58 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectExceptionSpark context Web UI available at http://192.168.9.102:4040Spark context available as 'sc' (master = local[*], app id = local-1538182253312).Spark session available as 'spark'.Welcome to ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ '_/ /___/ .__/\\_,_/_/ /_/\\_\\ version 2.1.1 /_/ Using Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_144)Type in expressions to have them evaluated.Type :help for more information. UI界面 sc：可用变量 参数：master = local[*], app id = local-1538182253312 app id：应用id。每个应用对yarn都有一个全局的唯一Id，当前的是临时生成的 WordCount案例在spark根目录下创建input文件夹，在内创建文件，输入单词以空格隔开 12scala&gt;sc.textFile(\"input\").flatMap(_.split(\" \")).map((_,1)).reduceByKey(_+_).collectres0: Array[(String, Int)] = Array((hadoop,6), (oozie,3), (spark,3), (hive,3), (atguigu,3), (hbase,6)) textFile(“input”)：input输入文件夹 flatMap(_.split(“ “))：以’ ‘为分隔符 map((_,1))：传入值为Key，1为Value reduceByKey(_+_)：根据Key化简，value相加 collect：收集起来 Idea下编写WordCountpom文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-core_2.11&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;WordCount&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt; &lt;artifactId&gt;scala-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;goal&gt;testCompile&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!--打包插件--&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;WordCount&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 12345678910111213141516171819202122232425262728293031package com.atguigu.bigdaata.sparkimport org.apache.spark._import org.apache.spark.rdd.RDDobject WordCount &#123; def main(args: Array[String]): Unit = &#123; //local模式 //设置环境 //1.创建SparkConf并设置App名称 val conf = new SparkConf().setMaster(\"local[*]\").setAppName(\"WC\") //2.创建SparkContext，该对象是提交Spark App的入口 val sc = new SparkContext(conf) //读取文件，一行一行读取 //文件放在项目当前项目根目录的in文件夹内 val lines: RDD[String] = sc.textFile(\"in\") //3.使用sc创建RDD并执行相应的transformation和action val words: RDD[String] = lines.flatMap(_.split(\" \")) // .reduceByKey(_ + _, 1).sortBy(_._2, false).saveAsTextFile(args(1)) val wordToOne: RDD[(String, Int)] = words.map((_, 1)) val wordToSum: RDD[(String, Int)] = wordToOne.reduceByKey(_ + _, 1) val result: Array[(String,Int)] = wordToSum.collect result.foreach(println) //4.关闭连接 sc.stop() &#125;&#125; RDD简述 只有在collect的时候才会真正开始运行，前面都只是封装逻辑 Yarn模式（重点）Spark客户端直接连接Yarn，不需要额外构建Spark集群。有yarn-client和yarn-cluster两种模式，主要区别在于：Driver程序的运行节点。 yarn-client：Driver程序运行在客户端，适用于交互、调试，希望立即看到app的输出 yarn-cluster：Driver程序运行在由RM（ResourceManager）启动的AP（APPMaster）适用于生产环境。 流程图 安装使用修改hadoop配置文件yarn-site.xml vi yarn-site.xml 1234567891011&lt;!--添加--&gt;&lt;!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; 修改spark-env.sh vi spark-env.sh YARN_CONF_DIR=/opt/module/hadoop-2.7.2/etc/hadoop 分发文件 xsync /opt/module/hadoop-2.7.2/etc/hadoop/yarn-site.xml xsync spark-env.sh 样例测试 在提交任务之前需启动HDFS以及YARN集群。 123456bin/spark-submit \\--class org.apache.spark.examples.SparkPi \\--master yarn \\--deploy-mode client \\./examples/jars/spark-examples_2.11-2.1.1.jar \\100 流程图 日志查看修改配置文件spark-defaults.conf spark.yarn.historyServer.address=hadoop102:18080 spark.history.ui.port=18080 重启spark历史服务 12$ sbin/stop-history-server.sh $ sbin/start-history-server.sh Standalone模式由Master+Slave构成的Spark集群，也就是Spark自己运行 安装使用在conf文件夹下 12$ mv slaves.template slaves$ mv spark-env.sh.template spark-env.sh 12345$ vim slaveshadoop102hadoop103hadoop104 1234$ vim spark-env.shSPARK_MASTER_HOST=hadoop102SPARK_MASTER_PORT=7077 1$ xsync spark/ 1$ sbin/start-all.sh 1234567891011$ xcall jps================atguigu@hadoop102================3330 Jps3238 Worker3163 Master================atguigu@hadoop103================2966 Jps2908 Worker================atguigu@hadoop104================2978 Worker3036 Jps 网页查看 如果遇到 “JAVA_HOME not set” 异常，可以在sbin目录下的spark-config.sh 文件中 加入： export JAVA_HOME=XXXX 测试用例 1234567bin/spark-submit \\--class org.apache.spark.examples.SparkPi \\--master spark://hadoop102:7077 \\--executor-memory 1G \\--total-executor-cores 2 \\./examples/jars/spark-examples_2.11-2.1.1.jar \\100","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"http://example.com/tags/Spark/"},{"name":"大数据","slug":"大数据","permalink":"http://example.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}]},{"title":"scala函数式编程","slug":"Scala编程","date":"2019-10-28T02:52:44.000Z","updated":"2021-07-08T07:56:31.295Z","comments":true,"path":"2019/10/28/Scala编程/","link":"","permalink":"http://example.com/2019/10/28/Scala%E7%BC%96%E7%A8%8B/","excerpt":"","text":"函数式编程偏函数在对部分符合某个条件时使用。 12345678new PartialFunction[Any, Int] &#123;//接受Any，返回Int类型 //如果返回true，就会触发apply方法。false则跳过 override def isDefinedAt(x: Any): Boolean = &#123; &#125; // override def apply(v1: Any): Int = &#123; &#125;&#125; 如果使用偏函数，不能使用map，应使用collect 简化1234567//形式1def partialfunction: PartialFunction[Any, Int]= &#123; case a: Int =&gt; a case b: Double =&gt; b.toInt&#125;//形式2list.collect&#123;case a:Int=&gt;a&#125; 匿名函数12//多行就加大括号(x:Double) =&gt; 3*x 高阶函数1234//高阶函数,传入Double类型，返回Doubledef test(f:Double =&gt; Double,n1:Double)=&#123; f(n1)&#125; 类型推断123456//类型推断var list = List(1, 2, 3)list.map((x: Int) =&gt; x + 1)list.map((x) =&gt; x + 1)list.map(x =&gt; x + 1)list.map( _ + 1) 闭包闭包就是一个函数和与其相关的引用环境组合的一个整体。（类似对象） 123def minusxy(X:Int) =(y:Int)=&gt;x-y//f就是一个闭包val f = minusxy(20) 函数柯里化就是只传一个值 123//分开传def m(x:Int)(y:Int)=x*ym(1)(2) 抽象控制传入没有参数没有返回值的函数 1234567891011def myRunInThread(f1:()=&gt;Unit)=&#123; new Thread&#123; override def run():Unit=&#123; f1() &#125; &#125;.start()&#125;myRunInThread&#123; ()=&gt; print(\"\")&#125; 12345678910def myRunInThread(f1:=&gt;Unit)=&#123; new Thread&#123; override def run():Unit=&#123; f1 &#125; &#125;.start()&#125;myRunInThread&#123; print(\"\")&#125; 12345678910111213//控制抽象模拟whiledef until(condition: =&gt; Boolean)(block: =&gt; Unit): Unit = &#123; if (condition) &#123; block until(condition)(block) &#125;&#125;var x = 10until(x &gt; 0) &#123; x -= 1 println(\"until x=\" + x)&#125;","categories":[],"tags":[{"name":"scala","slug":"scala","permalink":"http://example.com/tags/scala/"}]},{"title":"设计模式'","slug":"设计模式","date":"2019-10-28T02:02:46.000Z","updated":"2021-07-08T07:59:17.023Z","comments":true,"path":"2019/10/28/设计模式/","link":"","permalink":"http://example.com/2019/10/28/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"设计模式的好处 更易读懂源码。框架大量运用了设计模式。 提高代码的维护性 便于程序员间的交流 设计模式理解的层次 知道设计模式 学习过，勉强能看懂别人的设计模式代码 看懂大量的源码，并能体会设计模式的作用 自己会写设计模式 设计模式简介 设计模式是资深程序员，在写代码遇到问题，提出的有用的经验。是一种思想，不局限于一种语言 能提高通用性和扩展性，降低软件的复杂度 设计模式依赖抽象原则 创建对象实例时，不要直接new（变量不要直接持有具体类的引用） 设计模式分类共3类，23种 创建型模式：单例模式、抽象工厂模式、建造者模式、工厂模式、原型模式 结构型模式：适配器模式、桥接模式、装饰模式、组合模式、外观模式、享元模式、代理模式 行为型模式：模板方法模式、命令模式、迭代器模式、观察者模式、中介者模式、备忘录模式、解释器模式(Interpreter模式)、状态模式、策略模式、职责链模式(责任链模式)、访问者模式 简单工厂模式不属于GOF23之一。由工程对象决定创建哪一种类的实例 好处将实例化对象的代码封装到一个工程对象中。可以直接获取到对象，而不用关心对象创建过程中，一些复杂的逻辑环境。 若修改创建对象的逻辑，只需要改工厂内即可，降低耦合 工厂方法模式需要工厂按需返回相应的对象。 将工厂实例方法抽象，推迟到子类工厂实现。 抽象工厂模式将简单工厂模式和工厂方法模式进行整合。 定义了一trait用于创建相关或有依赖关系的对象族。 也可以将一个抽象类继承该trait，细分不同的工厂 单例模式懒汉式延迟加载，用的时候才加载 饿汉式创建的时候就加载 装饰者模式如果不使用装饰者模式，容易导致类爆炸（数量极多） 装饰者模式：动态的将新功能附加到对象上。在对象功能扩展方面，比继承更有弹性。更符合开闭原则 实施装饰者会持有包装的对象，利用方法（递归）。形成一个链，来执行。 观察者模式解决了无法动态加入新的观察者对象。 多对一 观察者 update()更新数据 中心 registerObserver()方法用来注册观察者 removeObserver()移除注册的观察者 notifyObservers()通知所有注册的观察者，更新数据 Java内置观察者模式java.util.Observalbe Observable等价于Subject Observable是类，已经实现了核心的三个方法 代理模式为对象提供一个替身，来控制对这个对象的访问 代理模式有不同的形式(静态代理，动态代理，远程代理) RMI远程方法调用（知道即可）远程对象有一个代理对象（本地代表），通过它把远程对象当作本地对象 RMI：是一种机制，能够让JAVA虚拟机上的对象调用另一个Java虚拟机中的对象上的方法。底层封装了socket编程，简化操作 RMI是一种面向对象的开发方式，通过调用远程对象来调用接口，RPC是远程过程调用 在java.rmi.包下，下面代码（RMI实现）了解即可 12345678910import java.rmi.&#123;Remote, RemoteException&#125;//这是一个接口文件.该文件会给远程端和本地端是使用trait MyRemote extends Remote&#123; //一个抽象方法 @throws(classOf[RemoteException]) def sayHello(): String //throws RemoteException&#125; 12345678910111213import java.rmi.Namingclass MyRemoteClient &#123; def go() = &#123; val service = Naming.lookup(\"rmi://127.0.0.1:9999/RemoteHello\").asInstanceOf[MyRemote] val str = service.sayHello() println(\"str = \" + str) &#125;&#125;object MyRemoteClient &#123; def main(args: Array[String]): Unit = &#123; new MyRemoteClient().go() &#125;&#125; 1234567891011121314151617181920212223import java.rmi.registry.LocateRegistryimport java.rmi.&#123;Naming, RemoteException&#125;import java.rmi.server.UnicastRemoteObject//这里就是实现了MyRemote traitclass MyRemoteImpl extends UnicastRemoteObject with MyRemote &#123; @throws(classOf[RemoteException]) override def sayHello(): String = &#123; \"Hello World!~\" &#125;&#125;//这里我们完成对服务(sayHello)注册任务-&gt;对服务管理object MyRemoteImpl &#123; def main(args: Array[String]): Unit = &#123; val service: MyRemote = new MyRemoteImpl() //准备把服务绑定到9999端口【第一种注册方式】 //LocateRegistry.createRegistry(9999) //Naming.rebind(\"RemoteHello\", service) //准备把服务绑定到9999端口【第二种注册方式】 Naming.rebind(\"rmi://127.0.0.1:9999/RemoteHello\", service) println(\"远程服务开启，在127.0.0.1 的 9999端口监听，服务名 RemoteHello\") &#125;&#125; 动态代理运行时动态的创建代理类（对象）。 使用反射创建一个代理对象，对代理对象增强，访问权限等 Scala中反射与Java有一定区别。在返回method.invoke时Java要传入对象和参数，Scala中只要传对象不要传方法，底层会去获取，否则会失败 常见的代理模式 防火墙代理 缓存代理 静态代理 Cglib代理 同步代理：多线程间的","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"AKKA","slug":"Akka","date":"2019-10-27T07:28:15.000Z","updated":"2021-07-08T07:54:37.764Z","comments":true,"path":"2019/10/27/Akka/","link":"","permalink":"http://example.com/2019/10/27/Akka/","excerpt":"","text":"简介 Akka是JVM平台上，高并发、分布式和容错应用的工具包。 能方便写出高效稳定的并发程序。 应用Actor模型能够解决并发所造成的，数据一致性问题，正确性问题等。 理论 Akka会有一个Actor System（单例，一个就VM进程中一个即可） 在这个系统中，所有事物都是Actor（继承Actor） Actor与Actor之间通过消息通信 每个Actor都会有对应的ActorRef。 通过使用ActorRef对Actor发消息 消息从ActorRef传到Dispatcher Message（线程池），然后Dispatcher Message发给对应的mailbox mailbox是一个Runable，内置一个队列。所有消息都会发给mailbox，mailbox调用Actor中的receive方法 引入jar包这里引入之后就不用再导Scala插件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697&lt;!-- 定义一下常量 --&gt; &lt;properties&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;scala.version&gt;2.11.8&lt;/scala.version&gt; &lt;scala.compat.version&gt;2.11&lt;/scala.compat.version&gt; &lt;akka.version&gt;2.4.17&lt;/akka.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- 添加scala的依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.scala-lang&lt;/groupId&gt; &lt;artifactId&gt;scala-library&lt;/artifactId&gt; &lt;version&gt;$&#123;scala.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 添加akka的actor依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.typesafe.akka&lt;/groupId&gt; &lt;artifactId&gt;akka-actor_$&#123;scala.compat.version&#125;&lt;/artifactId&gt; &lt;version&gt;$&#123;akka.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 多进程之间的Actor通信 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.typesafe.akka&lt;/groupId&gt; &lt;artifactId&gt;akka-remote_$&#123;scala.compat.version&#125;&lt;/artifactId&gt; &lt;version&gt;$&#123;akka.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 指定插件--&gt; &lt;build&gt; &lt;!-- 指定源码包和测试包的位置 --&gt; &lt;sourceDirectory&gt;src/main/scala&lt;/sourceDirectory&gt; &lt;testSourceDirectory&gt;src/test/scala&lt;/testSourceDirectory&gt; &lt;plugins&gt; &lt;!-- 指定编译scala的插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt; &lt;artifactId&gt;scala-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;goal&gt;testCompile&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;args&gt; &lt;arg&gt;-dependencyfile&lt;/arg&gt; &lt;arg&gt;$&#123;project.build.directory&#125;/.scala_dependencies&lt;/arg&gt; &lt;/args&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- maven打包的插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.3&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;filters&gt; &lt;filter&gt; &lt;artifact&gt;*:*&lt;/artifact&gt; &lt;excludes&gt; &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt; &lt;/excludes&gt; &lt;/filter&gt; &lt;/filters&gt; &lt;transformers&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.AppendingTransformer\"&gt; &lt;resource&gt;reference.conf&lt;/resource&gt; &lt;/transformer&gt; &lt;!-- 指定main方法 --&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\"&gt; &lt;mainClass&gt;xxx&lt;/mainClass&gt; &lt;/transformer&gt; &lt;/transformers&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 总结Akka，给我的感觉像是消息队列的复杂版。对于他是如何处理并发的问题，没有任何理解","categories":[],"tags":[{"name":"Scala","slug":"Scala","permalink":"http://example.com/tags/Scala/"},{"name":"并发","slug":"并发","permalink":"http://example.com/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"maven常见问题","slug":"maven常见问题","date":"2019-10-27T03:45:04.000Z","updated":"2021-07-08T07:55:51.547Z","comments":true,"path":"2019/10/27/maven常见问题/","link":"","permalink":"http://example.com/2019/10/27/maven%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","excerpt":"","text":"cannot resolve symbol idea中使用的是自带的maven。换成了自己的maven就成功了","categories":[],"tags":[{"name":"maven","slug":"maven","permalink":"http://example.com/tags/maven/"},{"name":"bug","slug":"bug","permalink":"http://example.com/tags/bug/"}]},{"title":"项目开发流程图(梗概)","slug":"项目开发流程图-梗概","date":"2019-10-26T11:32:30.000Z","updated":"2019-10-27T02:32:34.516Z","comments":true,"path":"2019/10/26/项目开发流程图-梗概/","link":"","permalink":"http://example.com/2019/10/26/%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B%E5%9B%BE-%E6%A2%97%E6%A6%82/","excerpt":"可行性分析 有没有市场，谁来做 市场部+销售部，出东西 可行性报告 需求分析","text":"可行性分析 有没有市场，谁来做 市场部+销售部，出东西 可行性报告 需求分析 需求分析师（懂技术+懂业务）[挖掘客户的需求] 需求分析报告（白皮书） 设计阶段 项目经理（架构师） 使用什么技术+架构+选人 设计文档（类图、时序图、部署图、用例图）+数据库 界面（原型开发） 一般从上往下设计 实现阶段 程序员 看懂文档，实现各个模块 设计功能模块 模块代码 一般从下往上实现 测试阶段（与实现阶段同步进行） 测试工程师 测试用例，完成对软件的测试（白盒测试，黑盒测试，灰盒） 找bug（复现bug） 实施阶段 实施工程师 将项目部署到系统，并匹配好参数，正确运行 维护阶段 不一定有专人","categories":[],"tags":[{"name":"流程","slug":"流程","permalink":"http://example.com/tags/%E6%B5%81%E7%A8%8B/"},{"name":"开发","slug":"开发","permalink":"http://example.com/tags/%E5%BC%80%E5%8F%91/"}]},{"title":"搭建hexo博客","slug":"搭建hexo博客","date":"2019-10-26T02:52:44.000Z","updated":"2021-07-08T07:58:22.801Z","comments":true,"path":"2019/10/26/搭建hexo博客/","link":"","permalink":"http://example.com/2019/10/26/%E6%90%AD%E5%BB%BAhexo%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"1.基础环境安装好node.js和git，配置好git的用户信息 2.安装hexo2.1配置taobao镜像npm install -g cnpm --registry=http://registry.npm.taobao.org #安装淘宝的cnpm 管理器 输入cnpm测试是否成功 2.2安装hexocnpm install -g hexo-cli全局安装hexo-cli 使用hexo -v验证是否成功 3.初始化博客在指定的博客空文件夹下运行hexi init命令。 Windows段下要再执行npm install，来安装依赖包 运行hexo s命令 在浏览器内输入红色框内的网址，查看是否运行成功 失败删除文件夹，重新来过 4.远程部署博客4.1推送至GitHub在博客本地目录下运行cnpm install --save hexo-deployer-git安装推送的插件 在自己的GitHub上创建仓库 格式必须为ID.github.io然后下一步 复制红色箭头的网址 在博客根目录下打开_config.yml拉到最下面，修改如下 123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: https://github.com/dianyang12138/dianyang12138.github.io.git branch: master 使用hexo d推送至远端，然后填写GitHub账号密码即可 4.2推送……5.推送更新先定位到博客文件夹，然后 123hexo cleanhexo ghexo d 三连解决 6.美化6.1更换主题样式这里以yilia为例 在网上寻找心仪的主题样式，在根目录下 安装 1git clone https:&#x2F;&#x2F;github.com&#x2F;litten&#x2F;hexo-theme-yilia.git themes&#x2F;yilia 配置 修改hexo根目录下的 _config.yml ： theme: yilia 即可 6.2maupassant主题官网 123git clone https://github.com/tufu9441/maupassant-hexo.git themes/maupassantcnpm install hexo-renderer-pug --savecnpm install hexo-renderer-sass --save 修改hexo根目录下的 _config.yml ： theme: maupassant 再依次执行： 123hexo cleanhexo g hexo d 7.常见问题7.1图片显示bug图片无法显示，查看根目录下的public文件夹，发现，没有图片资源文件 解决方案 将根目录下配置文件_config.yml 中有 post_asset_folder:false改为true。这样在使用hexo n &quot;文章名&quot;生成的时候就会生成对应的文件，然后将图片放入，在.md文件用相对路径引入xxx/xxx.jpg即可 npm install https://github.com/7ym0n/hexo-asset-image --save安装一个插件，具体干啥我也不清楚，只知道是用来处理图片的。 这里官方也提供了一种新的插入图片的语法，hexo插入图片说明 将样例中slug替换成图片的文件名，[title]写的是描述文字。将图片放入对应的资源文件夹下即可显示文件。当然md语法插入文件也是可以的 一般网上的博客，到这里就能成功，如果成功忽略以下步骤。 但是我的图片仍然无法显示，在使用hexo g会出现hexo update link as:xxxx，查看网页源代码，发现图片引用地址会出现奇怪的错误&quot;/.com//xxx.png&quot;我的错误是这样，我也见到网上有.io//此类错误的路径。查询后发现是第二步安装的插件有bug。 在根路径下打开/node_modules/hexo-asset-image/index.js，将内容替换成 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061'use strict';var cheerio = require('cheerio');// http://stackoverflow.com/questions/14480345/how-to-get-the-nth-occurrence-in-a-stringfunction getPosition(str, m, i) &#123; return str.split(m, i).join(m).length;&#125;var version = String(hexo.version).split('.');hexo.extend.filter.register('after_post_render', function(data)&#123; var config = hexo.config; if(config.post_asset_folder)&#123; var link = data.permalink; if(version.length &gt; 0 &amp;&amp; Number(version[0]) == 3) var beginPos = getPosition(link, '/', 1) + 1; else var beginPos = getPosition(link, '/', 3) + 1; // In hexo 3.1.1, the permalink of \"about\" page is like \".../about/index.html\". var endPos = link.lastIndexOf('/') + 1; link = link.substring(beginPos, endPos); var toprocess = ['excerpt', 'more', 'content']; for(var i = 0; i &lt; toprocess.length; i++)&#123; var key = toprocess[i]; var $ = cheerio.load(data[key], &#123; ignoreWhitespace: false, xmlMode: false, lowerCaseTags: false, decodeEntities: false &#125;); $('img').each(function()&#123; if ($(this).attr('src'))&#123; // For windows style path, we replace '\\' to '/'. var src = $(this).attr('src').replace('\\\\', '/'); if(!/http[s]*.*|\\/\\/.*/.test(src) &amp;&amp; !/^\\s*\\//.test(src)) &#123; // For \"about\" page, the first part of \"src\" can't be removed. // In addition, to support multi-level local directory. var linkArray = link.split('/').filter(function(elem)&#123; return elem != ''; &#125;); var srcArray = src.split('/').filter(function(elem)&#123; return elem != '' &amp;&amp; elem != '.'; &#125;); if(srcArray.length &gt; 1) srcArray.shift(); src = srcArray.join('/'); $(this).attr('src', config.root + link + src); console.info&amp;&amp;console.info(\"update link as:--&gt;\"+config.root + link + src); &#125; &#125;else&#123; console.info&amp;&amp;console.info(\"no src attr, skipped...\"); console.info&amp;&amp;console.info($(this)); &#125; &#125;); data[key] = $.html(); &#125; &#125;&#125;); 然后就解决了","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"博客","slug":"博客","permalink":"http://example.com/tags/%E5%8D%9A%E5%AE%A2/"}]},{"title":"Linux基础学习","slug":"Linux基础学习","date":"2019-10-26T01:33:50.000Z","updated":"2021-07-08T07:55:32.640Z","comments":true,"path":"2019/10/26/Linux基础学习/","link":"","permalink":"http://example.com/2019/10/26/Linux%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"Linux文件系统目录结构基本介绍Linux中一切皆为文件 具体的目录结构 /bin [重点] 存放常用指令 /sbin 存放系统管理员使用的系统管理程序 /home [重点] 存放普通用户的主目录，每个用户都有一个自己的目录，目录名为账号名 /root [root] 超级权限者用户主目录 /lib 系统开机所需的基本的动态连接共享库 /lost+found 一般为空，当系统非法关机后，这里会存放文件 /etc [重点] 所有系统管理所需要的配置文件和子目录 my.conf /usr [重点] 这是一个非常重要的目录，用户很多应用程序和文件放在这 /boot [重点] 存放启动Linux时使用的核心文件 /proc 别动 /srv 别动 /sys 别动 /tmp 存放临时文件 /dev 所有硬件以文件的形式存储 /media [重点] U盘，光驱等识别后挂载到此目录下 /mnt [重点] 让用户临时挂载别的文件系统的，可以将外部存储挂载到/mnt上 /opt 额外安装软件的目录 /usr/local [重点] 一般通过编译源码方式安装的程序的安装目录 /var [重点] 经常变化的文件放在者 /selinux 安全系统 远程软件XShell和Xftp远程登陆软件XShell安装如果希望安装好XShell5就能连接Linux，傻瓜安装，一直下一步，那么Linux的ssdh服务必须开启22端口 使用ifconfig查看IP地址，网络一定要连接。 XShell关键配置名称：随意 协议：ssh 主机：Linux的IP地址 远程上传下载文件Xftp基于SFTP、FTP协议 安装自用：选择免费 Xftp关键配置名称：随意 协议：SFTP 主机：Linux的IP地址 账号密码：填写 Xftp乱码问题-&gt;属性（方框加齿轮）-&gt;选项-&gt;勾选使用UTF8-&gt;刷新 vi和vim编辑器三种模式w：写入 q：退出 !：强行执行 正常模式ESC键退到正常模式正常模式下，可以使用快捷键 上下左右、删除字符、删除整行、复制、贴上 插入模式/编辑模式按下i,I,o,O,a,A,r,R任一一字母进入编辑模式 命令行模式输入:或者/进入命令行模式 可以提供相关指令，完成读取、存盘、替换、离开vim、显示行号等 快捷键 拷贝当前行：yy 拷贝当前行向下的5行：5yy 粘贴（p） 删除当前行 dd 删除当前行向下的5行 5dd 在文件中查找某个单词 [命令行下/关键字，回车 查找，输入n查找下一个] 设置文件行号，取消文件行号[命令行下：set nu和 set nonu] 使用快捷键到底文档的最末行[G]和最首行[gg] 撤销动作，输入u 讲光标移动到 第20行 shift+g 先显示行号：set nu (可省略) 输入20行号 输入shift+g 其他百度 开机、重启和用户登录注销关机&amp;重启命令基本介绍 shutdown -h now：立即关机 -h 1：一分钟后关机 -r now：立即重启 halt 直接使用，关机 reboot 重启 sync 把内存数据同步到磁盘 用户登录注销基本结束 少用root账号登陆，如果需要使用root，要用”su-用户名”来切换成root 在提示符下输入logout即可注销用户 logout在图形界面无效，在运行级别3下有效 在提示符下输入logout有效 用户管理说明 用户：root等，用户至少属于一个组 组：root组等 家目录：/home/下各个创建的用户对应的家目录，当用户登录时，自动进入家目录 基本命令 useradd 用户名：添加一个用户 如果没有指定组，会自动创建一个新租 用户创建成功后，自动创建一个同名的家目录 也可以通过useradd -d指定家目录 新的用户名，给新创建的用户指定家目录 passwd 用户名：指定密码 userdel 用户名：删除用户 -r ：也删除家目录 一般保留家目录 id 用户名：查询用户信息 su - 用户名：切换用户 返回使用exit whoami/who am I：查看当前用户 groupadd 组名：新增组 groupdel 组名 useradd -g 用户组 用户名 用户配置文件（用户信息）/etc/passwd 用户名:口令（密码（加密））:用户Id:组id:家目录:shell解释器 组配置文件（组信息）/etc/group 组名:口令:标识号:组内用户列表 口令配置文件（密码和登录信息，加密文件）/etc/shadow 登录名:加密口令:最后一次修改时间:最小时间间隔:最大时间间隔:警告时间:不活动时间:失效时间 实用指令运行级别 0：关机 1：单用户[找回密码] 2：多用户无网络服务 3：多用户有网络服务 4：系统未使用保留给用户 5：图形界面 6：系统重启 常用运行级别是3和5，要修改默认运行级别可改文件/etc/inittab的id:initdefault:这一行中的数字 命令init[012356] 找回密码开机-&gt;在引导输入 回车-&gt;看到界面输入 e-&gt;看到一个新的界面，选中第二行（编辑内核）在输入e-&gt;在这行输入 1-&gt;再回车-&gt;再次输入b，就能进入单用户模式-&gt;再使用passwd来修改root密码 帮助命令 man [命令或配置文件]：获得帮助信息 help 命令：获得shell内置命令的帮助信息 文件目录类 pwd：显示当前目录的绝对路径 ls [选项] [目录或是文件] -a：显示当前目录所有文件和目录，包括隐藏 -l：以列表的方式显示信息 -h：按照人习惯的格式查看 cd [参数]：切换目录 cd ~：回到家目录 cd ..：返回上一级 mkdir [选项] 要创建的目录 -p创建多级目录 rmdir [选项]：删除空目录 如果删除非空目录：rm -rf 目录 touch 文件名称 [文件名称2]：创建空文件，可以一次性创建多个文件 cp [选项] source dist： -r：递归复制整个文件夹 例子 cp a.txt b/ 将当前目录下的a.txt拷贝到当前目录的b目录下 \\cp [选项] source dist：强制覆盖，不询问 rm [选项] 要删除的文件或目录 -r：递归删除整个文件夹 -f：强制删除不提示 mv ：移动文件与目录或重命名 mv oldNameFile newNameFile ：重命名 mv /temp/movefile /targetFolder：移动文件 cat [选项] 要查看的文件：查看文件内容，不能修改 -n：显示行号 cat -n 文件名 | more：分页显示 more 要查看的文件：以全屏的方式按页显示文本内容 操作 功能 空格 代表向下翻一页 Enter 代表向下翻一行 q 退出 Ctrl+F 向下滚动一屏 Ctrl+B 向上滚动一屏 = 输出当前行的行号 :f 输出文件名和当前行号 less 要查看的文件：以全屏的方式按页显示文本内容，懒加载，对于大型文件有较高效率 操作 功能说明 空格 向下翻动一页 [pagedown] 向下翻动一页 [pageup] 向上翻动一页 /字串 向下寻找[字串]：n：向下查找 N：向上寻找 ？字串 向上寻找[字串]： n：向上查找 N：向下查找 q 退出 &gt;：输出重定向 和 &gt;&gt;：追加 ls -l &gt; a.txt 将内容写入a.txt（覆盖写） ls-al&gt;&gt;a.txt 将内容追加到a.txt的文末 cat 文件1 &gt; 文件2 将文件1内容覆盖到文件2 echo “内容” &gt;&gt; 文件 echo [选项] [输出内容]：输出内容到控制台 使用echo指令输出环境变量，echo $PATH 使用echo输出字符串 echo “撒旦撒” head 文件 ：查看文件前十行 head -n 5 文件 ：查看文件前5行 tail 文件：查看文件后10行 tail -n 5 文件：查看文件后5行 tail -f 文件：实时追踪该文件的所有更新，实时的追加日期 ln -s [原文件或目录] [软连接名] ：软连接，类似快捷方式 软链接进入的目录，用pwd看还是软链接所在的目录 history ：查看所有执行过的历史指令 history 10：查看最近10个指令 !数字：查看编号为该数字的指令 事件日期类命令 date：显示当前时间 date+%Y ：显示当前年份 date+%m：显示当前月份 date+%d：显示当前哪一天 date “+%Y-%m-%d %H:%M:%S”：显示年月日时分秒（-连接符可以替换） date -s 字符串时间：设置系统时间（date -s “2018-10-10 11:11:11”） cal [选项]：显示本月日历时间 cal 2020：显示2020年日历 搜索查找指令 find [搜索范围] [选项] find /home -name hello.txt：在home文件夹下按照名字查找文件 find /opt -user root：在opt文件夹下查找文件拥有者为root的文件 find / -size +20M：在/下查找大于20M的文件 find -name *.txt：可以使用通配符 locate 搜索文件 第一次运行前，必须使用updatedb，创建数据库 会很快查找文件 grep [选项] 查找内容 源文件 |管道符：表示将前一个命令的处理结果输出传递给后面的命令处理 -n：显示匹配行及行号 -i：忽略字母大小写 cat hello.txt | grep -i yes 在hello.txt忽略大小写查找hello 压缩和解压缩指令 gzip 文件：压缩文件（只能将文件压缩到*.gz，原文件不保留） gunzip 文件.gz：解压到当前文件夹下 zip [选项]XXX.zip 将要压缩的文件名 -r：递归压缩 zip -r mypackage.zip /home/ ：将home目录压缩到mypackage.zip unzip [选项]XXX.zip 文件名 -d 目录：指定解压后文件目录 unzip -d /opt/tmp mypackage.zip：将mypackage.zip解压到/opt/tmp tar [选项] XXX.tar.gz 打包内容 ：打包目录，或者解压文件） -c：产生.tar打包文件 -v：显示详细信息 -f：指定压缩后文件名 -z：打包时压缩 -x：解压.tar文件 tar -zcvf a.tar.gz a1.txt a2.txt：将a1.txt和a2.tx压缩t打包成a.tar.gz tar -zxvf a.tar.gz：将a.tar.gz解压到当前文件夹下 tar -zxvf a.tar.gz -C /opt：将文件解压到opt文件夹下 组管理和权限管理在linux中的每个用户必须属于一个组，不能独立于组外。在linux中每个文件有所有者，所在组，其他组的概念 所有者 所在组 其他组 改变用户所在的组 所有者一般为文件的创建者，谁创建了该文件，就自然成为该文件的所有者 查看文件所有者 ls -ahl：查看文件/目录所在组和所有者 实例：创建一个police，再创建用户tom将tom放入police组，然后用tom创建文件 groupadd police useradd -g police tom passwd 123 touch ok.txt ls -ahl 显示：-rw-r–r–. 1 tom polic 文件大小 时间 文件名 修改文件所有者 chown 用户名 文件夹 修改 ok.txt 的所有者为root：chown root ok.txt 但是文件所在组不会变 所有组一般为文件的所有者的组，为所有组 组的创建 groupadd 组名 上面演示过 ls -ahl：查看文件/目录所在组和所有者 chgrp 组名 文件名：修改文件所有组 usermod -g 组名 用户名：改变用户所在组 usermod -d 目录名 用户名 改变该用户登录的初始目录 创建bandit组，将tom修改到该组 id tom：查看用户tom usermod -g bandit tom 其他组除了所有组，就是其他组 权限管理主要指的是文件和目录的权限 -rw-r–r–. 1 root root 文件类型 -：普通文件 d：目录 l：软连接 c：字符设备（鼠标，键盘） b：块文件（硬盘） rwxr–r–： 每三个依次表示所有者权限，所有组权限，其他组权限 r=4：读 在目录上表示可以读取，ls查看内容 w=2：写 不代表可以删除文件，删除文件的前提条件是该文件所在的目录有写权限 在目录上表示，可以在目录内创建+删除+重命名目录 x=1：执行 在目录上可以进入该目录 1 数字表示，如果是文件是硬链接的个数，如果是目录表示子目录的个数，不包括，子文件，包括.和.. 所有者 所有组 文件大小 如果是目录显 示4096 最后修改时间 文件名 修改权限chmod通过chmod，可以修改文件或目录的权限 第一种方式：+、-、=变更权限 u：所有者 g：所有组 o：其他人 a：所有人（ugo） chmod u=rwx,g=rx,o=x 文件目录名 chmod o+w chmod a-x 第二种方式：通过数字变更权限chmod 751 文件目录 相当于chmod u=rwx,g=rx,o=x 文件目录名 修改文件所有者chown newowner file 改变文件的所有者 chown newowner:newgroup file 改变用户的所有者和所有组 -R 如果是目录，所有目录和文件递归生效 修改文件所在组-chgrpchgrp newgroup file 改变文件的所有组 -R 如果是目录，所有目录和文件递归生效 任务调度crond 任务调度crondtab 进行定时任务的设置 系统工作：有些需要周而复始执行的重要工作（杀毒） 个别用户工作：个别用户希望执行某些程序（备份数据库） crontab [选项] -e ：编辑定时任务 -l：查询任务 -r：删除当前用户所有任务 （终止任务调度） service crond restart [重启任务调度] 简单任务，直接在crontab中加入任务即可，复杂的任务需要编写脚本 项目 含义 范围 第一个”*” 一小时当中的第几分钟 0-59 第二个”*” 一天当中的第几小时 0-23 第三个”*” 一个月当中的第几天 1-31 第四个”*” 一年当中的第几月 1-12 第五个”*” 一周当中的星期几 0-7 特殊符号 含义 * 代表任何时间，比如第一个*表示一小时中每分钟都执行一次 , 代表不连续的时间。比如”0,8,12,16 * * * 命令”，代表每天8点12点16点执行 - 代表连续的时间范围内。比如”0 5 * * 1-6命令”表示礼拜一到礼拜六，5点执行 */n 代表隔多久执行一次。比如”*/10 * * * * 命令”代表每隔十分钟执行一次 案例： 设置任务调度文件：/etc/crontab 设置个人任务调度。执行crontab -e 命令 接着输入任务到调度文件 如：* /1 * * * * ls -l /etc&gt;&gt;/tmp/to.txt 每分钟将ls的内容追加到to.txt内 应用实例案例1每隔1分钟，就将当前的日期信息，追加到 /tmp/mydate 文件中 先编写一个文件 /home/mytask1.sh date &gt;&gt; /tmp/mydate 给mytask1.sh一个执行权限 chmod 744 /home/mytask1.sh crontab -e */1 * * * * /home/mytask1.sh 成功 案例2每隔1分钟， 将当前日期和日历都追加到 /home/mycal 文件中 先编写一个文件 /home/mytask2.sh date &gt;&gt; /tmp/mycal cal &gt;&gt; /tmp/mycal 给mytask1.sh一个执行权限 chmod 744 /home/mytask2.sh crontab -e */1 * * * * /home/mytask2.sh 成功 案例3每天凌晨2:00 将mysql数据库 testdb ，备份到文件中。 先编写一个文件 /home/mytask3.sh /usr/local/mysql/bin/mysqldump -u root -proot testdb &gt; /tmp/mydb.bak 一般mysql位于/usr/local 给mytask1.sh一个执行权限 chmod 744 /home/mytask3.sh crontab -e 0 2 * * * /home/mytask2.sh 成功 磁盘与分区Linux无论有几个分区，分给哪个目录使用，归根结底只有一个根目录，一个独立且唯一的文件结构，每一个分区都会挂载到一个目录下，可以认为，这个目录是这个分区 mbr分区: 最多支持四个主分区 系统只能安装在主分区 扩展分区要占一个主分区 MBR最大只支持2TB，但拥有最好的兼容性 gtp分区: 支持无限多个主分区（但操作系统可能限制，比如 windows下最多128个分区） 最大支持18EB的大容量（1EB=1024 PB， 1PB=1024 TB ） windows7 64位以后支持gtp 硬盘基本上为SCSI ide硬盘表示为”hdx“，”hd”表明设备的类型，”x”表示盘号（a基本盘，b基本从属盘，c辅助主盘，d为辅助从属盘），”“代表分区，前四个分区（主分区，扩展分区）用1到4表示，4开始为逻辑分区，sd表示SCSI lsblk -f：查看分区和挂载和文件系统类型，还有对应的40位唯一标识UUID 如何为Linux增加一块硬盘 虚拟机添加硬盘 在虚拟机的设置里添加硬盘 分区 先重启 fdisk /dev/sdb 格式化 mkfs -t ext4 /dev/sdb1 挂载 先创建一个文件夹 然后将设备挂载到文件夹下 mount /dev/sdb1 文件夹 开机就没了 卸载：umount 设备名称 或者 挂载目录 设置自动挂载（永久挂载） vim /etc/fstab 复制一份将uuid改成设备名 mount -a 磁盘情况查询 df -lh：查询系统整体磁盘使用情况 du -h /目录：查询指定目录磁盘占用情况 -s 指定目录占用大小汇总 -h 带计量单位 -a 含文件 -max-depth=1 子目录深度 -c 列出明细的同时，也列出汇总值 案例操作 统计home文件夹下文件个数 ls -l /home | grep “^-“ | wc -l 目录个数：ls -l /home | grep “^d” | wc -l 包括子文件夹下，所有目录个数： ls -lR /home | grep “^-“ | wc -l 以树状显示 tree [/目录]：默认本地目录 网络配置端口分类 0号保留端口 1-1024是固定端口 22：SSH远程登陆协议 23：telnet使用 21：ftp 25：smtp 80：iis 7：echo 1025-65535是动态端口 端口使用注意 尽量少开端口 一个端口只能被一个程序监听 netstat -an可以查看本机有哪些端口在监听 nestat -anb这些监听端口的pid 虚拟网络编辑器虚拟机的网络编辑器，可在内修改ip地址、 查看网关虚拟机的网络编辑器，点NAT设置查看 查看ip ipconfig 在windows中VMware8网卡中查看 通过ping 目标ip可以查看是否联网 配置网络自动连接直接修改配置文件来指定IP，并可以连接到外网(程序员推荐) 编辑 vim /etc/sysconfig/network-scripts/ifcfg-eth0 要求：将ip地址配置的静态的， ip地址为192.168.184.130 12345678910111213141516老师配置DEVICE=eth0 #接口名（设备,网卡）HWADDR=00:0C:2x:6x:0x:xx #MAC地址TYPE=Ethernet #网络类型（通常是Ethemet）UUID=926a57ba-92c6-4231-bacb-f27e5e6a9f44 #随机id#系统启动的时候网络接口是否有效（yes/no）ONBOOT=yes# 以下重点配置# IP的配置方法[none|static|bootp|dhcp]（引导时不使用协议|静态分配IP|BOOTP协议|DHCP协议）BOOTPROTO=static#IP地址IPADDR=192.168.184.130#网关GATEWAY=192.168.184.2#域名解析器DNS1=192.168.184.2 12345678910111213141516171819202122# 我的配置DEVICE=eth0TYPE=EthernetUUID=6b3609a3-f909-4f21-a1ee-0bc35b4cf3cdONBOOT=yesNM_CONTROLLED=yes# 静态网络BOOTPROTO=staticHWADDR=00:0C:29:40:90:09DEFROUTE=yesPEERDNS=yes# ip地址IPADDR=192.168.172.130# 网关GATEWAY=192.168.172.2# 域名解析器DNS1=192.168.172.2PEERROUTES=yesIPV4_FAILURE_FATAL=yesIPV6INIT=noNAME=\"System eth0\"LAST_CONNECT=1563404397 生效： 重启网络服务：service network restart 重启：reboot 进程管理进程的基本介绍 在LINUX中，每个执行的程序（代码） 都称为一个进程。每一个进程都分配一个ID号。 每一个进程，都会对应一个父进程，而这个父进程可以复制多个子进程。例如www服务器。 每个进程都可能以两种方式存在的。 前台与后台，所谓前台进程就是用户目前的屏幕上可以进行操作的。后台进程则是实际在操作，但由于屏幕上无法看到的进程，通常使用后台方式执行。 一般系统的服务都是以后台进程的方式存在，而且都会常驻在系统中。直到关机才才结束。 显示系统执行的进程 ps 查看目前系统中，进程情况 -a ：显示当前终端所有进程信息 -u：以用户格式显示进程数 -x：显示后台进程运行的参数 -ef：显示f全格式e所有进程可以显示父进程（ppid） 字段 说明 USER 用户名，进程是哪个用户执行的 PID 进程识别号 PPID 父进程 CPU 当前进程占用cpu情况 MEM 占用内存情况 VSZ 占用虚拟内存情况 RSS 使用物理内存情况 TTY 终端机号 STAT 进程状态。s：该进程是绘画的先导进程 S：休眠 R：正在运行 D：短期等待 Z：僵死进程 T：被跟踪或被停止登台 N：此进程比普通优先级更低的优先级 START 开始运行时间 TIME 此进程所消CPU时间 COMMAND 进程执行时的命令行，如果过长会被截断显示 CMD 正在持续的命令或进程名 终止进程 kill [选项] 进程号：杀死进程 -9：强制杀死 killall 进程名称：杀死进程，支持通配符 -9：强制杀死 pstree [选项] ：树状显示查看进程 -p：显示进程PID -u：显示进程所属用户 服务管理简介服务(service) 本质就是进程，但是是运行在后台的，通常都会监听某个端口，等待其它程序的请求，比如(mysql , sshd 防火墙等)，因此我们又称为守护进程，是Linux中非常重要的知识点。 service 服务名 [start | stop | restart | reload | status] 在CentOS7.0后 不再使用service ,而是systemctl 查看防火墙状况，关闭和重启防火墙 service iptables status service iptables stop service iptables restart 检测防火墙在win的dos下telnet ip地址 端口 setup ： 查看服务 打*表示开机自启动 在/etc/init.d ：查看服务 ls -l /etc/init.d/ 修改默认运行级别：vim /etc/inittab Linux系统有7种运行级别(runlevel)： 常用的是级别3和5 运行级别0： 系统停机状态，系统默认运行级别不能设为0，否则不能正常启动 运行级别1： 单用户工作状态， root权限，用于系统维护，禁止远程登陆 运行级别2： 多用户状态(没有NFS)，不支持网络 运行级别3： 完全的多用户状态(有NFS)，登陆后进入控制台命令行模式 运行级别4： 系统未使用，保留 运行级别5： X11控制台，登陆后进入图形GUI模式 运行级别6： 系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动 chkconfig 命令可以给各个运行己别设置自启动/关闭 查看网络服务 chkconfig –list | grep xxx chkconfig 服务名 –list chkconfig –level 5 服务名 on/off 在运行级别5下开/关自启动服务 在所有运行级别下，开启关闭，则不需要加–level 5 动态监控进程 top [选项]：和ps很像，但是会自动更新进程信息 -d 秒数 ：指定top命令每隔几秒更新。 默认是3秒在top命令的交互模式当中可以执行的命令： -i：使top不显示任何闲置或者僵死进程。 -p：通过指定监控进程ID来仅仅监控某个进程的状态。 操作 功能 P 以CPU使用率排序， 默认就是此项 M 以内存的使用率排序 N 以PID排序 q 退出top 案例 案例1.监视特定用户top：输入此命令，按回车键，查看执行的进程。u：然后输入“u”回车，再输入用户名，即可 案例2： 终止指定的进程。top：输入此命令，按回车键，查看执行的进程。k：然后输入“k”回车，再输入要结束的进程ID号 案例3:指定系统状态更新的时间(每隔10秒自动更新)： top -d 10 12345678910# 当前时间 运行时间 系统用户数 负载均衡：平均值超过0.7要注意 top - 08:26:00 up 1 min, 2 users, load average: 0.42, 0.14, 0.05#任务 总任务 在跑的 睡眠的 停止的 僵持的Tasks: 201 total, 1 running, 200 sleeping, 0 stopped, 0 zombie#cpu占用量 用户占 系统占 空闲Cpu(s): 0.9%us, 0.6%sy, 0.0%ni, 98.5%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%st#内存使用情况 总的 使用了 空闲的 Mem: 2038376k total, 648708k used, 1389668k free, 34136k buffers#虚拟分区使用情况Swap: 2097148k total, 0k used, 2097148k free, 217888k cached 网络监控 netstat [选项]:查看网络情况（一般用-anp | more） -an：按一定顺序排序输出 -p：显示哪个进程在调用 安装rpm包管理一种用于互联网下载包的打包及安装工具，它包含在某些Linux分发版中。它生成具有.RPM扩展名的文件。 RPM是RedHat Package Manager（RedHat软件包管理工具）的缩写，类似windows的setup.exe，这一文件格式名称虽然打上了RedHat的标志，但理念是通用的。Linux的分发版本都有采用（suse,redhat, centos 等等），可以算是公认的行业标准了。 rpm包的查询 rpm包的简单查询指令：查询已安装的rpm列表 rpm –qa|grep xx rpm包名基本格式：一个rpm包名： firefox-45.0.1-1.el6.centos.x86_64.rpm名称:firefox版本号： 45.0.1-1适用操作系统: el6.centos.x86_64表示centos6.x的64位系统如果是i686、 i386表示32位系统， noarch表示通用。。 rpm包的其它查询指令： rpm -qa :查询所安装的所有rpm软件包 rpm -qa | more rpm -qa | grep X [rpm -qa | grep firefox ] rpm -q 软件包名 :查询软件包是否安装 rpm -q firefox rpm -qi 软件包名 ：查询软件包信息 rpm -qi file rpm -ql 软件包名 :查询软件包中的文件 rpm -ql firefox rpm -qf 文件全路径名 查询文件所属的软件包 rpm -qf /etc/passwd rpm -qf /root/install.log rpm包的卸载 rpm -e RPM包的名称 应用案例 删除firefox 软件包 细节讨论1) 如果其它软件包依赖于您要卸载的软件包，卸载时则会产生错误信息。如： rpm -e fooremoving these packages would break dependencies:foo is needed by bar-1.0-12) 如果我们就是要删除 foo这个rpm 包，可以增加参数 –nodeps ,就可以强制删除，但是一般不推荐这样做， 因为依赖于该软件包的程序可能无法运行如： rpm -e –nodeps foo rpm包的安装 rpm -ivh RPM包全路径名称 i=install 安装 v=verbose 提示 h=hash 进度条 需要挂载安装光驱，然后到/media下寻找，再进入光驱，再进去packages 演示卸载和安装firefox浏览器yum包管理Yum 是一个Shell前端软件包管理器。基于RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系， 并且一次安装所有依赖的软件包。 指令 查询yum服务器是否有需要安装的软件yum list|grep xx软件列表 安装指定的yum包yum install xxx 下载安装 补充知识&gt;/dev/null 2&gt;&amp;1 1为system.out 2为system.error 默认滴。这条语句是将1（不写默认是1）输出到/dev/null下，2的输出和1一样 ssh时候，/etc/profile中环境变量失效。会使用~目录下的.bashrc，可以使用cat /etc/profile &gt;&gt; ~/.bashrc 非root权限，只能使用1024以上的端口号","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"}]}],"categories":[],"tags":[{"name":"后端","slug":"后端","permalink":"http://example.com/tags/%E5%90%8E%E7%AB%AF/"},{"name":"redis","slug":"redis","permalink":"http://example.com/tags/redis/"},{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"并发编程","slug":"并发编程","permalink":"http://example.com/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"JVM","slug":"JVM","permalink":"http://example.com/tags/JVM/"},{"name":"爬虫","slug":"爬虫","permalink":"http://example.com/tags/%E7%88%AC%E8%99%AB/"},{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"git","slug":"git","permalink":"http://example.com/tags/git/"},{"name":"marjora","slug":"marjora","permalink":"http://example.com/tags/marjora/"},{"name":"virtualbox","slug":"virtualbox","permalink":"http://example.com/tags/virtualbox/"},{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"},{"name":"数据结构","slug":"数据结构","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"spring","slug":"spring","permalink":"http://example.com/tags/spring/"},{"name":"springsecurity","slug":"springsecurity","permalink":"http://example.com/tags/springsecurity/"},{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"},{"name":"php","slug":"php","permalink":"http://example.com/tags/php/"},{"name":"wordpress","slug":"wordpress","permalink":"http://example.com/tags/wordpress/"},{"name":"大数据","slug":"大数据","permalink":"http://example.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"PHP","slug":"PHP","permalink":"http://example.com/tags/PHP/"},{"name":"Spark","slug":"Spark","permalink":"http://example.com/tags/Spark/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"http://example.com/tags/Shell/"},{"name":"Flink","slug":"Flink","permalink":"http://example.com/tags/Flink/"},{"name":"nosql","slug":"nosql","permalink":"http://example.com/tags/nosql/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://example.com/tags/elasticsearch/"},{"name":"服务器","slug":"服务器","permalink":"http://example.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"前端","slug":"前端","permalink":"http://example.com/tags/%E5%89%8D%E7%AB%AF/"},{"name":"Vue","slug":"Vue","permalink":"http://example.com/tags/Vue/"},{"name":"SQL","slug":"SQL","permalink":"http://example.com/tags/SQL/"},{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"},{"name":"scala","slug":"scala","permalink":"http://example.com/tags/scala/"},{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Scala","slug":"Scala","permalink":"http://example.com/tags/Scala/"},{"name":"并发","slug":"并发","permalink":"http://example.com/tags/%E5%B9%B6%E5%8F%91/"},{"name":"maven","slug":"maven","permalink":"http://example.com/tags/maven/"},{"name":"bug","slug":"bug","permalink":"http://example.com/tags/bug/"},{"name":"流程","slug":"流程","permalink":"http://example.com/tags/%E6%B5%81%E7%A8%8B/"},{"name":"开发","slug":"开发","permalink":"http://example.com/tags/%E5%BC%80%E5%8F%91/"},{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"博客","slug":"博客","permalink":"http://example.com/tags/%E5%8D%9A%E5%AE%A2/"}]}